{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1535004740000},{"_id":"source/baidu_verify_UTA2I8PqMM.html","hash":"2b50f3d023310d4798d685d2f19c834347b488ea","modified":1535078035000},{"_id":"themes/next/.git","hash":"042ff34da0707513a5681580b37513c890c671ef","modified":1527409906000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1527409906000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1527409906000},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1527409906000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1527409906000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1527409906000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1527409906000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1527409906000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1527409906000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1527409906000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1527409906000},{"_id":"themes/next/README.cn.md","hash":"2c766b3369ed477bce134a5450dab45bef161504","modified":1527409906000},{"_id":"themes/next/README.md","hash":"8ce60ce578963eb4e1eb5e33e1efc2fc4779af9c","modified":1527409906000},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1527409906000},{"_id":"themes/next/_config.yml","hash":"56c30939d99bed309bf3a1146f1854768ae15eac","modified":1535001916000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1527409906000},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1527409907000},{"_id":"source/_posts/201805-git-guide-for-freshman.md","hash":"b74b3a054acfef63d6598e6188df5c79a6edf5d4","modified":1533054887000},{"_id":"source/_posts/201805-hexo-blog-system-guide.md","hash":"fa275c2ebc22d1cc6ea60bf3916c754890a14c11","modified":1527411798000},{"_id":"source/_posts/201805-hexo-transfer.md","hash":"077eeb9697c582475ea2a75d0d9b8152debdc72d","modified":1527425577000},{"_id":"source/_posts/201805-linux-command-line-and-iterm-use-guide.md","hash":"258ce134938faf2bf8796c6aed5bf10611cccde0","modified":1527751606000},{"_id":"source/_posts/201805-scala-array-list-tuple-and-so-on.md","hash":"a6227d1ad85d2ae2a2937eda35c7c3ee5be98416","modified":1529722488000},{"_id":"source/_posts/201805-tensorflow-flags-guide.md","hash":"5b0635802cc3f18b2af7f730ad6584bb3fbbf940","modified":1527524233000},{"_id":"source/_posts/201805-vim-guide.md","hash":"75a50e288165f34a90bb61909e4a63595b38331e","modified":1533052349000},{"_id":"source/_posts/201806-google-deep-and-cross.md","hash":"54e434eaa3ca6b41ff34a61d953be26f7578c915","modified":1530065511000},{"_id":"source/_posts/201806-google-wide-and-deep-network.md","hash":"1cf8e807cbae9e57d4bab33a715510c34a8f6302","modified":1528095195000},{"_id":"source/_posts/201806-recommemder-alg-introduction.md","hash":"ed771de55ac90c24b10247eecce463bd036a4ff1","modified":1535076792000},{"_id":"source/_posts/201806-recommender-and-ads-algs.md","hash":"52c251d4f11d6328cd246e5aa255245304f29eb3","modified":1534997671000},{"_id":"source/_posts/201806-tensorflow-and-onlinelearning.md","hash":"5cd9ae75bb3f022efd697d922f41d0e22bc4149b","modified":1529716002000},{"_id":"source/_posts/201806-tensorflow-data-generation.md","hash":"57e229541b0828b8ba488cb7705b2e3890b99b81","modified":1528014899000},{"_id":"source/_posts/201806-tensorflow-loss-and-regularizer.md","hash":"08d45b1b7917a418c9bdf2ad71c32d3193f5adc1","modified":1528013358000},{"_id":"source/_posts/201806-tensorflow-embedding-lookup-sparse.md","hash":"ae2a7bc563dabfe1aaac6efcc32291b0e4876694","modified":1527922008000},{"_id":"source/_posts/201806-vscode-shortcuts.md","hash":"6cdc1ec27792f47476315126e2021e55287a8aaf","modified":1528906421000},{"_id":"source/_posts/201807-factory-model-in-cpp-programming.md","hash":"b4373cc19728f04e9613577044c4ae618e3da8fc","modified":1531153509000},{"_id":"source/_posts/201807-hadoop-common-warn-and-error.md","hash":"12ffd426e9566208cca44afad6bf9c362d603a2f","modified":1532005076000},{"_id":"source/_posts/201807-hadoop-experience.md","hash":"e464edaf90dd8885ea0828024ffb530c5549444e","modified":1533052221000},{"_id":"source/_posts/201807-math-in-machine-learning.md","hash":"4d57486f5ae58c5c3b87d9324ed56c0e5f6ae7dd","modified":1533052224000},{"_id":"source/_posts/201807-magic-machine-leaning-feature-engineering.md","hash":"d43a9bda1e8bcf5706d9a06a3ba0ad44262bbf71","modified":1532006586000},{"_id":"source/_posts/201807-meituan-ads-deep-learning.md","hash":"c37720359e0e514ec173f2455d704908003af88e","modified":1531153472000},{"_id":"source/_posts/201807-scons-cpp-sconstruct-tool.md","hash":"6fbfb8280b137aaac44f1818a8ad6e3b60e1e33f","modified":1532918714000},{"_id":"source/_posts/201807-tensorflow-spacial-API.md","hash":"2bce8ad53e34db7aa85a5546a4d09f63a20eb2b0","modified":1532314457000},{"_id":"source/_posts/201807-shell-script-guide.md","hash":"85263493d38e65e1709f3741e0b1a7074d576f29","modified":1534827142000},{"_id":"source/_posts/201807-spark-common-error-in-development.md","hash":"ef541a95866fe396ffc29a1b6e0afb688e033b96","modified":1533832995000},{"_id":"source/_posts/201808-alg-tree-traversal.md","hash":"686368161868ce10c55d5aa691b77b22a9684d52","modified":1533749791000},{"_id":"source/_posts/201808-happy-python.md","hash":"6fb5f3deb60b5e0bcdd29caea2d5fd8c81c408f2","modified":1533833290000},{"_id":"source/_posts/201808-lightgbm-and-I-dont-know-everything.md","hash":"822087cd38cd31b044c846aeb938db94844add74","modified":1533209012000},{"_id":"source/_posts/201808-online-ads-basics.md","hash":"9d1716d755fb3b0f633c1c7c557b5eb93c5a168a","modified":1533185688000},{"_id":"source/_posts/201808-pyspark-easy-lookup.md","hash":"ba929f9e630bc4a3f3a0529ab49aa69189184957","modified":1533835117000},{"_id":"source/_posts/201808-python-pandas-guide.md","hash":"a2f9f813d67089e3c0ab44f1b52f066466204dd8","modified":1535077529000},{"_id":"source/_posts/201808-python-string-handle.md","hash":"4c6cb659cf3bcb6df53ae33e6a86315d5da4a8cd","modified":1533456158000},{"_id":"source/_posts/201808-recommender-algorithm-fm-alg.md","hash":"665fcb056122f8fdc5a94b60e87b09f13e3b3890","modified":1535009159000},{"_id":"source/_posts/201808-spark-guide.md","hash":"e7e7830e686f1366d3d368fc853588a5b4e1b14a","modified":1534827146000},{"_id":"source/_posts/201808-spark-sql.md","hash":"574f73719ba87da97edd9635d364070e34211d5a","modified":1534827147000},{"_id":"source/_posts/201808-spark-parameters-balance.md","hash":"1bafda922c71a9399b96514268ac4d1b2ee8349d","modified":1534827143000},{"_id":"source/_posts/201808-time-parse-in-every-script.md","hash":"2c469d1d8a5b63ba56362b1a6bee3ca832c73a76","modified":1534827148000},{"_id":"source/about/index.md","hash":"6ed6c829266fada5d75f7f060f32e7dd872ee8f5","modified":1533054342000},{"_id":"source/categories/index.md","hash":"2b0a4f6cfd3ccb4498701b3fa5ebdf5266227a89","modified":1533054469000},{"_id":"source/tags/index.md","hash":"c92f1609fff580b7f492f377173daa412760c876","modified":1533054751000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1527409906000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"50d48c47162817a3810a9d9ad51104e83947419a","modified":1527409906000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1527409906000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1527409906000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1527409906000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1527409906000},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1535001534000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1527409906000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1527409906000},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1527409906000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1527409906000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1527409906000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1527409906000},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1527409906000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1527409906000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1527409906000},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1527409906000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1535001538000},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1527409906000},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1527409906000},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1527409906000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1527409907000},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1527409907000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1527409907000},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1527409907000},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1527409907000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1527409907000},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1527409907000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1527409907000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1527409907000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1527409907000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1527409907000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1527409907000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1527409907000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1527409906000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1527409906000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1527409906000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1527409906000},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1527409906000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1527409906000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1527409906000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1527409906000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1535001744000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1527409906000},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1535001730000},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1527409906000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1527409906000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1527409906000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1527409906000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1527409906000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1527409906000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1527409906000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1527409906000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1527409906000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1527409906000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1527409906000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1527409906000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1527409906000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1527409906000},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1527409907000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1527409907000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1527409907000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1527409907000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1527409907000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1527409907000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1527409907000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1527409907000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1527409907000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1527409907000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1527409907000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1527409907000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1527409907000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1527409907000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1527409907000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1527409907000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1527409907000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1527409907000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1527409907000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1527409907000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1527409907000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1527409907000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1527409907000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1527409907000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1527409907000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1527409907000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1527409907000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1527409907000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1527409906000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1527409906000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1527409907000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1527409907000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1527409907000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1527409907000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1527409907000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1527409906000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1527409906000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1527409906000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1527409906000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1527409906000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1527409906000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1527409906000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1527409906000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1527409906000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1527409906000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1527409906000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1527409906000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1527409906000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1527409906000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1527409906000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1527409906000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1527409906000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1527409906000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1527409906000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1527409906000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1527409906000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1527409906000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1527409906000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1527409907000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1527409907000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1527409907000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1527409907000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1527409907000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1527409907000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1527409907000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1527409907000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1527409907000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1527409907000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1527409907000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1527409907000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1527409907000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1527409907000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1527409907000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1527409907000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1527409907000},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1527409907000},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1527409907000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1527409907000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1527409907000},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1527409907000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1527409907000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1527409907000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1527409907000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1527409907000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1527409907000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1527409907000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1527409907000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1527409907000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1527409907000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1527409907000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1527409907000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1527409907000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1527409907000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1527409907000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1527409907000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1527409907000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1527409907000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1527409907000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1527409907000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1527409907000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1527409907000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1527409907000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1527409907000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1527409907000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1527409907000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1527409907000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1527409907000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1527409906000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1527409906000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1527409907000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1527409907000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1527409907000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1527409907000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1527409907000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1527409907000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1527409907000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1527409907000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1527409907000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1527409907000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1527409907000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1527409907000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1527409907000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1527409907000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1527409907000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1527409907000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1527409907000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1527409907000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1527409907000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1527409907000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1527409907000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1527409907000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1527409907000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1527409907000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1527409907000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1527409907000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1527409907000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1527409907000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1527409907000},{"_id":"public/baidu_verify_UTA2I8PqMM.html","hash":"4fecf3d6f657ca362a844841d0723912f2152f8c","modified":1535435259133},{"_id":"public/baidusitemap.xml","hash":"0a9972dc8ba22934c217dd5425594a7f99769dc8","modified":1535435259155},{"_id":"public/sitemap.xml","hash":"1f3b153dd8acb2bfd09582620e921b2ae7150b94","modified":1535435259156},{"_id":"public/about/index.html","hash":"7617854a9b2cfdb5dba3f6907686dad8f5ad6631","modified":1535435259266},{"_id":"public/categories/index.html","hash":"e83a4cc915026bada13c5da3086c24f41c10fc86","modified":1535435259266},{"_id":"public/tags/index.html","hash":"e5b1b7ed462e86be1867ee6972171a004986a1da","modified":1535435259266},{"_id":"public/2018/08/10/spark-sql/index.html","hash":"da61dd19b4df02f7ddd8308c5f8ae8dcc1690036","modified":1535435259266},{"_id":"public/2018/07/31/hadoop-experience/index.html","hash":"7294398e450c5c28110db57225afdeae15b5eb12","modified":1535435259267},{"_id":"public/2018/07/20/tensorflow-spacial-API/index.html","hash":"7de804bd11cea8b83ddeeced8827037be1a673b3","modified":1535435259267},{"_id":"public/2018/07/19/magic-machine-leaning-feature-engineering/index.html","hash":"c8e43f4d3a55fcb93a1eed39e9b1865e43ae21d8","modified":1535435259267},{"_id":"public/2018/06/03/google-deep-and-cross/index.html","hash":"185fc3d763efdf0a96d0e28e7872ed3ff2d53406","modified":1535435259267},{"_id":"public/2018/05/27/hexo-transfer/index.html","hash":"4d128fddb12f48067f37375fbb043fd123e36e6b","modified":1535435259268},{"_id":"public/archives/2018/08/page/2/index.html","hash":"e9c4f17df57ccb013c6401f03305137bfaca771e","modified":1535435259268},{"_id":"public/categories/工具箱/index.html","hash":"11028a509985532336cb96104e203700ec99691e","modified":1535435259268},{"_id":"public/categories/推荐系统算法/index.html","hash":"689a6d28832d6eea7b0e99e5427fc195a9b49eb5","modified":1535435259268},{"_id":"public/categories/算法/index.html","hash":"f463d502fac9091081f6bd5173cba0c3b23287b2","modified":1535435259269},{"_id":"public/categories/python/index.html","hash":"7dfce2808cd43a9638f24e2b6fc26b1b62654beb","modified":1535435259269},{"_id":"public/categories/计算广告/index.html","hash":"68e6e80442e486dc153505c9c9189a26ccca6c8e","modified":1535435259269},{"_id":"public/categories/spark/index.html","hash":"e6a63077b32f29e82f1c05326c5792103e7d172b","modified":1535435259269},{"_id":"public/categories/推荐系统/index.html","hash":"af8bdb0b2a97a2c368fee65aa1ee755b892b16e6","modified":1535435259269},{"_id":"public/categories/珍惜时间/index.html","hash":"a8afe3c8efa9c52e21add7ba66c8a842c0d963cb","modified":1535435259269},{"_id":"public/tags/git/index.html","hash":"7142adff848115dca1dd82a34fa15322c1a423aa","modified":1535435259270},{"_id":"public/tags/linux-command-line-iterms-shortcut/index.html","hash":"6e20396df73754e97044348ddbf571ba4c311771","modified":1535435259270},{"_id":"public/tags/Linux-vim/index.html","hash":"fbafb4065e790d05098c997fc1e04bbe97c56554","modified":1535435259270},{"_id":"public/tags/推荐系统/index.html","hash":"1fb9d3281f9509b7aa1895fc0af9d9fcfdad5ce9","modified":1535435259270},{"_id":"public/tags/计算广告/index.html","hash":"4d37deec4fceb22b466120c5623ec7eb2dd77d1b","modified":1535435259270},{"_id":"public/tags/tensorflow-onlinelearning-在线学习/index.html","hash":"45f5b33f42bd727b6623e09e7f82672413ad6a78","modified":1535435259270},{"_id":"public/tags/embedding-lookup-tf-gather-embedding-lookup-sparse/index.html","hash":"2581633d044c791888b14022db3390e1d13c97f6","modified":1535435259270},{"_id":"public/tags/vscode-shortcut-mac-os/index.html","hash":"ea5fae7adbc112393f0144d5751845f19b5eb5c3","modified":1535435259270},{"_id":"public/tags/设计模式-工程模式-代码-宏定义/index.html","hash":"a11f67e90c1df396e77fd136ebf599a346abcc21","modified":1535435259270},{"_id":"public/tags/shell/index.html","hash":"8e0018048097f39bca70a37e6c9aec08f40c89eb","modified":1535435259270},{"_id":"public/tags/脚本/index.html","hash":"176a12f4fd1dc763f5554166b35dfdbbd3cec544","modified":1535435259271},{"_id":"public/tags/树遍历/index.html","hash":"24170d0e659a52df41fbb5e4636dc43c4d840004","modified":1535435259271},{"_id":"public/tags/树算法/index.html","hash":"2c41f8c4a910475370b50d2d1ecb69c73571d7d2","modified":1535435259271},{"_id":"public/tags/算法/index.html","hash":"365898867398e0cd839b56b8e0747234395ff58f","modified":1535435259271},{"_id":"public/tags/python/index.html","hash":"0d7dbd76437e71d79399177b34389379449ce8c1","modified":1535435259271},{"_id":"public/tags/happy/index.html","hash":"e000801650befe81a7bd728bf0bbbb42dca954f7","modified":1535435259271},{"_id":"public/tags/gg/index.html","hash":"fbbf6c38c3f700692a986309fa528cd816ebb3a7","modified":1535435259271},{"_id":"public/tags/pyspark/index.html","hash":"9dc2e0ad1cca04a004b8fc80d19bbbb166ed6e3a","modified":1535435259271},{"_id":"public/tags/大数据/index.html","hash":"4ec70de5d54765822d95e49a90964ffe50f6d046","modified":1535435259272},{"_id":"public/tags/工具箱/index.html","hash":"5093bbd58eea07206e17d09d06aadd9b8a6b983f","modified":1535435259272},{"_id":"public/tags/spark/index.html","hash":"7715449dc1a16ed5a3c33c1d058a0f9928deaa4f","modified":1535435259272},{"_id":"public/tags/time/index.html","hash":"09e4b2884a8c415ec6dd77f8ba3a5a5963320bcc","modified":1535435259272},{"_id":"public/tags/datetime/index.html","hash":"5923ed0c53675b19a663540bd9c18a0d885900a4","modified":1535435259272},{"_id":"public/baidu_urls.txt","hash":"c1ac8cbb35f1e9c977d23edf447aa18e3e23006c","modified":1535435259272},{"_id":"public/2018/08/23/recommender-algorithm-fm-alg/index.html","hash":"47b9eade6d7d261024c2bc369b51d79d6c71d515","modified":1535435259272},{"_id":"public/2018/08/24/python-pandas-guide/index.html","hash":"79eeb67807899c048f59fb0e1b82a117019a16ea","modified":1535435259272},{"_id":"public/2018/08/21/spark-guide/index.html","hash":"8c5e5508d0b64863c0f55d770e41b3e0b433d2e6","modified":1535435259273},{"_id":"public/2018/08/10/time-parse-in-every-script/index.html","hash":"299c37df24c1be2de0a30c21ba7b974dd14fae11","modified":1535435259273},{"_id":"public/2018/08/10/spark-parameters-balance/index.html","hash":"ca6e7f3c43d04b4b0333e9156629a9e4692631ec","modified":1535435259273},{"_id":"public/2018/08/09/happy-python/index.html","hash":"abc3a09b17f4649ed67ec8840c3cc0cdc35dbbcc","modified":1535435259273},{"_id":"public/2018/08/08/alg-tree-traversal/index.html","hash":"1336c50a23878f84493b43d867c76a98b6dac8ee","modified":1535435259273},{"_id":"public/2018/08/02/pyspark-easy-lookup/index.html","hash":"f6c1cc4c41744f14b4d8e3d4e1019b134bd6b0f1","modified":1535435259273},{"_id":"public/2018/08/02/lightgbm-and-I-dont-know-everything/index.html","hash":"5086e4ad21deca9402b602cada2dd42b1f42dc60","modified":1535435259273},{"_id":"public/2018/08/01/online-ads-basics/index.html","hash":"4274df3cf3a5058e4bec928721411364909d3c20","modified":1535435259273},{"_id":"public/2018/08/01/python-string-handle/index.html","hash":"051b72a31d5df93ddb3cda00da937368600583b0","modified":1535435259274},{"_id":"public/2018/07/31/math-in-machine-learning/index.html","hash":"8d418e41b78ce97821a0ce84b66ba7d22ed8107b","modified":1535435259274},{"_id":"public/2018/07/30/shell-script-guide/index.html","hash":"bd4153c7f8607666b929d565fc041c524d1bc57b","modified":1535435259274},{"_id":"public/2018/07/30/spark-common-error-in-development/index.html","hash":"eb4e2e4890c8bdd1fb1e9df40aab6718794e35b3","modified":1535435259274},{"_id":"public/2018/07/19/hadoop-common-warn-and-error/index.html","hash":"62a8dee5dcc0f80bfc9386478659704f87f1fe09","modified":1535435259274},{"_id":"public/2018/07/10/scons-cpp-sconstruct-tool/index.html","hash":"f33c932f7a98c8d79ec98f3844f99caef5021a28","modified":1535435259274},{"_id":"public/2018/07/09/meituan-ads-deep-learning/index.html","hash":"682b106bb01dfdd67b523ad8e8a7fab0fc42d581","modified":1535435259274},{"_id":"public/2018/07/07/factory-model-in-cpp-programming/index.html","hash":"2967aac77f2e38f2a917abcaf36d3ddb31aa4642","modified":1535435259274},{"_id":"public/2018/06/24/recommender-and-ads-algs/index.html","hash":"1b7e7b78057cd8d2feb7febd54b25de22190232b","modified":1535435259274},{"_id":"public/2018/06/23/tensorflow-and-onlinelearning/index.html","hash":"36ad6f66ae32a7747b263164badda7aa92687ee2","modified":1535435259274},{"_id":"public/2018/06/13/vscode-shortcuts/index.html","hash":"e770b20faaadac7fee25c8ed498e19254a8a1f27","modified":1535435259274},{"_id":"public/2018/06/03/tensorflow-data-generation/index.html","hash":"a93c6516ed9c953b95c57225bdfa4fabb2c73328","modified":1535435259274},{"_id":"public/2018/06/03/tensorflow-loss-and-regularizer/index.html","hash":"f1969f0975a031a1cd0c6fc4cb58aa5c9fbe9ad9","modified":1535435259275},{"_id":"public/2018/06/03/recommemder-alg-introduction/index.html","hash":"2131cc97ab1a872a3ca690738d0b8097372a9eb8","modified":1535435259275},{"_id":"public/2018/06/02/google-wide-and-deep-network/index.html","hash":"ff045afa3ec4a06dee04bc104306d30cdf12e2e4","modified":1535435259275},{"_id":"public/2018/06/01/tensorflow-embedding-lookup-sparse/index.html","hash":"7c13fcee72adcd675083a6d35eb6044632417418","modified":1535435259275},{"_id":"public/2018/05/31/linux-command-line-and-iterm-use-guide/index.html","hash":"a9bda637d233c7dc860d80aa57875ac70a97faad","modified":1535435259275},{"_id":"public/2018/05/21/tensorflow-flags-guide/index.html","hash":"41ddc2c129e45390b8b0322460eb1b6588a3dac4","modified":1535435259275},{"_id":"public/2018/05/20/scala-array-list-tuple-and-so-on/index.html","hash":"c0fc0eade2308f3e9b4d605298425a8a0d8a2df2","modified":1535435259275},{"_id":"public/2018/05/20/vim-guide/index.html","hash":"1e142c758739d77d94db50f595f7d7544bec4b84","modified":1535435259275},{"_id":"public/2018/05/18/hexo-blog-system-guide/index.html","hash":"8c481da15b60b145f8903ea86f4653b7cd55a495","modified":1535435259275},{"_id":"public/2018/05/18/git-guide-for-freshman/index.html","hash":"0c8f0f26cf2da2c5e104951f63a4499731625567","modified":1535435259275},{"_id":"public/archives/index.html","hash":"b4fdf6e1fcefcaa966b0d08e38c5f48aaab4a99d","modified":1535435259275},{"_id":"public/archives/page/2/index.html","hash":"338ac878b5d9764fb453d07846d1c0ef081ce264","modified":1535435259275},{"_id":"public/archives/page/3/index.html","hash":"221aaaa0aed58b08d8c17686b7c6e5727240fc87","modified":1535435259275},{"_id":"public/archives/page/4/index.html","hash":"9e961c24a8671ca2fdba6ed1a06ad9e9a0db26dd","modified":1535435259275},{"_id":"public/archives/2018/index.html","hash":"90e9d53579828f69151dfb30a985f0dd13aa516b","modified":1535435259276},{"_id":"public/archives/2018/page/2/index.html","hash":"094bbd06f516dffca839df3a5bd6c45404723aa5","modified":1535435259276},{"_id":"public/archives/2018/page/3/index.html","hash":"3d937a77238829a88f9fb762b9ac826aa8c26733","modified":1535435259276},{"_id":"public/archives/2018/page/4/index.html","hash":"1675ae992ae5751695664dd5ded24277449a7dff","modified":1535435259276},{"_id":"public/archives/2018/05/index.html","hash":"6e17661f26be8d385a5c59a16051b50334cf67ee","modified":1535435259276},{"_id":"public/archives/2018/06/index.html","hash":"9f35f924e692a36a8a5f483ce2e0af6d2230376f","modified":1535435259276},{"_id":"public/archives/2018/07/index.html","hash":"849bea71f09a034cb60a183c17d097dc792aba0f","modified":1535435259276},{"_id":"public/archives/2018/08/index.html","hash":"b54506a9a6d2e081fceaf5d914e35fbf4f559b77","modified":1535435259276},{"_id":"public/index.html","hash":"77228077cea78e83cec69a8c5503845976a2d9bf","modified":1535435259276},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1535435259304},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1535435259304},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1535435259305},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1535435259305},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1535435259305},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1535435259305},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1535435259305},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1535435259305},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1535435259305},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1535435259305},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1535435259305},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1535435259306},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1535435259306},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1535435259306},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1535435259306},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1535435259306},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1535435259306},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1535435259306},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1535435259306},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1535435259306},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1535435259306},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1535435259307},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1535435259307},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1535435259307},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1535435259307},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1535435259307},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1535435259307},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1535435259308},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1535435259308},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1535435259308},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1535435259308},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1535435259308},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1535435259308},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1535435259830},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1535435259836},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1535435259879},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1535435259879},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1535435259879},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1535435259879},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1535435259879},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1535435259879},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1535435259879},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1535435259879},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1535435259879},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1535435259879},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1535435259879},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1535435259879},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1535435259879},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1535435259879},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1535435259879},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1535435259880},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1535435259880},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1535435259880},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1535435259880},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1535435259880},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1535435259880},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1535435259880},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1535435259881},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1535435259881},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1535435259881},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1535435259881},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1535435259881},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1535435259881},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1535435259881},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1535435259881},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1535435259881},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1535435259882},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1535435259882},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1535435259882},{"_id":"public/lib/fastclick/README.html","hash":"d6e90449a2c09f3033f7e43d68b0cc8208e22e09","modified":1535435259882},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"06811ca2f722dead021493457f27cdc264ef928d","modified":1535435259882},{"_id":"public/lib/jquery_lazyload/README.html","hash":"a08fccd381c8fdb70ba8974b208254c5ba23a95f","modified":1535435259882},{"_id":"public/css/main.css","hash":"dc874c63e9a2a7f2a6d23a399c636a462910ab86","modified":1535435259882},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1535435259882},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1535435259882},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1535435259882},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1535435259882},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1535435259882},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1535435259883},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1535435259883},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1535435259883},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1535435259883},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1535435259884},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1535435259884},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1535435259884},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1535435259884},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1535435259884},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1535435259884},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1535435259884},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1535435259884},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1535435259884},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1535435259885},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1535435259885},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1535435259885},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1535435259885},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1535435259887},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1535435259913}],"Category":[{"name":"工具箱","_id":"cjldai7x90005n61dsma0zbhw"},{"name":"推荐系统算法","_id":"cjldai7xq000on61ddroa2apy"},{"name":"算法","_id":"cjldai7y9001jn61ddwe1scyf"},{"name":"python","_id":"cjldai7yd001pn61d2p1qz3oq"},{"name":"计算广告","_id":"cjldai7yf001wn61dks5def30"},{"name":"spark","_id":"cjldai7yi0022n61dt4vsbmoa"},{"name":"推荐系统","_id":"cjldai7yl0028n61d8rlnr6rs"},{"name":"珍惜时间","_id":"cjldai7yn002dn61dd31evkny"}],"Data":[],"Page":[{"layout":"false","_content":"UTA2I8PqMM","source":"baidu_verify_UTA2I8PqMM.html","raw":"---\nlayout: false\n---\nUTA2I8PqMM","date":"2018-08-24T02:33:55.000Z","updated":"2018-08-24T02:33:55.000Z","path":"baidu_verify_UTA2I8PqMM.html","title":"","comments":1,"_id":"cjldai7vx0000n61dmhexe3te","content":"UTA2I8PqMM","site":{"data":{}},"excerpt":"","more":"UTA2I8PqMM"},{"title":"关于","date":"2018-07-31T16:20:55.000Z","_content":"\n高尚\n\n北京邮电大学 计算机渣硕\n\n\b喜欢研究计算广告和推荐系统相关的算法和工程问题，努力成长\n\nwechat：gshtime","source":"about/index.md","raw":"---\ntitle: 关于\ndate: 2018-08-01 00:20:55\n---\n\n高尚\n\n北京邮电大学 计算机渣硕\n\n\b喜欢研究计算广告和推荐系统相关的算法和工程问题，努力成长\n\nwechat：gshtime","updated":"2018-07-31T16:25:42.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjldai7x60002n61djuxoa3ra","content":"<p>高尚</p>\n<p>北京邮电大学 计算机渣硕</p>\n<p>\b喜欢研究计算广告和推荐系统相关的算法和工程问题，努力成长</p>\n<p>wechat：gshtime</p>\n","site":{"data":{}},"excerpt":"","more":"<p>高尚</p>\n<p>北京邮电大学 计算机渣硕</p>\n<p>\b喜欢研究计算广告和推荐系统相关的算法和工程问题，努力成长</p>\n<p>wechat：gshtime</p>\n"},{"title":"categories","date":"2018-07-31T16:27:35.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-08-01 00:27:35\ntype: \"categories\"\n---\n","updated":"2018-07-31T16:27:49.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjldai7x80004n61d8qhh3szb","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2018-07-31T16:26:13.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-08-01 00:26:13\ntype: \"tags\"\n---\n","updated":"2018-07-31T16:32:31.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjldai7xc0008n61dzhpiiejj","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"git 使用指南","date":"2018-05-17T16:11:03.000Z","_content":"\n# git 回滚\n\n``` bash\n# 回退命令：\n\n$ git reset --hard HEAD^         回退到上个版本\n$ git reset --hard HEAD~3        回退到前3次提交之前，以此类推，回退到n次提交之前\n$ git reset --hard commit_id     退到/进到 指定commit的sha码\n\n# 强推到远程：\n\n$ git push origin HEAD --force\n```\n\n# git branch 命令\n\n``` bash\n# 重命名分支\ngit branch -m [old name] [new name]\n```\n\n# 克隆 git 仓库\n\n``` bash\ngit clone <remote_repo> -b <branch>\n```\n\n# 远程仓库\n\n查看、添加远程分支\n\n``` bash\n# 查看远程分支\ngit branch -r \n\n# 添加远程仓库\ngit remote add origin http://192.168.36.10:10080/quantum_rng_testing/nist # 添加远程仓库 origin 为自设的名字, ”quantum_rng_testing/nist“ 为工程的目录\n```\n\n## 远程分支基本操作\n\n拉取篇\n\n``` bash\n# 拉取远程分支并创建本地分支\n# 方法一，使用该方式会在本地新建分支，并自动切换到该本地分支，并建立映射关系\ngit checkout -b 本地分支名 origin/远程分支名\n# 方式二，在本地新建分支，不会自动切换到该本地分支x，需要手动checkout，不会建立映射关系\ngit fetch origin 远程分支名:本地分支名\n\n# 放弃本地所有修改，强制拉取远程更新\n# 对于本地的项目中修改不做保存操作（或代码改崩），可以用到Git pull的强制覆盖\ngit fetch --all\ngit reset --hard origin/master\ngit pull  # 可以省略\n# git fetch 指令是下载远程仓库最新内容，不做合并 \n# git reset 指令把HEAD指向master最新版本\n```\n\n``` bash \n# 从远程仓库抓取数据\ngit fetch [remote-name]\ngit fetch -p  # 在fetch之后删除掉没有与远程分支对应的本地分支\n```\n\n推送篇\n\n``` bash\n# \b推送\n# git push -u <远程主机名> <本地分支名>  # 首次推送\ngit push [参数] <远程主机名> <本地分支名>:<远程分支名>\n# [参数] -u 第一次推送的时候，可以将分支进行关联，以后只要 `git push` 就行了\n\n# 推送本地所有分支\n# 不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用–all选项。\ngit push --all origin\n\n# 强制覆盖远程分支\n# 方法一\ngit push origin develop:master -f # 就可以把本地的develop分支强制(-f)推送到远程master\n# 方法二 \ngit checkout master \t\t# 切换到旧的分支 \ngit reset –hard develop \t# 将本地的旧分支 master 重置成 develop \ngit push origin master –force \t# 再推送到远程仓库\n```\n\n删除篇\n\n``` bash\n# 删除远程分支\n$ git push origin --delete master\n# 等同于推送一个空的本地分支到远程分支\n$ git push origin :master\n# git remote show origin 状态为stale是\b远端已经删除的\ngit remote prune origin  # 可以将其从本地版本库中去除\n```\n\n## 远程分支高级知识\n\n本地分支和远程分支建立映射关系（跟踪关系track）后，使用 `git pull` 或者 `git push` 时就不必每次都要指定从远程的哪个分支拉取合并和推送到远程的哪个分支。\n\n``` bash\n# 查看映射关系（注意是双v）\ngit branch -vv\n\n# 建立映射关系\ngit branch -u origin/hexo\n# 或者\ngit branch --set-upstream-to origin/hexo  # git branch --set-upstream-to=origin/<branch> hexo\n# \b或者\ngit push --set-upstream[-u] origin hexo\n\n# 撤销映射关系\ngit branch --unset-upstream\n```\n\n注：\n> 本地分支可以与远程不同名的分支建立映射关系\n\n# Refs \n\n[Git branch upstream](https://blog.csdn.net/tterminator/article/details/78108550)\n\n# git diff \n\n用于比较两次修改的差异\n\n``` bash\n# 比较工作区与暂存区\ngit diff 不加参数即默认比较工作区与暂存区\n\n# 比较暂存区与最新本地版本库（本地库中最近一次commit的内容）\n\ngit diff --cached  [<path>...] \n\n# 比较工作区与最新本地版本库\n\ngit diff HEAD [<path>...]  如果HEAD指向的是master分支，那么HEAD还可以换成master\n\n# 比较工作区与指定commit-id的差异\n\ngit diff commit-id  [<path>...] \n\n# 比较暂存区与指定commit-id的差异\n\ngit diff --cached [<commit-id>] [<path>...] \n\n# 比较两个commit-id之间的差异\n\ngit diff [<commit-id>] [<commit-id>]\n\n```\n\n## 使用git diff打补丁\n\n``` bash\ngit diff > patch  # patch的命名是随意的，不加其他参数时作用是当我们希望将我们本仓库工作区的修改拷贝一份到其他机器上使用，但是修改的文件比较多，拷贝量比较大，\n\n# 此时我们可以将修改的代码做成补丁，之后在其他机器上对应目录下使用 git apply patch 将补丁打上即可\n\ngit diff --cached > patch  # 是将我们暂存区与版本库的差异做成补丁\n\ngit diff --HEAD > patch  # 是将工作区与版本库的差异做成补丁\n\ngit diff Testfile > patch  # 将单个文件做成一个单独的补丁\n\n# 拓展：git apply patch 应用补丁，应用补丁之前我们可以先检验一下补丁能否应用，git apply --check patch 如果没有任何输出，那么表示可以顺利接受这个补丁\n```\n另外，可以使用git apply --reject patch将能打的补丁先打上，有冲突的会生成.rej文件，此时可以找到这些文件进行手动打补丁　","source":"_posts/201805-git-guide-for-freshman.md","raw":"---\ntitle: git 使用指南\ndate: 2018-05-18 00:11:03\ncategories: 工具箱\ntags: \n    - git\n---\n\n# git 回滚\n\n``` bash\n# 回退命令：\n\n$ git reset --hard HEAD^         回退到上个版本\n$ git reset --hard HEAD~3        回退到前3次提交之前，以此类推，回退到n次提交之前\n$ git reset --hard commit_id     退到/进到 指定commit的sha码\n\n# 强推到远程：\n\n$ git push origin HEAD --force\n```\n\n# git branch 命令\n\n``` bash\n# 重命名分支\ngit branch -m [old name] [new name]\n```\n\n# 克隆 git 仓库\n\n``` bash\ngit clone <remote_repo> -b <branch>\n```\n\n# 远程仓库\n\n查看、添加远程分支\n\n``` bash\n# 查看远程分支\ngit branch -r \n\n# 添加远程仓库\ngit remote add origin http://192.168.36.10:10080/quantum_rng_testing/nist # 添加远程仓库 origin 为自设的名字, ”quantum_rng_testing/nist“ 为工程的目录\n```\n\n## 远程分支基本操作\n\n拉取篇\n\n``` bash\n# 拉取远程分支并创建本地分支\n# 方法一，使用该方式会在本地新建分支，并自动切换到该本地分支，并建立映射关系\ngit checkout -b 本地分支名 origin/远程分支名\n# 方式二，在本地新建分支，不会自动切换到该本地分支x，需要手动checkout，不会建立映射关系\ngit fetch origin 远程分支名:本地分支名\n\n# 放弃本地所有修改，强制拉取远程更新\n# 对于本地的项目中修改不做保存操作（或代码改崩），可以用到Git pull的强制覆盖\ngit fetch --all\ngit reset --hard origin/master\ngit pull  # 可以省略\n# git fetch 指令是下载远程仓库最新内容，不做合并 \n# git reset 指令把HEAD指向master最新版本\n```\n\n``` bash \n# 从远程仓库抓取数据\ngit fetch [remote-name]\ngit fetch -p  # 在fetch之后删除掉没有与远程分支对应的本地分支\n```\n\n推送篇\n\n``` bash\n# \b推送\n# git push -u <远程主机名> <本地分支名>  # 首次推送\ngit push [参数] <远程主机名> <本地分支名>:<远程分支名>\n# [参数] -u 第一次推送的时候，可以将分支进行关联，以后只要 `git push` 就行了\n\n# 推送本地所有分支\n# 不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用–all选项。\ngit push --all origin\n\n# 强制覆盖远程分支\n# 方法一\ngit push origin develop:master -f # 就可以把本地的develop分支强制(-f)推送到远程master\n# 方法二 \ngit checkout master \t\t# 切换到旧的分支 \ngit reset –hard develop \t# 将本地的旧分支 master 重置成 develop \ngit push origin master –force \t# 再推送到远程仓库\n```\n\n删除篇\n\n``` bash\n# 删除远程分支\n$ git push origin --delete master\n# 等同于推送一个空的本地分支到远程分支\n$ git push origin :master\n# git remote show origin 状态为stale是\b远端已经删除的\ngit remote prune origin  # 可以将其从本地版本库中去除\n```\n\n## 远程分支高级知识\n\n本地分支和远程分支建立映射关系（跟踪关系track）后，使用 `git pull` 或者 `git push` 时就不必每次都要指定从远程的哪个分支拉取合并和推送到远程的哪个分支。\n\n``` bash\n# 查看映射关系（注意是双v）\ngit branch -vv\n\n# 建立映射关系\ngit branch -u origin/hexo\n# 或者\ngit branch --set-upstream-to origin/hexo  # git branch --set-upstream-to=origin/<branch> hexo\n# \b或者\ngit push --set-upstream[-u] origin hexo\n\n# 撤销映射关系\ngit branch --unset-upstream\n```\n\n注：\n> 本地分支可以与远程不同名的分支建立映射关系\n\n# Refs \n\n[Git branch upstream](https://blog.csdn.net/tterminator/article/details/78108550)\n\n# git diff \n\n用于比较两次修改的差异\n\n``` bash\n# 比较工作区与暂存区\ngit diff 不加参数即默认比较工作区与暂存区\n\n# 比较暂存区与最新本地版本库（本地库中最近一次commit的内容）\n\ngit diff --cached  [<path>...] \n\n# 比较工作区与最新本地版本库\n\ngit diff HEAD [<path>...]  如果HEAD指向的是master分支，那么HEAD还可以换成master\n\n# 比较工作区与指定commit-id的差异\n\ngit diff commit-id  [<path>...] \n\n# 比较暂存区与指定commit-id的差异\n\ngit diff --cached [<commit-id>] [<path>...] \n\n# 比较两个commit-id之间的差异\n\ngit diff [<commit-id>] [<commit-id>]\n\n```\n\n## 使用git diff打补丁\n\n``` bash\ngit diff > patch  # patch的命名是随意的，不加其他参数时作用是当我们希望将我们本仓库工作区的修改拷贝一份到其他机器上使用，但是修改的文件比较多，拷贝量比较大，\n\n# 此时我们可以将修改的代码做成补丁，之后在其他机器上对应目录下使用 git apply patch 将补丁打上即可\n\ngit diff --cached > patch  # 是将我们暂存区与版本库的差异做成补丁\n\ngit diff --HEAD > patch  # 是将工作区与版本库的差异做成补丁\n\ngit diff Testfile > patch  # 将单个文件做成一个单独的补丁\n\n# 拓展：git apply patch 应用补丁，应用补丁之前我们可以先检验一下补丁能否应用，git apply --check patch 如果没有任何输出，那么表示可以顺利接受这个补丁\n```\n另外，可以使用git apply --reject patch将能打的补丁先打上，有冲突的会生成.rej文件，此时可以找到这些文件进行手动打补丁　","slug":"git-guide-for-freshman","published":1,"updated":"2018-07-31T16:34:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7x20001n61dfdawpuns","content":"<h1 id=\"git-回滚\"><a href=\"#git-回滚\" class=\"headerlink\" title=\"git 回滚\"></a>git 回滚</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 回退命令：</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git reset --hard HEAD^         回退到上个版本</span><br><span class=\"line\">$ git reset --hard HEAD~3        回退到前3次提交之前，以此类推，回退到n次提交之前</span><br><span class=\"line\">$ git reset --hard commit_id     退到/进到 指定commit的sha码</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 强推到远程：</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git push origin HEAD --force</span><br></pre></td></tr></table></figure>\n<h1 id=\"git-branch-命令\"><a href=\"#git-branch-命令\" class=\"headerlink\" title=\"git branch 命令\"></a>git branch 命令</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 重命名分支</span></span><br><span class=\"line\">git branch -m [old name] [new name]</span><br></pre></td></tr></table></figure>\n<h1 id=\"克隆-git-仓库\"><a href=\"#克隆-git-仓库\" class=\"headerlink\" title=\"克隆 git 仓库\"></a>克隆 git 仓库</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> &lt;remote_repo&gt; -b &lt;branch&gt;</span><br></pre></td></tr></table></figure>\n<h1 id=\"远程仓库\"><a href=\"#远程仓库\" class=\"headerlink\" title=\"远程仓库\"></a>远程仓库</h1><p>查看、添加远程分支</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看远程分支</span></span><br><span class=\"line\">git branch -r </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 添加远程仓库</span></span><br><span class=\"line\">git remote add origin http://192.168.36.10:10080/quantum_rng_testing/nist <span class=\"comment\"># 添加远程仓库 origin 为自设的名字, ”quantum_rng_testing/nist“ 为工程的目录</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"远程分支基本操作\"><a href=\"#远程分支基本操作\" class=\"headerlink\" title=\"远程分支基本操作\"></a>远程分支基本操作</h2><p>拉取篇</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 拉取远程分支并创建本地分支</span></span><br><span class=\"line\"><span class=\"comment\"># 方法一，使用该方式会在本地新建分支，并自动切换到该本地分支，并建立映射关系</span></span><br><span class=\"line\">git checkout -b 本地分支名 origin/远程分支名</span><br><span class=\"line\"><span class=\"comment\"># 方式二，在本地新建分支，不会自动切换到该本地分支x，需要手动checkout，不会建立映射关系</span></span><br><span class=\"line\">git fetch origin 远程分支名:本地分支名</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 放弃本地所有修改，强制拉取远程更新</span></span><br><span class=\"line\"><span class=\"comment\"># 对于本地的项目中修改不做保存操作（或代码改崩），可以用到Git pull的强制覆盖</span></span><br><span class=\"line\">git fetch --all</span><br><span class=\"line\">git reset --hard origin/master</span><br><span class=\"line\">git pull  <span class=\"comment\"># 可以省略</span></span><br><span class=\"line\"><span class=\"comment\"># git fetch 指令是下载远程仓库最新内容，不做合并 </span></span><br><span class=\"line\"><span class=\"comment\"># git reset 指令把HEAD指向master最新版本</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 从远程仓库抓取数据</span></span><br><span class=\"line\">git fetch [remote-name]</span><br><span class=\"line\">git fetch -p  <span class=\"comment\"># 在fetch之后删除掉没有与远程分支对应的本地分支</span></span><br></pre></td></tr></table></figure>\n<p>推送篇</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># \b推送</span></span><br><span class=\"line\"><span class=\"comment\"># git push -u &lt;远程主机名&gt; &lt;本地分支名&gt;  # 首次推送</span></span><br><span class=\"line\">git push [参数] &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;</span><br><span class=\"line\"><span class=\"comment\"># [参数] -u 第一次推送的时候，可以将分支进行关联，以后只要 `git push` 就行了</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 推送本地所有分支</span></span><br><span class=\"line\"><span class=\"comment\"># 不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用–all选项。</span></span><br><span class=\"line\">git push --all origin</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 强制覆盖远程分支</span></span><br><span class=\"line\"><span class=\"comment\"># 方法一</span></span><br><span class=\"line\">git push origin develop:master -f <span class=\"comment\"># 就可以把本地的develop分支强制(-f)推送到远程master</span></span><br><span class=\"line\"><span class=\"comment\"># 方法二 </span></span><br><span class=\"line\">git checkout master \t\t<span class=\"comment\"># 切换到旧的分支 </span></span><br><span class=\"line\">git reset –hard develop \t<span class=\"comment\"># 将本地的旧分支 master 重置成 develop </span></span><br><span class=\"line\">git push origin master –force \t<span class=\"comment\"># 再推送到远程仓库</span></span><br></pre></td></tr></table></figure>\n<p>删除篇</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 删除远程分支</span></span><br><span class=\"line\">$ git push origin --delete master</span><br><span class=\"line\"><span class=\"comment\"># 等同于推送一个空的本地分支到远程分支</span></span><br><span class=\"line\">$ git push origin :master</span><br><span class=\"line\"><span class=\"comment\"># git remote show origin 状态为stale是\b远端已经删除的</span></span><br><span class=\"line\">git remote prune origin  <span class=\"comment\"># 可以将其从本地版本库中去除</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"远程分支高级知识\"><a href=\"#远程分支高级知识\" class=\"headerlink\" title=\"远程分支高级知识\"></a>远程分支高级知识</h2><p>本地分支和远程分支建立映射关系（跟踪关系track）后，使用 <code>git pull</code> 或者 <code>git push</code> 时就不必每次都要指定从远程的哪个分支拉取合并和推送到远程的哪个分支。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看映射关系（注意是双v）</span></span><br><span class=\"line\">git branch -vv</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 建立映射关系</span></span><br><span class=\"line\">git branch -u origin/hexo</span><br><span class=\"line\"><span class=\"comment\"># 或者</span></span><br><span class=\"line\">git branch --<span class=\"built_in\">set</span>-upstream-to origin/hexo  <span class=\"comment\"># git branch --set-upstream-to=origin/&lt;branch&gt; hexo</span></span><br><span class=\"line\"><span class=\"comment\"># \b或者</span></span><br><span class=\"line\">git push --<span class=\"built_in\">set</span>-upstream[-u] origin hexo</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 撤销映射关系</span></span><br><span class=\"line\">git branch --<span class=\"built_in\">unset</span>-upstream</span><br></pre></td></tr></table></figure>\n<p>注：</p>\n<blockquote>\n<p>本地分支可以与远程不同名的分支建立映射关系</p>\n</blockquote>\n<h1 id=\"Refs\"><a href=\"#Refs\" class=\"headerlink\" title=\"Refs\"></a>Refs</h1><p><a href=\"https://blog.csdn.net/tterminator/article/details/78108550\" target=\"_blank\" rel=\"noopener\">Git branch upstream</a></p>\n<h1 id=\"git-diff\"><a href=\"#git-diff\" class=\"headerlink\" title=\"git diff\"></a>git diff</h1><p>用于比较两次修改的差异</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 比较工作区与暂存区</span></span><br><span class=\"line\">git diff 不加参数即默认比较工作区与暂存区</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较暂存区与最新本地版本库（本地库中最近一次commit的内容）</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff --cached  [&lt;path&gt;...] </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较工作区与最新本地版本库</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff HEAD [&lt;path&gt;...]  如果HEAD指向的是master分支，那么HEAD还可以换成master</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较工作区与指定commit-id的差异</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff commit-id  [&lt;path&gt;...] </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较暂存区与指定commit-id的差异</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff --cached [&lt;commit-id&gt;] [&lt;path&gt;...] </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较两个commit-id之间的差异</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff [&lt;commit-id&gt;] [&lt;commit-id&gt;]</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用git-diff打补丁\"><a href=\"#使用git-diff打补丁\" class=\"headerlink\" title=\"使用git diff打补丁\"></a>使用git diff打补丁</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git diff &gt; patch  <span class=\"comment\"># patch的命名是随意的，不加其他参数时作用是当我们希望将我们本仓库工作区的修改拷贝一份到其他机器上使用，但是修改的文件比较多，拷贝量比较大，</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 此时我们可以将修改的代码做成补丁，之后在其他机器上对应目录下使用 git apply patch 将补丁打上即可</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff --cached &gt; patch  <span class=\"comment\"># 是将我们暂存区与版本库的差异做成补丁</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff --HEAD &gt; patch  <span class=\"comment\"># 是将工作区与版本库的差异做成补丁</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff Testfile &gt; patch  <span class=\"comment\"># 将单个文件做成一个单独的补丁</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 拓展：git apply patch 应用补丁，应用补丁之前我们可以先检验一下补丁能否应用，git apply --check patch 如果没有任何输出，那么表示可以顺利接受这个补丁</span></span><br></pre></td></tr></table></figure>\n<p>另外，可以使用git apply —reject patch将能打的补丁先打上，有冲突的会生成.rej文件，此时可以找到这些文件进行手动打补丁　</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"git-回滚\"><a href=\"#git-回滚\" class=\"headerlink\" title=\"git 回滚\"></a>git 回滚</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 回退命令：</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git reset --hard HEAD^         回退到上个版本</span><br><span class=\"line\">$ git reset --hard HEAD~3        回退到前3次提交之前，以此类推，回退到n次提交之前</span><br><span class=\"line\">$ git reset --hard commit_id     退到/进到 指定commit的sha码</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 强推到远程：</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ git push origin HEAD --force</span><br></pre></td></tr></table></figure>\n<h1 id=\"git-branch-命令\"><a href=\"#git-branch-命令\" class=\"headerlink\" title=\"git branch 命令\"></a>git branch 命令</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 重命名分支</span></span><br><span class=\"line\">git branch -m [old name] [new name]</span><br></pre></td></tr></table></figure>\n<h1 id=\"克隆-git-仓库\"><a href=\"#克隆-git-仓库\" class=\"headerlink\" title=\"克隆 git 仓库\"></a>克隆 git 仓库</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> &lt;remote_repo&gt; -b &lt;branch&gt;</span><br></pre></td></tr></table></figure>\n<h1 id=\"远程仓库\"><a href=\"#远程仓库\" class=\"headerlink\" title=\"远程仓库\"></a>远程仓库</h1><p>查看、添加远程分支</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看远程分支</span></span><br><span class=\"line\">git branch -r </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 添加远程仓库</span></span><br><span class=\"line\">git remote add origin http://192.168.36.10:10080/quantum_rng_testing/nist <span class=\"comment\"># 添加远程仓库 origin 为自设的名字, ”quantum_rng_testing/nist“ 为工程的目录</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"远程分支基本操作\"><a href=\"#远程分支基本操作\" class=\"headerlink\" title=\"远程分支基本操作\"></a>远程分支基本操作</h2><p>拉取篇</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 拉取远程分支并创建本地分支</span></span><br><span class=\"line\"><span class=\"comment\"># 方法一，使用该方式会在本地新建分支，并自动切换到该本地分支，并建立映射关系</span></span><br><span class=\"line\">git checkout -b 本地分支名 origin/远程分支名</span><br><span class=\"line\"><span class=\"comment\"># 方式二，在本地新建分支，不会自动切换到该本地分支x，需要手动checkout，不会建立映射关系</span></span><br><span class=\"line\">git fetch origin 远程分支名:本地分支名</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 放弃本地所有修改，强制拉取远程更新</span></span><br><span class=\"line\"><span class=\"comment\"># 对于本地的项目中修改不做保存操作（或代码改崩），可以用到Git pull的强制覆盖</span></span><br><span class=\"line\">git fetch --all</span><br><span class=\"line\">git reset --hard origin/master</span><br><span class=\"line\">git pull  <span class=\"comment\"># 可以省略</span></span><br><span class=\"line\"><span class=\"comment\"># git fetch 指令是下载远程仓库最新内容，不做合并 </span></span><br><span class=\"line\"><span class=\"comment\"># git reset 指令把HEAD指向master最新版本</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 从远程仓库抓取数据</span></span><br><span class=\"line\">git fetch [remote-name]</span><br><span class=\"line\">git fetch -p  <span class=\"comment\"># 在fetch之后删除掉没有与远程分支对应的本地分支</span></span><br></pre></td></tr></table></figure>\n<p>推送篇</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># \b推送</span></span><br><span class=\"line\"><span class=\"comment\"># git push -u &lt;远程主机名&gt; &lt;本地分支名&gt;  # 首次推送</span></span><br><span class=\"line\">git push [参数] &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;</span><br><span class=\"line\"><span class=\"comment\"># [参数] -u 第一次推送的时候，可以将分支进行关联，以后只要 `git push` 就行了</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 推送本地所有分支</span></span><br><span class=\"line\"><span class=\"comment\"># 不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用–all选项。</span></span><br><span class=\"line\">git push --all origin</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 强制覆盖远程分支</span></span><br><span class=\"line\"><span class=\"comment\"># 方法一</span></span><br><span class=\"line\">git push origin develop:master -f <span class=\"comment\"># 就可以把本地的develop分支强制(-f)推送到远程master</span></span><br><span class=\"line\"><span class=\"comment\"># 方法二 </span></span><br><span class=\"line\">git checkout master \t\t<span class=\"comment\"># 切换到旧的分支 </span></span><br><span class=\"line\">git reset –hard develop \t<span class=\"comment\"># 将本地的旧分支 master 重置成 develop </span></span><br><span class=\"line\">git push origin master –force \t<span class=\"comment\"># 再推送到远程仓库</span></span><br></pre></td></tr></table></figure>\n<p>删除篇</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 删除远程分支</span></span><br><span class=\"line\">$ git push origin --delete master</span><br><span class=\"line\"><span class=\"comment\"># 等同于推送一个空的本地分支到远程分支</span></span><br><span class=\"line\">$ git push origin :master</span><br><span class=\"line\"><span class=\"comment\"># git remote show origin 状态为stale是\b远端已经删除的</span></span><br><span class=\"line\">git remote prune origin  <span class=\"comment\"># 可以将其从本地版本库中去除</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"远程分支高级知识\"><a href=\"#远程分支高级知识\" class=\"headerlink\" title=\"远程分支高级知识\"></a>远程分支高级知识</h2><p>本地分支和远程分支建立映射关系（跟踪关系track）后，使用 <code>git pull</code> 或者 <code>git push</code> 时就不必每次都要指定从远程的哪个分支拉取合并和推送到远程的哪个分支。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 查看映射关系（注意是双v）</span></span><br><span class=\"line\">git branch -vv</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 建立映射关系</span></span><br><span class=\"line\">git branch -u origin/hexo</span><br><span class=\"line\"><span class=\"comment\"># 或者</span></span><br><span class=\"line\">git branch --<span class=\"built_in\">set</span>-upstream-to origin/hexo  <span class=\"comment\"># git branch --set-upstream-to=origin/&lt;branch&gt; hexo</span></span><br><span class=\"line\"><span class=\"comment\"># \b或者</span></span><br><span class=\"line\">git push --<span class=\"built_in\">set</span>-upstream[-u] origin hexo</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 撤销映射关系</span></span><br><span class=\"line\">git branch --<span class=\"built_in\">unset</span>-upstream</span><br></pre></td></tr></table></figure>\n<p>注：</p>\n<blockquote>\n<p>本地分支可以与远程不同名的分支建立映射关系</p>\n</blockquote>\n<h1 id=\"Refs\"><a href=\"#Refs\" class=\"headerlink\" title=\"Refs\"></a>Refs</h1><p><a href=\"https://blog.csdn.net/tterminator/article/details/78108550\" target=\"_blank\" rel=\"noopener\">Git branch upstream</a></p>\n<h1 id=\"git-diff\"><a href=\"#git-diff\" class=\"headerlink\" title=\"git diff\"></a>git diff</h1><p>用于比较两次修改的差异</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 比较工作区与暂存区</span></span><br><span class=\"line\">git diff 不加参数即默认比较工作区与暂存区</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较暂存区与最新本地版本库（本地库中最近一次commit的内容）</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff --cached  [&lt;path&gt;...] </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较工作区与最新本地版本库</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff HEAD [&lt;path&gt;...]  如果HEAD指向的是master分支，那么HEAD还可以换成master</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较工作区与指定commit-id的差异</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff commit-id  [&lt;path&gt;...] </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较暂存区与指定commit-id的差异</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff --cached [&lt;commit-id&gt;] [&lt;path&gt;...] </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较两个commit-id之间的差异</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff [&lt;commit-id&gt;] [&lt;commit-id&gt;]</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用git-diff打补丁\"><a href=\"#使用git-diff打补丁\" class=\"headerlink\" title=\"使用git diff打补丁\"></a>使用git diff打补丁</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git diff &gt; patch  <span class=\"comment\"># patch的命名是随意的，不加其他参数时作用是当我们希望将我们本仓库工作区的修改拷贝一份到其他机器上使用，但是修改的文件比较多，拷贝量比较大，</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 此时我们可以将修改的代码做成补丁，之后在其他机器上对应目录下使用 git apply patch 将补丁打上即可</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff --cached &gt; patch  <span class=\"comment\"># 是将我们暂存区与版本库的差异做成补丁</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff --HEAD &gt; patch  <span class=\"comment\"># 是将工作区与版本库的差异做成补丁</span></span><br><span class=\"line\"></span><br><span class=\"line\">git diff Testfile &gt; patch  <span class=\"comment\"># 将单个文件做成一个单独的补丁</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 拓展：git apply patch 应用补丁，应用补丁之前我们可以先检验一下补丁能否应用，git apply --check patch 如果没有任何输出，那么表示可以顺利接受这个补丁</span></span><br></pre></td></tr></table></figure>\n<p>另外，可以使用git apply —reject patch将能打的补丁先打上，有冲突的会生成.rej文件，此时可以找到这些文件进行手动打补丁　</p>\n"},{"title":"hexo 使用指南","date":"2018-05-18T03:03:14.000Z","_content":"\n# 安装\b支持\n\n1. 安装Node.js\n\nmac系统到 node.js 官网下安装包\n\n``` bash\n# 安装 Node.js\n# 安装 Node.js 的最佳方式是使用 nvm。\n\n# cURL方式\n$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh\n\n# Wget方式\n$ wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh\n\n# 安装完成后，重启终端并执行下列命令即可安装 Node.js。\n$ nvm install stable\n```\n\n2. 安装git\n\n``` bash\n# Windows：下载并安装 git.\n\n# Mac：使用 Homebrew, MacPorts ：\nbrew install git  # ;或下载 安装程序 安装。\n\n# Linux (Ubuntu, Debian)：\nsudo apt-get install git-core\n\n# Linux (Fedora, Red Hat, CentOS)：\nsudo yum install git-core\n```\n\n# 安装Hexo\n\n```\n$ sudo npm install -g hexo-cli\n```\n之后要在博客的文件夹下执行以下命令\n\n``` bash\nnpm install hexo  # 有上面一步可以省略 \nhexo init <folder>  # 初始化\ncd <folder> \nnpm install\nnpm install hexo-deployer-git\n```\n\n# 可视化写博客\n\n借助vsc、atom之类的编辑器，可以实现hexo博客的编辑和实时预览，还可以试试 `hexo-admin`这款插件。\n\n`hexo-admin` 能够管理文章，添加分类和标签，也可以一键部署到pages,现在图片可以实现粘贴上传，原插件为保存到`source/images`目录下,部署博客时同时上传。\n\n另外，还有一款`hexo-admin-qiniu` 插件，实现了自动上传文件到七牛云的配置，比较方便。（不需要先安装`hexo-admin`，直接装这个就行了）\n\n网址： [hexo-admin-qiniu github](https://github.com/xbotao/hexo-admin-qiniu)\n\n# hexo 主题\n\n> 说明：在 Hexo 中有两份主要的配置文件，其名称都是 `_config.yml`。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。\n\n为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件。\n## Next\n\nNext是Hexo一个精简的主题系统，包含多种外观（Schema）选择，\b“精于心，简于形”是Next的目标。\n\n[Next主题主页](http://theme-next.iissnan.com/)\n\n### 下载主题\n\n``` bash\n$ cd your-hexo-site\n$ git clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n\n### 启用主题\n\n与所有 Hexo 主题启用的模式一样。 当 克隆/下载 完成后，打开站点配置文件 `_config.yml`， 找到 theme 字段，并将其值更改为 next。\n\n```\n# 启用 NexT 主题\ntheme: next\n```\n到此，NexT 主题安装完成。下一步我们将验证主题是否正确启用。在切换主题之后、验证之前， 我们最好使用 hexo clean 来清除 Hexo 的缓存。\n\n主题设定包括：详细见官网介绍\n- 选择「Scheme」\n- 设置「界面语言」\n- 设置「菜单」\n- 设置「侧栏」\n- 设置「头像」\n- 设置「作者昵称」\n- 设置「站点描述」\n\n### 设置语言\n\n编辑 站点配置文件， 将 language 设置成你所需要的语言。建议明确设置你所需要的语言，例如选用简体中文，配置如下：\n\n`language: zh-Hans`\n\n\n# 异常\n\n- hexo本地测试运行重启后页面空白,提示 : `WARN No layout: index.html`?\n\n原因：从git hexo分支（存放hexo文件）把代码拉下来，\b之前的Next 主题被忽略了，就没拉下来，所以必须重新 git clone Next主题的\b仓库\n\n``` bash\ngit clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n\n- Hexo异常：fatal:inunpopulatedsubmodule'.deploy_git'怎么解决？\n\n这种情况可以先安装下相关的依赖：\n\n``` bash\nnpm install hexo-deployer-git –save\n```\n\n实在不行，就把它删掉，然后重新生成和部署。\n\n``` bash\nrm -rf .deploy_git\nhexo g\nhexo d\n```","source":"_posts/201805-hexo-blog-system-guide.md","raw":"---\ntitle: hexo 使用指南\ndate: 2018-05-18 11:03:14\ntags:\n---\n\n# 安装\b支持\n\n1. 安装Node.js\n\nmac系统到 node.js 官网下安装包\n\n``` bash\n# 安装 Node.js\n# 安装 Node.js 的最佳方式是使用 nvm。\n\n# cURL方式\n$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh\n\n# Wget方式\n$ wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh\n\n# 安装完成后，重启终端并执行下列命令即可安装 Node.js。\n$ nvm install stable\n```\n\n2. 安装git\n\n``` bash\n# Windows：下载并安装 git.\n\n# Mac：使用 Homebrew, MacPorts ：\nbrew install git  # ;或下载 安装程序 安装。\n\n# Linux (Ubuntu, Debian)：\nsudo apt-get install git-core\n\n# Linux (Fedora, Red Hat, CentOS)：\nsudo yum install git-core\n```\n\n# 安装Hexo\n\n```\n$ sudo npm install -g hexo-cli\n```\n之后要在博客的文件夹下执行以下命令\n\n``` bash\nnpm install hexo  # 有上面一步可以省略 \nhexo init <folder>  # 初始化\ncd <folder> \nnpm install\nnpm install hexo-deployer-git\n```\n\n# 可视化写博客\n\n借助vsc、atom之类的编辑器，可以实现hexo博客的编辑和实时预览，还可以试试 `hexo-admin`这款插件。\n\n`hexo-admin` 能够管理文章，添加分类和标签，也可以一键部署到pages,现在图片可以实现粘贴上传，原插件为保存到`source/images`目录下,部署博客时同时上传。\n\n另外，还有一款`hexo-admin-qiniu` 插件，实现了自动上传文件到七牛云的配置，比较方便。（不需要先安装`hexo-admin`，直接装这个就行了）\n\n网址： [hexo-admin-qiniu github](https://github.com/xbotao/hexo-admin-qiniu)\n\n# hexo 主题\n\n> 说明：在 Hexo 中有两份主要的配置文件，其名称都是 `_config.yml`。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。\n\n为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件。\n## Next\n\nNext是Hexo一个精简的主题系统，包含多种外观（Schema）选择，\b“精于心，简于形”是Next的目标。\n\n[Next主题主页](http://theme-next.iissnan.com/)\n\n### 下载主题\n\n``` bash\n$ cd your-hexo-site\n$ git clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n\n### 启用主题\n\n与所有 Hexo 主题启用的模式一样。 当 克隆/下载 完成后，打开站点配置文件 `_config.yml`， 找到 theme 字段，并将其值更改为 next。\n\n```\n# 启用 NexT 主题\ntheme: next\n```\n到此，NexT 主题安装完成。下一步我们将验证主题是否正确启用。在切换主题之后、验证之前， 我们最好使用 hexo clean 来清除 Hexo 的缓存。\n\n主题设定包括：详细见官网介绍\n- 选择「Scheme」\n- 设置「界面语言」\n- 设置「菜单」\n- 设置「侧栏」\n- 设置「头像」\n- 设置「作者昵称」\n- 设置「站点描述」\n\n### 设置语言\n\n编辑 站点配置文件， 将 language 设置成你所需要的语言。建议明确设置你所需要的语言，例如选用简体中文，配置如下：\n\n`language: zh-Hans`\n\n\n# 异常\n\n- hexo本地测试运行重启后页面空白,提示 : `WARN No layout: index.html`?\n\n原因：从git hexo分支（存放hexo文件）把代码拉下来，\b之前的Next 主题被忽略了，就没拉下来，所以必须重新 git clone Next主题的\b仓库\n\n``` bash\ngit clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n\n- Hexo异常：fatal:inunpopulatedsubmodule'.deploy_git'怎么解决？\n\n这种情况可以先安装下相关的依赖：\n\n``` bash\nnpm install hexo-deployer-git –save\n```\n\n实在不行，就把它删掉，然后重新生成和部署。\n\n``` bash\nrm -rf .deploy_git\nhexo g\nhexo d\n```","slug":"hexo-blog-system-guide","published":1,"updated":"2018-05-27T09:03:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7x70003n61dz5xvobqv","content":"<h1 id=\"安装支持\"><a href=\"#安装支持\" class=\"headerlink\" title=\"安装\b支持\"></a>安装\b支持</h1><ol>\n<li>安装Node.js</li>\n</ol>\n<p>mac系统到 node.js 官网下安装包</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 安装 Node.js</span></span><br><span class=\"line\"><span class=\"comment\"># 安装 Node.js 的最佳方式是使用 nvm。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># cURL方式</span></span><br><span class=\"line\">$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Wget方式</span></span><br><span class=\"line\">$ wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 安装完成后，重启终端并执行下列命令即可安装 Node.js。</span></span><br><span class=\"line\">$ nvm install stable</span><br></pre></td></tr></table></figure>\n<ol>\n<li>安装git</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Windows：下载并安装 git.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Mac：使用 Homebrew, MacPorts ：</span></span><br><span class=\"line\">brew install git  <span class=\"comment\"># ;或下载 安装程序 安装。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Linux (Ubuntu, Debian)：</span></span><br><span class=\"line\">sudo apt-get install git-core</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Linux (Fedora, Red Hat, CentOS)：</span></span><br><span class=\"line\">sudo yum install git-core</span><br></pre></td></tr></table></figure>\n<h1 id=\"安装Hexo\"><a href=\"#安装Hexo\" class=\"headerlink\" title=\"安装Hexo\"></a>安装Hexo</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo npm install -g hexo-cli</span><br></pre></td></tr></table></figure>\n<p>之后要在博客的文件夹下执行以下命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo  <span class=\"comment\"># 有上面一步可以省略 </span></span><br><span class=\"line\">hexo init &lt;folder&gt;  <span class=\"comment\"># 初始化</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> &lt;folder&gt; </span><br><span class=\"line\">npm install</span><br><span class=\"line\">npm install hexo-deployer-git</span><br></pre></td></tr></table></figure>\n<h1 id=\"可视化写博客\"><a href=\"#可视化写博客\" class=\"headerlink\" title=\"可视化写博客\"></a>可视化写博客</h1><p>借助vsc、atom之类的编辑器，可以实现hexo博客的编辑和实时预览，还可以试试 <code>hexo-admin</code>这款插件。</p>\n<p><code>hexo-admin</code> 能够管理文章，添加分类和标签，也可以一键部署到pages,现在图片可以实现粘贴上传，原插件为保存到<code>source/images</code>目录下,部署博客时同时上传。</p>\n<p>另外，还有一款<code>hexo-admin-qiniu</code> 插件，实现了自动上传文件到七牛云的配置，比较方便。（不需要先安装<code>hexo-admin</code>，直接装这个就行了）</p>\n<p>网址： <a href=\"https://github.com/xbotao/hexo-admin-qiniu\" target=\"_blank\" rel=\"noopener\">hexo-admin-qiniu github</a></p>\n<h1 id=\"hexo-主题\"><a href=\"#hexo-主题\" class=\"headerlink\" title=\"hexo 主题\"></a>hexo 主题</h1><blockquote>\n<p>说明：在 Hexo 中有两份主要的配置文件，其名称都是 <code>_config.yml</code>。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。</p>\n</blockquote>\n<p>为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件。</p>\n<h2 id=\"Next\"><a href=\"#Next\" class=\"headerlink\" title=\"Next\"></a>Next</h2><p>Next是Hexo一个精简的主题系统，包含多种外观（Schema）选择，\b“精于心，简于形”是Next的目标。</p>\n<p><a href=\"http://theme-next.iissnan.com/\" target=\"_blank\" rel=\"noopener\">Next主题主页</a></p>\n<h3 id=\"下载主题\"><a href=\"#下载主题\" class=\"headerlink\" title=\"下载主题\"></a>下载主题</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> your-hexo-site</span><br><span class=\"line\">$ git <span class=\"built_in\">clone</span> https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>\n<h3 id=\"启用主题\"><a href=\"#启用主题\" class=\"headerlink\" title=\"启用主题\"></a>启用主题</h3><p>与所有 Hexo 主题启用的模式一样。 当 克隆/下载 完成后，打开站点配置文件 <code>_config.yml</code>， 找到 theme 字段，并将其值更改为 next。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 启用 NexT 主题</span><br><span class=\"line\">theme: next</span><br></pre></td></tr></table></figure>\n<p>到此，NexT 主题安装完成。下一步我们将验证主题是否正确启用。在切换主题之后、验证之前， 我们最好使用 hexo clean 来清除 Hexo 的缓存。</p>\n<p>主题设定包括：详细见官网介绍</p>\n<ul>\n<li>选择「Scheme」</li>\n<li>设置「界面语言」</li>\n<li>设置「菜单」</li>\n<li>设置「侧栏」</li>\n<li>设置「头像」</li>\n<li>设置「作者昵称」</li>\n<li>设置「站点描述」</li>\n</ul>\n<h3 id=\"设置语言\"><a href=\"#设置语言\" class=\"headerlink\" title=\"设置语言\"></a>设置语言</h3><p>编辑 站点配置文件， 将 language 设置成你所需要的语言。建议明确设置你所需要的语言，例如选用简体中文，配置如下：</p>\n<p><code>language: zh-Hans</code></p>\n<h1 id=\"异常\"><a href=\"#异常\" class=\"headerlink\" title=\"异常\"></a>异常</h1><ul>\n<li>hexo本地测试运行重启后页面空白,提示 : <code>WARN No layout: index.html</code>?</li>\n</ul>\n<p>原因：从git hexo分支（存放hexo文件）把代码拉下来，\b之前的Next 主题被忽略了，就没拉下来，所以必须重新 git clone Next主题的\b仓库</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Hexo异常：fatal:inunpopulatedsubmodule’.deploy_git’怎么解决？</li>\n</ul>\n<p>这种情况可以先安装下相关的依赖：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-deployer-git –save</span><br></pre></td></tr></table></figure>\n<p>实在不行，就把它删掉，然后重新生成和部署。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rm -rf .deploy_git</span><br><span class=\"line\">hexo g</span><br><span class=\"line\">hexo d</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"安装支持\"><a href=\"#安装支持\" class=\"headerlink\" title=\"安装\b支持\"></a>安装\b支持</h1><ol>\n<li>安装Node.js</li>\n</ol>\n<p>mac系统到 node.js 官网下安装包</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 安装 Node.js</span></span><br><span class=\"line\"><span class=\"comment\"># 安装 Node.js 的最佳方式是使用 nvm。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># cURL方式</span></span><br><span class=\"line\">$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Wget方式</span></span><br><span class=\"line\">$ wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 安装完成后，重启终端并执行下列命令即可安装 Node.js。</span></span><br><span class=\"line\">$ nvm install stable</span><br></pre></td></tr></table></figure>\n<ol>\n<li>安装git</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Windows：下载并安装 git.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Mac：使用 Homebrew, MacPorts ：</span></span><br><span class=\"line\">brew install git  <span class=\"comment\"># ;或下载 安装程序 安装。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Linux (Ubuntu, Debian)：</span></span><br><span class=\"line\">sudo apt-get install git-core</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Linux (Fedora, Red Hat, CentOS)：</span></span><br><span class=\"line\">sudo yum install git-core</span><br></pre></td></tr></table></figure>\n<h1 id=\"安装Hexo\"><a href=\"#安装Hexo\" class=\"headerlink\" title=\"安装Hexo\"></a>安装Hexo</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo npm install -g hexo-cli</span><br></pre></td></tr></table></figure>\n<p>之后要在博客的文件夹下执行以下命令</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo  <span class=\"comment\"># 有上面一步可以省略 </span></span><br><span class=\"line\">hexo init &lt;folder&gt;  <span class=\"comment\"># 初始化</span></span><br><span class=\"line\"><span class=\"built_in\">cd</span> &lt;folder&gt; </span><br><span class=\"line\">npm install</span><br><span class=\"line\">npm install hexo-deployer-git</span><br></pre></td></tr></table></figure>\n<h1 id=\"可视化写博客\"><a href=\"#可视化写博客\" class=\"headerlink\" title=\"可视化写博客\"></a>可视化写博客</h1><p>借助vsc、atom之类的编辑器，可以实现hexo博客的编辑和实时预览，还可以试试 <code>hexo-admin</code>这款插件。</p>\n<p><code>hexo-admin</code> 能够管理文章，添加分类和标签，也可以一键部署到pages,现在图片可以实现粘贴上传，原插件为保存到<code>source/images</code>目录下,部署博客时同时上传。</p>\n<p>另外，还有一款<code>hexo-admin-qiniu</code> 插件，实现了自动上传文件到七牛云的配置，比较方便。（不需要先安装<code>hexo-admin</code>，直接装这个就行了）</p>\n<p>网址： <a href=\"https://github.com/xbotao/hexo-admin-qiniu\" target=\"_blank\" rel=\"noopener\">hexo-admin-qiniu github</a></p>\n<h1 id=\"hexo-主题\"><a href=\"#hexo-主题\" class=\"headerlink\" title=\"hexo 主题\"></a>hexo 主题</h1><blockquote>\n<p>说明：在 Hexo 中有两份主要的配置文件，其名称都是 <code>_config.yml</code>。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。</p>\n</blockquote>\n<p>为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件。</p>\n<h2 id=\"Next\"><a href=\"#Next\" class=\"headerlink\" title=\"Next\"></a>Next</h2><p>Next是Hexo一个精简的主题系统，包含多种外观（Schema）选择，\b“精于心，简于形”是Next的目标。</p>\n<p><a href=\"http://theme-next.iissnan.com/\" target=\"_blank\" rel=\"noopener\">Next主题主页</a></p>\n<h3 id=\"下载主题\"><a href=\"#下载主题\" class=\"headerlink\" title=\"下载主题\"></a>下载主题</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> your-hexo-site</span><br><span class=\"line\">$ git <span class=\"built_in\">clone</span> https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>\n<h3 id=\"启用主题\"><a href=\"#启用主题\" class=\"headerlink\" title=\"启用主题\"></a>启用主题</h3><p>与所有 Hexo 主题启用的模式一样。 当 克隆/下载 完成后，打开站点配置文件 <code>_config.yml</code>， 找到 theme 字段，并将其值更改为 next。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 启用 NexT 主题</span><br><span class=\"line\">theme: next</span><br></pre></td></tr></table></figure>\n<p>到此，NexT 主题安装完成。下一步我们将验证主题是否正确启用。在切换主题之后、验证之前， 我们最好使用 hexo clean 来清除 Hexo 的缓存。</p>\n<p>主题设定包括：详细见官网介绍</p>\n<ul>\n<li>选择「Scheme」</li>\n<li>设置「界面语言」</li>\n<li>设置「菜单」</li>\n<li>设置「侧栏」</li>\n<li>设置「头像」</li>\n<li>设置「作者昵称」</li>\n<li>设置「站点描述」</li>\n</ul>\n<h3 id=\"设置语言\"><a href=\"#设置语言\" class=\"headerlink\" title=\"设置语言\"></a>设置语言</h3><p>编辑 站点配置文件， 将 language 设置成你所需要的语言。建议明确设置你所需要的语言，例如选用简体中文，配置如下：</p>\n<p><code>language: zh-Hans</code></p>\n<h1 id=\"异常\"><a href=\"#异常\" class=\"headerlink\" title=\"异常\"></a>异常</h1><ul>\n<li>hexo本地测试运行重启后页面空白,提示 : <code>WARN No layout: index.html</code>?</li>\n</ul>\n<p>原因：从git hexo分支（存放hexo文件）把代码拉下来，\b之前的Next 主题被忽略了，就没拉下来，所以必须重新 git clone Next主题的\b仓库</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Hexo异常：fatal:inunpopulatedsubmodule’.deploy_git’怎么解决？</li>\n</ul>\n<p>这种情况可以先安装下相关的依赖：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-deployer-git –save</span><br></pre></td></tr></table></figure>\n<p>实在不行，就把它删掉，然后重新生成和部署。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rm -rf .deploy_git</span><br><span class=\"line\">hexo g</span><br><span class=\"line\">hexo d</span><br></pre></td></tr></table></figure>"},{"title":"hexo 网站的迁移","date":"2018-05-27T09:06:53.000Z","_content":"\nmark\nhttps://blog.csdn.net/aceking10/article/details/41540889\n\nhttps://www.jianshu.com/p/f8a55b972972","source":"_posts/201805-hexo-transfer.md","raw":"---\ntitle: hexo 网站的迁移\ndate: 2018-05-27 17:06:53\ntags:\n---\n\nmark\nhttps://blog.csdn.net/aceking10/article/details/41540889\n\nhttps://www.jianshu.com/p/f8a55b972972","slug":"hexo-transfer","published":1,"updated":"2018-05-27T12:52:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xb0007n61do1nrkrzl","content":"<p>mark<br><a href=\"https://blog.csdn.net/aceking10/article/details/41540889\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/aceking10/article/details/41540889</a></p>\n<p><a href=\"https://www.jianshu.com/p/f8a55b972972\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/f8a55b972972</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>mark<br><a href=\"https://blog.csdn.net/aceking10/article/details/41540889\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/aceking10/article/details/41540889</a></p>\n<p><a href=\"https://www.jianshu.com/p/f8a55b972972\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/f8a55b972972</a></p>\n"},{"title":"linux 命令行和 iterm2 操作指南","date":"2018-05-31T04:39:47.000Z","_content":"\n# 标签\n\n- 新建标签：`command + t`\n- 关闭标签：`command + w`\n- 切换标签：`command + 数字` 或 `command + 左右方向键`\n- 切换全屏：`command + enter`\n\n# 分屏\n\n- 垂直分屏：command + d\n- 水平分屏：command + shift + d\n- 切换屏幕：command + option + 方向键 command + [ 或 command + ]\n\n# 命令编辑\n\n## 删除\n\n- 删除单词：ctrl + w, 删除光标之前的单词\n- 删除行：ctrl + u，删除到行首\n- 删除行：ctrl + k，删除到行尾\n- 删除字符：删除当前光标`ctrl + d`，删除光标之前：`ctrl + h`\n- 清屏1：command + r\n- 清屏2：ctrl + l\n\n## 光标移动\n\n- 光标到行首：ctrl + a (同 ⌘ + ←)\n- 光标到行尾：ctrl + e (同 ⌘ + →)\n- 单词移动：alt + b / alt + b 按单词前移/后移\n- 字符移动：ctrl + f / ctrl +b 按字符前移/后移，相当于左右方向\n- 交换光标处文本：ctrl + t\n\n## 历史命令\n\n- 查看历史命令：`command + ;` （输入打头几个字母，然后输入 `command + ;` iterm2将自动列出之前输入过的类似命令。）\n- 查看剪贴板历史：command + shift + h\n- 上一条命令：ctrl + p\n- 搜索命令历史：ctrl + r\n\n# 选中即复制\n\niterm2 有 2 种好用的选中即复制模式。\n\n- 一种是用鼠标，在 iterm2 中，选中某个路径或者某个词汇，那么，iterm2 就自动复制了。 　　\n- 另一种是无鼠标模式，`command + f`,弹出 iterm2 的查找模式，输入要查找并复制的内容的前几个字母，确认找到的是自己的内容之- 后，输入 tab，查找窗口将自动变化内容，并将其复制。如果输入的是 s- hift+tab，则自动将查找内容的左边选中并复制。\n","source":"_posts/201805-linux-command-line-and-iterm-use-guide.md","raw":"---\ntitle: linux 命令行和 iterm2 操作指南\ndate: 2018-05-31 12:39:47\ntags: linux command line, iterms, shortcut\n---\n\n# 标签\n\n- 新建标签：`command + t`\n- 关闭标签：`command + w`\n- 切换标签：`command + 数字` 或 `command + 左右方向键`\n- 切换全屏：`command + enter`\n\n# 分屏\n\n- 垂直分屏：command + d\n- 水平分屏：command + shift + d\n- 切换屏幕：command + option + 方向键 command + [ 或 command + ]\n\n# 命令编辑\n\n## 删除\n\n- 删除单词：ctrl + w, 删除光标之前的单词\n- 删除行：ctrl + u，删除到行首\n- 删除行：ctrl + k，删除到行尾\n- 删除字符：删除当前光标`ctrl + d`，删除光标之前：`ctrl + h`\n- 清屏1：command + r\n- 清屏2：ctrl + l\n\n## 光标移动\n\n- 光标到行首：ctrl + a (同 ⌘ + ←)\n- 光标到行尾：ctrl + e (同 ⌘ + →)\n- 单词移动：alt + b / alt + b 按单词前移/后移\n- 字符移动：ctrl + f / ctrl +b 按字符前移/后移，相当于左右方向\n- 交换光标处文本：ctrl + t\n\n## 历史命令\n\n- 查看历史命令：`command + ;` （输入打头几个字母，然后输入 `command + ;` iterm2将自动列出之前输入过的类似命令。）\n- 查看剪贴板历史：command + shift + h\n- 上一条命令：ctrl + p\n- 搜索命令历史：ctrl + r\n\n# 选中即复制\n\niterm2 有 2 种好用的选中即复制模式。\n\n- 一种是用鼠标，在 iterm2 中，选中某个路径或者某个词汇，那么，iterm2 就自动复制了。 　　\n- 另一种是无鼠标模式，`command + f`,弹出 iterm2 的查找模式，输入要查找并复制的内容的前几个字母，确认找到的是自己的内容之- 后，输入 tab，查找窗口将自动变化内容，并将其复制。如果输入的是 s- hift+tab，则自动将查找内容的左边选中并复制。\n","slug":"linux-command-line-and-iterm-use-guide","published":1,"updated":"2018-05-31T07:26:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xd0009n61d9i0zgl89","content":"<h1 id=\"标签\"><a href=\"#标签\" class=\"headerlink\" title=\"标签\"></a>标签</h1><ul>\n<li>新建标签：<code>command + t</code></li>\n<li>关闭标签：<code>command + w</code></li>\n<li>切换标签：<code>command + 数字</code> 或 <code>command + 左右方向键</code></li>\n<li>切换全屏：<code>command + enter</code></li>\n</ul>\n<h1 id=\"分屏\"><a href=\"#分屏\" class=\"headerlink\" title=\"分屏\"></a>分屏</h1><ul>\n<li>垂直分屏：command + d</li>\n<li>水平分屏：command + shift + d</li>\n<li>切换屏幕：command + option + 方向键 command + [ 或 command + ]</li>\n</ul>\n<h1 id=\"命令编辑\"><a href=\"#命令编辑\" class=\"headerlink\" title=\"命令编辑\"></a>命令编辑</h1><h2 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h2><ul>\n<li>删除单词：ctrl + w, 删除光标之前的单词</li>\n<li>删除行：ctrl + u，删除到行首</li>\n<li>删除行：ctrl + k，删除到行尾</li>\n<li>删除字符：删除当前光标<code>ctrl + d</code>，删除光标之前：<code>ctrl + h</code></li>\n<li>清屏1：command + r</li>\n<li>清屏2：ctrl + l</li>\n</ul>\n<h2 id=\"光标移动\"><a href=\"#光标移动\" class=\"headerlink\" title=\"光标移动\"></a>光标移动</h2><ul>\n<li>光标到行首：ctrl + a (同 ⌘ + ←)</li>\n<li>光标到行尾：ctrl + e (同 ⌘ + →)</li>\n<li>单词移动：alt + b / alt + b 按单词前移/后移</li>\n<li>字符移动：ctrl + f / ctrl +b 按字符前移/后移，相当于左右方向</li>\n<li>交换光标处文本：ctrl + t</li>\n</ul>\n<h2 id=\"历史命令\"><a href=\"#历史命令\" class=\"headerlink\" title=\"历史命令\"></a>历史命令</h2><ul>\n<li>查看历史命令：<code>command + ;</code> （输入打头几个字母，然后输入 <code>command + ;</code> iterm2将自动列出之前输入过的类似命令。）</li>\n<li>查看剪贴板历史：command + shift + h</li>\n<li>上一条命令：ctrl + p</li>\n<li>搜索命令历史：ctrl + r</li>\n</ul>\n<h1 id=\"选中即复制\"><a href=\"#选中即复制\" class=\"headerlink\" title=\"选中即复制\"></a>选中即复制</h1><p>iterm2 有 2 种好用的选中即复制模式。</p>\n<ul>\n<li>一种是用鼠标，在 iterm2 中，选中某个路径或者某个词汇，那么，iterm2 就自动复制了。 　　</li>\n<li>另一种是无鼠标模式，<code>command + f</code>,弹出 iterm2 的查找模式，输入要查找并复制的内容的前几个字母，确认找到的是自己的内容之- 后，输入 tab，查找窗口将自动变化内容，并将其复制。如果输入的是 s- hift+tab，则自动将查找内容的左边选中并复制。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"标签\"><a href=\"#标签\" class=\"headerlink\" title=\"标签\"></a>标签</h1><ul>\n<li>新建标签：<code>command + t</code></li>\n<li>关闭标签：<code>command + w</code></li>\n<li>切换标签：<code>command + 数字</code> 或 <code>command + 左右方向键</code></li>\n<li>切换全屏：<code>command + enter</code></li>\n</ul>\n<h1 id=\"分屏\"><a href=\"#分屏\" class=\"headerlink\" title=\"分屏\"></a>分屏</h1><ul>\n<li>垂直分屏：command + d</li>\n<li>水平分屏：command + shift + d</li>\n<li>切换屏幕：command + option + 方向键 command + [ 或 command + ]</li>\n</ul>\n<h1 id=\"命令编辑\"><a href=\"#命令编辑\" class=\"headerlink\" title=\"命令编辑\"></a>命令编辑</h1><h2 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h2><ul>\n<li>删除单词：ctrl + w, 删除光标之前的单词</li>\n<li>删除行：ctrl + u，删除到行首</li>\n<li>删除行：ctrl + k，删除到行尾</li>\n<li>删除字符：删除当前光标<code>ctrl + d</code>，删除光标之前：<code>ctrl + h</code></li>\n<li>清屏1：command + r</li>\n<li>清屏2：ctrl + l</li>\n</ul>\n<h2 id=\"光标移动\"><a href=\"#光标移动\" class=\"headerlink\" title=\"光标移动\"></a>光标移动</h2><ul>\n<li>光标到行首：ctrl + a (同 ⌘ + ←)</li>\n<li>光标到行尾：ctrl + e (同 ⌘ + →)</li>\n<li>单词移动：alt + b / alt + b 按单词前移/后移</li>\n<li>字符移动：ctrl + f / ctrl +b 按字符前移/后移，相当于左右方向</li>\n<li>交换光标处文本：ctrl + t</li>\n</ul>\n<h2 id=\"历史命令\"><a href=\"#历史命令\" class=\"headerlink\" title=\"历史命令\"></a>历史命令</h2><ul>\n<li>查看历史命令：<code>command + ;</code> （输入打头几个字母，然后输入 <code>command + ;</code> iterm2将自动列出之前输入过的类似命令。）</li>\n<li>查看剪贴板历史：command + shift + h</li>\n<li>上一条命令：ctrl + p</li>\n<li>搜索命令历史：ctrl + r</li>\n</ul>\n<h1 id=\"选中即复制\"><a href=\"#选中即复制\" class=\"headerlink\" title=\"选中即复制\"></a>选中即复制</h1><p>iterm2 有 2 种好用的选中即复制模式。</p>\n<ul>\n<li>一种是用鼠标，在 iterm2 中，选中某个路径或者某个词汇，那么，iterm2 就自动复制了。 　　</li>\n<li>另一种是无鼠标模式，<code>command + f</code>,弹出 iterm2 的查找模式，输入要查找并复制的内容的前几个字母，确认找到的是自己的内容之- 后，输入 tab，查找窗口将自动变化内容，并将其复制。如果输入的是 s- hift+tab，则自动将查找内容的左边选中并复制。</li>\n</ul>\n"},{"title":"scala 数据结构 array list tuple","date":"2018-05-20T02:11:31.000Z","_content":"\n# Array 类型参数化数组\n\nscala Array 的初始化\n\n``` java\n// 简洁的方法创造和初始化：\nval numNames = Array(\"zero\", \"one\", \"two\")\n\n// 更罗嗦的调用 apply 方法：\nval numNames2 = Array.apply(\"zero\", \"one\", \"two\") \n```\n\n``` java\nobject HelloWorld \n{\n\n    def main(args: Array[String]) \n    {\n      val greetStrings = new Array[String](3)  \n\n      greetStrings(0) = \"Scala: Hello\" \n      greetStrings(1) = \", \" \n      greetStrings(2) = \"world!\\n\" \n      for (i <- 0 to 2) \n           print(greetStrings(i)) \n    }\n\n}\n// 输出结果：Scala: Hello, world!\n```\n\nScala里的数组是通过把索引放在圆括号里面访问的，而不是像Java那样放在方括号里。所以数组的第零个元素是greetStrings(0)，不是greetStrings[0]。\n\n`val` 的概念: 当你用val定义一个变量，那么这个变量就不能重新赋值，但它指向的对象却仍可以改变。\n\n> 在本例中，你不能把greetStrings重新赋值成不同的数组；greetStrings将永远指向那个它被初始化时候指向的同一个Array[String]实例。但是你能一遍遍修改那个Array[String]的元素，因此数组本身是可变的。\n\n# 使用列表【List】\n\nScala `Array` 数组是一个所有对象都共享相同类型的可变序列。比方说Array[String]仅包含String。尽管实例化之后你无法改变Array的长度，它的元素值却是可变的。因此，Array是可变的对象。\n\nScala的List类是共享相同类型的不可变对象序列。\n\n和数组一样，List[String]包含的仅仅是String。 \nScala的List不同于Java的java.util.List，总是不可变的（而Java的List可变）。\n\n``` java\n// 创建一个Scala的List很简单\nval oneTwoThree = List(1, 2, 3)\n\n```\n上述代码完成了一个新的叫做oneTwoThree的val，并已经用带有整数元素值1，2和3的新List[Int]初始化。\n\n## List 操作\n\n这个List可以这么用：\n\n``` java\nval oneTwo = List(1, 2)  \nval threeFour = List(3, 4) \nval oneTwoThreeFour = oneTwo ::: threeFour  // ::: 拼接List\n\nprintln(oneTwo + \" 和 \" + threeFour + \" 是不可变的\")  \nprintln(oneTwoThreeFour + \" 是个新列表了\")\n\n// 运行结果:\n// List(1, 2) 和 List(3, 4) 是不可变的\n// List(1, 2, 3, 4) 是个新列表了\n```\n\nList最常用的操作符是发音为”cons”的” :: “. 例如，\n\n``` java\nval twoThree = List(2, 3)\nval oneTwoThree = 1 :: twoThree  // 拼接元素 和 List\nprintln(oneTwoThree) \n\n// 结果为：List(1, 2, 3) \n```\n\n类List没有提供append操作。 \n如果你想通过添加元素来构造列表： \n- 前缀进去，完成之后再调用reverse； \n- 使用ListBuffer，一种提供append操作的可变列表，完成之后调用toList。\n\n# 使用元组【Tuple】\n\n另一种有用的容器对象是元组：tuple。与列表一样，元组也是不可变的，但与列表不同，元组可以包含不同类型的元素。\n\n列表应该是List[Int]或List[String]的样子，元组可以同时拥有Int和String。\n\nScala里你可以简单地返回一个元组。 \n而且这么做的确简单：实例化一个装有一些对象的新元组，只要把这些对象放在括号里，并用逗号分隔即可。 \n一旦你已经实例化了一个元组，你可以用点号，下划线和一个基于1的元素索引访问它。\n\n一个例子：\n\n``` java\nval pair = (99, \"Luftballons\")  //Scala推断元组类型为Tuple2[Int, String]，并把它赋给变量pair。\nprintln(pair._1)                //访问_1字段，从而输出第一个元素，99。\nprintln(pair._2)                \n\n// 运行结果\n// 99\n// Luftballons\n```\n\n元组第一个元素是以99为值的Int，第二个是”luftballons”为值的String。\n\n元组的实际类型取决于它含有的元素数量和这些元素的类型。 \n因此，(99, “Luftballons”)的类型是Tuple2[Int, String]。\n\n类似地，(‘u’, ‘r’, ‘the’, 1, 4, “me”)是Tuple6[Char, Char, String, Int, Int, String]。\n\n## 访问元组的元素\n\n为什么你不能像访问List里的元素那样访问元组的，就像pair(0)？ \n因为List的apply方法始终返回同样的类型，但是元组里的或许类型不同。 \n_1可以有一个结果类型，_2是另外一个。 \n\n> 另：元组元素编号从1开始。\n\n# 使用Set和Map\n\n当问题讨论到集和映射，Scala同样提供了可变和不可变的替代品，不过用了不同的办法。\n\n对于集和映射，Scala把可变性建模在类继承中。\n\n例如，Scala的API包含了集的一个基本特质：trait，特质这个概念接近于Java的接口。\n\nScala于是提供了两个子特质，一个是可变的集，另一个是不可变的集。这三个特质都共享同样的简化名，Set。\n\n如果你想要使用HashSet，你可以根据你的需要选择可变的或不可变的变体。\n\n创造集的缺省方法实例：\n\n``` java\nvar jetSet = Set(\"Boeing\", \"Airbus\")  //定义了名为jetSet的新var，包含两个字串\njetSet += \"Lear\"                      // jetSet = jetSet + \"Lear\" \nprintln(jetSet.contains(\"Cessna\"))    //打印输出集是否包含字串\"Cessna\"。\nprintln(jetSet.contains(\"Lear\"))      //打印输出集是否包含字串\"Lear\"。\n\n// 运行结果：\n// false\n// true\n```\n\n需要不可变集，就需要使用一个引用：import，如下所示：\n\n``` java\nimport scala.collection.mutable.Set  \n\nval movieSet = Set(\"Hitch\", \"Poltergeist\")  \nmovieSet += \"Shrek\" \nprintln(movieSet)  \n\n// 运行结果：\n// Set(Poltergeist, Shrek, Hitch)\n```\n\n需要一个不可变的HashSet，你可以这么做：\n\n``` java\nimport scala.collection.immutable.HashSet  \nval hashSet = HashSet(\"Tomatoes\", \"Chilies\")  \nprintln(hashSet + \"Coriander\") \n\n// 运行结果\n// Set(Chilies, Tomatoes, Coriander)\n```\n\nMap是Scala里另一种有用的集合类。 \n和集一样，Scala采用了类继承机制提供了可变的和不可变的两种版本的Map。\n\n`scala.collection` 包里面有一个基础Map特质和两个子特质Map： \n可变的Map在scala.collection.mutable里，不可变的在scala.collection.immutable里。\n\n可变映射的创造过程：\n\n``` java\nimport scala.collection.mutable.Map  \n\nval treasureMap = Map[Int, String]()  \ntreasureMap += (1 -> \"我在\")  \ntreasureMap += (2 -> \"学习\")  \ntreasureMap += (3 -> \"Scala\")  \nprintln(treasureMap(1) + treasureMap(2) + treasureMap(3)) \n\n// 运行结果：\n// 我在学习Scala.\n```\n\n至于不可变映射，就不用引用任何类了，因为不可变映射是缺省的，代码例子：\n\n``` java\nval romanNumeral = Map(      \n        1 -> \"我\", 2 -> \"是\", 3 -> \"缺\", 4 -> \"省\", 5 -> \"的\" )  \nprintln(romanNumeral(1) + romanNumeral(2) + romanNumeral(3) + romanNumeral(4) + romanNumeral(5))  \n\n// 运行结果：\n// 我是缺省的\n```","source":"_posts/201805-scala-array-list-tuple-and-so-on.md","raw":"---\ntitle: scala 数据结构 array list tuple\ndate: 2018-05-20 10:11:31\ntags:\n---\n\n# Array 类型参数化数组\n\nscala Array 的初始化\n\n``` java\n// 简洁的方法创造和初始化：\nval numNames = Array(\"zero\", \"one\", \"two\")\n\n// 更罗嗦的调用 apply 方法：\nval numNames2 = Array.apply(\"zero\", \"one\", \"two\") \n```\n\n``` java\nobject HelloWorld \n{\n\n    def main(args: Array[String]) \n    {\n      val greetStrings = new Array[String](3)  \n\n      greetStrings(0) = \"Scala: Hello\" \n      greetStrings(1) = \", \" \n      greetStrings(2) = \"world!\\n\" \n      for (i <- 0 to 2) \n           print(greetStrings(i)) \n    }\n\n}\n// 输出结果：Scala: Hello, world!\n```\n\nScala里的数组是通过把索引放在圆括号里面访问的，而不是像Java那样放在方括号里。所以数组的第零个元素是greetStrings(0)，不是greetStrings[0]。\n\n`val` 的概念: 当你用val定义一个变量，那么这个变量就不能重新赋值，但它指向的对象却仍可以改变。\n\n> 在本例中，你不能把greetStrings重新赋值成不同的数组；greetStrings将永远指向那个它被初始化时候指向的同一个Array[String]实例。但是你能一遍遍修改那个Array[String]的元素，因此数组本身是可变的。\n\n# 使用列表【List】\n\nScala `Array` 数组是一个所有对象都共享相同类型的可变序列。比方说Array[String]仅包含String。尽管实例化之后你无法改变Array的长度，它的元素值却是可变的。因此，Array是可变的对象。\n\nScala的List类是共享相同类型的不可变对象序列。\n\n和数组一样，List[String]包含的仅仅是String。 \nScala的List不同于Java的java.util.List，总是不可变的（而Java的List可变）。\n\n``` java\n// 创建一个Scala的List很简单\nval oneTwoThree = List(1, 2, 3)\n\n```\n上述代码完成了一个新的叫做oneTwoThree的val，并已经用带有整数元素值1，2和3的新List[Int]初始化。\n\n## List 操作\n\n这个List可以这么用：\n\n``` java\nval oneTwo = List(1, 2)  \nval threeFour = List(3, 4) \nval oneTwoThreeFour = oneTwo ::: threeFour  // ::: 拼接List\n\nprintln(oneTwo + \" 和 \" + threeFour + \" 是不可变的\")  \nprintln(oneTwoThreeFour + \" 是个新列表了\")\n\n// 运行结果:\n// List(1, 2) 和 List(3, 4) 是不可变的\n// List(1, 2, 3, 4) 是个新列表了\n```\n\nList最常用的操作符是发音为”cons”的” :: “. 例如，\n\n``` java\nval twoThree = List(2, 3)\nval oneTwoThree = 1 :: twoThree  // 拼接元素 和 List\nprintln(oneTwoThree) \n\n// 结果为：List(1, 2, 3) \n```\n\n类List没有提供append操作。 \n如果你想通过添加元素来构造列表： \n- 前缀进去，完成之后再调用reverse； \n- 使用ListBuffer，一种提供append操作的可变列表，完成之后调用toList。\n\n# 使用元组【Tuple】\n\n另一种有用的容器对象是元组：tuple。与列表一样，元组也是不可变的，但与列表不同，元组可以包含不同类型的元素。\n\n列表应该是List[Int]或List[String]的样子，元组可以同时拥有Int和String。\n\nScala里你可以简单地返回一个元组。 \n而且这么做的确简单：实例化一个装有一些对象的新元组，只要把这些对象放在括号里，并用逗号分隔即可。 \n一旦你已经实例化了一个元组，你可以用点号，下划线和一个基于1的元素索引访问它。\n\n一个例子：\n\n``` java\nval pair = (99, \"Luftballons\")  //Scala推断元组类型为Tuple2[Int, String]，并把它赋给变量pair。\nprintln(pair._1)                //访问_1字段，从而输出第一个元素，99。\nprintln(pair._2)                \n\n// 运行结果\n// 99\n// Luftballons\n```\n\n元组第一个元素是以99为值的Int，第二个是”luftballons”为值的String。\n\n元组的实际类型取决于它含有的元素数量和这些元素的类型。 \n因此，(99, “Luftballons”)的类型是Tuple2[Int, String]。\n\n类似地，(‘u’, ‘r’, ‘the’, 1, 4, “me”)是Tuple6[Char, Char, String, Int, Int, String]。\n\n## 访问元组的元素\n\n为什么你不能像访问List里的元素那样访问元组的，就像pair(0)？ \n因为List的apply方法始终返回同样的类型，但是元组里的或许类型不同。 \n_1可以有一个结果类型，_2是另外一个。 \n\n> 另：元组元素编号从1开始。\n\n# 使用Set和Map\n\n当问题讨论到集和映射，Scala同样提供了可变和不可变的替代品，不过用了不同的办法。\n\n对于集和映射，Scala把可变性建模在类继承中。\n\n例如，Scala的API包含了集的一个基本特质：trait，特质这个概念接近于Java的接口。\n\nScala于是提供了两个子特质，一个是可变的集，另一个是不可变的集。这三个特质都共享同样的简化名，Set。\n\n如果你想要使用HashSet，你可以根据你的需要选择可变的或不可变的变体。\n\n创造集的缺省方法实例：\n\n``` java\nvar jetSet = Set(\"Boeing\", \"Airbus\")  //定义了名为jetSet的新var，包含两个字串\njetSet += \"Lear\"                      // jetSet = jetSet + \"Lear\" \nprintln(jetSet.contains(\"Cessna\"))    //打印输出集是否包含字串\"Cessna\"。\nprintln(jetSet.contains(\"Lear\"))      //打印输出集是否包含字串\"Lear\"。\n\n// 运行结果：\n// false\n// true\n```\n\n需要不可变集，就需要使用一个引用：import，如下所示：\n\n``` java\nimport scala.collection.mutable.Set  \n\nval movieSet = Set(\"Hitch\", \"Poltergeist\")  \nmovieSet += \"Shrek\" \nprintln(movieSet)  \n\n// 运行结果：\n// Set(Poltergeist, Shrek, Hitch)\n```\n\n需要一个不可变的HashSet，你可以这么做：\n\n``` java\nimport scala.collection.immutable.HashSet  \nval hashSet = HashSet(\"Tomatoes\", \"Chilies\")  \nprintln(hashSet + \"Coriander\") \n\n// 运行结果\n// Set(Chilies, Tomatoes, Coriander)\n```\n\nMap是Scala里另一种有用的集合类。 \n和集一样，Scala采用了类继承机制提供了可变的和不可变的两种版本的Map。\n\n`scala.collection` 包里面有一个基础Map特质和两个子特质Map： \n可变的Map在scala.collection.mutable里，不可变的在scala.collection.immutable里。\n\n可变映射的创造过程：\n\n``` java\nimport scala.collection.mutable.Map  \n\nval treasureMap = Map[Int, String]()  \ntreasureMap += (1 -> \"我在\")  \ntreasureMap += (2 -> \"学习\")  \ntreasureMap += (3 -> \"Scala\")  \nprintln(treasureMap(1) + treasureMap(2) + treasureMap(3)) \n\n// 运行结果：\n// 我在学习Scala.\n```\n\n至于不可变映射，就不用引用任何类了，因为不可变映射是缺省的，代码例子：\n\n``` java\nval romanNumeral = Map(      \n        1 -> \"我\", 2 -> \"是\", 3 -> \"缺\", 4 -> \"省\", 5 -> \"的\" )  \nprintln(romanNumeral(1) + romanNumeral(2) + romanNumeral(3) + romanNumeral(4) + romanNumeral(5))  \n\n// 运行结果：\n// 我是缺省的\n```","slug":"scala-array-list-tuple-and-so-on","published":1,"updated":"2018-06-23T02:54:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xf000an61d4secgimc","content":"<h1 id=\"Array-类型参数化数组\"><a href=\"#Array-类型参数化数组\" class=\"headerlink\" title=\"Array 类型参数化数组\"></a>Array 类型参数化数组</h1><p>scala Array 的初始化</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 简洁的方法创造和初始化：</span></span><br><span class=\"line\">val numNames = Array(<span class=\"string\">\"zero\"</span>, <span class=\"string\">\"one\"</span>, <span class=\"string\">\"two\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 更罗嗦的调用 apply 方法：</span></span><br><span class=\"line\">val numNames2 = Array.apply(<span class=\"string\">\"zero\"</span>, <span class=\"string\">\"one\"</span>, <span class=\"string\">\"two\"</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">object HelloWorld </span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\">def <span class=\"title\">main</span><span class=\"params\">(args: Array[String])</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">      val greetStrings = <span class=\"keyword\">new</span> Array[String](<span class=\"number\">3</span>)  </span><br><span class=\"line\"></span><br><span class=\"line\">      greetStrings(<span class=\"number\">0</span>) = <span class=\"string\">\"Scala: Hello\"</span> </span><br><span class=\"line\">      greetStrings(<span class=\"number\">1</span>) = <span class=\"string\">\", \"</span> </span><br><span class=\"line\">      greetStrings(<span class=\"number\">2</span>) = <span class=\"string\">\"world!\\n\"</span> </span><br><span class=\"line\">      <span class=\"keyword\">for</span> (i &lt;- <span class=\"number\">0</span> to <span class=\"number\">2</span>) </span><br><span class=\"line\">           print(greetStrings(i)) </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 输出结果：Scala: Hello, world!</span></span><br></pre></td></tr></table></figure>\n<p>Scala里的数组是通过把索引放在圆括号里面访问的，而不是像Java那样放在方括号里。所以数组的第零个元素是greetStrings(0)，不是greetStrings[0]。</p>\n<p><code>val</code> 的概念: 当你用val定义一个变量，那么这个变量就不能重新赋值，但它指向的对象却仍可以改变。</p>\n<blockquote>\n<p>在本例中，你不能把greetStrings重新赋值成不同的数组；greetStrings将永远指向那个它被初始化时候指向的同一个Array[String]实例。但是你能一遍遍修改那个Array[String]的元素，因此数组本身是可变的。</p>\n</blockquote>\n<h1 id=\"使用列表【List】\"><a href=\"#使用列表【List】\" class=\"headerlink\" title=\"使用列表【List】\"></a>使用列表【List】</h1><p>Scala <code>Array</code> 数组是一个所有对象都共享相同类型的可变序列。比方说Array[String]仅包含String。尽管实例化之后你无法改变Array的长度，它的元素值却是可变的。因此，Array是可变的对象。</p>\n<p>Scala的List类是共享相同类型的不可变对象序列。</p>\n<p>和数组一样，List[String]包含的仅仅是String。<br>Scala的List不同于Java的java.util.List，总是不可变的（而Java的List可变）。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 创建一个Scala的List很简单</span></span><br><span class=\"line\">val oneTwoThree = List(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n<p>上述代码完成了一个新的叫做oneTwoThree的val，并已经用带有整数元素值1，2和3的新List[Int]初始化。</p>\n<h2 id=\"List-操作\"><a href=\"#List-操作\" class=\"headerlink\" title=\"List 操作\"></a>List 操作</h2><p>这个List可以这么用：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val oneTwo = List(<span class=\"number\">1</span>, <span class=\"number\">2</span>)  </span><br><span class=\"line\">val threeFour = List(<span class=\"number\">3</span>, <span class=\"number\">4</span>) </span><br><span class=\"line\">val oneTwoThreeFour = oneTwo ::: threeFour  <span class=\"comment\">// ::: 拼接List</span></span><br><span class=\"line\"></span><br><span class=\"line\">println(oneTwo + <span class=\"string\">\" 和 \"</span> + threeFour + <span class=\"string\">\" 是不可变的\"</span>)  </span><br><span class=\"line\">println(oneTwoThreeFour + <span class=\"string\">\" 是个新列表了\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果:</span></span><br><span class=\"line\"><span class=\"comment\">// List(1, 2) 和 List(3, 4) 是不可变的</span></span><br><span class=\"line\"><span class=\"comment\">// List(1, 2, 3, 4) 是个新列表了</span></span><br></pre></td></tr></table></figure>\n<p>List最常用的操作符是发音为”cons”的” :: “. 例如，</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val twoThree = List(<span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">val oneTwoThree = <span class=\"number\">1</span> :: twoThree  <span class=\"comment\">// 拼接元素 和 List</span></span><br><span class=\"line\">println(oneTwoThree) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 结果为：List(1, 2, 3)</span></span><br></pre></td></tr></table></figure>\n<p>类List没有提供append操作。<br>如果你想通过添加元素来构造列表： </p>\n<ul>\n<li>前缀进去，完成之后再调用reverse； </li>\n<li>使用ListBuffer，一种提供append操作的可变列表，完成之后调用toList。</li>\n</ul>\n<h1 id=\"使用元组【Tuple】\"><a href=\"#使用元组【Tuple】\" class=\"headerlink\" title=\"使用元组【Tuple】\"></a>使用元组【Tuple】</h1><p>另一种有用的容器对象是元组：tuple。与列表一样，元组也是不可变的，但与列表不同，元组可以包含不同类型的元素。</p>\n<p>列表应该是List[Int]或List[String]的样子，元组可以同时拥有Int和String。</p>\n<p>Scala里你可以简单地返回一个元组。<br>而且这么做的确简单：实例化一个装有一些对象的新元组，只要把这些对象放在括号里，并用逗号分隔即可。<br>一旦你已经实例化了一个元组，你可以用点号，下划线和一个基于1的元素索引访问它。</p>\n<p>一个例子：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val pair = (<span class=\"number\">99</span>, <span class=\"string\">\"Luftballons\"</span>)  <span class=\"comment\">//Scala推断元组类型为Tuple2[Int, String]，并把它赋给变量pair。</span></span><br><span class=\"line\">println(pair._1)                <span class=\"comment\">//访问_1字段，从而输出第一个元素，99。</span></span><br><span class=\"line\">println(pair._2)                </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果</span></span><br><span class=\"line\"><span class=\"comment\">// 99</span></span><br><span class=\"line\"><span class=\"comment\">// Luftballons</span></span><br></pre></td></tr></table></figure>\n<p>元组第一个元素是以99为值的Int，第二个是”luftballons”为值的String。</p>\n<p>元组的实际类型取决于它含有的元素数量和这些元素的类型。<br>因此，(99, “Luftballons”)的类型是Tuple2[Int, String]。</p>\n<p>类似地，(‘u’, ‘r’, ‘the’, 1, 4, “me”)是Tuple6[Char, Char, String, Int, Int, String]。</p>\n<h2 id=\"访问元组的元素\"><a href=\"#访问元组的元素\" class=\"headerlink\" title=\"访问元组的元素\"></a>访问元组的元素</h2><p>为什么你不能像访问List里的元素那样访问元组的，就像pair(0)？<br>因为List的apply方法始终返回同样的类型，但是元组里的或许类型不同。<br>_1可以有一个结果类型，_2是另外一个。 </p>\n<blockquote>\n<p>另：元组元素编号从1开始。</p>\n</blockquote>\n<h1 id=\"使用Set和Map\"><a href=\"#使用Set和Map\" class=\"headerlink\" title=\"使用Set和Map\"></a>使用Set和Map</h1><p>当问题讨论到集和映射，Scala同样提供了可变和不可变的替代品，不过用了不同的办法。</p>\n<p>对于集和映射，Scala把可变性建模在类继承中。</p>\n<p>例如，Scala的API包含了集的一个基本特质：trait，特质这个概念接近于Java的接口。</p>\n<p>Scala于是提供了两个子特质，一个是可变的集，另一个是不可变的集。这三个特质都共享同样的简化名，Set。</p>\n<p>如果你想要使用HashSet，你可以根据你的需要选择可变的或不可变的变体。</p>\n<p>创造集的缺省方法实例：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var jetSet = Set(<span class=\"string\">\"Boeing\"</span>, <span class=\"string\">\"Airbus\"</span>)  <span class=\"comment\">//定义了名为jetSet的新var，包含两个字串</span></span><br><span class=\"line\">jetSet += <span class=\"string\">\"Lear\"</span>                      <span class=\"comment\">// jetSet = jetSet + \"Lear\" </span></span><br><span class=\"line\">println(jetSet.contains(<span class=\"string\">\"Cessna\"</span>))    <span class=\"comment\">//打印输出集是否包含字串\"Cessna\"。</span></span><br><span class=\"line\">println(jetSet.contains(<span class=\"string\">\"Lear\"</span>))      <span class=\"comment\">//打印输出集是否包含字串\"Lear\"。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果：</span></span><br><span class=\"line\"><span class=\"comment\">// false</span></span><br><span class=\"line\"><span class=\"comment\">// true</span></span><br></pre></td></tr></table></figure>\n<p>需要不可变集，就需要使用一个引用：import，如下所示：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scala.collection.mutable.Set  </span><br><span class=\"line\"></span><br><span class=\"line\">val movieSet = Set(<span class=\"string\">\"Hitch\"</span>, <span class=\"string\">\"Poltergeist\"</span>)  </span><br><span class=\"line\">movieSet += <span class=\"string\">\"Shrek\"</span> </span><br><span class=\"line\">println(movieSet)  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果：</span></span><br><span class=\"line\"><span class=\"comment\">// Set(Poltergeist, Shrek, Hitch)</span></span><br></pre></td></tr></table></figure>\n<p>需要一个不可变的HashSet，你可以这么做：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scala.collection.immutable.HashSet  </span><br><span class=\"line\">val hashSet = HashSet(<span class=\"string\">\"Tomatoes\"</span>, <span class=\"string\">\"Chilies\"</span>)  </span><br><span class=\"line\">println(hashSet + <span class=\"string\">\"Coriander\"</span>) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果</span></span><br><span class=\"line\"><span class=\"comment\">// Set(Chilies, Tomatoes, Coriander)</span></span><br></pre></td></tr></table></figure>\n<p>Map是Scala里另一种有用的集合类。<br>和集一样，Scala采用了类继承机制提供了可变的和不可变的两种版本的Map。</p>\n<p><code>scala.collection</code> 包里面有一个基础Map特质和两个子特质Map：<br>可变的Map在scala.collection.mutable里，不可变的在scala.collection.immutable里。</p>\n<p>可变映射的创造过程：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scala.collection.mutable.Map  </span><br><span class=\"line\"></span><br><span class=\"line\">val treasureMap = Map[Int, String]()  </span><br><span class=\"line\">treasureMap += (<span class=\"number\">1</span> -&gt; <span class=\"string\">\"我在\"</span>)  </span><br><span class=\"line\">treasureMap += (<span class=\"number\">2</span> -&gt; <span class=\"string\">\"学习\"</span>)  </span><br><span class=\"line\">treasureMap += (<span class=\"number\">3</span> -&gt; <span class=\"string\">\"Scala\"</span>)  </span><br><span class=\"line\">println(treasureMap(<span class=\"number\">1</span>) + treasureMap(<span class=\"number\">2</span>) + treasureMap(<span class=\"number\">3</span>)) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果：</span></span><br><span class=\"line\"><span class=\"comment\">// 我在学习Scala.</span></span><br></pre></td></tr></table></figure>\n<p>至于不可变映射，就不用引用任何类了，因为不可变映射是缺省的，代码例子：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val romanNumeral = Map(      </span><br><span class=\"line\">        <span class=\"number\">1</span> -&gt; <span class=\"string\">\"我\"</span>, <span class=\"number\">2</span> -&gt; <span class=\"string\">\"是\"</span>, <span class=\"number\">3</span> -&gt; <span class=\"string\">\"缺\"</span>, <span class=\"number\">4</span> -&gt; <span class=\"string\">\"省\"</span>, <span class=\"number\">5</span> -&gt; <span class=\"string\">\"的\"</span> )  </span><br><span class=\"line\">println(romanNumeral(<span class=\"number\">1</span>) + romanNumeral(<span class=\"number\">2</span>) + romanNumeral(<span class=\"number\">3</span>) + romanNumeral(<span class=\"number\">4</span>) + romanNumeral(<span class=\"number\">5</span>))  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果：</span></span><br><span class=\"line\"><span class=\"comment\">// 我是缺省的</span></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Array-类型参数化数组\"><a href=\"#Array-类型参数化数组\" class=\"headerlink\" title=\"Array 类型参数化数组\"></a>Array 类型参数化数组</h1><p>scala Array 的初始化</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 简洁的方法创造和初始化：</span></span><br><span class=\"line\">val numNames = Array(<span class=\"string\">\"zero\"</span>, <span class=\"string\">\"one\"</span>, <span class=\"string\">\"two\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 更罗嗦的调用 apply 方法：</span></span><br><span class=\"line\">val numNames2 = Array.apply(<span class=\"string\">\"zero\"</span>, <span class=\"string\">\"one\"</span>, <span class=\"string\">\"two\"</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">object HelloWorld </span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\">def <span class=\"title\">main</span><span class=\"params\">(args: Array[String])</span> </span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">      val greetStrings = <span class=\"keyword\">new</span> Array[String](<span class=\"number\">3</span>)  </span><br><span class=\"line\"></span><br><span class=\"line\">      greetStrings(<span class=\"number\">0</span>) = <span class=\"string\">\"Scala: Hello\"</span> </span><br><span class=\"line\">      greetStrings(<span class=\"number\">1</span>) = <span class=\"string\">\", \"</span> </span><br><span class=\"line\">      greetStrings(<span class=\"number\">2</span>) = <span class=\"string\">\"world!\\n\"</span> </span><br><span class=\"line\">      <span class=\"keyword\">for</span> (i &lt;- <span class=\"number\">0</span> to <span class=\"number\">2</span>) </span><br><span class=\"line\">           print(greetStrings(i)) </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 输出结果：Scala: Hello, world!</span></span><br></pre></td></tr></table></figure>\n<p>Scala里的数组是通过把索引放在圆括号里面访问的，而不是像Java那样放在方括号里。所以数组的第零个元素是greetStrings(0)，不是greetStrings[0]。</p>\n<p><code>val</code> 的概念: 当你用val定义一个变量，那么这个变量就不能重新赋值，但它指向的对象却仍可以改变。</p>\n<blockquote>\n<p>在本例中，你不能把greetStrings重新赋值成不同的数组；greetStrings将永远指向那个它被初始化时候指向的同一个Array[String]实例。但是你能一遍遍修改那个Array[String]的元素，因此数组本身是可变的。</p>\n</blockquote>\n<h1 id=\"使用列表【List】\"><a href=\"#使用列表【List】\" class=\"headerlink\" title=\"使用列表【List】\"></a>使用列表【List】</h1><p>Scala <code>Array</code> 数组是一个所有对象都共享相同类型的可变序列。比方说Array[String]仅包含String。尽管实例化之后你无法改变Array的长度，它的元素值却是可变的。因此，Array是可变的对象。</p>\n<p>Scala的List类是共享相同类型的不可变对象序列。</p>\n<p>和数组一样，List[String]包含的仅仅是String。<br>Scala的List不同于Java的java.util.List，总是不可变的（而Java的List可变）。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 创建一个Scala的List很简单</span></span><br><span class=\"line\">val oneTwoThree = List(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br></pre></td></tr></table></figure>\n<p>上述代码完成了一个新的叫做oneTwoThree的val，并已经用带有整数元素值1，2和3的新List[Int]初始化。</p>\n<h2 id=\"List-操作\"><a href=\"#List-操作\" class=\"headerlink\" title=\"List 操作\"></a>List 操作</h2><p>这个List可以这么用：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val oneTwo = List(<span class=\"number\">1</span>, <span class=\"number\">2</span>)  </span><br><span class=\"line\">val threeFour = List(<span class=\"number\">3</span>, <span class=\"number\">4</span>) </span><br><span class=\"line\">val oneTwoThreeFour = oneTwo ::: threeFour  <span class=\"comment\">// ::: 拼接List</span></span><br><span class=\"line\"></span><br><span class=\"line\">println(oneTwo + <span class=\"string\">\" 和 \"</span> + threeFour + <span class=\"string\">\" 是不可变的\"</span>)  </span><br><span class=\"line\">println(oneTwoThreeFour + <span class=\"string\">\" 是个新列表了\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果:</span></span><br><span class=\"line\"><span class=\"comment\">// List(1, 2) 和 List(3, 4) 是不可变的</span></span><br><span class=\"line\"><span class=\"comment\">// List(1, 2, 3, 4) 是个新列表了</span></span><br></pre></td></tr></table></figure>\n<p>List最常用的操作符是发音为”cons”的” :: “. 例如，</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val twoThree = List(<span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">val oneTwoThree = <span class=\"number\">1</span> :: twoThree  <span class=\"comment\">// 拼接元素 和 List</span></span><br><span class=\"line\">println(oneTwoThree) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 结果为：List(1, 2, 3)</span></span><br></pre></td></tr></table></figure>\n<p>类List没有提供append操作。<br>如果你想通过添加元素来构造列表： </p>\n<ul>\n<li>前缀进去，完成之后再调用reverse； </li>\n<li>使用ListBuffer，一种提供append操作的可变列表，完成之后调用toList。</li>\n</ul>\n<h1 id=\"使用元组【Tuple】\"><a href=\"#使用元组【Tuple】\" class=\"headerlink\" title=\"使用元组【Tuple】\"></a>使用元组【Tuple】</h1><p>另一种有用的容器对象是元组：tuple。与列表一样，元组也是不可变的，但与列表不同，元组可以包含不同类型的元素。</p>\n<p>列表应该是List[Int]或List[String]的样子，元组可以同时拥有Int和String。</p>\n<p>Scala里你可以简单地返回一个元组。<br>而且这么做的确简单：实例化一个装有一些对象的新元组，只要把这些对象放在括号里，并用逗号分隔即可。<br>一旦你已经实例化了一个元组，你可以用点号，下划线和一个基于1的元素索引访问它。</p>\n<p>一个例子：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val pair = (<span class=\"number\">99</span>, <span class=\"string\">\"Luftballons\"</span>)  <span class=\"comment\">//Scala推断元组类型为Tuple2[Int, String]，并把它赋给变量pair。</span></span><br><span class=\"line\">println(pair._1)                <span class=\"comment\">//访问_1字段，从而输出第一个元素，99。</span></span><br><span class=\"line\">println(pair._2)                </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果</span></span><br><span class=\"line\"><span class=\"comment\">// 99</span></span><br><span class=\"line\"><span class=\"comment\">// Luftballons</span></span><br></pre></td></tr></table></figure>\n<p>元组第一个元素是以99为值的Int，第二个是”luftballons”为值的String。</p>\n<p>元组的实际类型取决于它含有的元素数量和这些元素的类型。<br>因此，(99, “Luftballons”)的类型是Tuple2[Int, String]。</p>\n<p>类似地，(‘u’, ‘r’, ‘the’, 1, 4, “me”)是Tuple6[Char, Char, String, Int, Int, String]。</p>\n<h2 id=\"访问元组的元素\"><a href=\"#访问元组的元素\" class=\"headerlink\" title=\"访问元组的元素\"></a>访问元组的元素</h2><p>为什么你不能像访问List里的元素那样访问元组的，就像pair(0)？<br>因为List的apply方法始终返回同样的类型，但是元组里的或许类型不同。<br>_1可以有一个结果类型，_2是另外一个。 </p>\n<blockquote>\n<p>另：元组元素编号从1开始。</p>\n</blockquote>\n<h1 id=\"使用Set和Map\"><a href=\"#使用Set和Map\" class=\"headerlink\" title=\"使用Set和Map\"></a>使用Set和Map</h1><p>当问题讨论到集和映射，Scala同样提供了可变和不可变的替代品，不过用了不同的办法。</p>\n<p>对于集和映射，Scala把可变性建模在类继承中。</p>\n<p>例如，Scala的API包含了集的一个基本特质：trait，特质这个概念接近于Java的接口。</p>\n<p>Scala于是提供了两个子特质，一个是可变的集，另一个是不可变的集。这三个特质都共享同样的简化名，Set。</p>\n<p>如果你想要使用HashSet，你可以根据你的需要选择可变的或不可变的变体。</p>\n<p>创造集的缺省方法实例：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var jetSet = Set(<span class=\"string\">\"Boeing\"</span>, <span class=\"string\">\"Airbus\"</span>)  <span class=\"comment\">//定义了名为jetSet的新var，包含两个字串</span></span><br><span class=\"line\">jetSet += <span class=\"string\">\"Lear\"</span>                      <span class=\"comment\">// jetSet = jetSet + \"Lear\" </span></span><br><span class=\"line\">println(jetSet.contains(<span class=\"string\">\"Cessna\"</span>))    <span class=\"comment\">//打印输出集是否包含字串\"Cessna\"。</span></span><br><span class=\"line\">println(jetSet.contains(<span class=\"string\">\"Lear\"</span>))      <span class=\"comment\">//打印输出集是否包含字串\"Lear\"。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果：</span></span><br><span class=\"line\"><span class=\"comment\">// false</span></span><br><span class=\"line\"><span class=\"comment\">// true</span></span><br></pre></td></tr></table></figure>\n<p>需要不可变集，就需要使用一个引用：import，如下所示：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scala.collection.mutable.Set  </span><br><span class=\"line\"></span><br><span class=\"line\">val movieSet = Set(<span class=\"string\">\"Hitch\"</span>, <span class=\"string\">\"Poltergeist\"</span>)  </span><br><span class=\"line\">movieSet += <span class=\"string\">\"Shrek\"</span> </span><br><span class=\"line\">println(movieSet)  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果：</span></span><br><span class=\"line\"><span class=\"comment\">// Set(Poltergeist, Shrek, Hitch)</span></span><br></pre></td></tr></table></figure>\n<p>需要一个不可变的HashSet，你可以这么做：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scala.collection.immutable.HashSet  </span><br><span class=\"line\">val hashSet = HashSet(<span class=\"string\">\"Tomatoes\"</span>, <span class=\"string\">\"Chilies\"</span>)  </span><br><span class=\"line\">println(hashSet + <span class=\"string\">\"Coriander\"</span>) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果</span></span><br><span class=\"line\"><span class=\"comment\">// Set(Chilies, Tomatoes, Coriander)</span></span><br></pre></td></tr></table></figure>\n<p>Map是Scala里另一种有用的集合类。<br>和集一样，Scala采用了类继承机制提供了可变的和不可变的两种版本的Map。</p>\n<p><code>scala.collection</code> 包里面有一个基础Map特质和两个子特质Map：<br>可变的Map在scala.collection.mutable里，不可变的在scala.collection.immutable里。</p>\n<p>可变映射的创造过程：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> scala.collection.mutable.Map  </span><br><span class=\"line\"></span><br><span class=\"line\">val treasureMap = Map[Int, String]()  </span><br><span class=\"line\">treasureMap += (<span class=\"number\">1</span> -&gt; <span class=\"string\">\"我在\"</span>)  </span><br><span class=\"line\">treasureMap += (<span class=\"number\">2</span> -&gt; <span class=\"string\">\"学习\"</span>)  </span><br><span class=\"line\">treasureMap += (<span class=\"number\">3</span> -&gt; <span class=\"string\">\"Scala\"</span>)  </span><br><span class=\"line\">println(treasureMap(<span class=\"number\">1</span>) + treasureMap(<span class=\"number\">2</span>) + treasureMap(<span class=\"number\">3</span>)) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果：</span></span><br><span class=\"line\"><span class=\"comment\">// 我在学习Scala.</span></span><br></pre></td></tr></table></figure>\n<p>至于不可变映射，就不用引用任何类了，因为不可变映射是缺省的，代码例子：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">val romanNumeral = Map(      </span><br><span class=\"line\">        <span class=\"number\">1</span> -&gt; <span class=\"string\">\"我\"</span>, <span class=\"number\">2</span> -&gt; <span class=\"string\">\"是\"</span>, <span class=\"number\">3</span> -&gt; <span class=\"string\">\"缺\"</span>, <span class=\"number\">4</span> -&gt; <span class=\"string\">\"省\"</span>, <span class=\"number\">5</span> -&gt; <span class=\"string\">\"的\"</span> )  </span><br><span class=\"line\">println(romanNumeral(<span class=\"number\">1</span>) + romanNumeral(<span class=\"number\">2</span>) + romanNumeral(<span class=\"number\">3</span>) + romanNumeral(<span class=\"number\">4</span>) + romanNumeral(<span class=\"number\">5</span>))  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 运行结果：</span></span><br><span class=\"line\"><span class=\"comment\">// 我是缺省的</span></span><br></pre></td></tr></table></figure>"},{"title":"tensorflow 中的 tf.app.flags","date":"2018-05-21T12:29:51.000Z","_content":"\ntf定义了tf.app.flags，用于支持接受命令行传递参数，相当于接受argv\n\n``` python\nimport tensorflow as tf\nflags = tf.app.flags #flags是一个文件：flags.py，用于处理命令行参数的解析工作\n\n# 第一个是参数名称，第二个参数是默认值，第三个是参数描述\nflags.DEFINE_string(\"para_string\", \"default_val\", \"description\") # 定义一个 string\nflags.DEFINE_integer(\"pare_int\", 1000, \"this is an integer\") # 定义一个integer\nflags.DEFINE_bool(\"para_bool\", True, \"description\") # 定义一个 bool\n\n# FLAGS是一个对象，保存了解析后的命令行参数\nFLAGS = flags.FLAGS\ndef main(_):\n    print FLAGS.para_string #调用命令行输入的参数\n\nif __name__ = \"__main__\": # 使用这种方式保证了，如果此文件被其它文件import的时候，不会执行main中的代码\n    tf.app.run() # 解析命令行参数，调用main函数 main(sys.argv)\n```\n\n传入参数方法：\n\n``` bash\n$ python script.py --para_1=value1 --para_2=value2\n# 不传的话，会使用默认值,注意等号左右没有空格\n```","source":"_posts/201805-tensorflow-flags-guide.md","raw":"---\ntitle: tensorflow 中的 tf.app.flags\ndate: 2018-05-21 20:29:51\ntags:\n---\n\ntf定义了tf.app.flags，用于支持接受命令行传递参数，相当于接受argv\n\n``` python\nimport tensorflow as tf\nflags = tf.app.flags #flags是一个文件：flags.py，用于处理命令行参数的解析工作\n\n# 第一个是参数名称，第二个参数是默认值，第三个是参数描述\nflags.DEFINE_string(\"para_string\", \"default_val\", \"description\") # 定义一个 string\nflags.DEFINE_integer(\"pare_int\", 1000, \"this is an integer\") # 定义一个integer\nflags.DEFINE_bool(\"para_bool\", True, \"description\") # 定义一个 bool\n\n# FLAGS是一个对象，保存了解析后的命令行参数\nFLAGS = flags.FLAGS\ndef main(_):\n    print FLAGS.para_string #调用命令行输入的参数\n\nif __name__ = \"__main__\": # 使用这种方式保证了，如果此文件被其它文件import的时候，不会执行main中的代码\n    tf.app.run() # 解析命令行参数，调用main函数 main(sys.argv)\n```\n\n传入参数方法：\n\n``` bash\n$ python script.py --para_1=value1 --para_2=value2\n# 不传的话，会使用默认值,注意等号左右没有空格\n```","slug":"tensorflow-flags-guide","published":1,"updated":"2018-05-28T16:17:13.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xh000dn61dypefgpne","content":"<p>tf定义了tf.app.flags，用于支持接受命令行传递参数，相当于接受argv</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\">flags = tf.app.flags <span class=\"comment\">#flags是一个文件：flags.py，用于处理命令行参数的解析工作</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 第一个是参数名称，第二个参数是默认值，第三个是参数描述</span></span><br><span class=\"line\">flags.DEFINE_string(<span class=\"string\">\"para_string\"</span>, <span class=\"string\">\"default_val\"</span>, <span class=\"string\">\"description\"</span>) <span class=\"comment\"># 定义一个 string</span></span><br><span class=\"line\">flags.DEFINE_integer(<span class=\"string\">\"pare_int\"</span>, <span class=\"number\">1000</span>, <span class=\"string\">\"this is an integer\"</span>) <span class=\"comment\"># 定义一个integer</span></span><br><span class=\"line\">flags.DEFINE_bool(<span class=\"string\">\"para_bool\"</span>, <span class=\"keyword\">True</span>, <span class=\"string\">\"description\"</span>) <span class=\"comment\"># 定义一个 bool</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># FLAGS是一个对象，保存了解析后的命令行参数</span></span><br><span class=\"line\">FLAGS = flags.FLAGS</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">(_)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> FLAGS.para_string <span class=\"comment\">#调用命令行输入的参数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ = <span class=\"string\">\"__main__\"</span>: <span class=\"comment\"># 使用这种方式保证了，如果此文件被其它文件import的时候，不会执行main中的代码</span></span><br><span class=\"line\">    tf.app.run() <span class=\"comment\"># 解析命令行参数，调用main函数 main(sys.argv)</span></span><br></pre></td></tr></table></figure>\n<p>传入参数方法：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ python script.py --para_1=value1 --para_2=value2</span><br><span class=\"line\"><span class=\"comment\"># 不传的话，会使用默认值,注意等号左右没有空格</span></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p>tf定义了tf.app.flags，用于支持接受命令行传递参数，相当于接受argv</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\">flags = tf.app.flags <span class=\"comment\">#flags是一个文件：flags.py，用于处理命令行参数的解析工作</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 第一个是参数名称，第二个参数是默认值，第三个是参数描述</span></span><br><span class=\"line\">flags.DEFINE_string(<span class=\"string\">\"para_string\"</span>, <span class=\"string\">\"default_val\"</span>, <span class=\"string\">\"description\"</span>) <span class=\"comment\"># 定义一个 string</span></span><br><span class=\"line\">flags.DEFINE_integer(<span class=\"string\">\"pare_int\"</span>, <span class=\"number\">1000</span>, <span class=\"string\">\"this is an integer\"</span>) <span class=\"comment\"># 定义一个integer</span></span><br><span class=\"line\">flags.DEFINE_bool(<span class=\"string\">\"para_bool\"</span>, <span class=\"keyword\">True</span>, <span class=\"string\">\"description\"</span>) <span class=\"comment\"># 定义一个 bool</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># FLAGS是一个对象，保存了解析后的命令行参数</span></span><br><span class=\"line\">FLAGS = flags.FLAGS</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">(_)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> FLAGS.para_string <span class=\"comment\">#调用命令行输入的参数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ = <span class=\"string\">\"__main__\"</span>: <span class=\"comment\"># 使用这种方式保证了，如果此文件被其它文件import的时候，不会执行main中的代码</span></span><br><span class=\"line\">    tf.app.run() <span class=\"comment\"># 解析命令行参数，调用main函数 main(sys.argv)</span></span><br></pre></td></tr></table></figure>\n<p>传入参数方法：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ python script.py --para_1=value1 --para_2=value2</span><br><span class=\"line\"><span class=\"comment\"># 不传的话，会使用默认值,注意等号左右没有空格</span></span><br></pre></td></tr></table></figure>"},{"title":"vim使用指南及vim快捷键","date":"2018-05-19T17:12:54.000Z","_content":"\n# 移动光标\n\n``` \nh, j, k, l 上，下，左，右\nctrl-e 移动页面\nctrl-f 上翻一页\nctrl-b 下翻一页\nctrl-u 上翻半页\nctrl-d 下翻半页\nw 跳到下一个字首，按标点或单词分割\nW 跳到下一个字首，长跳，如end-of-line被认为是一个字\ne 跳到下一个字尾\nE 跳到下一个字尾，长跳\nb 跳到上一个字\nB 跳到上一个字，长跳\n0 跳至行首，不管有无缩进，就是跳到第0个字符\n^ 跳至行首的第一个字符\n$ 跳至行尾\ngg 跳至文首\nG 调至文尾\n5gg/5G 调至第5行\ngd 跳至当前光标所在的变量的声明处\nfx 在当前行中找x字符，找到了就跳转至\n; 重复上一个f命令，而不用重复的输入fx\n* 查找光标所在处的单词，向下查找\n# 查找光标所在处的单词，向上查找\n```\n\n# 删除复制\n\n```\ndd 删除光标所在行\ndw 删除一个字(word)\nd/D删除到行末x删除当前字符X删除前一个字符yy复制一行yw复制一个字y/Y 复制到行末\np 粘贴粘贴板的内容到当前行的下面\nP 粘贴粘贴板的内容到当前行的上面\n```\n\n# 插入模式\n\n```\ni 从当前光标处进入插入模式\nI 进入插入模式，并置光标于行首\na 追加模式，置光标于当前光标之后\nA 追加模式，置光标于行末\no 在当前行之下新加一行，并进入插入模式\nO 在当前行之上新加一行，并进入插入模式\nEsc 退出插入模式\n```\n\n# 编辑\n\n```\nJ 将下一行和当前行连接为一行\ncc 删除当前行并进入编辑模式\ncw 删除当前字，并进入编辑模式\nc$ 擦除从当前位置至行末的内容，并进入编辑模式\ns 删除当前字符并进入编辑模式\nS 删除光标所在行并进入编辑模式\nxp 交换当前字符和下一个字符\nu 撤销\nctrl+r 重做\n~ 切换大小写，当前字符\n>> 将当前行右移一个单位\n<< 将当前行左移一个单位(一个tab符)\n== 自动缩进当前行\n```\n\n# 查找\n``` bash\n/pattern 向后搜索字符串pattern\n?pattern 向前搜索字符串pattern\n\"\\c\" 忽略大小写\n\"\\C\" 大小写敏感\nn 下一个匹配(如果是/搜索，则是向下的下一个，?搜索则是向上的下一个)\nN 上一个匹配(同上)\n```\n\n# 替换\n``` bash\n:%s/old/new/g 搜索整个文件，将所有的old替换为new\n:%s/old/new/gc 搜索整个文件，将所有的old替换为new，每次都要你确认是否替换\n```\n\n# 退出编辑器\n\n``` bash\n:w 将缓冲区写入文件，即保存修改\n:wq 保存修改并退出\n:x 保存修改并退出\n:q 退出，如果对缓冲区进行过修改，则会提示\n:q! 强制退出，放弃修改\n```\n\n# 多文件编辑\n\n``` bash\nvim file1.. 同时打开多个文件\n:args 显示当前编辑文件\n:next 切换到下个文件\n:prev 切换到前个文件\n:next！ 不保存当前编辑文件并切换到下个文件\n:prev！ 不保存当前编辑文件并切换到上个文件\n:wnext 保存当前编辑文件并切换到下个文件\n:wprev 保存当前编辑文件并切换到上个文件\n:first 定位首文件\n:last 定位尾文件\nctrl+^ 快速在最近打开的两个文件间切换\n:split[sp] 把当前文件水平分割\n:split file 把当前窗口水平分割, file\n:vsplit[vsp] file 把当前窗口垂直分割, file\n:new file 同split file\n:close 关闭当前窗口\n:only 只显示当前窗口, 关闭所有其他的窗口\n:all 打开所有的窗口\n:vertical all 打开所有的窗口, 垂直打开\n:qall 对所有窗口执行：q操作\n:qall! 对所有窗口执行：q!操作\n:wall 对所有窗口执行：w操作\n:wqall 对所有窗口执行：wq操作\nctrl-w h 跳转到左边的窗口\nctrl-w j 跳转到下面的窗口\nctrl-w k 跳转到上面的窗口\nctrl-w l 跳转到右边的窗口\nctrl-w t 跳转到最顶上的窗口\nctrl-w b 跳转到最底下的窗口\n```\n# 多标签编辑\n\n``` bash\n:tabedit file 在新标签中打开文件file\n:tab split file 在新标签中打开文件file\n:tabp 切换到前一个标签\n:tabn 切换到后一个标签\n:tabc 关闭当前标签\n:tabo 关闭其他标签\ngt 到下一个tab\ngT 到上一个tab\n0gt 跳到第一个tab\n5gt 跳到第五个tab\n```\n\n# 执行shell命令\n\n1、在命令模式下输入\":sh\"，可以运行相当于在字符模式下，到输入结束想回到VIM编辑器中用exit，ctrl+D返回VIM编辑器\n2、可以\"!command\"，运行结束后自动回到VIM编辑器中\n3、用“Ctrl+Z“回到shell，用fg返回编辑\n4、:!make -> 直接在当前目录下运行make指令\n\n# VIM启动项\n-o[n] 以水平分屏的方式打开多个文件\n-O[n] 以垂直分屏的方式打开多个文件\n\n# 自动排版\n在粘贴了一些代码之后，vim变得比较乱，只要执行gg=G就能搞定\n\n# 如何在vim中编译程序\n在vim中可以完成make,而且可以将编译的结果也显示在vim里，先执行 :copen 命令，将结果输出的窗口打开，然后执行 :make\n编译后的结果就显示在了copen打开的小窗口里了，而且用鼠标双击错误信息，就会跳转到发生错误的行。\n\n# buffer操作\n\n## buffer状态\n```\n- （非活动的缓冲区）\na （当前被激活缓冲区）\nh （隐藏的缓冲区）\n% （当前的缓冲区）\n# （交换缓冲区）\n= （只读缓冲区）\n+ （已经更改的缓冲区）\n```\n\n# VIM 操作目录\n## 打开目录\n\n```\nvim .\nvim a-path/\n```\n## 以下操作在操作目录时生效\n```\np,P,t,u,U,x,v,o,r,s\n\nc 使当前打开的目录成为当前目录\nd 创建目录\n% 创建文件\nD 删除文件/目录\n- 转到上层目录\ngb 转到上一个 bookmarked directory\ni 改变目录文件列表方式\n^l 刷新当前打开的目录\n\nmf - 标记文件\nmu - unmark all marked files\nmz - Compress/decompress marked files\ngh 显示/不显示隐藏文件( dot-files)\n^h 编辑隐藏文件列表\na 转换显示模式, all - hide - unhide\nqf diplay infomation about file\nqb list the bookmarked directories and directory traversal history\ngi Display information on file\n\nmb\nmc\nmd - 将标记的文件(mf标记文件)使用 diff 模式\nme - 编辑标记的文件,只显示一个，其余放入 buffer 中\nmh\nmm - move marked files to marked-file target directory\nmc - copy\nmp\nmr\nmt\n```\n\nvim 中复制,移动文件\n```\n1, mt - 移动到的目录\n2, mf - 标记要移动的文件\n3, mc - 移动/复制\n```\n\nR 移动文件\n\n打开当前编辑文件的目录\n\n```\n:Explore\n:Hexplore\n:Nexplore\n:Pexplore\n:Sexplore\n:Texplore\n:Vexplore\n```\n\n[详细使用教程](https://www.cnblogs.com/lijia0511/p/5644566.html)","source":"_posts/201805-vim-guide.md","raw":"---\ntitle: vim使用指南及vim快捷键\ndate: 2018-05-20 01:12:54\ntags: Linux, vim\n---\n\n# 移动光标\n\n``` \nh, j, k, l 上，下，左，右\nctrl-e 移动页面\nctrl-f 上翻一页\nctrl-b 下翻一页\nctrl-u 上翻半页\nctrl-d 下翻半页\nw 跳到下一个字首，按标点或单词分割\nW 跳到下一个字首，长跳，如end-of-line被认为是一个字\ne 跳到下一个字尾\nE 跳到下一个字尾，长跳\nb 跳到上一个字\nB 跳到上一个字，长跳\n0 跳至行首，不管有无缩进，就是跳到第0个字符\n^ 跳至行首的第一个字符\n$ 跳至行尾\ngg 跳至文首\nG 调至文尾\n5gg/5G 调至第5行\ngd 跳至当前光标所在的变量的声明处\nfx 在当前行中找x字符，找到了就跳转至\n; 重复上一个f命令，而不用重复的输入fx\n* 查找光标所在处的单词，向下查找\n# 查找光标所在处的单词，向上查找\n```\n\n# 删除复制\n\n```\ndd 删除光标所在行\ndw 删除一个字(word)\nd/D删除到行末x删除当前字符X删除前一个字符yy复制一行yw复制一个字y/Y 复制到行末\np 粘贴粘贴板的内容到当前行的下面\nP 粘贴粘贴板的内容到当前行的上面\n```\n\n# 插入模式\n\n```\ni 从当前光标处进入插入模式\nI 进入插入模式，并置光标于行首\na 追加模式，置光标于当前光标之后\nA 追加模式，置光标于行末\no 在当前行之下新加一行，并进入插入模式\nO 在当前行之上新加一行，并进入插入模式\nEsc 退出插入模式\n```\n\n# 编辑\n\n```\nJ 将下一行和当前行连接为一行\ncc 删除当前行并进入编辑模式\ncw 删除当前字，并进入编辑模式\nc$ 擦除从当前位置至行末的内容，并进入编辑模式\ns 删除当前字符并进入编辑模式\nS 删除光标所在行并进入编辑模式\nxp 交换当前字符和下一个字符\nu 撤销\nctrl+r 重做\n~ 切换大小写，当前字符\n>> 将当前行右移一个单位\n<< 将当前行左移一个单位(一个tab符)\n== 自动缩进当前行\n```\n\n# 查找\n``` bash\n/pattern 向后搜索字符串pattern\n?pattern 向前搜索字符串pattern\n\"\\c\" 忽略大小写\n\"\\C\" 大小写敏感\nn 下一个匹配(如果是/搜索，则是向下的下一个，?搜索则是向上的下一个)\nN 上一个匹配(同上)\n```\n\n# 替换\n``` bash\n:%s/old/new/g 搜索整个文件，将所有的old替换为new\n:%s/old/new/gc 搜索整个文件，将所有的old替换为new，每次都要你确认是否替换\n```\n\n# 退出编辑器\n\n``` bash\n:w 将缓冲区写入文件，即保存修改\n:wq 保存修改并退出\n:x 保存修改并退出\n:q 退出，如果对缓冲区进行过修改，则会提示\n:q! 强制退出，放弃修改\n```\n\n# 多文件编辑\n\n``` bash\nvim file1.. 同时打开多个文件\n:args 显示当前编辑文件\n:next 切换到下个文件\n:prev 切换到前个文件\n:next！ 不保存当前编辑文件并切换到下个文件\n:prev！ 不保存当前编辑文件并切换到上个文件\n:wnext 保存当前编辑文件并切换到下个文件\n:wprev 保存当前编辑文件并切换到上个文件\n:first 定位首文件\n:last 定位尾文件\nctrl+^ 快速在最近打开的两个文件间切换\n:split[sp] 把当前文件水平分割\n:split file 把当前窗口水平分割, file\n:vsplit[vsp] file 把当前窗口垂直分割, file\n:new file 同split file\n:close 关闭当前窗口\n:only 只显示当前窗口, 关闭所有其他的窗口\n:all 打开所有的窗口\n:vertical all 打开所有的窗口, 垂直打开\n:qall 对所有窗口执行：q操作\n:qall! 对所有窗口执行：q!操作\n:wall 对所有窗口执行：w操作\n:wqall 对所有窗口执行：wq操作\nctrl-w h 跳转到左边的窗口\nctrl-w j 跳转到下面的窗口\nctrl-w k 跳转到上面的窗口\nctrl-w l 跳转到右边的窗口\nctrl-w t 跳转到最顶上的窗口\nctrl-w b 跳转到最底下的窗口\n```\n# 多标签编辑\n\n``` bash\n:tabedit file 在新标签中打开文件file\n:tab split file 在新标签中打开文件file\n:tabp 切换到前一个标签\n:tabn 切换到后一个标签\n:tabc 关闭当前标签\n:tabo 关闭其他标签\ngt 到下一个tab\ngT 到上一个tab\n0gt 跳到第一个tab\n5gt 跳到第五个tab\n```\n\n# 执行shell命令\n\n1、在命令模式下输入\":sh\"，可以运行相当于在字符模式下，到输入结束想回到VIM编辑器中用exit，ctrl+D返回VIM编辑器\n2、可以\"!command\"，运行结束后自动回到VIM编辑器中\n3、用“Ctrl+Z“回到shell，用fg返回编辑\n4、:!make -> 直接在当前目录下运行make指令\n\n# VIM启动项\n-o[n] 以水平分屏的方式打开多个文件\n-O[n] 以垂直分屏的方式打开多个文件\n\n# 自动排版\n在粘贴了一些代码之后，vim变得比较乱，只要执行gg=G就能搞定\n\n# 如何在vim中编译程序\n在vim中可以完成make,而且可以将编译的结果也显示在vim里，先执行 :copen 命令，将结果输出的窗口打开，然后执行 :make\n编译后的结果就显示在了copen打开的小窗口里了，而且用鼠标双击错误信息，就会跳转到发生错误的行。\n\n# buffer操作\n\n## buffer状态\n```\n- （非活动的缓冲区）\na （当前被激活缓冲区）\nh （隐藏的缓冲区）\n% （当前的缓冲区）\n# （交换缓冲区）\n= （只读缓冲区）\n+ （已经更改的缓冲区）\n```\n\n# VIM 操作目录\n## 打开目录\n\n```\nvim .\nvim a-path/\n```\n## 以下操作在操作目录时生效\n```\np,P,t,u,U,x,v,o,r,s\n\nc 使当前打开的目录成为当前目录\nd 创建目录\n% 创建文件\nD 删除文件/目录\n- 转到上层目录\ngb 转到上一个 bookmarked directory\ni 改变目录文件列表方式\n^l 刷新当前打开的目录\n\nmf - 标记文件\nmu - unmark all marked files\nmz - Compress/decompress marked files\ngh 显示/不显示隐藏文件( dot-files)\n^h 编辑隐藏文件列表\na 转换显示模式, all - hide - unhide\nqf diplay infomation about file\nqb list the bookmarked directories and directory traversal history\ngi Display information on file\n\nmb\nmc\nmd - 将标记的文件(mf标记文件)使用 diff 模式\nme - 编辑标记的文件,只显示一个，其余放入 buffer 中\nmh\nmm - move marked files to marked-file target directory\nmc - copy\nmp\nmr\nmt\n```\n\nvim 中复制,移动文件\n```\n1, mt - 移动到的目录\n2, mf - 标记要移动的文件\n3, mc - 移动/复制\n```\n\nR 移动文件\n\n打开当前编辑文件的目录\n\n```\n:Explore\n:Hexplore\n:Nexplore\n:Pexplore\n:Sexplore\n:Texplore\n:Vexplore\n```\n\n[详细使用教程](https://www.cnblogs.com/lijia0511/p/5644566.html)","slug":"vim-guide","published":1,"updated":"2018-07-31T15:52:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xj000en61dej98qgq8","content":"<h1 id=\"移动光标\"><a href=\"#移动光标\" class=\"headerlink\" title=\"移动光标\"></a>移动光标</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">h, j, k, l 上，下，左，右</span><br><span class=\"line\">ctrl-e 移动页面</span><br><span class=\"line\">ctrl-f 上翻一页</span><br><span class=\"line\">ctrl-b 下翻一页</span><br><span class=\"line\">ctrl-u 上翻半页</span><br><span class=\"line\">ctrl-d 下翻半页</span><br><span class=\"line\">w 跳到下一个字首，按标点或单词分割</span><br><span class=\"line\">W 跳到下一个字首，长跳，如end-of-line被认为是一个字</span><br><span class=\"line\">e 跳到下一个字尾</span><br><span class=\"line\">E 跳到下一个字尾，长跳</span><br><span class=\"line\">b 跳到上一个字</span><br><span class=\"line\">B 跳到上一个字，长跳</span><br><span class=\"line\">0 跳至行首，不管有无缩进，就是跳到第0个字符</span><br><span class=\"line\">^ 跳至行首的第一个字符</span><br><span class=\"line\">$ 跳至行尾</span><br><span class=\"line\">gg 跳至文首</span><br><span class=\"line\">G 调至文尾</span><br><span class=\"line\">5gg/5G 调至第5行</span><br><span class=\"line\">gd 跳至当前光标所在的变量的声明处</span><br><span class=\"line\">fx 在当前行中找x字符，找到了就跳转至</span><br><span class=\"line\">; 重复上一个f命令，而不用重复的输入fx</span><br><span class=\"line\">* 查找光标所在处的单词，向下查找</span><br><span class=\"line\"># 查找光标所在处的单词，向上查找</span><br></pre></td></tr></table></figure>\n<h1 id=\"删除复制\"><a href=\"#删除复制\" class=\"headerlink\" title=\"删除复制\"></a>删除复制</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dd 删除光标所在行</span><br><span class=\"line\">dw 删除一个字(word)</span><br><span class=\"line\">d/D删除到行末x删除当前字符X删除前一个字符yy复制一行yw复制一个字y/Y 复制到行末</span><br><span class=\"line\">p 粘贴粘贴板的内容到当前行的下面</span><br><span class=\"line\">P 粘贴粘贴板的内容到当前行的上面</span><br></pre></td></tr></table></figure>\n<h1 id=\"插入模式\"><a href=\"#插入模式\" class=\"headerlink\" title=\"插入模式\"></a>插入模式</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">i 从当前光标处进入插入模式</span><br><span class=\"line\">I 进入插入模式，并置光标于行首</span><br><span class=\"line\">a 追加模式，置光标于当前光标之后</span><br><span class=\"line\">A 追加模式，置光标于行末</span><br><span class=\"line\">o 在当前行之下新加一行，并进入插入模式</span><br><span class=\"line\">O 在当前行之上新加一行，并进入插入模式</span><br><span class=\"line\">Esc 退出插入模式</span><br></pre></td></tr></table></figure>\n<h1 id=\"编辑\"><a href=\"#编辑\" class=\"headerlink\" title=\"编辑\"></a>编辑</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">J 将下一行和当前行连接为一行</span><br><span class=\"line\">cc 删除当前行并进入编辑模式</span><br><span class=\"line\">cw 删除当前字，并进入编辑模式</span><br><span class=\"line\">c$ 擦除从当前位置至行末的内容，并进入编辑模式</span><br><span class=\"line\">s 删除当前字符并进入编辑模式</span><br><span class=\"line\">S 删除光标所在行并进入编辑模式</span><br><span class=\"line\">xp 交换当前字符和下一个字符</span><br><span class=\"line\">u 撤销</span><br><span class=\"line\">ctrl+r 重做</span><br><span class=\"line\">~ 切换大小写，当前字符</span><br><span class=\"line\">&gt;&gt; 将当前行右移一个单位</span><br><span class=\"line\">&lt;&lt; 将当前行左移一个单位(一个tab符)</span><br><span class=\"line\">== 自动缩进当前行</span><br></pre></td></tr></table></figure>\n<h1 id=\"查找\"><a href=\"#查找\" class=\"headerlink\" title=\"查找\"></a>查找</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/pattern 向后搜索字符串pattern</span><br><span class=\"line\">?pattern 向前搜索字符串pattern</span><br><span class=\"line\"><span class=\"string\">\"\\c\"</span> 忽略大小写</span><br><span class=\"line\"><span class=\"string\">\"\\C\"</span> 大小写敏感</span><br><span class=\"line\">n 下一个匹配(如果是/搜索，则是向下的下一个，?搜索则是向上的下一个)</span><br><span class=\"line\">N 上一个匹配(同上)</span><br></pre></td></tr></table></figure>\n<h1 id=\"替换\"><a href=\"#替换\" class=\"headerlink\" title=\"替换\"></a>替换</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:%s/old/new/g 搜索整个文件，将所有的old替换为new</span><br><span class=\"line\">:%s/old/new/gc 搜索整个文件，将所有的old替换为new，每次都要你确认是否替换</span><br></pre></td></tr></table></figure>\n<h1 id=\"退出编辑器\"><a href=\"#退出编辑器\" class=\"headerlink\" title=\"退出编辑器\"></a>退出编辑器</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:w 将缓冲区写入文件，即保存修改</span><br><span class=\"line\">:wq 保存修改并退出</span><br><span class=\"line\">:x 保存修改并退出</span><br><span class=\"line\">:q 退出，如果对缓冲区进行过修改，则会提示</span><br><span class=\"line\">:q! 强制退出，放弃修改</span><br></pre></td></tr></table></figure>\n<h1 id=\"多文件编辑\"><a href=\"#多文件编辑\" class=\"headerlink\" title=\"多文件编辑\"></a>多文件编辑</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim file1.. 同时打开多个文件</span><br><span class=\"line\">:args 显示当前编辑文件</span><br><span class=\"line\">:next 切换到下个文件</span><br><span class=\"line\">:prev 切换到前个文件</span><br><span class=\"line\">:next！ 不保存当前编辑文件并切换到下个文件</span><br><span class=\"line\">:prev！ 不保存当前编辑文件并切换到上个文件</span><br><span class=\"line\">:wnext 保存当前编辑文件并切换到下个文件</span><br><span class=\"line\">:wprev 保存当前编辑文件并切换到上个文件</span><br><span class=\"line\">:first 定位首文件</span><br><span class=\"line\">:last 定位尾文件</span><br><span class=\"line\">ctrl+^ 快速在最近打开的两个文件间切换</span><br><span class=\"line\">:split[sp] 把当前文件水平分割</span><br><span class=\"line\">:split file 把当前窗口水平分割, file</span><br><span class=\"line\">:vsplit[vsp] file 把当前窗口垂直分割, file</span><br><span class=\"line\">:new file 同split file</span><br><span class=\"line\">:close 关闭当前窗口</span><br><span class=\"line\">:only 只显示当前窗口, 关闭所有其他的窗口</span><br><span class=\"line\">:all 打开所有的窗口</span><br><span class=\"line\">:vertical all 打开所有的窗口, 垂直打开</span><br><span class=\"line\">:qall 对所有窗口执行：q操作</span><br><span class=\"line\">:qall! 对所有窗口执行：q!操作</span><br><span class=\"line\">:wall 对所有窗口执行：w操作</span><br><span class=\"line\">:wqall 对所有窗口执行：wq操作</span><br><span class=\"line\">ctrl-w h 跳转到左边的窗口</span><br><span class=\"line\">ctrl-w j 跳转到下面的窗口</span><br><span class=\"line\">ctrl-w k 跳转到上面的窗口</span><br><span class=\"line\">ctrl-w l 跳转到右边的窗口</span><br><span class=\"line\">ctrl-w t 跳转到最顶上的窗口</span><br><span class=\"line\">ctrl-w b 跳转到最底下的窗口</span><br></pre></td></tr></table></figure>\n<h1 id=\"多标签编辑\"><a href=\"#多标签编辑\" class=\"headerlink\" title=\"多标签编辑\"></a>多标签编辑</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:tabedit file 在新标签中打开文件file</span><br><span class=\"line\">:tab split file 在新标签中打开文件file</span><br><span class=\"line\">:tabp 切换到前一个标签</span><br><span class=\"line\">:tabn 切换到后一个标签</span><br><span class=\"line\">:tabc 关闭当前标签</span><br><span class=\"line\">:tabo 关闭其他标签</span><br><span class=\"line\">gt 到下一个tab</span><br><span class=\"line\">gT 到上一个tab</span><br><span class=\"line\">0gt 跳到第一个tab</span><br><span class=\"line\">5gt 跳到第五个tab</span><br></pre></td></tr></table></figure>\n<h1 id=\"执行shell命令\"><a href=\"#执行shell命令\" class=\"headerlink\" title=\"执行shell命令\"></a>执行shell命令</h1><p>1、在命令模式下输入”:sh”，可以运行相当于在字符模式下，到输入结束想回到VIM编辑器中用exit，ctrl+D返回VIM编辑器<br>2、可以”!command”，运行结束后自动回到VIM编辑器中<br>3、用“Ctrl+Z“回到shell，用fg返回编辑<br>4、:!make -&gt; 直接在当前目录下运行make指令</p>\n<h1 id=\"VIM启动项\"><a href=\"#VIM启动项\" class=\"headerlink\" title=\"VIM启动项\"></a>VIM启动项</h1><p>-o[n] 以水平分屏的方式打开多个文件<br>-O[n] 以垂直分屏的方式打开多个文件</p>\n<h1 id=\"自动排版\"><a href=\"#自动排版\" class=\"headerlink\" title=\"自动排版\"></a>自动排版</h1><p>在粘贴了一些代码之后，vim变得比较乱，只要执行gg=G就能搞定</p>\n<h1 id=\"如何在vim中编译程序\"><a href=\"#如何在vim中编译程序\" class=\"headerlink\" title=\"如何在vim中编译程序\"></a>如何在vim中编译程序</h1><p>在vim中可以完成make,而且可以将编译的结果也显示在vim里，先执行 :copen 命令，将结果输出的窗口打开，然后执行 :make<br>编译后的结果就显示在了copen打开的小窗口里了，而且用鼠标双击错误信息，就会跳转到发生错误的行。</p>\n<h1 id=\"buffer操作\"><a href=\"#buffer操作\" class=\"headerlink\" title=\"buffer操作\"></a>buffer操作</h1><h2 id=\"buffer状态\"><a href=\"#buffer状态\" class=\"headerlink\" title=\"buffer状态\"></a>buffer状态</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- （非活动的缓冲区）</span><br><span class=\"line\">a （当前被激活缓冲区）</span><br><span class=\"line\">h （隐藏的缓冲区）</span><br><span class=\"line\">% （当前的缓冲区）</span><br><span class=\"line\"># （交换缓冲区）</span><br><span class=\"line\">= （只读缓冲区）</span><br><span class=\"line\">+ （已经更改的缓冲区）</span><br></pre></td></tr></table></figure>\n<h1 id=\"VIM-操作目录\"><a href=\"#VIM-操作目录\" class=\"headerlink\" title=\"VIM 操作目录\"></a>VIM 操作目录</h1><h2 id=\"打开目录\"><a href=\"#打开目录\" class=\"headerlink\" title=\"打开目录\"></a>打开目录</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim .</span><br><span class=\"line\">vim a-path/</span><br></pre></td></tr></table></figure>\n<h2 id=\"以下操作在操作目录时生效\"><a href=\"#以下操作在操作目录时生效\" class=\"headerlink\" title=\"以下操作在操作目录时生效\"></a>以下操作在操作目录时生效</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">p,P,t,u,U,x,v,o,r,s</span><br><span class=\"line\"></span><br><span class=\"line\">c 使当前打开的目录成为当前目录</span><br><span class=\"line\">d 创建目录</span><br><span class=\"line\">% 创建文件</span><br><span class=\"line\">D 删除文件/目录</span><br><span class=\"line\">- 转到上层目录</span><br><span class=\"line\">gb 转到上一个 bookmarked directory</span><br><span class=\"line\">i 改变目录文件列表方式</span><br><span class=\"line\">^l 刷新当前打开的目录</span><br><span class=\"line\"></span><br><span class=\"line\">mf - 标记文件</span><br><span class=\"line\">mu - unmark all marked files</span><br><span class=\"line\">mz - Compress/decompress marked files</span><br><span class=\"line\">gh 显示/不显示隐藏文件( dot-files)</span><br><span class=\"line\">^h 编辑隐藏文件列表</span><br><span class=\"line\">a 转换显示模式, all - hide - unhide</span><br><span class=\"line\">qf diplay infomation about file</span><br><span class=\"line\">qb list the bookmarked directories and directory traversal history</span><br><span class=\"line\">gi Display information on file</span><br><span class=\"line\"></span><br><span class=\"line\">mb</span><br><span class=\"line\">mc</span><br><span class=\"line\">md - 将标记的文件(mf标记文件)使用 diff 模式</span><br><span class=\"line\">me - 编辑标记的文件,只显示一个，其余放入 buffer 中</span><br><span class=\"line\">mh</span><br><span class=\"line\">mm - move marked files to marked-file target directory</span><br><span class=\"line\">mc - copy</span><br><span class=\"line\">mp</span><br><span class=\"line\">mr</span><br><span class=\"line\">mt</span><br></pre></td></tr></table></figure>\n<p>vim 中复制,移动文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1, mt - 移动到的目录</span><br><span class=\"line\">2, mf - 标记要移动的文件</span><br><span class=\"line\">3, mc - 移动/复制</span><br></pre></td></tr></table></figure></p>\n<p>R 移动文件</p>\n<p>打开当前编辑文件的目录</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:Explore</span><br><span class=\"line\">:Hexplore</span><br><span class=\"line\">:Nexplore</span><br><span class=\"line\">:Pexplore</span><br><span class=\"line\">:Sexplore</span><br><span class=\"line\">:Texplore</span><br><span class=\"line\">:Vexplore</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://www.cnblogs.com/lijia0511/p/5644566.html\" target=\"_blank\" rel=\"noopener\">详细使用教程</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"移动光标\"><a href=\"#移动光标\" class=\"headerlink\" title=\"移动光标\"></a>移动光标</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">h, j, k, l 上，下，左，右</span><br><span class=\"line\">ctrl-e 移动页面</span><br><span class=\"line\">ctrl-f 上翻一页</span><br><span class=\"line\">ctrl-b 下翻一页</span><br><span class=\"line\">ctrl-u 上翻半页</span><br><span class=\"line\">ctrl-d 下翻半页</span><br><span class=\"line\">w 跳到下一个字首，按标点或单词分割</span><br><span class=\"line\">W 跳到下一个字首，长跳，如end-of-line被认为是一个字</span><br><span class=\"line\">e 跳到下一个字尾</span><br><span class=\"line\">E 跳到下一个字尾，长跳</span><br><span class=\"line\">b 跳到上一个字</span><br><span class=\"line\">B 跳到上一个字，长跳</span><br><span class=\"line\">0 跳至行首，不管有无缩进，就是跳到第0个字符</span><br><span class=\"line\">^ 跳至行首的第一个字符</span><br><span class=\"line\">$ 跳至行尾</span><br><span class=\"line\">gg 跳至文首</span><br><span class=\"line\">G 调至文尾</span><br><span class=\"line\">5gg/5G 调至第5行</span><br><span class=\"line\">gd 跳至当前光标所在的变量的声明处</span><br><span class=\"line\">fx 在当前行中找x字符，找到了就跳转至</span><br><span class=\"line\">; 重复上一个f命令，而不用重复的输入fx</span><br><span class=\"line\">* 查找光标所在处的单词，向下查找</span><br><span class=\"line\"># 查找光标所在处的单词，向上查找</span><br></pre></td></tr></table></figure>\n<h1 id=\"删除复制\"><a href=\"#删除复制\" class=\"headerlink\" title=\"删除复制\"></a>删除复制</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dd 删除光标所在行</span><br><span class=\"line\">dw 删除一个字(word)</span><br><span class=\"line\">d/D删除到行末x删除当前字符X删除前一个字符yy复制一行yw复制一个字y/Y 复制到行末</span><br><span class=\"line\">p 粘贴粘贴板的内容到当前行的下面</span><br><span class=\"line\">P 粘贴粘贴板的内容到当前行的上面</span><br></pre></td></tr></table></figure>\n<h1 id=\"插入模式\"><a href=\"#插入模式\" class=\"headerlink\" title=\"插入模式\"></a>插入模式</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">i 从当前光标处进入插入模式</span><br><span class=\"line\">I 进入插入模式，并置光标于行首</span><br><span class=\"line\">a 追加模式，置光标于当前光标之后</span><br><span class=\"line\">A 追加模式，置光标于行末</span><br><span class=\"line\">o 在当前行之下新加一行，并进入插入模式</span><br><span class=\"line\">O 在当前行之上新加一行，并进入插入模式</span><br><span class=\"line\">Esc 退出插入模式</span><br></pre></td></tr></table></figure>\n<h1 id=\"编辑\"><a href=\"#编辑\" class=\"headerlink\" title=\"编辑\"></a>编辑</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">J 将下一行和当前行连接为一行</span><br><span class=\"line\">cc 删除当前行并进入编辑模式</span><br><span class=\"line\">cw 删除当前字，并进入编辑模式</span><br><span class=\"line\">c$ 擦除从当前位置至行末的内容，并进入编辑模式</span><br><span class=\"line\">s 删除当前字符并进入编辑模式</span><br><span class=\"line\">S 删除光标所在行并进入编辑模式</span><br><span class=\"line\">xp 交换当前字符和下一个字符</span><br><span class=\"line\">u 撤销</span><br><span class=\"line\">ctrl+r 重做</span><br><span class=\"line\">~ 切换大小写，当前字符</span><br><span class=\"line\">&gt;&gt; 将当前行右移一个单位</span><br><span class=\"line\">&lt;&lt; 将当前行左移一个单位(一个tab符)</span><br><span class=\"line\">== 自动缩进当前行</span><br></pre></td></tr></table></figure>\n<h1 id=\"查找\"><a href=\"#查找\" class=\"headerlink\" title=\"查找\"></a>查找</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/pattern 向后搜索字符串pattern</span><br><span class=\"line\">?pattern 向前搜索字符串pattern</span><br><span class=\"line\"><span class=\"string\">\"\\c\"</span> 忽略大小写</span><br><span class=\"line\"><span class=\"string\">\"\\C\"</span> 大小写敏感</span><br><span class=\"line\">n 下一个匹配(如果是/搜索，则是向下的下一个，?搜索则是向上的下一个)</span><br><span class=\"line\">N 上一个匹配(同上)</span><br></pre></td></tr></table></figure>\n<h1 id=\"替换\"><a href=\"#替换\" class=\"headerlink\" title=\"替换\"></a>替换</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:%s/old/new/g 搜索整个文件，将所有的old替换为new</span><br><span class=\"line\">:%s/old/new/gc 搜索整个文件，将所有的old替换为new，每次都要你确认是否替换</span><br></pre></td></tr></table></figure>\n<h1 id=\"退出编辑器\"><a href=\"#退出编辑器\" class=\"headerlink\" title=\"退出编辑器\"></a>退出编辑器</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:w 将缓冲区写入文件，即保存修改</span><br><span class=\"line\">:wq 保存修改并退出</span><br><span class=\"line\">:x 保存修改并退出</span><br><span class=\"line\">:q 退出，如果对缓冲区进行过修改，则会提示</span><br><span class=\"line\">:q! 强制退出，放弃修改</span><br></pre></td></tr></table></figure>\n<h1 id=\"多文件编辑\"><a href=\"#多文件编辑\" class=\"headerlink\" title=\"多文件编辑\"></a>多文件编辑</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim file1.. 同时打开多个文件</span><br><span class=\"line\">:args 显示当前编辑文件</span><br><span class=\"line\">:next 切换到下个文件</span><br><span class=\"line\">:prev 切换到前个文件</span><br><span class=\"line\">:next！ 不保存当前编辑文件并切换到下个文件</span><br><span class=\"line\">:prev！ 不保存当前编辑文件并切换到上个文件</span><br><span class=\"line\">:wnext 保存当前编辑文件并切换到下个文件</span><br><span class=\"line\">:wprev 保存当前编辑文件并切换到上个文件</span><br><span class=\"line\">:first 定位首文件</span><br><span class=\"line\">:last 定位尾文件</span><br><span class=\"line\">ctrl+^ 快速在最近打开的两个文件间切换</span><br><span class=\"line\">:split[sp] 把当前文件水平分割</span><br><span class=\"line\">:split file 把当前窗口水平分割, file</span><br><span class=\"line\">:vsplit[vsp] file 把当前窗口垂直分割, file</span><br><span class=\"line\">:new file 同split file</span><br><span class=\"line\">:close 关闭当前窗口</span><br><span class=\"line\">:only 只显示当前窗口, 关闭所有其他的窗口</span><br><span class=\"line\">:all 打开所有的窗口</span><br><span class=\"line\">:vertical all 打开所有的窗口, 垂直打开</span><br><span class=\"line\">:qall 对所有窗口执行：q操作</span><br><span class=\"line\">:qall! 对所有窗口执行：q!操作</span><br><span class=\"line\">:wall 对所有窗口执行：w操作</span><br><span class=\"line\">:wqall 对所有窗口执行：wq操作</span><br><span class=\"line\">ctrl-w h 跳转到左边的窗口</span><br><span class=\"line\">ctrl-w j 跳转到下面的窗口</span><br><span class=\"line\">ctrl-w k 跳转到上面的窗口</span><br><span class=\"line\">ctrl-w l 跳转到右边的窗口</span><br><span class=\"line\">ctrl-w t 跳转到最顶上的窗口</span><br><span class=\"line\">ctrl-w b 跳转到最底下的窗口</span><br></pre></td></tr></table></figure>\n<h1 id=\"多标签编辑\"><a href=\"#多标签编辑\" class=\"headerlink\" title=\"多标签编辑\"></a>多标签编辑</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:tabedit file 在新标签中打开文件file</span><br><span class=\"line\">:tab split file 在新标签中打开文件file</span><br><span class=\"line\">:tabp 切换到前一个标签</span><br><span class=\"line\">:tabn 切换到后一个标签</span><br><span class=\"line\">:tabc 关闭当前标签</span><br><span class=\"line\">:tabo 关闭其他标签</span><br><span class=\"line\">gt 到下一个tab</span><br><span class=\"line\">gT 到上一个tab</span><br><span class=\"line\">0gt 跳到第一个tab</span><br><span class=\"line\">5gt 跳到第五个tab</span><br></pre></td></tr></table></figure>\n<h1 id=\"执行shell命令\"><a href=\"#执行shell命令\" class=\"headerlink\" title=\"执行shell命令\"></a>执行shell命令</h1><p>1、在命令模式下输入”:sh”，可以运行相当于在字符模式下，到输入结束想回到VIM编辑器中用exit，ctrl+D返回VIM编辑器<br>2、可以”!command”，运行结束后自动回到VIM编辑器中<br>3、用“Ctrl+Z“回到shell，用fg返回编辑<br>4、:!make -&gt; 直接在当前目录下运行make指令</p>\n<h1 id=\"VIM启动项\"><a href=\"#VIM启动项\" class=\"headerlink\" title=\"VIM启动项\"></a>VIM启动项</h1><p>-o[n] 以水平分屏的方式打开多个文件<br>-O[n] 以垂直分屏的方式打开多个文件</p>\n<h1 id=\"自动排版\"><a href=\"#自动排版\" class=\"headerlink\" title=\"自动排版\"></a>自动排版</h1><p>在粘贴了一些代码之后，vim变得比较乱，只要执行gg=G就能搞定</p>\n<h1 id=\"如何在vim中编译程序\"><a href=\"#如何在vim中编译程序\" class=\"headerlink\" title=\"如何在vim中编译程序\"></a>如何在vim中编译程序</h1><p>在vim中可以完成make,而且可以将编译的结果也显示在vim里，先执行 :copen 命令，将结果输出的窗口打开，然后执行 :make<br>编译后的结果就显示在了copen打开的小窗口里了，而且用鼠标双击错误信息，就会跳转到发生错误的行。</p>\n<h1 id=\"buffer操作\"><a href=\"#buffer操作\" class=\"headerlink\" title=\"buffer操作\"></a>buffer操作</h1><h2 id=\"buffer状态\"><a href=\"#buffer状态\" class=\"headerlink\" title=\"buffer状态\"></a>buffer状态</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- （非活动的缓冲区）</span><br><span class=\"line\">a （当前被激活缓冲区）</span><br><span class=\"line\">h （隐藏的缓冲区）</span><br><span class=\"line\">% （当前的缓冲区）</span><br><span class=\"line\"># （交换缓冲区）</span><br><span class=\"line\">= （只读缓冲区）</span><br><span class=\"line\">+ （已经更改的缓冲区）</span><br></pre></td></tr></table></figure>\n<h1 id=\"VIM-操作目录\"><a href=\"#VIM-操作目录\" class=\"headerlink\" title=\"VIM 操作目录\"></a>VIM 操作目录</h1><h2 id=\"打开目录\"><a href=\"#打开目录\" class=\"headerlink\" title=\"打开目录\"></a>打开目录</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim .</span><br><span class=\"line\">vim a-path/</span><br></pre></td></tr></table></figure>\n<h2 id=\"以下操作在操作目录时生效\"><a href=\"#以下操作在操作目录时生效\" class=\"headerlink\" title=\"以下操作在操作目录时生效\"></a>以下操作在操作目录时生效</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">p,P,t,u,U,x,v,o,r,s</span><br><span class=\"line\"></span><br><span class=\"line\">c 使当前打开的目录成为当前目录</span><br><span class=\"line\">d 创建目录</span><br><span class=\"line\">% 创建文件</span><br><span class=\"line\">D 删除文件/目录</span><br><span class=\"line\">- 转到上层目录</span><br><span class=\"line\">gb 转到上一个 bookmarked directory</span><br><span class=\"line\">i 改变目录文件列表方式</span><br><span class=\"line\">^l 刷新当前打开的目录</span><br><span class=\"line\"></span><br><span class=\"line\">mf - 标记文件</span><br><span class=\"line\">mu - unmark all marked files</span><br><span class=\"line\">mz - Compress/decompress marked files</span><br><span class=\"line\">gh 显示/不显示隐藏文件( dot-files)</span><br><span class=\"line\">^h 编辑隐藏文件列表</span><br><span class=\"line\">a 转换显示模式, all - hide - unhide</span><br><span class=\"line\">qf diplay infomation about file</span><br><span class=\"line\">qb list the bookmarked directories and directory traversal history</span><br><span class=\"line\">gi Display information on file</span><br><span class=\"line\"></span><br><span class=\"line\">mb</span><br><span class=\"line\">mc</span><br><span class=\"line\">md - 将标记的文件(mf标记文件)使用 diff 模式</span><br><span class=\"line\">me - 编辑标记的文件,只显示一个，其余放入 buffer 中</span><br><span class=\"line\">mh</span><br><span class=\"line\">mm - move marked files to marked-file target directory</span><br><span class=\"line\">mc - copy</span><br><span class=\"line\">mp</span><br><span class=\"line\">mr</span><br><span class=\"line\">mt</span><br></pre></td></tr></table></figure>\n<p>vim 中复制,移动文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1, mt - 移动到的目录</span><br><span class=\"line\">2, mf - 标记要移动的文件</span><br><span class=\"line\">3, mc - 移动/复制</span><br></pre></td></tr></table></figure></p>\n<p>R 移动文件</p>\n<p>打开当前编辑文件的目录</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">:Explore</span><br><span class=\"line\">:Hexplore</span><br><span class=\"line\">:Nexplore</span><br><span class=\"line\">:Pexplore</span><br><span class=\"line\">:Sexplore</span><br><span class=\"line\">:Texplore</span><br><span class=\"line\">:Vexplore</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://www.cnblogs.com/lijia0511/p/5644566.html\" target=\"_blank\" rel=\"noopener\">详细使用教程</a></p>\n"},{"title":"google-deep-and-cross","date":"2018-06-03T03:17:46.000Z","_content":"\nsoftmax 反向传播\nhttps://blog.csdn.net/yujianmin1990/article/details/78989099","source":"_posts/201806-google-deep-and-cross.md","raw":"---\ntitle: google-deep-and-cross\ndate: 2018-06-03 11:17:46\ntags:\n---\n\nsoftmax 反向传播\nhttps://blog.csdn.net/yujianmin1990/article/details/78989099","slug":"google-deep-and-cross","published":1,"updated":"2018-06-27T02:11:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xl000gn61di16z20n4","content":"<p>softmax 反向传播<br><a href=\"https://blog.csdn.net/yujianmin1990/article/details/78989099\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yujianmin1990/article/details/78989099</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>softmax 反向传播<br><a href=\"https://blog.csdn.net/yujianmin1990/article/details/78989099\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yujianmin1990/article/details/78989099</a></p>\n"},{"title":"google-wide-and-deep-network","date":"2018-06-02T05:32:55.000Z","mathjax":true,"_content":"\n# 第0章\n\nwide是指高维特征+特征组合的LR。LR高效、容易规模化（scalable）、可解释性强。但是泛化性需要在特征工程上下功夫\ndeep就是deep learning了。特征工程省力，但是容易过度泛化over-generalize。\n\n## 参考阅读\n\n- 2016 《Wide & Deep Learning for Recommender Systems》 \b[blog]()\n- 2017 《Deep & Cross Network for Ad Click Predictions》 [blog]()\n- [google research blog](https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html)\n- [wide & deep github code](https://github.com/tensorflow/models/tree/master/official/wide_deep)\n- 《2016-Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features》 \n\n链接：本文参考：https://blog.csdn.net/yujianmin1990/article/details/78989099\n\n# paper\n\nWide & Deep前者是用来给用户推荐潜在喜欢的APP；Deep & Cross是用来预测用户可能点击的广告排序。\n\n## Memorization 和 Generalization\n\npaper 的两个重要概念：\n\nMemorization（对应wide）: 特征关系的 Memorization ，是 cross-product transformation 实现的一个wide set，它有效也便于理解。*Memorization* 可以宽泛地定义成学到items或features的共现率，并利用（exploiting）这种在历史数据中的相关关系（correlation）。\n\nGeneralization （对应deep)： 相关性的传递（transitivity），新特征组合,多样性（diversity）好一些。是基于相关关系的转移，并探索（explores）在过往很少或从不出现的新的特征组合。\n\n基于Memorization的推荐系统通常更局部化(topical)，将items与执行相应动作的users直接相关。而基于Generalization的推荐则更趋向于推荐多样化的items。\n\n## 本文的主要贡献\n\nWide & Deep 学习框架，可以用于联合训练带embeddings的feed-forward神经网络，以及对于稀疏输入的常用推荐系统所使用的带特征转换的线性模型。\nWide & Deep推荐系统的实现和评估在Google Play上已经产品化，这个app store具有数十亿的活跃用户、以及上百万的app。\n开源，在Tensorflow上提供了一个高级API。\n\n## 特征输入\n\nW&D的特征包括三方面： \n- User-Feature：contry, language, demographics. \n- Contextual-Feature：device, hour of the day, day of the week. 像余额宝、阿里音乐那个比赛都用了时间特征\n- Impression-Feature：app age, historical statistics of an app. \n\n1. Wide部分的输入特征\n\n    - raw input features and transformed features [手挑的交叉特征]. \n\nnotice: Wide_Deep 这里的 cross-product transformation：只在离散特征（稀疏）之间做组合，不管是文本策略型的，还是离散值的；没有连续值特征的啥事，至少在W&D的paper里面是这样使用的。 \n\n2. Deep部分的输入特征\n\n    - raw input + embeding处理 \n\n对非连续值之外的特征做 embedding 处理，这里都是策略特征，就是乘以个 embedding_matrix 。在TensorFlow里面的接口是：tf.feature_column.embedding_column，默认trainable=True. \n\n对连续值特征的处理是：将其按照累积分布函数P(X≤x)，压缩至[0,1]内。 \n\n### notice\n\nWide部分用FTRL+L1来训练；Deep部分用AdaGrad来训练。 \n\nWide&Deep在TensorFlow里面的API接口为：tf.estimator.DNNLinearCombinedClassifier \n\n![](http://p8vrqzrnj.bkt.clouddn.com/wide-and-deep-1.png)\n\n## 3. Wide & Deep Learning\n\n### 3.1 Wide组件\n\nwide组件是一个泛化的线性模型，形式为：$y=w^Tx+b$，如图1(左）所示。y是预测，$x = [x_1, x_2, …, x_d]$ 是d维的特征向量， $w = [w_1, w_2,…, w_d]$ 是模型参数，其中b为bias。特征集包括原始的输入特征和转换后的特征，一个最重要的转换是，cross-product transformation。它可以定义成：\n\n$\\phi_k(x)=\\prod_{i=1}^{d}x_{i}^{c_{ki}}, c_{ki} \\in \\{0, 1\\}$ (paper 公式1)\n\n其中 $c_{ki}$ 为一个boolean变量，如果第i个特征是第k个变换ϕk的一部分，那么为1; 否则为0.对于二值特征，一个cross-product transformation（比如：”AND(gender=female, language=en)”）只能当组成特征（“gender=female” 和 “language=en”）都为1时才会为1, 否则为0. 这会捕获二值特征间的交叉，为通用的线性模型添加非线性。\n\n### 3.2 Deep组件\n\nDeep组件是一个前馈神经网络(feed-forward NN)，如图1(右）所示。对于类别型特征，原始的输入是特征字符串（比如：”language=en”）。这些稀疏的，高维的类别型特征会首先被转换成一个低维的、dense的、real-valued的向量，通常叫做“embedding vector”。embedding的维度通常是O(10)到O(100)的阶。该 embedding vectors 被随机初始化，接着最小化最终的loss的方式训练得到该值。这些低维的dense embedding vectors接着通过前向传递被feed给神经网络的隐层。特别地，每个隐层都会执行以下的计算：\n\n$a^{l+1}=f(W^{(l)}a^{(l)}+b^{(l)})$ (公式2)\n\n其中，l是层数，f是激活函数（通常为ReLUs），$a^{(l)}$，$b^{(l)}$ 和$W^{(l)}$分别是第l层的activations, bias，以及weights。\n\n![](http://p8vrqzrnj.bkt.clouddn.com/DX-20180603@2x.png)\n\n### 3.3 Wide & Deep模型的联合训练\n\nWide组件和Deep组件组合在一起，对它们的输入日志进行一个加权求和来做为预测，它会被feed给一个常见的logistic loss function来进行联合训练。注意，联合训练（joint training）和集成训练（ensemble）有明显的区别。在ensemble中，每个独立的模型会单独训练，相互并不知道，只有在预测时会组合在一起。相反地，**联合训练（joint training）会同时优化所有参数，通过将wide组件和deep组件在训练时进行加权求和的方式进行。**这也暗示了模型的size：对于一个ensemble，由于训练是不联合的（disjoint），每个单独的模型size通常需要更大些（例如：更多的特征和转换）来达到合理的精度。相比之下，对于联合训练（joint training）来说，wide组件只需要补充deep组件的缺点，使用一小部分的cross-product特征转换即可，而非使用一个full-size的wide模型。\n\n一个Wide&Deep模型的联合训练，通过对梯度进行后向传播算法、SGD优化来完成。在试验中，我们使用FTRL算法，使用L1正则做为Wide组件的优化器，对Deep组件使用AdaGrad。\n\n组合模型如图一（中）所示。对于一个logistic regression问题，模型的预测为：\n\n$P(Y = 1 | x) = \\sigma(w_{wide}^{T} [x, \\phi(x)] + w_{deep}^{T} a^{(l_f)} + b)$  (paper \b公式3)\n\n其中Y是二分类的label，$\\sigma(·)$是sigmoid function， $\\phi(x)$ 是对原始特征x做cross product transformations，b是bias项。$w_{wide}$ 是所有wide模型权重向量，$w_{deep}$ 是应用在最终激活函数 $a^{(lf)}$ 上的权重。\n\n## 4 \b系统实践\n\n连续值先用累计分布函数CDF归一化到[0,1]，再划档离散化。\n\n# 论文翻译\n\n[基于Wide & Deep Learning的推荐系统](http://d0evi1.com/widedeep-recsys/)\n\n# 附\n\n## Tensorflow\n\n只需要3步，即可以使用tf.estimator API来配置一个wide，deep或者Wide&Deep：\n\n1. 选中wide组件的特征：选中你想用的稀疏的base特征列和交叉列特征列\n2. 选择deep组件的特征：选择连续型的列，对于每个类别型列的embedding维，以及隐层的size。\n\n将它们放置到一个Wide&Deep模型中（DNNLinearCombinedClassifier）\n\n关于更详细的操作，示例代码在：/tensorflow/tensorflow/examples/learn/wide_n_deep_tutorial.py，具体详见tensorflow tutorial。\n\n## tf.nn.embedding_lookup_sparse\n\n如何处理不定长的字符串的embedding问题\n\n``` python\nimport tensorflow as tf\n\n# 输入数据如下\ncsv = [\n    \"1,oscars|brad-pitt|awards\",\n    \"2,oscars|film|reviews\",\n    \"3,matt-damon|bourne\",\n]\n\n# 第二列是不定长的特征。处理如下\n# Purposefully omitting \"bourne\" to demonstrate OOV mappings.\nTAG_SET = [\"oscars\", \"brad-pitt\", \"awards\", \"film\", \"reviews\", \"matt-damon\"]\nNUM_OOV = 1\n\ndef sparse_from_csv(csv):\n    ids, post_tags_str = tf.decode_csv(csv, [[-1], [\"\"]])\n    table = tf.contrib.lookup.index_table_from_tensor(\n        mapping=TAG_SET, num_oov_buckets=NUM_OOV, default_value=-1)  # 构造查找表\n    split_tags = tf.string_split(post_tags_str, \"|\")\n    return ids, tf.SparseTensor(\n            indices=split_tags.indices,\n            values=table.lookup(split_tags.values),  # 不同值通过表查到的index\n            dense_shape=split_tags.dense_shape)\n\n# Optionally create an embedding for this.\nTAG_EMBEDDING_DIM = 3\n\nids, tags = sparse_from_csv(csv)\n\nembedding_params = tf.Variable(tf.truncated_normal([len(TAG_SET) + NUM_OOV, TAG_EMBEDDING_DIM]))\nembedded_tags = tf.nn.embedding_lookup_sparse(embedding_params, sp_ids=tags, sp_weights=None)\n\n# Test it out\nwith tf.Session() as sess:\n    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n    print(s.run([ids, embedded_tags]))\n```\n\n## 继续学习\n\n[TensorFlow Wide And Deep 模型详解与应用](https://blog.csdn.net/kwame211/article/details/78015498)\n","source":"_posts/201806-google-wide-and-deep-network.md","raw":"---\ntitle: google-wide-and-deep-network\ndate: 2018-06-02 13:32:55\nmathjax: true\ntags:\n---\n\n# 第0章\n\nwide是指高维特征+特征组合的LR。LR高效、容易规模化（scalable）、可解释性强。但是泛化性需要在特征工程上下功夫\ndeep就是deep learning了。特征工程省力，但是容易过度泛化over-generalize。\n\n## 参考阅读\n\n- 2016 《Wide & Deep Learning for Recommender Systems》 \b[blog]()\n- 2017 《Deep & Cross Network for Ad Click Predictions》 [blog]()\n- [google research blog](https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html)\n- [wide & deep github code](https://github.com/tensorflow/models/tree/master/official/wide_deep)\n- 《2016-Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features》 \n\n链接：本文参考：https://blog.csdn.net/yujianmin1990/article/details/78989099\n\n# paper\n\nWide & Deep前者是用来给用户推荐潜在喜欢的APP；Deep & Cross是用来预测用户可能点击的广告排序。\n\n## Memorization 和 Generalization\n\npaper 的两个重要概念：\n\nMemorization（对应wide）: 特征关系的 Memorization ，是 cross-product transformation 实现的一个wide set，它有效也便于理解。*Memorization* 可以宽泛地定义成学到items或features的共现率，并利用（exploiting）这种在历史数据中的相关关系（correlation）。\n\nGeneralization （对应deep)： 相关性的传递（transitivity），新特征组合,多样性（diversity）好一些。是基于相关关系的转移，并探索（explores）在过往很少或从不出现的新的特征组合。\n\n基于Memorization的推荐系统通常更局部化(topical)，将items与执行相应动作的users直接相关。而基于Generalization的推荐则更趋向于推荐多样化的items。\n\n## 本文的主要贡献\n\nWide & Deep 学习框架，可以用于联合训练带embeddings的feed-forward神经网络，以及对于稀疏输入的常用推荐系统所使用的带特征转换的线性模型。\nWide & Deep推荐系统的实现和评估在Google Play上已经产品化，这个app store具有数十亿的活跃用户、以及上百万的app。\n开源，在Tensorflow上提供了一个高级API。\n\n## 特征输入\n\nW&D的特征包括三方面： \n- User-Feature：contry, language, demographics. \n- Contextual-Feature：device, hour of the day, day of the week. 像余额宝、阿里音乐那个比赛都用了时间特征\n- Impression-Feature：app age, historical statistics of an app. \n\n1. Wide部分的输入特征\n\n    - raw input features and transformed features [手挑的交叉特征]. \n\nnotice: Wide_Deep 这里的 cross-product transformation：只在离散特征（稀疏）之间做组合，不管是文本策略型的，还是离散值的；没有连续值特征的啥事，至少在W&D的paper里面是这样使用的。 \n\n2. Deep部分的输入特征\n\n    - raw input + embeding处理 \n\n对非连续值之外的特征做 embedding 处理，这里都是策略特征，就是乘以个 embedding_matrix 。在TensorFlow里面的接口是：tf.feature_column.embedding_column，默认trainable=True. \n\n对连续值特征的处理是：将其按照累积分布函数P(X≤x)，压缩至[0,1]内。 \n\n### notice\n\nWide部分用FTRL+L1来训练；Deep部分用AdaGrad来训练。 \n\nWide&Deep在TensorFlow里面的API接口为：tf.estimator.DNNLinearCombinedClassifier \n\n![](http://p8vrqzrnj.bkt.clouddn.com/wide-and-deep-1.png)\n\n## 3. Wide & Deep Learning\n\n### 3.1 Wide组件\n\nwide组件是一个泛化的线性模型，形式为：$y=w^Tx+b$，如图1(左）所示。y是预测，$x = [x_1, x_2, …, x_d]$ 是d维的特征向量， $w = [w_1, w_2,…, w_d]$ 是模型参数，其中b为bias。特征集包括原始的输入特征和转换后的特征，一个最重要的转换是，cross-product transformation。它可以定义成：\n\n$\\phi_k(x)=\\prod_{i=1}^{d}x_{i}^{c_{ki}}, c_{ki} \\in \\{0, 1\\}$ (paper 公式1)\n\n其中 $c_{ki}$ 为一个boolean变量，如果第i个特征是第k个变换ϕk的一部分，那么为1; 否则为0.对于二值特征，一个cross-product transformation（比如：”AND(gender=female, language=en)”）只能当组成特征（“gender=female” 和 “language=en”）都为1时才会为1, 否则为0. 这会捕获二值特征间的交叉，为通用的线性模型添加非线性。\n\n### 3.2 Deep组件\n\nDeep组件是一个前馈神经网络(feed-forward NN)，如图1(右）所示。对于类别型特征，原始的输入是特征字符串（比如：”language=en”）。这些稀疏的，高维的类别型特征会首先被转换成一个低维的、dense的、real-valued的向量，通常叫做“embedding vector”。embedding的维度通常是O(10)到O(100)的阶。该 embedding vectors 被随机初始化，接着最小化最终的loss的方式训练得到该值。这些低维的dense embedding vectors接着通过前向传递被feed给神经网络的隐层。特别地，每个隐层都会执行以下的计算：\n\n$a^{l+1}=f(W^{(l)}a^{(l)}+b^{(l)})$ (公式2)\n\n其中，l是层数，f是激活函数（通常为ReLUs），$a^{(l)}$，$b^{(l)}$ 和$W^{(l)}$分别是第l层的activations, bias，以及weights。\n\n![](http://p8vrqzrnj.bkt.clouddn.com/DX-20180603@2x.png)\n\n### 3.3 Wide & Deep模型的联合训练\n\nWide组件和Deep组件组合在一起，对它们的输入日志进行一个加权求和来做为预测，它会被feed给一个常见的logistic loss function来进行联合训练。注意，联合训练（joint training）和集成训练（ensemble）有明显的区别。在ensemble中，每个独立的模型会单独训练，相互并不知道，只有在预测时会组合在一起。相反地，**联合训练（joint training）会同时优化所有参数，通过将wide组件和deep组件在训练时进行加权求和的方式进行。**这也暗示了模型的size：对于一个ensemble，由于训练是不联合的（disjoint），每个单独的模型size通常需要更大些（例如：更多的特征和转换）来达到合理的精度。相比之下，对于联合训练（joint training）来说，wide组件只需要补充deep组件的缺点，使用一小部分的cross-product特征转换即可，而非使用一个full-size的wide模型。\n\n一个Wide&Deep模型的联合训练，通过对梯度进行后向传播算法、SGD优化来完成。在试验中，我们使用FTRL算法，使用L1正则做为Wide组件的优化器，对Deep组件使用AdaGrad。\n\n组合模型如图一（中）所示。对于一个logistic regression问题，模型的预测为：\n\n$P(Y = 1 | x) = \\sigma(w_{wide}^{T} [x, \\phi(x)] + w_{deep}^{T} a^{(l_f)} + b)$  (paper \b公式3)\n\n其中Y是二分类的label，$\\sigma(·)$是sigmoid function， $\\phi(x)$ 是对原始特征x做cross product transformations，b是bias项。$w_{wide}$ 是所有wide模型权重向量，$w_{deep}$ 是应用在最终激活函数 $a^{(lf)}$ 上的权重。\n\n## 4 \b系统实践\n\n连续值先用累计分布函数CDF归一化到[0,1]，再划档离散化。\n\n# 论文翻译\n\n[基于Wide & Deep Learning的推荐系统](http://d0evi1.com/widedeep-recsys/)\n\n# 附\n\n## Tensorflow\n\n只需要3步，即可以使用tf.estimator API来配置一个wide，deep或者Wide&Deep：\n\n1. 选中wide组件的特征：选中你想用的稀疏的base特征列和交叉列特征列\n2. 选择deep组件的特征：选择连续型的列，对于每个类别型列的embedding维，以及隐层的size。\n\n将它们放置到一个Wide&Deep模型中（DNNLinearCombinedClassifier）\n\n关于更详细的操作，示例代码在：/tensorflow/tensorflow/examples/learn/wide_n_deep_tutorial.py，具体详见tensorflow tutorial。\n\n## tf.nn.embedding_lookup_sparse\n\n如何处理不定长的字符串的embedding问题\n\n``` python\nimport tensorflow as tf\n\n# 输入数据如下\ncsv = [\n    \"1,oscars|brad-pitt|awards\",\n    \"2,oscars|film|reviews\",\n    \"3,matt-damon|bourne\",\n]\n\n# 第二列是不定长的特征。处理如下\n# Purposefully omitting \"bourne\" to demonstrate OOV mappings.\nTAG_SET = [\"oscars\", \"brad-pitt\", \"awards\", \"film\", \"reviews\", \"matt-damon\"]\nNUM_OOV = 1\n\ndef sparse_from_csv(csv):\n    ids, post_tags_str = tf.decode_csv(csv, [[-1], [\"\"]])\n    table = tf.contrib.lookup.index_table_from_tensor(\n        mapping=TAG_SET, num_oov_buckets=NUM_OOV, default_value=-1)  # 构造查找表\n    split_tags = tf.string_split(post_tags_str, \"|\")\n    return ids, tf.SparseTensor(\n            indices=split_tags.indices,\n            values=table.lookup(split_tags.values),  # 不同值通过表查到的index\n            dense_shape=split_tags.dense_shape)\n\n# Optionally create an embedding for this.\nTAG_EMBEDDING_DIM = 3\n\nids, tags = sparse_from_csv(csv)\n\nembedding_params = tf.Variable(tf.truncated_normal([len(TAG_SET) + NUM_OOV, TAG_EMBEDDING_DIM]))\nembedded_tags = tf.nn.embedding_lookup_sparse(embedding_params, sp_ids=tags, sp_weights=None)\n\n# Test it out\nwith tf.Session() as sess:\n    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n    print(s.run([ids, embedded_tags]))\n```\n\n## 继续学习\n\n[TensorFlow Wide And Deep 模型详解与应用](https://blog.csdn.net/kwame211/article/details/78015498)\n","slug":"google-wide-and-deep-network","published":1,"updated":"2018-06-04T06:53:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xm000jn61dgl4o09dz","content":"<h1 id=\"第0章\"><a href=\"#第0章\" class=\"headerlink\" title=\"第0章\"></a>第0章</h1><p>wide是指高维特征+特征组合的LR。LR高效、容易规模化（scalable）、可解释性强。但是泛化性需要在特征工程上下功夫<br>deep就是deep learning了。特征工程省力，但是容易过度泛化over-generalize。</p>\n<h2 id=\"参考阅读\"><a href=\"#参考阅读\" class=\"headerlink\" title=\"参考阅读\"></a>参考阅读</h2><ul>\n<li>2016 《Wide &amp; Deep Learning for Recommender Systems》 \b<a href=\"\">blog</a></li>\n<li>2017 《Deep &amp; Cross Network for Ad Click Predictions》 <a href=\"\">blog</a></li>\n<li><a href=\"https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html\" target=\"_blank\" rel=\"noopener\">google research blog</a></li>\n<li><a href=\"https://github.com/tensorflow/models/tree/master/official/wide_deep\" target=\"_blank\" rel=\"noopener\">wide &amp; deep github code</a></li>\n<li>《2016-Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features》 </li>\n</ul>\n<p>链接：本文参考：<a href=\"https://blog.csdn.net/yujianmin1990/article/details/78989099\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yujianmin1990/article/details/78989099</a></p>\n<h1 id=\"paper\"><a href=\"#paper\" class=\"headerlink\" title=\"paper\"></a>paper</h1><p>Wide &amp; Deep前者是用来给用户推荐潜在喜欢的APP；Deep &amp; Cross是用来预测用户可能点击的广告排序。</p>\n<h2 id=\"Memorization-和-Generalization\"><a href=\"#Memorization-和-Generalization\" class=\"headerlink\" title=\"Memorization 和 Generalization\"></a>Memorization 和 Generalization</h2><p>paper 的两个重要概念：</p>\n<p>Memorization（对应wide）: 特征关系的 Memorization ，是 cross-product transformation 实现的一个wide set，它有效也便于理解。<em>Memorization</em> 可以宽泛地定义成学到items或features的共现率，并利用（exploiting）这种在历史数据中的相关关系（correlation）。</p>\n<p>Generalization （对应deep)： 相关性的传递（transitivity），新特征组合,多样性（diversity）好一些。是基于相关关系的转移，并探索（explores）在过往很少或从不出现的新的特征组合。</p>\n<p>基于Memorization的推荐系统通常更局部化(topical)，将items与执行相应动作的users直接相关。而基于Generalization的推荐则更趋向于推荐多样化的items。</p>\n<h2 id=\"本文的主要贡献\"><a href=\"#本文的主要贡献\" class=\"headerlink\" title=\"本文的主要贡献\"></a>本文的主要贡献</h2><p>Wide &amp; Deep 学习框架，可以用于联合训练带embeddings的feed-forward神经网络，以及对于稀疏输入的常用推荐系统所使用的带特征转换的线性模型。<br>Wide &amp; Deep推荐系统的实现和评估在Google Play上已经产品化，这个app store具有数十亿的活跃用户、以及上百万的app。<br>开源，在Tensorflow上提供了一个高级API。</p>\n<h2 id=\"特征输入\"><a href=\"#特征输入\" class=\"headerlink\" title=\"特征输入\"></a>特征输入</h2><p>W&amp;D的特征包括三方面： </p>\n<ul>\n<li>User-Feature：contry, language, demographics. </li>\n<li>Contextual-Feature：device, hour of the day, day of the week. 像余额宝、阿里音乐那个比赛都用了时间特征</li>\n<li>Impression-Feature：app age, historical statistics of an app. </li>\n</ul>\n<ol>\n<li><p>Wide部分的输入特征</p>\n<ul>\n<li>raw input features and transformed features [手挑的交叉特征]. </li>\n</ul>\n</li>\n</ol>\n<p>notice: Wide_Deep 这里的 cross-product transformation：只在离散特征（稀疏）之间做组合，不管是文本策略型的，还是离散值的；没有连续值特征的啥事，至少在W&amp;D的paper里面是这样使用的。 </p>\n<ol>\n<li><p>Deep部分的输入特征</p>\n<ul>\n<li>raw input + embeding处理 </li>\n</ul>\n</li>\n</ol>\n<p>对非连续值之外的特征做 embedding 处理，这里都是策略特征，就是乘以个 embedding_matrix 。在TensorFlow里面的接口是：tf.feature_column.embedding_column，默认trainable=True. </p>\n<p>对连续值特征的处理是：将其按照累积分布函数P(X≤x)，压缩至[0,1]内。 </p>\n<h3 id=\"notice\"><a href=\"#notice\" class=\"headerlink\" title=\"notice\"></a>notice</h3><p>Wide部分用FTRL+L1来训练；Deep部分用AdaGrad来训练。 </p>\n<p>Wide&amp;Deep在TensorFlow里面的API接口为：tf.estimator.DNNLinearCombinedClassifier </p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/wide-and-deep-1.png\" alt=\"\"></p>\n<h2 id=\"3-Wide-amp-Deep-Learning\"><a href=\"#3-Wide-amp-Deep-Learning\" class=\"headerlink\" title=\"3. Wide &amp; Deep Learning\"></a>3. Wide &amp; Deep Learning</h2><h3 id=\"3-1-Wide组件\"><a href=\"#3-1-Wide组件\" class=\"headerlink\" title=\"3.1 Wide组件\"></a>3.1 Wide组件</h3><p>wide组件是一个泛化的线性模型，形式为：$y=w^Tx+b$，如图1(左）所示。y是预测，$x = [x_1, x_2, …, x_d]$ 是d维的特征向量， $w = [w_1, w_2,…, w_d]$ 是模型参数，其中b为bias。特征集包括原始的输入特征和转换后的特征，一个最重要的转换是，cross-product transformation。它可以定义成：</p>\n<p>$\\phi_k(x)=\\prod_{i=1}^{d}x_{i}^{c_{ki}}, c_{ki} \\in \\{0, 1\\}$ (paper 公式1)</p>\n<p>其中 $c_{ki}$ 为一个boolean变量，如果第i个特征是第k个变换ϕk的一部分，那么为1; 否则为0.对于二值特征，一个cross-product transformation（比如：”AND(gender=female, language=en)”）只能当组成特征（“gender=female” 和 “language=en”）都为1时才会为1, 否则为0. 这会捕获二值特征间的交叉，为通用的线性模型添加非线性。</p>\n<h3 id=\"3-2-Deep组件\"><a href=\"#3-2-Deep组件\" class=\"headerlink\" title=\"3.2 Deep组件\"></a>3.2 Deep组件</h3><p>Deep组件是一个前馈神经网络(feed-forward NN)，如图1(右）所示。对于类别型特征，原始的输入是特征字符串（比如：”language=en”）。这些稀疏的，高维的类别型特征会首先被转换成一个低维的、dense的、real-valued的向量，通常叫做“embedding vector”。embedding的维度通常是O(10)到O(100)的阶。该 embedding vectors 被随机初始化，接着最小化最终的loss的方式训练得到该值。这些低维的dense embedding vectors接着通过前向传递被feed给神经网络的隐层。特别地，每个隐层都会执行以下的计算：</p>\n<p>$a^{l+1}=f(W^{(l)}a^{(l)}+b^{(l)})$ (公式2)</p>\n<p>其中，l是层数，f是激活函数（通常为ReLUs），$a^{(l)}$，$b^{(l)}$ 和$W^{(l)}$分别是第l层的activations, bias，以及weights。</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/DX-20180603@2x.png\" alt=\"\"></p>\n<h3 id=\"3-3-Wide-amp-Deep模型的联合训练\"><a href=\"#3-3-Wide-amp-Deep模型的联合训练\" class=\"headerlink\" title=\"3.3 Wide &amp; Deep模型的联合训练\"></a>3.3 Wide &amp; Deep模型的联合训练</h3><p>Wide组件和Deep组件组合在一起，对它们的输入日志进行一个加权求和来做为预测，它会被feed给一个常见的logistic loss function来进行联合训练。注意，联合训练（joint training）和集成训练（ensemble）有明显的区别。在ensemble中，每个独立的模型会单独训练，相互并不知道，只有在预测时会组合在一起。相反地，<strong>联合训练（joint training）会同时优化所有参数，通过将wide组件和deep组件在训练时进行加权求和的方式进行。</strong>这也暗示了模型的size：对于一个ensemble，由于训练是不联合的（disjoint），每个单独的模型size通常需要更大些（例如：更多的特征和转换）来达到合理的精度。相比之下，对于联合训练（joint training）来说，wide组件只需要补充deep组件的缺点，使用一小部分的cross-product特征转换即可，而非使用一个full-size的wide模型。</p>\n<p>一个Wide&amp;Deep模型的联合训练，通过对梯度进行后向传播算法、SGD优化来完成。在试验中，我们使用FTRL算法，使用L1正则做为Wide组件的优化器，对Deep组件使用AdaGrad。</p>\n<p>组合模型如图一（中）所示。对于一个logistic regression问题，模型的预测为：</p>\n<p>$P(Y = 1 | x) = \\sigma(w_{wide}^{T} [x, \\phi(x)] + w_{deep}^{T} a^{(l_f)} + b)$  (paper \b公式3)</p>\n<p>其中Y是二分类的label，$\\sigma(·)$是sigmoid function， $\\phi(x)$ 是对原始特征x做cross product transformations，b是bias项。$w_{wide}$ 是所有wide模型权重向量，$w_{deep}$ 是应用在最终激活函数 $a^{(lf)}$ 上的权重。</p>\n<h2 id=\"4-系统实践\"><a href=\"#4-系统实践\" class=\"headerlink\" title=\"4 \b系统实践\"></a>4 \b系统实践</h2><p>连续值先用累计分布函数CDF归一化到[0,1]，再划档离散化。</p>\n<h1 id=\"论文翻译\"><a href=\"#论文翻译\" class=\"headerlink\" title=\"论文翻译\"></a>论文翻译</h1><p><a href=\"http://d0evi1.com/widedeep-recsys/\" target=\"_blank\" rel=\"noopener\">基于Wide &amp; Deep Learning的推荐系统</a></p>\n<h1 id=\"附\"><a href=\"#附\" class=\"headerlink\" title=\"附\"></a>附</h1><h2 id=\"Tensorflow\"><a href=\"#Tensorflow\" class=\"headerlink\" title=\"Tensorflow\"></a>Tensorflow</h2><p>只需要3步，即可以使用tf.estimator API来配置一个wide，deep或者Wide&amp;Deep：</p>\n<ol>\n<li>选中wide组件的特征：选中你想用的稀疏的base特征列和交叉列特征列</li>\n<li>选择deep组件的特征：选择连续型的列，对于每个类别型列的embedding维，以及隐层的size。</li>\n</ol>\n<p>将它们放置到一个Wide&amp;Deep模型中（DNNLinearCombinedClassifier）</p>\n<p>关于更详细的操作，示例代码在：/tensorflow/tensorflow/examples/learn/wide_n_deep_tutorial.py，具体详见tensorflow tutorial。</p>\n<h2 id=\"tf-nn-embedding-lookup-sparse\"><a href=\"#tf-nn-embedding-lookup-sparse\" class=\"headerlink\" title=\"tf.nn.embedding_lookup_sparse\"></a>tf.nn.embedding_lookup_sparse</h2><p>如何处理不定长的字符串的embedding问题</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输入数据如下</span></span><br><span class=\"line\">csv = [</span><br><span class=\"line\">    <span class=\"string\">\"1,oscars|brad-pitt|awards\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"2,oscars|film|reviews\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"3,matt-damon|bourne\"</span>,</span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 第二列是不定长的特征。处理如下</span></span><br><span class=\"line\"><span class=\"comment\"># Purposefully omitting \"bourne\" to demonstrate OOV mappings.</span></span><br><span class=\"line\">TAG_SET = [<span class=\"string\">\"oscars\"</span>, <span class=\"string\">\"brad-pitt\"</span>, <span class=\"string\">\"awards\"</span>, <span class=\"string\">\"film\"</span>, <span class=\"string\">\"reviews\"</span>, <span class=\"string\">\"matt-damon\"</span>]</span><br><span class=\"line\">NUM_OOV = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sparse_from_csv</span><span class=\"params\">(csv)</span>:</span></span><br><span class=\"line\">    ids, post_tags_str = tf.decode_csv(csv, [[<span class=\"number\">-1</span>], [<span class=\"string\">\"\"</span>]])</span><br><span class=\"line\">    table = tf.contrib.lookup.index_table_from_tensor(</span><br><span class=\"line\">        mapping=TAG_SET, num_oov_buckets=NUM_OOV, default_value=<span class=\"number\">-1</span>)  <span class=\"comment\"># 构造查找表</span></span><br><span class=\"line\">    split_tags = tf.string_split(post_tags_str, <span class=\"string\">\"|\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ids, tf.SparseTensor(</span><br><span class=\"line\">            indices=split_tags.indices,</span><br><span class=\"line\">            values=table.lookup(split_tags.values),  <span class=\"comment\"># 不同值通过表查到的index</span></span><br><span class=\"line\">            dense_shape=split_tags.dense_shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Optionally create an embedding for this.</span></span><br><span class=\"line\">TAG_EMBEDDING_DIM = <span class=\"number\">3</span></span><br><span class=\"line\"></span><br><span class=\"line\">ids, tags = sparse_from_csv(csv)</span><br><span class=\"line\"></span><br><span class=\"line\">embedding_params = tf.Variable(tf.truncated_normal([len(TAG_SET) + NUM_OOV, TAG_EMBEDDING_DIM]))</span><br><span class=\"line\">embedded_tags = tf.nn.embedding_lookup_sparse(embedding_params, sp_ids=tags, sp_weights=<span class=\"keyword\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Test it out</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])</span><br><span class=\"line\">    print(s.run([ids, embedded_tags]))</span><br></pre></td></tr></table></figure>\n<h2 id=\"继续学习\"><a href=\"#继续学习\" class=\"headerlink\" title=\"继续学习\"></a>继续学习</h2><p><a href=\"https://blog.csdn.net/kwame211/article/details/78015498\" target=\"_blank\" rel=\"noopener\">TensorFlow Wide And Deep 模型详解与应用</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"第0章\"><a href=\"#第0章\" class=\"headerlink\" title=\"第0章\"></a>第0章</h1><p>wide是指高维特征+特征组合的LR。LR高效、容易规模化（scalable）、可解释性强。但是泛化性需要在特征工程上下功夫<br>deep就是deep learning了。特征工程省力，但是容易过度泛化over-generalize。</p>\n<h2 id=\"参考阅读\"><a href=\"#参考阅读\" class=\"headerlink\" title=\"参考阅读\"></a>参考阅读</h2><ul>\n<li>2016 《Wide &amp; Deep Learning for Recommender Systems》 \b<a href=\"\">blog</a></li>\n<li>2017 《Deep &amp; Cross Network for Ad Click Predictions》 <a href=\"\">blog</a></li>\n<li><a href=\"https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html\" target=\"_blank\" rel=\"noopener\">google research blog</a></li>\n<li><a href=\"https://github.com/tensorflow/models/tree/master/official/wide_deep\" target=\"_blank\" rel=\"noopener\">wide &amp; deep github code</a></li>\n<li>《2016-Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features》 </li>\n</ul>\n<p>链接：本文参考：<a href=\"https://blog.csdn.net/yujianmin1990/article/details/78989099\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yujianmin1990/article/details/78989099</a></p>\n<h1 id=\"paper\"><a href=\"#paper\" class=\"headerlink\" title=\"paper\"></a>paper</h1><p>Wide &amp; Deep前者是用来给用户推荐潜在喜欢的APP；Deep &amp; Cross是用来预测用户可能点击的广告排序。</p>\n<h2 id=\"Memorization-和-Generalization\"><a href=\"#Memorization-和-Generalization\" class=\"headerlink\" title=\"Memorization 和 Generalization\"></a>Memorization 和 Generalization</h2><p>paper 的两个重要概念：</p>\n<p>Memorization（对应wide）: 特征关系的 Memorization ，是 cross-product transformation 实现的一个wide set，它有效也便于理解。<em>Memorization</em> 可以宽泛地定义成学到items或features的共现率，并利用（exploiting）这种在历史数据中的相关关系（correlation）。</p>\n<p>Generalization （对应deep)： 相关性的传递（transitivity），新特征组合,多样性（diversity）好一些。是基于相关关系的转移，并探索（explores）在过往很少或从不出现的新的特征组合。</p>\n<p>基于Memorization的推荐系统通常更局部化(topical)，将items与执行相应动作的users直接相关。而基于Generalization的推荐则更趋向于推荐多样化的items。</p>\n<h2 id=\"本文的主要贡献\"><a href=\"#本文的主要贡献\" class=\"headerlink\" title=\"本文的主要贡献\"></a>本文的主要贡献</h2><p>Wide &amp; Deep 学习框架，可以用于联合训练带embeddings的feed-forward神经网络，以及对于稀疏输入的常用推荐系统所使用的带特征转换的线性模型。<br>Wide &amp; Deep推荐系统的实现和评估在Google Play上已经产品化，这个app store具有数十亿的活跃用户、以及上百万的app。<br>开源，在Tensorflow上提供了一个高级API。</p>\n<h2 id=\"特征输入\"><a href=\"#特征输入\" class=\"headerlink\" title=\"特征输入\"></a>特征输入</h2><p>W&amp;D的特征包括三方面： </p>\n<ul>\n<li>User-Feature：contry, language, demographics. </li>\n<li>Contextual-Feature：device, hour of the day, day of the week. 像余额宝、阿里音乐那个比赛都用了时间特征</li>\n<li>Impression-Feature：app age, historical statistics of an app. </li>\n</ul>\n<ol>\n<li><p>Wide部分的输入特征</p>\n<ul>\n<li>raw input features and transformed features [手挑的交叉特征]. </li>\n</ul>\n</li>\n</ol>\n<p>notice: Wide_Deep 这里的 cross-product transformation：只在离散特征（稀疏）之间做组合，不管是文本策略型的，还是离散值的；没有连续值特征的啥事，至少在W&amp;D的paper里面是这样使用的。 </p>\n<ol>\n<li><p>Deep部分的输入特征</p>\n<ul>\n<li>raw input + embeding处理 </li>\n</ul>\n</li>\n</ol>\n<p>对非连续值之外的特征做 embedding 处理，这里都是策略特征，就是乘以个 embedding_matrix 。在TensorFlow里面的接口是：tf.feature_column.embedding_column，默认trainable=True. </p>\n<p>对连续值特征的处理是：将其按照累积分布函数P(X≤x)，压缩至[0,1]内。 </p>\n<h3 id=\"notice\"><a href=\"#notice\" class=\"headerlink\" title=\"notice\"></a>notice</h3><p>Wide部分用FTRL+L1来训练；Deep部分用AdaGrad来训练。 </p>\n<p>Wide&amp;Deep在TensorFlow里面的API接口为：tf.estimator.DNNLinearCombinedClassifier </p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/wide-and-deep-1.png\" alt=\"\"></p>\n<h2 id=\"3-Wide-amp-Deep-Learning\"><a href=\"#3-Wide-amp-Deep-Learning\" class=\"headerlink\" title=\"3. Wide &amp; Deep Learning\"></a>3. Wide &amp; Deep Learning</h2><h3 id=\"3-1-Wide组件\"><a href=\"#3-1-Wide组件\" class=\"headerlink\" title=\"3.1 Wide组件\"></a>3.1 Wide组件</h3><p>wide组件是一个泛化的线性模型，形式为：$y=w^Tx+b$，如图1(左）所示。y是预测，$x = [x_1, x_2, …, x_d]$ 是d维的特征向量， $w = [w_1, w_2,…, w_d]$ 是模型参数，其中b为bias。特征集包括原始的输入特征和转换后的特征，一个最重要的转换是，cross-product transformation。它可以定义成：</p>\n<p>$\\phi_k(x)=\\prod_{i=1}^{d}x_{i}^{c_{ki}}, c_{ki} \\in \\{0, 1\\}$ (paper 公式1)</p>\n<p>其中 $c_{ki}$ 为一个boolean变量，如果第i个特征是第k个变换ϕk的一部分，那么为1; 否则为0.对于二值特征，一个cross-product transformation（比如：”AND(gender=female, language=en)”）只能当组成特征（“gender=female” 和 “language=en”）都为1时才会为1, 否则为0. 这会捕获二值特征间的交叉，为通用的线性模型添加非线性。</p>\n<h3 id=\"3-2-Deep组件\"><a href=\"#3-2-Deep组件\" class=\"headerlink\" title=\"3.2 Deep组件\"></a>3.2 Deep组件</h3><p>Deep组件是一个前馈神经网络(feed-forward NN)，如图1(右）所示。对于类别型特征，原始的输入是特征字符串（比如：”language=en”）。这些稀疏的，高维的类别型特征会首先被转换成一个低维的、dense的、real-valued的向量，通常叫做“embedding vector”。embedding的维度通常是O(10)到O(100)的阶。该 embedding vectors 被随机初始化，接着最小化最终的loss的方式训练得到该值。这些低维的dense embedding vectors接着通过前向传递被feed给神经网络的隐层。特别地，每个隐层都会执行以下的计算：</p>\n<p>$a^{l+1}=f(W^{(l)}a^{(l)}+b^{(l)})$ (公式2)</p>\n<p>其中，l是层数，f是激活函数（通常为ReLUs），$a^{(l)}$，$b^{(l)}$ 和$W^{(l)}$分别是第l层的activations, bias，以及weights。</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/DX-20180603@2x.png\" alt=\"\"></p>\n<h3 id=\"3-3-Wide-amp-Deep模型的联合训练\"><a href=\"#3-3-Wide-amp-Deep模型的联合训练\" class=\"headerlink\" title=\"3.3 Wide &amp; Deep模型的联合训练\"></a>3.3 Wide &amp; Deep模型的联合训练</h3><p>Wide组件和Deep组件组合在一起，对它们的输入日志进行一个加权求和来做为预测，它会被feed给一个常见的logistic loss function来进行联合训练。注意，联合训练（joint training）和集成训练（ensemble）有明显的区别。在ensemble中，每个独立的模型会单独训练，相互并不知道，只有在预测时会组合在一起。相反地，<strong>联合训练（joint training）会同时优化所有参数，通过将wide组件和deep组件在训练时进行加权求和的方式进行。</strong>这也暗示了模型的size：对于一个ensemble，由于训练是不联合的（disjoint），每个单独的模型size通常需要更大些（例如：更多的特征和转换）来达到合理的精度。相比之下，对于联合训练（joint training）来说，wide组件只需要补充deep组件的缺点，使用一小部分的cross-product特征转换即可，而非使用一个full-size的wide模型。</p>\n<p>一个Wide&amp;Deep模型的联合训练，通过对梯度进行后向传播算法、SGD优化来完成。在试验中，我们使用FTRL算法，使用L1正则做为Wide组件的优化器，对Deep组件使用AdaGrad。</p>\n<p>组合模型如图一（中）所示。对于一个logistic regression问题，模型的预测为：</p>\n<p>$P(Y = 1 | x) = \\sigma(w_{wide}^{T} [x, \\phi(x)] + w_{deep}^{T} a^{(l_f)} + b)$  (paper \b公式3)</p>\n<p>其中Y是二分类的label，$\\sigma(·)$是sigmoid function， $\\phi(x)$ 是对原始特征x做cross product transformations，b是bias项。$w_{wide}$ 是所有wide模型权重向量，$w_{deep}$ 是应用在最终激活函数 $a^{(lf)}$ 上的权重。</p>\n<h2 id=\"4-系统实践\"><a href=\"#4-系统实践\" class=\"headerlink\" title=\"4 \b系统实践\"></a>4 \b系统实践</h2><p>连续值先用累计分布函数CDF归一化到[0,1]，再划档离散化。</p>\n<h1 id=\"论文翻译\"><a href=\"#论文翻译\" class=\"headerlink\" title=\"论文翻译\"></a>论文翻译</h1><p><a href=\"http://d0evi1.com/widedeep-recsys/\" target=\"_blank\" rel=\"noopener\">基于Wide &amp; Deep Learning的推荐系统</a></p>\n<h1 id=\"附\"><a href=\"#附\" class=\"headerlink\" title=\"附\"></a>附</h1><h2 id=\"Tensorflow\"><a href=\"#Tensorflow\" class=\"headerlink\" title=\"Tensorflow\"></a>Tensorflow</h2><p>只需要3步，即可以使用tf.estimator API来配置一个wide，deep或者Wide&amp;Deep：</p>\n<ol>\n<li>选中wide组件的特征：选中你想用的稀疏的base特征列和交叉列特征列</li>\n<li>选择deep组件的特征：选择连续型的列，对于每个类别型列的embedding维，以及隐层的size。</li>\n</ol>\n<p>将它们放置到一个Wide&amp;Deep模型中（DNNLinearCombinedClassifier）</p>\n<p>关于更详细的操作，示例代码在：/tensorflow/tensorflow/examples/learn/wide_n_deep_tutorial.py，具体详见tensorflow tutorial。</p>\n<h2 id=\"tf-nn-embedding-lookup-sparse\"><a href=\"#tf-nn-embedding-lookup-sparse\" class=\"headerlink\" title=\"tf.nn.embedding_lookup_sparse\"></a>tf.nn.embedding_lookup_sparse</h2><p>如何处理不定长的字符串的embedding问题</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输入数据如下</span></span><br><span class=\"line\">csv = [</span><br><span class=\"line\">    <span class=\"string\">\"1,oscars|brad-pitt|awards\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"2,oscars|film|reviews\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"3,matt-damon|bourne\"</span>,</span><br><span class=\"line\">]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 第二列是不定长的特征。处理如下</span></span><br><span class=\"line\"><span class=\"comment\"># Purposefully omitting \"bourne\" to demonstrate OOV mappings.</span></span><br><span class=\"line\">TAG_SET = [<span class=\"string\">\"oscars\"</span>, <span class=\"string\">\"brad-pitt\"</span>, <span class=\"string\">\"awards\"</span>, <span class=\"string\">\"film\"</span>, <span class=\"string\">\"reviews\"</span>, <span class=\"string\">\"matt-damon\"</span>]</span><br><span class=\"line\">NUM_OOV = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sparse_from_csv</span><span class=\"params\">(csv)</span>:</span></span><br><span class=\"line\">    ids, post_tags_str = tf.decode_csv(csv, [[<span class=\"number\">-1</span>], [<span class=\"string\">\"\"</span>]])</span><br><span class=\"line\">    table = tf.contrib.lookup.index_table_from_tensor(</span><br><span class=\"line\">        mapping=TAG_SET, num_oov_buckets=NUM_OOV, default_value=<span class=\"number\">-1</span>)  <span class=\"comment\"># 构造查找表</span></span><br><span class=\"line\">    split_tags = tf.string_split(post_tags_str, <span class=\"string\">\"|\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ids, tf.SparseTensor(</span><br><span class=\"line\">            indices=split_tags.indices,</span><br><span class=\"line\">            values=table.lookup(split_tags.values),  <span class=\"comment\"># 不同值通过表查到的index</span></span><br><span class=\"line\">            dense_shape=split_tags.dense_shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Optionally create an embedding for this.</span></span><br><span class=\"line\">TAG_EMBEDDING_DIM = <span class=\"number\">3</span></span><br><span class=\"line\"></span><br><span class=\"line\">ids, tags = sparse_from_csv(csv)</span><br><span class=\"line\"></span><br><span class=\"line\">embedding_params = tf.Variable(tf.truncated_normal([len(TAG_SET) + NUM_OOV, TAG_EMBEDDING_DIM]))</span><br><span class=\"line\">embedded_tags = tf.nn.embedding_lookup_sparse(embedding_params, sp_ids=tags, sp_weights=<span class=\"keyword\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Test it out</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])</span><br><span class=\"line\">    print(s.run([ids, embedded_tags]))</span><br></pre></td></tr></table></figure>\n<h2 id=\"继续学习\"><a href=\"#继续学习\" class=\"headerlink\" title=\"继续学习\"></a>继续学习</h2><p><a href=\"https://blog.csdn.net/kwame211/article/details/78015498\" target=\"_blank\" rel=\"noopener\">TensorFlow Wide And Deep 模型详解与应用</a></p>\n"},{"title":"推荐算法方面的优秀文章","date":"2018-06-03T07:18:15.000Z","_content":"\n# 一些概念\n\n推荐广告怎么做？\n\n系统架构是什么样？ \n系统架构： bizer(特征抽取) → QR(用户理解 利用user id或上下文、位置等 → 相关的tag list) → Searcher(广告倒排 tag → ad list(后续ctr排序预选的ad)) → Ranker(根据cpm = ctr*bid，以及相关性等精排), 然后依次返回到用户做个性化推荐。\n\n广告从投放到计费经过哪些主要流程？\n投放到计费流程：点击付费(CPC), 展示付费(CPM), 按销售收入付费(CPS)等。\n\n这个流程中算法策略关注什么？\n算法策略关注：架构流程中每个步骤的数据的准确性，完整性对整个系统的准确度有重要影响。\n\n# 综述 \n\n[CTR预估算法之FM, FFM, DeepFM及实践](https://blog.csdn.net/John_xyz/article/details/78933253)\n\n阿里巴巴\n\n- [常用推荐算法（50页干货）](https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&mid=2247483811&idx=1&sn=fc3ee4ddfc4a8d6014a4cd90cdb5983c&scene=4#wechat_redirect)\n\n腾讯\n\n- [常见计算广告点击率预估算法总结](https://cloud.tencent.com/developer/article/1005915)\n- 高航，[深度学习在 CTR 中应用](https://cloud.tencent.com/developer/article/1006667)\n\n美团\n\n- [第09章：深入浅出ML之Factorization家族](http://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/)\n# 时间线\n\n\n[FM算法(一)：算法理论](https://www.cnblogs.com/AndyJee/p/7879765.html)\n[FM算法(二)：工程实现](https://www.cnblogs.com/AndyJee/p/8032553.html)\n[FM算法详解](https://blog.csdn.net/bitcarmanlee/article/details/52143909)\n\n[深入FFM原理与实践](https://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html)\n\n# 2013 \n\n[各大公司广泛使用的在线学习算法FTRL详解](http://www.cnblogs.com/EE-NovRain/p/3810737.html )\n\n\n# code + action\n\n[TensorFlow Estimator of Deep CTR --DeepFM/NFM/AFM/FNN/PNN](https://zhuanlan.zhihu.com/p/33699909)\n\n# 协同过滤 待总结\nhttps://blog.csdn.net/u010297828/article/details/51504952\n\n# AFM\n\nhttps://blog.csdn.net/jiangjiang_jian/article/details/80674250\n\n# embedding\nhttps://ask.hellobi.com/blog/wenwen/11885","source":"_posts/201806-recommemder-alg-introduction.md","raw":"---\ntitle: 推荐算法方面的优秀文章\ndate: 2018-06-03 15:18:15\ntags:\n---\n\n# 一些概念\n\n推荐广告怎么做？\n\n系统架构是什么样？ \n系统架构： bizer(特征抽取) → QR(用户理解 利用user id或上下文、位置等 → 相关的tag list) → Searcher(广告倒排 tag → ad list(后续ctr排序预选的ad)) → Ranker(根据cpm = ctr*bid，以及相关性等精排), 然后依次返回到用户做个性化推荐。\n\n广告从投放到计费经过哪些主要流程？\n投放到计费流程：点击付费(CPC), 展示付费(CPM), 按销售收入付费(CPS)等。\n\n这个流程中算法策略关注什么？\n算法策略关注：架构流程中每个步骤的数据的准确性，完整性对整个系统的准确度有重要影响。\n\n# 综述 \n\n[CTR预估算法之FM, FFM, DeepFM及实践](https://blog.csdn.net/John_xyz/article/details/78933253)\n\n阿里巴巴\n\n- [常用推荐算法（50页干货）](https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&mid=2247483811&idx=1&sn=fc3ee4ddfc4a8d6014a4cd90cdb5983c&scene=4#wechat_redirect)\n\n腾讯\n\n- [常见计算广告点击率预估算法总结](https://cloud.tencent.com/developer/article/1005915)\n- 高航，[深度学习在 CTR 中应用](https://cloud.tencent.com/developer/article/1006667)\n\n美团\n\n- [第09章：深入浅出ML之Factorization家族](http://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/)\n# 时间线\n\n\n[FM算法(一)：算法理论](https://www.cnblogs.com/AndyJee/p/7879765.html)\n[FM算法(二)：工程实现](https://www.cnblogs.com/AndyJee/p/8032553.html)\n[FM算法详解](https://blog.csdn.net/bitcarmanlee/article/details/52143909)\n\n[深入FFM原理与实践](https://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html)\n\n# 2013 \n\n[各大公司广泛使用的在线学习算法FTRL详解](http://www.cnblogs.com/EE-NovRain/p/3810737.html )\n\n\n# code + action\n\n[TensorFlow Estimator of Deep CTR --DeepFM/NFM/AFM/FNN/PNN](https://zhuanlan.zhihu.com/p/33699909)\n\n# 协同过滤 待总结\nhttps://blog.csdn.net/u010297828/article/details/51504952\n\n# AFM\n\nhttps://blog.csdn.net/jiangjiang_jian/article/details/80674250\n\n# embedding\nhttps://ask.hellobi.com/blog/wenwen/11885","slug":"recommemder-alg-introduction","published":1,"updated":"2018-08-24T02:13:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xn000kn61dg9cig6mr","content":"<h1 id=\"一些概念\"><a href=\"#一些概念\" class=\"headerlink\" title=\"一些概念\"></a>一些概念</h1><p>推荐广告怎么做？</p>\n<p>系统架构是什么样？<br>系统架构： bizer(特征抽取) → QR(用户理解 利用user id或上下文、位置等 → 相关的tag list) → Searcher(广告倒排 tag → ad list(后续ctr排序预选的ad)) → Ranker(根据cpm = ctr*bid，以及相关性等精排), 然后依次返回到用户做个性化推荐。</p>\n<p>广告从投放到计费经过哪些主要流程？<br>投放到计费流程：点击付费(CPC), 展示付费(CPM), 按销售收入付费(CPS)等。</p>\n<p>这个流程中算法策略关注什么？<br>算法策略关注：架构流程中每个步骤的数据的准确性，完整性对整个系统的准确度有重要影响。</p>\n<h1 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h1><p><a href=\"https://blog.csdn.net/John_xyz/article/details/78933253\" target=\"_blank\" rel=\"noopener\">CTR预估算法之FM, FFM, DeepFM及实践</a></p>\n<p>阿里巴巴</p>\n<ul>\n<li><a href=\"https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&amp;mid=2247483811&amp;idx=1&amp;sn=fc3ee4ddfc4a8d6014a4cd90cdb5983c&amp;scene=4#wechat_redirect\" target=\"_blank\" rel=\"noopener\">常用推荐算法（50页干货）</a></li>\n</ul>\n<p>腾讯</p>\n<ul>\n<li><a href=\"https://cloud.tencent.com/developer/article/1005915\" target=\"_blank\" rel=\"noopener\">常见计算广告点击率预估算法总结</a></li>\n<li>高航，<a href=\"https://cloud.tencent.com/developer/article/1006667\" target=\"_blank\" rel=\"noopener\">深度学习在 CTR 中应用</a></li>\n</ul>\n<p>美团</p>\n<ul>\n<li><a href=\"http://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/\" target=\"_blank\" rel=\"noopener\">第09章：深入浅出ML之Factorization家族</a><h1 id=\"时间线\"><a href=\"#时间线\" class=\"headerlink\" title=\"时间线\"></a>时间线</h1></li>\n</ul>\n<p><a href=\"https://www.cnblogs.com/AndyJee/p/7879765.html\" target=\"_blank\" rel=\"noopener\">FM算法(一)：算法理论</a><br><a href=\"https://www.cnblogs.com/AndyJee/p/8032553.html\" target=\"_blank\" rel=\"noopener\">FM算法(二)：工程实现</a><br><a href=\"https://blog.csdn.net/bitcarmanlee/article/details/52143909\" target=\"_blank\" rel=\"noopener\">FM算法详解</a></p>\n<p><a href=\"https://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html\" target=\"_blank\" rel=\"noopener\">深入FFM原理与实践</a></p>\n<h1 id=\"2013\"><a href=\"#2013\" class=\"headerlink\" title=\"2013\"></a>2013</h1><p><a href=\"http://www.cnblogs.com/EE-NovRain/p/3810737.html\" target=\"_blank\" rel=\"noopener\">各大公司广泛使用的在线学习算法FTRL详解</a></p>\n<h1 id=\"code-action\"><a href=\"#code-action\" class=\"headerlink\" title=\"code + action\"></a>code + action</h1><p><a href=\"https://zhuanlan.zhihu.com/p/33699909\" target=\"_blank\" rel=\"noopener\">TensorFlow Estimator of Deep CTR —DeepFM/NFM/AFM/FNN/PNN</a></p>\n<h1 id=\"协同过滤-待总结\"><a href=\"#协同过滤-待总结\" class=\"headerlink\" title=\"协同过滤 待总结\"></a>协同过滤 待总结</h1><p><a href=\"https://blog.csdn.net/u010297828/article/details/51504952\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u010297828/article/details/51504952</a></p>\n<h1 id=\"AFM\"><a href=\"#AFM\" class=\"headerlink\" title=\"AFM\"></a>AFM</h1><p><a href=\"https://blog.csdn.net/jiangjiang_jian/article/details/80674250\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jiangjiang_jian/article/details/80674250</a></p>\n<h1 id=\"embedding\"><a href=\"#embedding\" class=\"headerlink\" title=\"embedding\"></a>embedding</h1><p><a href=\"https://ask.hellobi.com/blog/wenwen/11885\" target=\"_blank\" rel=\"noopener\">https://ask.hellobi.com/blog/wenwen/11885</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一些概念\"><a href=\"#一些概念\" class=\"headerlink\" title=\"一些概念\"></a>一些概念</h1><p>推荐广告怎么做？</p>\n<p>系统架构是什么样？<br>系统架构： bizer(特征抽取) → QR(用户理解 利用user id或上下文、位置等 → 相关的tag list) → Searcher(广告倒排 tag → ad list(后续ctr排序预选的ad)) → Ranker(根据cpm = ctr*bid，以及相关性等精排), 然后依次返回到用户做个性化推荐。</p>\n<p>广告从投放到计费经过哪些主要流程？<br>投放到计费流程：点击付费(CPC), 展示付费(CPM), 按销售收入付费(CPS)等。</p>\n<p>这个流程中算法策略关注什么？<br>算法策略关注：架构流程中每个步骤的数据的准确性，完整性对整个系统的准确度有重要影响。</p>\n<h1 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h1><p><a href=\"https://blog.csdn.net/John_xyz/article/details/78933253\" target=\"_blank\" rel=\"noopener\">CTR预估算法之FM, FFM, DeepFM及实践</a></p>\n<p>阿里巴巴</p>\n<ul>\n<li><a href=\"https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&amp;mid=2247483811&amp;idx=1&amp;sn=fc3ee4ddfc4a8d6014a4cd90cdb5983c&amp;scene=4#wechat_redirect\" target=\"_blank\" rel=\"noopener\">常用推荐算法（50页干货）</a></li>\n</ul>\n<p>腾讯</p>\n<ul>\n<li><a href=\"https://cloud.tencent.com/developer/article/1005915\" target=\"_blank\" rel=\"noopener\">常见计算广告点击率预估算法总结</a></li>\n<li>高航，<a href=\"https://cloud.tencent.com/developer/article/1006667\" target=\"_blank\" rel=\"noopener\">深度学习在 CTR 中应用</a></li>\n</ul>\n<p>美团</p>\n<ul>\n<li><a href=\"http://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/\" target=\"_blank\" rel=\"noopener\">第09章：深入浅出ML之Factorization家族</a><h1 id=\"时间线\"><a href=\"#时间线\" class=\"headerlink\" title=\"时间线\"></a>时间线</h1></li>\n</ul>\n<p><a href=\"https://www.cnblogs.com/AndyJee/p/7879765.html\" target=\"_blank\" rel=\"noopener\">FM算法(一)：算法理论</a><br><a href=\"https://www.cnblogs.com/AndyJee/p/8032553.html\" target=\"_blank\" rel=\"noopener\">FM算法(二)：工程实现</a><br><a href=\"https://blog.csdn.net/bitcarmanlee/article/details/52143909\" target=\"_blank\" rel=\"noopener\">FM算法详解</a></p>\n<p><a href=\"https://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html\" target=\"_blank\" rel=\"noopener\">深入FFM原理与实践</a></p>\n<h1 id=\"2013\"><a href=\"#2013\" class=\"headerlink\" title=\"2013\"></a>2013</h1><p><a href=\"http://www.cnblogs.com/EE-NovRain/p/3810737.html\" target=\"_blank\" rel=\"noopener\">各大公司广泛使用的在线学习算法FTRL详解</a></p>\n<h1 id=\"code-action\"><a href=\"#code-action\" class=\"headerlink\" title=\"code + action\"></a>code + action</h1><p><a href=\"https://zhuanlan.zhihu.com/p/33699909\" target=\"_blank\" rel=\"noopener\">TensorFlow Estimator of Deep CTR —DeepFM/NFM/AFM/FNN/PNN</a></p>\n<h1 id=\"协同过滤-待总结\"><a href=\"#协同过滤-待总结\" class=\"headerlink\" title=\"协同过滤 待总结\"></a>协同过滤 待总结</h1><p><a href=\"https://blog.csdn.net/u010297828/article/details/51504952\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u010297828/article/details/51504952</a></p>\n<h1 id=\"AFM\"><a href=\"#AFM\" class=\"headerlink\" title=\"AFM\"></a>AFM</h1><p><a href=\"https://blog.csdn.net/jiangjiang_jian/article/details/80674250\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jiangjiang_jian/article/details/80674250</a></p>\n<h1 id=\"embedding\"><a href=\"#embedding\" class=\"headerlink\" title=\"embedding\"></a>embedding</h1><p><a href=\"https://ask.hellobi.com/blog/wenwen/11885\" target=\"_blank\" rel=\"noopener\">https://ask.hellobi.com/blog/wenwen/11885</a></p>\n"},{"title":"推荐系统及广告系统相关算法综述","date":"2018-06-23T16:01:42.000Z","mathjax":true,"_content":"\n目前，推荐系统领域主流的算法主要包括：\n\n1. ftrl, 2013年, Google公司, 《Ad click prediction: a view from the trenches》\n\n# 在线学习 ftrl\n\n传统的批量算法的每次迭代是对全体训练数据集进行计算（例如计算全局梯度），优点是精度和收敛还可以，缺点是无法有效处理大数据集（此时全局梯度计算代价太大），且没法应用于数据流做在线学习。\n\n而在线学习算法的特点是：每来一个训练样本，就用该样本产生的loss和梯度对模型迭代一次，一个一个数据地进行训练，因此可以处理大数据量训练和在线训练。准确地说，Online Learning并不是一种模型，而是一种模型的训练方法，Online Learning能够根据线上反馈数据，实时快速地进行模型调整，使得模型及时反映线上的变化，提高线上预测的准确率。\n\nOnline Learning的流程包括：将模型的预测结果展现给用户，然后收集用户的反馈数据，再用来训练模型，形成闭环的系统。如下图所示：\n\n![](http://p8vrqzrnj.bkt.clouddn.com/onlinelearning1.png)\n\n## CTR预测算法\n\n这篇论文提出的基于FTRL的在线CTR预测算法，就是一种Online Learning算法。\n\n即，针对每一个训练样本，首先通过一种方式进行预测，然后再利用一种损失函数进行误差评估，最后再通过所评估的误差值对参数进行更新迭代。直到所有样本全部遍历完，则结束。\n\n那么，如何选择模型预测方法、评估指标以及模型更新公式就是该算法的重点所在。下面将介绍论文中这三部分内容：\n\n1.预测方法：在每一轮 $t$ 中，针对特征样本 ${x}_{t}\\in {R}^{d}$，以及迭代后(第一此则是给定初值)的模型参数 $w_t$，我们可以预测该样本的标记值：${p}_{t}=\\sigma({w}_{t},{x}_{t})$ ，其中 $\\sigma(a)=\\frac{1}{1+exp(-a)}$ 是一个sigmoid函数。\n\n2.损失函数：对一个特征样本 $x_t$，对应的标记为 $y_t \\in 0, 1$， 则通过logistic loss 来作为损失函数，即： ${\\mathit{l}}_{t}({w}_{t})= -{y}_{t}log{p}_{t}-(1-{y}_{t})log(1-{p}_{t})$ \n\n3.迭代公式： 目的是使得损失函数尽可能小，即可以采用极大似然估计来求解参数。首先求梯度：\n\n$${g}_{t}=\\frac{d\\mathit{l}_{t}(w)}{dw}=(\\sigma(w*{x}_{t})-{y}_{t}){x}_{t}=({p}_{t}-{y}_{t}){x}_{t}$$\n\n暂时看不懂了\n基于FTRL的在线CTR预测算法\nhttps://blog.csdn.net/yz930618/article/details/75270869\n\n## ftrl References\n[@默一鸣](https://blog.csdn.net/yimingsilence/article/details/75123026) 标注了一下各篇paper的主要内容，感兴趣的可以有选择性地看一下，如果只关注工程实现，看标红的那篇就ok了：\n[1] J. Langford, L. Li, and T. Zhang. Sparse online learning via truncated gradient.JMLR, 10, 2009. （截断梯度的paper）\n\n[2] H. B. McMahan. Follow-the-regularized-leader and mirror descent: Equivalence theorems and L1 regularization. In AISTATS, 2011 （FOBOS、RDA、FTRL等各种方法对比的paper）\n\n[3] L. Xiao. Dual averaging method for regularized stochastic learning and online optimization. In NIPS, 2009 （RDA方法）\n\n[4] J. Duchi and Y. Singer. Efficient learning using forward-backward splitting. In Advances in Neural Information Processing Systems 22, pages 495{503. 2009. （FOBOS方法）\n\n[5] H. Brendan McMahan, Gary Holt, D. Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos, Jeremy Kubica, Ad Click Prediction: a View from the Trenches, Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) (2013) （这篇是那篇工程性的paper）\n\n[6] H. Brendan McMahan. A unied analysis of regular-ized dual averaging and composite mirror descent with implicit updates. Submitted, 2011 （FTRL理论发展，regret bound和加入通用正则化项）\n\n[7] H. Brendan McMahan and Matthew Streeter. Adap-tive bound optimization for online convex optimiza-tion. InCOLT, 2010 （开始的那篇理论性paper）\n\n# embedding\n\nhttps://www.cntk.ai/pythondocs/layerref.html#embedding\n\nembedding层，是一种用连续值向量来表示离散值或者word的方法，与one-hot相比，推荐系统中embedding层减少了特征的维度。在cntk中，embedding vector用行向量的方式来表示，将一个word映射到它的embedding只需要向量相乘（选取索引对应的embedding行）。\n\n梯度： embedding矩阵的梯度矩阵也是只在非0值的地方存在梯度，每次更新只要更新存在值的embedding层就行了（和推荐系统好像有点不同）\n\nword2vec中的bp\nhttp://www.claudiobellei.com/2018/01/06/backprop-word2vec/\n\n","source":"_posts/201806-recommender-and-ads-algs.md","raw":"---\ntitle: 推荐系统及广告系统相关算法综述\ndate: 2018-06-24 00:01:42\ncategories: 推荐系统算法\ntags:\n    - 推荐系统\n    - 计算广告\nmathjax: true\n---\n\n目前，推荐系统领域主流的算法主要包括：\n\n1. ftrl, 2013年, Google公司, 《Ad click prediction: a view from the trenches》\n\n# 在线学习 ftrl\n\n传统的批量算法的每次迭代是对全体训练数据集进行计算（例如计算全局梯度），优点是精度和收敛还可以，缺点是无法有效处理大数据集（此时全局梯度计算代价太大），且没法应用于数据流做在线学习。\n\n而在线学习算法的特点是：每来一个训练样本，就用该样本产生的loss和梯度对模型迭代一次，一个一个数据地进行训练，因此可以处理大数据量训练和在线训练。准确地说，Online Learning并不是一种模型，而是一种模型的训练方法，Online Learning能够根据线上反馈数据，实时快速地进行模型调整，使得模型及时反映线上的变化，提高线上预测的准确率。\n\nOnline Learning的流程包括：将模型的预测结果展现给用户，然后收集用户的反馈数据，再用来训练模型，形成闭环的系统。如下图所示：\n\n![](http://p8vrqzrnj.bkt.clouddn.com/onlinelearning1.png)\n\n## CTR预测算法\n\n这篇论文提出的基于FTRL的在线CTR预测算法，就是一种Online Learning算法。\n\n即，针对每一个训练样本，首先通过一种方式进行预测，然后再利用一种损失函数进行误差评估，最后再通过所评估的误差值对参数进行更新迭代。直到所有样本全部遍历完，则结束。\n\n那么，如何选择模型预测方法、评估指标以及模型更新公式就是该算法的重点所在。下面将介绍论文中这三部分内容：\n\n1.预测方法：在每一轮 $t$ 中，针对特征样本 ${x}_{t}\\in {R}^{d}$，以及迭代后(第一此则是给定初值)的模型参数 $w_t$，我们可以预测该样本的标记值：${p}_{t}=\\sigma({w}_{t},{x}_{t})$ ，其中 $\\sigma(a)=\\frac{1}{1+exp(-a)}$ 是一个sigmoid函数。\n\n2.损失函数：对一个特征样本 $x_t$，对应的标记为 $y_t \\in 0, 1$， 则通过logistic loss 来作为损失函数，即： ${\\mathit{l}}_{t}({w}_{t})= -{y}_{t}log{p}_{t}-(1-{y}_{t})log(1-{p}_{t})$ \n\n3.迭代公式： 目的是使得损失函数尽可能小，即可以采用极大似然估计来求解参数。首先求梯度：\n\n$${g}_{t}=\\frac{d\\mathit{l}_{t}(w)}{dw}=(\\sigma(w*{x}_{t})-{y}_{t}){x}_{t}=({p}_{t}-{y}_{t}){x}_{t}$$\n\n暂时看不懂了\n基于FTRL的在线CTR预测算法\nhttps://blog.csdn.net/yz930618/article/details/75270869\n\n## ftrl References\n[@默一鸣](https://blog.csdn.net/yimingsilence/article/details/75123026) 标注了一下各篇paper的主要内容，感兴趣的可以有选择性地看一下，如果只关注工程实现，看标红的那篇就ok了：\n[1] J. Langford, L. Li, and T. Zhang. Sparse online learning via truncated gradient.JMLR, 10, 2009. （截断梯度的paper）\n\n[2] H. B. McMahan. Follow-the-regularized-leader and mirror descent: Equivalence theorems and L1 regularization. In AISTATS, 2011 （FOBOS、RDA、FTRL等各种方法对比的paper）\n\n[3] L. Xiao. Dual averaging method for regularized stochastic learning and online optimization. In NIPS, 2009 （RDA方法）\n\n[4] J. Duchi and Y. Singer. Efficient learning using forward-backward splitting. In Advances in Neural Information Processing Systems 22, pages 495{503. 2009. （FOBOS方法）\n\n[5] H. Brendan McMahan, Gary Holt, D. Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos, Jeremy Kubica, Ad Click Prediction: a View from the Trenches, Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) (2013) （这篇是那篇工程性的paper）\n\n[6] H. Brendan McMahan. A unied analysis of regular-ized dual averaging and composite mirror descent with implicit updates. Submitted, 2011 （FTRL理论发展，regret bound和加入通用正则化项）\n\n[7] H. Brendan McMahan and Matthew Streeter. Adap-tive bound optimization for online convex optimiza-tion. InCOLT, 2010 （开始的那篇理论性paper）\n\n# embedding\n\nhttps://www.cntk.ai/pythondocs/layerref.html#embedding\n\nembedding层，是一种用连续值向量来表示离散值或者word的方法，与one-hot相比，推荐系统中embedding层减少了特征的维度。在cntk中，embedding vector用行向量的方式来表示，将一个word映射到它的embedding只需要向量相乘（选取索引对应的embedding行）。\n\n梯度： embedding矩阵的梯度矩阵也是只在非0值的地方存在梯度，每次更新只要更新存在值的embedding层就行了（和推荐系统好像有点不同）\n\nword2vec中的bp\nhttp://www.claudiobellei.com/2018/01/06/backprop-word2vec/\n\n","slug":"recommender-and-ads-algs","published":1,"updated":"2018-08-23T04:14:31.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xo000ln61d1kevt15n","content":"<p>目前，推荐系统领域主流的算法主要包括：</p>\n<ol>\n<li>ftrl, 2013年, Google公司, 《Ad click prediction: a view from the trenches》</li>\n</ol>\n<h1 id=\"在线学习-ftrl\"><a href=\"#在线学习-ftrl\" class=\"headerlink\" title=\"在线学习 ftrl\"></a>在线学习 ftrl</h1><p>传统的批量算法的每次迭代是对全体训练数据集进行计算（例如计算全局梯度），优点是精度和收敛还可以，缺点是无法有效处理大数据集（此时全局梯度计算代价太大），且没法应用于数据流做在线学习。</p>\n<p>而在线学习算法的特点是：每来一个训练样本，就用该样本产生的loss和梯度对模型迭代一次，一个一个数据地进行训练，因此可以处理大数据量训练和在线训练。准确地说，Online Learning并不是一种模型，而是一种模型的训练方法，Online Learning能够根据线上反馈数据，实时快速地进行模型调整，使得模型及时反映线上的变化，提高线上预测的准确率。</p>\n<p>Online Learning的流程包括：将模型的预测结果展现给用户，然后收集用户的反馈数据，再用来训练模型，形成闭环的系统。如下图所示：</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/onlinelearning1.png\" alt=\"\"></p>\n<h2 id=\"CTR预测算法\"><a href=\"#CTR预测算法\" class=\"headerlink\" title=\"CTR预测算法\"></a>CTR预测算法</h2><p>这篇论文提出的基于FTRL的在线CTR预测算法，就是一种Online Learning算法。</p>\n<p>即，针对每一个训练样本，首先通过一种方式进行预测，然后再利用一种损失函数进行误差评估，最后再通过所评估的误差值对参数进行更新迭代。直到所有样本全部遍历完，则结束。</p>\n<p>那么，如何选择模型预测方法、评估指标以及模型更新公式就是该算法的重点所在。下面将介绍论文中这三部分内容：</p>\n<p>1.预测方法：在每一轮 $t$ 中，针对特征样本 ${x}_{t}\\in {R}^{d}$，以及迭代后(第一此则是给定初值)的模型参数 $w_t$，我们可以预测该样本的标记值：${p}_{t}=\\sigma({w}_{t},{x}_{t})$ ，其中 $\\sigma(a)=\\frac{1}{1+exp(-a)}$ 是一个sigmoid函数。</p>\n<p>2.损失函数：对一个特征样本 $x_t$，对应的标记为 $y_t \\in 0, 1$， 则通过logistic loss 来作为损失函数，即： ${\\mathit{l}}_{t}({w}_{t})= -{y}_{t}log{p}_{t}-(1-{y}_{t})log(1-{p}_{t})$ </p>\n<p>3.迭代公式： 目的是使得损失函数尽可能小，即可以采用极大似然估计来求解参数。首先求梯度：</p>\n<script type=\"math/tex; mode=display\">{g}_{t}=\\frac{d\\mathit{l}_{t}(w)}{dw}=(\\sigma(w*{x}_{t})-{y}_{t}){x}_{t}=({p}_{t}-{y}_{t}){x}_{t}</script><p>暂时看不懂了<br>基于FTRL的在线CTR预测算法<br><a href=\"https://blog.csdn.net/yz930618/article/details/75270869\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yz930618/article/details/75270869</a></p>\n<h2 id=\"ftrl-References\"><a href=\"#ftrl-References\" class=\"headerlink\" title=\"ftrl References\"></a>ftrl References</h2><p><a href=\"https://blog.csdn.net/yimingsilence/article/details/75123026\" target=\"_blank\" rel=\"noopener\">@默一鸣</a> 标注了一下各篇paper的主要内容，感兴趣的可以有选择性地看一下，如果只关注工程实现，看标红的那篇就ok了：<br>[1] J. Langford, L. Li, and T. Zhang. Sparse online learning via truncated gradient.JMLR, 10, 2009. （截断梯度的paper）</p>\n<p>[2] H. B. McMahan. Follow-the-regularized-leader and mirror descent: Equivalence theorems and L1 regularization. In AISTATS, 2011 （FOBOS、RDA、FTRL等各种方法对比的paper）</p>\n<p>[3] L. Xiao. Dual averaging method for regularized stochastic learning and online optimization. In NIPS, 2009 （RDA方法）</p>\n<p>[4] J. Duchi and Y. Singer. Efficient learning using forward-backward splitting. In Advances in Neural Information Processing Systems 22, pages 495{503. 2009. （FOBOS方法）</p>\n<p>[5] H. Brendan McMahan, Gary Holt, D. Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos, Jeremy Kubica, Ad Click Prediction: a View from the Trenches, Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) (2013) （这篇是那篇工程性的paper）</p>\n<p>[6] H. Brendan McMahan. A unied analysis of regular-ized dual averaging and composite mirror descent with implicit updates. Submitted, 2011 （FTRL理论发展，regret bound和加入通用正则化项）</p>\n<p>[7] H. Brendan McMahan and Matthew Streeter. Adap-tive bound optimization for online convex optimiza-tion. InCOLT, 2010 （开始的那篇理论性paper）</p>\n<h1 id=\"embedding\"><a href=\"#embedding\" class=\"headerlink\" title=\"embedding\"></a>embedding</h1><p><a href=\"https://www.cntk.ai/pythondocs/layerref.html#embedding\" target=\"_blank\" rel=\"noopener\">https://www.cntk.ai/pythondocs/layerref.html#embedding</a></p>\n<p>embedding层，是一种用连续值向量来表示离散值或者word的方法，与one-hot相比，推荐系统中embedding层减少了特征的维度。在cntk中，embedding vector用行向量的方式来表示，将一个word映射到它的embedding只需要向量相乘（选取索引对应的embedding行）。</p>\n<p>梯度： embedding矩阵的梯度矩阵也是只在非0值的地方存在梯度，每次更新只要更新存在值的embedding层就行了（和推荐系统好像有点不同）</p>\n<p>word2vec中的bp<br><a href=\"http://www.claudiobellei.com/2018/01/06/backprop-word2vec/\" target=\"_blank\" rel=\"noopener\">http://www.claudiobellei.com/2018/01/06/backprop-word2vec/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>目前，推荐系统领域主流的算法主要包括：</p>\n<ol>\n<li>ftrl, 2013年, Google公司, 《Ad click prediction: a view from the trenches》</li>\n</ol>\n<h1 id=\"在线学习-ftrl\"><a href=\"#在线学习-ftrl\" class=\"headerlink\" title=\"在线学习 ftrl\"></a>在线学习 ftrl</h1><p>传统的批量算法的每次迭代是对全体训练数据集进行计算（例如计算全局梯度），优点是精度和收敛还可以，缺点是无法有效处理大数据集（此时全局梯度计算代价太大），且没法应用于数据流做在线学习。</p>\n<p>而在线学习算法的特点是：每来一个训练样本，就用该样本产生的loss和梯度对模型迭代一次，一个一个数据地进行训练，因此可以处理大数据量训练和在线训练。准确地说，Online Learning并不是一种模型，而是一种模型的训练方法，Online Learning能够根据线上反馈数据，实时快速地进行模型调整，使得模型及时反映线上的变化，提高线上预测的准确率。</p>\n<p>Online Learning的流程包括：将模型的预测结果展现给用户，然后收集用户的反馈数据，再用来训练模型，形成闭环的系统。如下图所示：</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/onlinelearning1.png\" alt=\"\"></p>\n<h2 id=\"CTR预测算法\"><a href=\"#CTR预测算法\" class=\"headerlink\" title=\"CTR预测算法\"></a>CTR预测算法</h2><p>这篇论文提出的基于FTRL的在线CTR预测算法，就是一种Online Learning算法。</p>\n<p>即，针对每一个训练样本，首先通过一种方式进行预测，然后再利用一种损失函数进行误差评估，最后再通过所评估的误差值对参数进行更新迭代。直到所有样本全部遍历完，则结束。</p>\n<p>那么，如何选择模型预测方法、评估指标以及模型更新公式就是该算法的重点所在。下面将介绍论文中这三部分内容：</p>\n<p>1.预测方法：在每一轮 $t$ 中，针对特征样本 ${x}_{t}\\in {R}^{d}$，以及迭代后(第一此则是给定初值)的模型参数 $w_t$，我们可以预测该样本的标记值：${p}_{t}=\\sigma({w}_{t},{x}_{t})$ ，其中 $\\sigma(a)=\\frac{1}{1+exp(-a)}$ 是一个sigmoid函数。</p>\n<p>2.损失函数：对一个特征样本 $x_t$，对应的标记为 $y_t \\in 0, 1$， 则通过logistic loss 来作为损失函数，即： ${\\mathit{l}}_{t}({w}_{t})= -{y}_{t}log{p}_{t}-(1-{y}_{t})log(1-{p}_{t})$ </p>\n<p>3.迭代公式： 目的是使得损失函数尽可能小，即可以采用极大似然估计来求解参数。首先求梯度：</p>\n<script type=\"math/tex; mode=display\">{g}_{t}=\\frac{d\\mathit{l}_{t}(w)}{dw}=(\\sigma(w*{x}_{t})-{y}_{t}){x}_{t}=({p}_{t}-{y}_{t}){x}_{t}</script><p>暂时看不懂了<br>基于FTRL的在线CTR预测算法<br><a href=\"https://blog.csdn.net/yz930618/article/details/75270869\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yz930618/article/details/75270869</a></p>\n<h2 id=\"ftrl-References\"><a href=\"#ftrl-References\" class=\"headerlink\" title=\"ftrl References\"></a>ftrl References</h2><p><a href=\"https://blog.csdn.net/yimingsilence/article/details/75123026\" target=\"_blank\" rel=\"noopener\">@默一鸣</a> 标注了一下各篇paper的主要内容，感兴趣的可以有选择性地看一下，如果只关注工程实现，看标红的那篇就ok了：<br>[1] J. Langford, L. Li, and T. Zhang. Sparse online learning via truncated gradient.JMLR, 10, 2009. （截断梯度的paper）</p>\n<p>[2] H. B. McMahan. Follow-the-regularized-leader and mirror descent: Equivalence theorems and L1 regularization. In AISTATS, 2011 （FOBOS、RDA、FTRL等各种方法对比的paper）</p>\n<p>[3] L. Xiao. Dual averaging method for regularized stochastic learning and online optimization. In NIPS, 2009 （RDA方法）</p>\n<p>[4] J. Duchi and Y. Singer. Efficient learning using forward-backward splitting. In Advances in Neural Information Processing Systems 22, pages 495{503. 2009. （FOBOS方法）</p>\n<p>[5] H. Brendan McMahan, Gary Holt, D. Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos, Jeremy Kubica, Ad Click Prediction: a View from the Trenches, Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) (2013) （这篇是那篇工程性的paper）</p>\n<p>[6] H. Brendan McMahan. A unied analysis of regular-ized dual averaging and composite mirror descent with implicit updates. Submitted, 2011 （FTRL理论发展，regret bound和加入通用正则化项）</p>\n<p>[7] H. Brendan McMahan and Matthew Streeter. Adap-tive bound optimization for online convex optimiza-tion. InCOLT, 2010 （开始的那篇理论性paper）</p>\n<h1 id=\"embedding\"><a href=\"#embedding\" class=\"headerlink\" title=\"embedding\"></a>embedding</h1><p><a href=\"https://www.cntk.ai/pythondocs/layerref.html#embedding\" target=\"_blank\" rel=\"noopener\">https://www.cntk.ai/pythondocs/layerref.html#embedding</a></p>\n<p>embedding层，是一种用连续值向量来表示离散值或者word的方法，与one-hot相比，推荐系统中embedding层减少了特征的维度。在cntk中，embedding vector用行向量的方式来表示，将一个word映射到它的embedding只需要向量相乘（选取索引对应的embedding行）。</p>\n<p>梯度： embedding矩阵的梯度矩阵也是只在非0值的地方存在梯度，每次更新只要更新存在值的embedding层就行了（和推荐系统好像有点不同）</p>\n<p>word2vec中的bp<br><a href=\"http://www.claudiobellei.com/2018/01/06/backprop-word2vec/\" target=\"_blank\" rel=\"noopener\">http://www.claudiobellei.com/2018/01/06/backprop-word2vec/</a></p>\n"},{"title":"tensorflow 和 在线学习 onlinelearning","date":"2018-06-22T16:50:14.000Z","_content":"\n# 阿里巴巴 TFRS\n\n[阿里妈妈基于TensorFlow做了哪些深度优化？TensorFlowRS架构解析](https://mp.weixin.qq.com/s/yuHavuGTYMH5JDC_1fnjcg)\n\n亮点：\n\n1. ps-plus框架\b重构，解决了水平扩展问题，支持增量更新，（grpc，lock，graph-engine）方面，Failover机制。\n\n2. 在线学习\n\n问题：\n\n1、tensorflow的worker与ps-plus的对接，是重构worker还是对接口进行了修改？\n\n\n## 综述\n\n场景：搜索、广告、推荐\n场景特点: 样本规模和特征空间通常非常巨大，千亿样本、百亿特征并不罕见，同时存在大量的稀疏特征作为Embedding输入\n\nTFRS主要成果：\n\n1. 解决了原生TF水平扩展能力不足的问题。在我们的测试中，绝大多数搜索广告模型的训练性能提升在十倍以上，某些模型的极限性能最高可提升百倍。\n2. 支持完备的在线学习语义，模型变更实时写出；稀疏特征无需做连续ID化，可以直接使用原始特征表征进行训练，大幅简化了特征工程的复杂度。\n3. 异步训练的梯度修正优化器（grad-compensation optimizer），有效减少了异步大规模并发引起的训练效果损失。\n4. 集成了高效的Graph Embedding、Memory Network、Cross Media等多种高级训练模式。\n5. 模型可视化系统DeepInSight提供深度模型训练的多维度可视化分析。\n\n## TensorFlowRS分布式架构\n\n在使用TensorFlow的过程中我们发现TF作为一个分布式训练系统有两个主要的问题：\n\n1. 水平扩展能力差：在大部分模型的性能测试中,我们发现随着数据并行度的增加，单个worker的样本处理QPS急剧下降。当worker数量增大到一定规模的时候，系统整体QPS不再有增长甚至有所下降。\n2. 缺乏完备的分布式Failover机制。\n\nTensorFlowRS采取的解决方案包括：\n\n- 通过对接独立参数服务器提升水平扩展能力\n\n在对TF做过细致的profiling之后，我们发现TF原生的PS由于设计和实现方面的多种原因（grpc，lock，graph-engine），很难达良好的水平扩展能力。于是我们决定丢掉TF-PS的包袱，重新实现一个高性能的参数服务器：PS-Plus。此外我们提供了完整的TF on PS-Plus方案，可以支持用户在Native-PS和PS-Plus之间自由切换，并且完全兼容TensorFlow的Graph语义和所有API。用户可以在深度网络代码一行不改的情况下，将参数分布和运行在PS-Plus上，享受高性能的参数交换和良好的水平扩展能力。 \n\n- 重新设计Failover机制，支持动态组网和Exactly-Once的Failover\n\nTensorFlowRS引入了worker state，在checkpoint中存储了worker的状态信息，worker重启后，会从接着上次的进度继续训练。此外TensorFlowRS通过zk生成cluster配置，支持了动态组网的Failover。新的Failover机制可以保证任意角色挂掉的情况下，系统都能在分钟级完成Failover，并且不多算和漏算数据。\n\nTensorFlowRS的整体架构\n\n![TensorFlowRS的整体架构](http://p8vrqzrnj.bkt.clouddn.com/tfrs_instruction.jpg)\n\n## PS-Plus\n\nPS-Plus相对于传统的ParameterServer有如下特点：\n\n(1)高性能：PS-Plus通过智能参数分配，零拷贝，seastar等多项技术，进一步提升了单台server的服务能力和系统整体的水平扩展能力。在实测中，在64core的机器上单个server能轻松用满55+的核心，在dense场景下io能打满双25G网卡，系统整体在 1~4000 worker 的范围内都具有近似线性的水平扩展能力\n\n(2)高度灵活：PS-Plus拥有完善的UDF接口，用户可使用SDK开发定制化的UDF插件，并且可以通过简单的C++以及Python接口进行调用。\n\n(3)完备的在线学习支持：PS-Plus支持非ID化特征训练，特征动态增删，以及模型增量实时导出等支撑在线学习的重要特性。\n\n下面从中选取几点做比较详细的介绍：\n\n1. 智能参数分配\n\n参数分配策略(variable placement)，决定了如何将一个参数切分并放置到不同的server上。placement策略的好坏在高并发的情况下对PS的整体性能有着重大的影响。传统ParameterServer的placement方案是由系统预先实现几种常见的placement算法（比如平均切分+roundrobin），或者由用户在创建参数的时候手工划分，往往没有综合考虑全局的参数规模、Server的负载等。\n\nPS-Plus实现了基于模拟退火算法的启发式参数分配策略，后续也在考虑实现基于运行时负载，动态rebalance的placement策略。PS-Plus的placement设计有如下优点：\n\n- 综合考虑了全局参数的shape信息，在cpu，内存，网络带宽等限制条件下给出了近似最优的placement方案，避免了手工分配造成的不均匀、热点等问题。\n- 整个参数分配过程由系统内部自动完成，用户无需配置即可获得接近最优的性能，用户无需了解PS底层实现的具体细节。\n- Partition由框架自动完成，在上层算法代码，如TF代码中，不需要额外使用PartitionedVariable等机制，使用简单方便。\n\n2. 去ID化特征支持\n\n目前主流的深度学习框架都是以连续的内存来存储训练参数，通过偏移量（ID值）来寻址到具体的权重。为了避免内存的浪费，需要对特征做从0开始的连续ID化编码，这一过程我们称之为特征ID化。特征ID化是一个非常复杂的过程，尤其是当样本和特征数量非常庞大的时候，特征ID化会占用大量的时间和机器资源，给样本构建带来了很大的复杂度。\n\nPS-Plus内部实现了一个定制化的hashmap，针对参数交换场景做了专门的优化，在支持特征动态增删的同时提供了超高的性能。通过hashmap，PS-Plus直接实现了对非ID特征的支持，极大的简化了样本构建的复杂度。\n\n3. 通信层优化\n\n对于Parameter Server架构，延迟是影响整体性能的重要原因。尤其是在模型复杂度不高的情况下，模型计算部分往往在10~100ms量级，那么总体通信的延迟就成为一个关键因素。\n\n在传统的pipeline线程模型，高并发情况下中断和线程上下文切换会导致很大的开销，同时会引起大量的cache-line miss。此外，高频的锁竞争是带来延迟的最主要原因之一，即便是各类SpinLock、读写锁等优化也并不能有效消除这个问题。我们认为polling + run to completion是一个正确的选择，并且设计了我们的整体通信层架构。在新的通信层中，我们使用了Seastar作为底层的框架。对于Server、Worker上的connection，都严格保证connection绑定到固定的线程，同时线程与CPU核心绑定。Request、response直接采用run to completion的方式在当前线程处理。\n\n整体架构如下图所示：\n\n![ps-plus架构](http://p8vrqzrnj.bkt.clouddn.com/ps-plus.jpg)\n\n在Seastar的基础上，我们做了很多功能、性能的改进和优化，这里做一些简要的介绍。\n\n外部线程交互队列。我们借鉴Seastar核心之间的交互机制，提供了一个 M:N 无锁生产者消费者队列，用于外部线程与Seastar内部线程进行交互。相比传统队列性能有极大的提升。\n\n写请求顺序调度。从外部线程poll到的写请求，如果直接调用Seastar的写接口，会导致写buffer无法保证有序。我们通过队列机制的改造，自动保证了写顺序，同时基本不损失多connection的并发写的性能。\n\n灵活的编解码层。我们提供了一套编解码层的抽象接口，方便用户使用，从而不需要借助protobuf等传统的序列化、反序列化的第三方库，同时也避免了protobuf的一些性能问题。\n\n## 在线学习\n\n1. 非ID化特征支持\n2. 特征动态增删\n3. 模型增量实时导出\n4. AUC Decay\n\n## 大规模训练场景下的收敛效果优化\n\nboost 方法解决分布式并行训练中梯度和模型不一致的问题。\n\n## 高级训练模式\n\nTFRS中集成了多种高阶训练模式，例如Graph Embedding，Memory Network，Cross Media Training等。\n\n## 可视化模型分析系统DeepInsight\n\nDeepInsight是一个深度学习可视化质量评估系统，支持训练阶段模型内部数据的全面透出与可视化分析，用以解决模型评估、分析、调试等一系列问题，提高深度模型的可解释性。\n\n# tensorflow issue\nAPI: sparse_column_with_hash_bucket.\nparams: hash_keys\nsource: https://github.com/tensorflow/tensorflow/issues/19324#issuecomment-394597155\n","source":"_posts/201806-tensorflow-and-onlinelearning.md","raw":"---\ntitle: tensorflow 和 在线学习 onlinelearning\ndate: 2018-06-23 00:50:14\ntags: tensorflow onlinelearning 在线学习\n---\n\n# 阿里巴巴 TFRS\n\n[阿里妈妈基于TensorFlow做了哪些深度优化？TensorFlowRS架构解析](https://mp.weixin.qq.com/s/yuHavuGTYMH5JDC_1fnjcg)\n\n亮点：\n\n1. ps-plus框架\b重构，解决了水平扩展问题，支持增量更新，（grpc，lock，graph-engine）方面，Failover机制。\n\n2. 在线学习\n\n问题：\n\n1、tensorflow的worker与ps-plus的对接，是重构worker还是对接口进行了修改？\n\n\n## 综述\n\n场景：搜索、广告、推荐\n场景特点: 样本规模和特征空间通常非常巨大，千亿样本、百亿特征并不罕见，同时存在大量的稀疏特征作为Embedding输入\n\nTFRS主要成果：\n\n1. 解决了原生TF水平扩展能力不足的问题。在我们的测试中，绝大多数搜索广告模型的训练性能提升在十倍以上，某些模型的极限性能最高可提升百倍。\n2. 支持完备的在线学习语义，模型变更实时写出；稀疏特征无需做连续ID化，可以直接使用原始特征表征进行训练，大幅简化了特征工程的复杂度。\n3. 异步训练的梯度修正优化器（grad-compensation optimizer），有效减少了异步大规模并发引起的训练效果损失。\n4. 集成了高效的Graph Embedding、Memory Network、Cross Media等多种高级训练模式。\n5. 模型可视化系统DeepInSight提供深度模型训练的多维度可视化分析。\n\n## TensorFlowRS分布式架构\n\n在使用TensorFlow的过程中我们发现TF作为一个分布式训练系统有两个主要的问题：\n\n1. 水平扩展能力差：在大部分模型的性能测试中,我们发现随着数据并行度的增加，单个worker的样本处理QPS急剧下降。当worker数量增大到一定规模的时候，系统整体QPS不再有增长甚至有所下降。\n2. 缺乏完备的分布式Failover机制。\n\nTensorFlowRS采取的解决方案包括：\n\n- 通过对接独立参数服务器提升水平扩展能力\n\n在对TF做过细致的profiling之后，我们发现TF原生的PS由于设计和实现方面的多种原因（grpc，lock，graph-engine），很难达良好的水平扩展能力。于是我们决定丢掉TF-PS的包袱，重新实现一个高性能的参数服务器：PS-Plus。此外我们提供了完整的TF on PS-Plus方案，可以支持用户在Native-PS和PS-Plus之间自由切换，并且完全兼容TensorFlow的Graph语义和所有API。用户可以在深度网络代码一行不改的情况下，将参数分布和运行在PS-Plus上，享受高性能的参数交换和良好的水平扩展能力。 \n\n- 重新设计Failover机制，支持动态组网和Exactly-Once的Failover\n\nTensorFlowRS引入了worker state，在checkpoint中存储了worker的状态信息，worker重启后，会从接着上次的进度继续训练。此外TensorFlowRS通过zk生成cluster配置，支持了动态组网的Failover。新的Failover机制可以保证任意角色挂掉的情况下，系统都能在分钟级完成Failover，并且不多算和漏算数据。\n\nTensorFlowRS的整体架构\n\n![TensorFlowRS的整体架构](http://p8vrqzrnj.bkt.clouddn.com/tfrs_instruction.jpg)\n\n## PS-Plus\n\nPS-Plus相对于传统的ParameterServer有如下特点：\n\n(1)高性能：PS-Plus通过智能参数分配，零拷贝，seastar等多项技术，进一步提升了单台server的服务能力和系统整体的水平扩展能力。在实测中，在64core的机器上单个server能轻松用满55+的核心，在dense场景下io能打满双25G网卡，系统整体在 1~4000 worker 的范围内都具有近似线性的水平扩展能力\n\n(2)高度灵活：PS-Plus拥有完善的UDF接口，用户可使用SDK开发定制化的UDF插件，并且可以通过简单的C++以及Python接口进行调用。\n\n(3)完备的在线学习支持：PS-Plus支持非ID化特征训练，特征动态增删，以及模型增量实时导出等支撑在线学习的重要特性。\n\n下面从中选取几点做比较详细的介绍：\n\n1. 智能参数分配\n\n参数分配策略(variable placement)，决定了如何将一个参数切分并放置到不同的server上。placement策略的好坏在高并发的情况下对PS的整体性能有着重大的影响。传统ParameterServer的placement方案是由系统预先实现几种常见的placement算法（比如平均切分+roundrobin），或者由用户在创建参数的时候手工划分，往往没有综合考虑全局的参数规模、Server的负载等。\n\nPS-Plus实现了基于模拟退火算法的启发式参数分配策略，后续也在考虑实现基于运行时负载，动态rebalance的placement策略。PS-Plus的placement设计有如下优点：\n\n- 综合考虑了全局参数的shape信息，在cpu，内存，网络带宽等限制条件下给出了近似最优的placement方案，避免了手工分配造成的不均匀、热点等问题。\n- 整个参数分配过程由系统内部自动完成，用户无需配置即可获得接近最优的性能，用户无需了解PS底层实现的具体细节。\n- Partition由框架自动完成，在上层算法代码，如TF代码中，不需要额外使用PartitionedVariable等机制，使用简单方便。\n\n2. 去ID化特征支持\n\n目前主流的深度学习框架都是以连续的内存来存储训练参数，通过偏移量（ID值）来寻址到具体的权重。为了避免内存的浪费，需要对特征做从0开始的连续ID化编码，这一过程我们称之为特征ID化。特征ID化是一个非常复杂的过程，尤其是当样本和特征数量非常庞大的时候，特征ID化会占用大量的时间和机器资源，给样本构建带来了很大的复杂度。\n\nPS-Plus内部实现了一个定制化的hashmap，针对参数交换场景做了专门的优化，在支持特征动态增删的同时提供了超高的性能。通过hashmap，PS-Plus直接实现了对非ID特征的支持，极大的简化了样本构建的复杂度。\n\n3. 通信层优化\n\n对于Parameter Server架构，延迟是影响整体性能的重要原因。尤其是在模型复杂度不高的情况下，模型计算部分往往在10~100ms量级，那么总体通信的延迟就成为一个关键因素。\n\n在传统的pipeline线程模型，高并发情况下中断和线程上下文切换会导致很大的开销，同时会引起大量的cache-line miss。此外，高频的锁竞争是带来延迟的最主要原因之一，即便是各类SpinLock、读写锁等优化也并不能有效消除这个问题。我们认为polling + run to completion是一个正确的选择，并且设计了我们的整体通信层架构。在新的通信层中，我们使用了Seastar作为底层的框架。对于Server、Worker上的connection，都严格保证connection绑定到固定的线程，同时线程与CPU核心绑定。Request、response直接采用run to completion的方式在当前线程处理。\n\n整体架构如下图所示：\n\n![ps-plus架构](http://p8vrqzrnj.bkt.clouddn.com/ps-plus.jpg)\n\n在Seastar的基础上，我们做了很多功能、性能的改进和优化，这里做一些简要的介绍。\n\n外部线程交互队列。我们借鉴Seastar核心之间的交互机制，提供了一个 M:N 无锁生产者消费者队列，用于外部线程与Seastar内部线程进行交互。相比传统队列性能有极大的提升。\n\n写请求顺序调度。从外部线程poll到的写请求，如果直接调用Seastar的写接口，会导致写buffer无法保证有序。我们通过队列机制的改造，自动保证了写顺序，同时基本不损失多connection的并发写的性能。\n\n灵活的编解码层。我们提供了一套编解码层的抽象接口，方便用户使用，从而不需要借助protobuf等传统的序列化、反序列化的第三方库，同时也避免了protobuf的一些性能问题。\n\n## 在线学习\n\n1. 非ID化特征支持\n2. 特征动态增删\n3. 模型增量实时导出\n4. AUC Decay\n\n## 大规模训练场景下的收敛效果优化\n\nboost 方法解决分布式并行训练中梯度和模型不一致的问题。\n\n## 高级训练模式\n\nTFRS中集成了多种高阶训练模式，例如Graph Embedding，Memory Network，Cross Media Training等。\n\n## 可视化模型分析系统DeepInsight\n\nDeepInsight是一个深度学习可视化质量评估系统，支持训练阶段模型内部数据的全面透出与可视化分析，用以解决模型评估、分析、调试等一系列问题，提高深度模型的可解释性。\n\n# tensorflow issue\nAPI: sparse_column_with_hash_bucket.\nparams: hash_keys\nsource: https://github.com/tensorflow/tensorflow/issues/19324#issuecomment-394597155\n","slug":"tensorflow-and-onlinelearning","published":1,"updated":"2018-06-23T01:06:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xp000nn61dqvitxwlu","content":"<h1 id=\"阿里巴巴-TFRS\"><a href=\"#阿里巴巴-TFRS\" class=\"headerlink\" title=\"阿里巴巴 TFRS\"></a>阿里巴巴 TFRS</h1><p><a href=\"https://mp.weixin.qq.com/s/yuHavuGTYMH5JDC_1fnjcg\" target=\"_blank\" rel=\"noopener\">阿里妈妈基于TensorFlow做了哪些深度优化？TensorFlowRS架构解析</a></p>\n<p>亮点：</p>\n<ol>\n<li><p>ps-plus框架\b重构，解决了水平扩展问题，支持增量更新，（grpc，lock，graph-engine）方面，Failover机制。</p>\n</li>\n<li><p>在线学习</p>\n</li>\n</ol>\n<p>问题：</p>\n<p>1、tensorflow的worker与ps-plus的对接，是重构worker还是对接口进行了修改？</p>\n<h2 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h2><p>场景：搜索、广告、推荐<br>场景特点: 样本规模和特征空间通常非常巨大，千亿样本、百亿特征并不罕见，同时存在大量的稀疏特征作为Embedding输入</p>\n<p>TFRS主要成果：</p>\n<ol>\n<li>解决了原生TF水平扩展能力不足的问题。在我们的测试中，绝大多数搜索广告模型的训练性能提升在十倍以上，某些模型的极限性能最高可提升百倍。</li>\n<li>支持完备的在线学习语义，模型变更实时写出；稀疏特征无需做连续ID化，可以直接使用原始特征表征进行训练，大幅简化了特征工程的复杂度。</li>\n<li>异步训练的梯度修正优化器（grad-compensation optimizer），有效减少了异步大规模并发引起的训练效果损失。</li>\n<li>集成了高效的Graph Embedding、Memory Network、Cross Media等多种高级训练模式。</li>\n<li>模型可视化系统DeepInSight提供深度模型训练的多维度可视化分析。</li>\n</ol>\n<h2 id=\"TensorFlowRS分布式架构\"><a href=\"#TensorFlowRS分布式架构\" class=\"headerlink\" title=\"TensorFlowRS分布式架构\"></a>TensorFlowRS分布式架构</h2><p>在使用TensorFlow的过程中我们发现TF作为一个分布式训练系统有两个主要的问题：</p>\n<ol>\n<li>水平扩展能力差：在大部分模型的性能测试中,我们发现随着数据并行度的增加，单个worker的样本处理QPS急剧下降。当worker数量增大到一定规模的时候，系统整体QPS不再有增长甚至有所下降。</li>\n<li>缺乏完备的分布式Failover机制。</li>\n</ol>\n<p>TensorFlowRS采取的解决方案包括：</p>\n<ul>\n<li>通过对接独立参数服务器提升水平扩展能力</li>\n</ul>\n<p>在对TF做过细致的profiling之后，我们发现TF原生的PS由于设计和实现方面的多种原因（grpc，lock，graph-engine），很难达良好的水平扩展能力。于是我们决定丢掉TF-PS的包袱，重新实现一个高性能的参数服务器：PS-Plus。此外我们提供了完整的TF on PS-Plus方案，可以支持用户在Native-PS和PS-Plus之间自由切换，并且完全兼容TensorFlow的Graph语义和所有API。用户可以在深度网络代码一行不改的情况下，将参数分布和运行在PS-Plus上，享受高性能的参数交换和良好的水平扩展能力。 </p>\n<ul>\n<li>重新设计Failover机制，支持动态组网和Exactly-Once的Failover</li>\n</ul>\n<p>TensorFlowRS引入了worker state，在checkpoint中存储了worker的状态信息，worker重启后，会从接着上次的进度继续训练。此外TensorFlowRS通过zk生成cluster配置，支持了动态组网的Failover。新的Failover机制可以保证任意角色挂掉的情况下，系统都能在分钟级完成Failover，并且不多算和漏算数据。</p>\n<p>TensorFlowRS的整体架构</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/tfrs_instruction.jpg\" alt=\"TensorFlowRS的整体架构\"></p>\n<h2 id=\"PS-Plus\"><a href=\"#PS-Plus\" class=\"headerlink\" title=\"PS-Plus\"></a>PS-Plus</h2><p>PS-Plus相对于传统的ParameterServer有如下特点：</p>\n<p>(1)高性能：PS-Plus通过智能参数分配，零拷贝，seastar等多项技术，进一步提升了单台server的服务能力和系统整体的水平扩展能力。在实测中，在64core的机器上单个server能轻松用满55+的核心，在dense场景下io能打满双25G网卡，系统整体在 1~4000 worker 的范围内都具有近似线性的水平扩展能力</p>\n<p>(2)高度灵活：PS-Plus拥有完善的UDF接口，用户可使用SDK开发定制化的UDF插件，并且可以通过简单的C++以及Python接口进行调用。</p>\n<p>(3)完备的在线学习支持：PS-Plus支持非ID化特征训练，特征动态增删，以及模型增量实时导出等支撑在线学习的重要特性。</p>\n<p>下面从中选取几点做比较详细的介绍：</p>\n<ol>\n<li>智能参数分配</li>\n</ol>\n<p>参数分配策略(variable placement)，决定了如何将一个参数切分并放置到不同的server上。placement策略的好坏在高并发的情况下对PS的整体性能有着重大的影响。传统ParameterServer的placement方案是由系统预先实现几种常见的placement算法（比如平均切分+roundrobin），或者由用户在创建参数的时候手工划分，往往没有综合考虑全局的参数规模、Server的负载等。</p>\n<p>PS-Plus实现了基于模拟退火算法的启发式参数分配策略，后续也在考虑实现基于运行时负载，动态rebalance的placement策略。PS-Plus的placement设计有如下优点：</p>\n<ul>\n<li>综合考虑了全局参数的shape信息，在cpu，内存，网络带宽等限制条件下给出了近似最优的placement方案，避免了手工分配造成的不均匀、热点等问题。</li>\n<li>整个参数分配过程由系统内部自动完成，用户无需配置即可获得接近最优的性能，用户无需了解PS底层实现的具体细节。</li>\n<li>Partition由框架自动完成，在上层算法代码，如TF代码中，不需要额外使用PartitionedVariable等机制，使用简单方便。</li>\n</ul>\n<ol>\n<li>去ID化特征支持</li>\n</ol>\n<p>目前主流的深度学习框架都是以连续的内存来存储训练参数，通过偏移量（ID值）来寻址到具体的权重。为了避免内存的浪费，需要对特征做从0开始的连续ID化编码，这一过程我们称之为特征ID化。特征ID化是一个非常复杂的过程，尤其是当样本和特征数量非常庞大的时候，特征ID化会占用大量的时间和机器资源，给样本构建带来了很大的复杂度。</p>\n<p>PS-Plus内部实现了一个定制化的hashmap，针对参数交换场景做了专门的优化，在支持特征动态增删的同时提供了超高的性能。通过hashmap，PS-Plus直接实现了对非ID特征的支持，极大的简化了样本构建的复杂度。</p>\n<ol>\n<li>通信层优化</li>\n</ol>\n<p>对于Parameter Server架构，延迟是影响整体性能的重要原因。尤其是在模型复杂度不高的情况下，模型计算部分往往在10~100ms量级，那么总体通信的延迟就成为一个关键因素。</p>\n<p>在传统的pipeline线程模型，高并发情况下中断和线程上下文切换会导致很大的开销，同时会引起大量的cache-line miss。此外，高频的锁竞争是带来延迟的最主要原因之一，即便是各类SpinLock、读写锁等优化也并不能有效消除这个问题。我们认为polling + run to completion是一个正确的选择，并且设计了我们的整体通信层架构。在新的通信层中，我们使用了Seastar作为底层的框架。对于Server、Worker上的connection，都严格保证connection绑定到固定的线程，同时线程与CPU核心绑定。Request、response直接采用run to completion的方式在当前线程处理。</p>\n<p>整体架构如下图所示：</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/ps-plus.jpg\" alt=\"ps-plus架构\"></p>\n<p>在Seastar的基础上，我们做了很多功能、性能的改进和优化，这里做一些简要的介绍。</p>\n<p>外部线程交互队列。我们借鉴Seastar核心之间的交互机制，提供了一个 M:N 无锁生产者消费者队列，用于外部线程与Seastar内部线程进行交互。相比传统队列性能有极大的提升。</p>\n<p>写请求顺序调度。从外部线程poll到的写请求，如果直接调用Seastar的写接口，会导致写buffer无法保证有序。我们通过队列机制的改造，自动保证了写顺序，同时基本不损失多connection的并发写的性能。</p>\n<p>灵活的编解码层。我们提供了一套编解码层的抽象接口，方便用户使用，从而不需要借助protobuf等传统的序列化、反序列化的第三方库，同时也避免了protobuf的一些性能问题。</p>\n<h2 id=\"在线学习\"><a href=\"#在线学习\" class=\"headerlink\" title=\"在线学习\"></a>在线学习</h2><ol>\n<li>非ID化特征支持</li>\n<li>特征动态增删</li>\n<li>模型增量实时导出</li>\n<li>AUC Decay</li>\n</ol>\n<h2 id=\"大规模训练场景下的收敛效果优化\"><a href=\"#大规模训练场景下的收敛效果优化\" class=\"headerlink\" title=\"大规模训练场景下的收敛效果优化\"></a>大规模训练场景下的收敛效果优化</h2><p>boost 方法解决分布式并行训练中梯度和模型不一致的问题。</p>\n<h2 id=\"高级训练模式\"><a href=\"#高级训练模式\" class=\"headerlink\" title=\"高级训练模式\"></a>高级训练模式</h2><p>TFRS中集成了多种高阶训练模式，例如Graph Embedding，Memory Network，Cross Media Training等。</p>\n<h2 id=\"可视化模型分析系统DeepInsight\"><a href=\"#可视化模型分析系统DeepInsight\" class=\"headerlink\" title=\"可视化模型分析系统DeepInsight\"></a>可视化模型分析系统DeepInsight</h2><p>DeepInsight是一个深度学习可视化质量评估系统，支持训练阶段模型内部数据的全面透出与可视化分析，用以解决模型评估、分析、调试等一系列问题，提高深度模型的可解释性。</p>\n<h1 id=\"tensorflow-issue\"><a href=\"#tensorflow-issue\" class=\"headerlink\" title=\"tensorflow issue\"></a>tensorflow issue</h1><p>API: sparse_column_with_hash_bucket.<br>params: hash_keys<br>source: <a href=\"https://github.com/tensorflow/tensorflow/issues/19324#issuecomment-394597155\" target=\"_blank\" rel=\"noopener\">https://github.com/tensorflow/tensorflow/issues/19324#issuecomment-394597155</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"阿里巴巴-TFRS\"><a href=\"#阿里巴巴-TFRS\" class=\"headerlink\" title=\"阿里巴巴 TFRS\"></a>阿里巴巴 TFRS</h1><p><a href=\"https://mp.weixin.qq.com/s/yuHavuGTYMH5JDC_1fnjcg\" target=\"_blank\" rel=\"noopener\">阿里妈妈基于TensorFlow做了哪些深度优化？TensorFlowRS架构解析</a></p>\n<p>亮点：</p>\n<ol>\n<li><p>ps-plus框架\b重构，解决了水平扩展问题，支持增量更新，（grpc，lock，graph-engine）方面，Failover机制。</p>\n</li>\n<li><p>在线学习</p>\n</li>\n</ol>\n<p>问题：</p>\n<p>1、tensorflow的worker与ps-plus的对接，是重构worker还是对接口进行了修改？</p>\n<h2 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h2><p>场景：搜索、广告、推荐<br>场景特点: 样本规模和特征空间通常非常巨大，千亿样本、百亿特征并不罕见，同时存在大量的稀疏特征作为Embedding输入</p>\n<p>TFRS主要成果：</p>\n<ol>\n<li>解决了原生TF水平扩展能力不足的问题。在我们的测试中，绝大多数搜索广告模型的训练性能提升在十倍以上，某些模型的极限性能最高可提升百倍。</li>\n<li>支持完备的在线学习语义，模型变更实时写出；稀疏特征无需做连续ID化，可以直接使用原始特征表征进行训练，大幅简化了特征工程的复杂度。</li>\n<li>异步训练的梯度修正优化器（grad-compensation optimizer），有效减少了异步大规模并发引起的训练效果损失。</li>\n<li>集成了高效的Graph Embedding、Memory Network、Cross Media等多种高级训练模式。</li>\n<li>模型可视化系统DeepInSight提供深度模型训练的多维度可视化分析。</li>\n</ol>\n<h2 id=\"TensorFlowRS分布式架构\"><a href=\"#TensorFlowRS分布式架构\" class=\"headerlink\" title=\"TensorFlowRS分布式架构\"></a>TensorFlowRS分布式架构</h2><p>在使用TensorFlow的过程中我们发现TF作为一个分布式训练系统有两个主要的问题：</p>\n<ol>\n<li>水平扩展能力差：在大部分模型的性能测试中,我们发现随着数据并行度的增加，单个worker的样本处理QPS急剧下降。当worker数量增大到一定规模的时候，系统整体QPS不再有增长甚至有所下降。</li>\n<li>缺乏完备的分布式Failover机制。</li>\n</ol>\n<p>TensorFlowRS采取的解决方案包括：</p>\n<ul>\n<li>通过对接独立参数服务器提升水平扩展能力</li>\n</ul>\n<p>在对TF做过细致的profiling之后，我们发现TF原生的PS由于设计和实现方面的多种原因（grpc，lock，graph-engine），很难达良好的水平扩展能力。于是我们决定丢掉TF-PS的包袱，重新实现一个高性能的参数服务器：PS-Plus。此外我们提供了完整的TF on PS-Plus方案，可以支持用户在Native-PS和PS-Plus之间自由切换，并且完全兼容TensorFlow的Graph语义和所有API。用户可以在深度网络代码一行不改的情况下，将参数分布和运行在PS-Plus上，享受高性能的参数交换和良好的水平扩展能力。 </p>\n<ul>\n<li>重新设计Failover机制，支持动态组网和Exactly-Once的Failover</li>\n</ul>\n<p>TensorFlowRS引入了worker state，在checkpoint中存储了worker的状态信息，worker重启后，会从接着上次的进度继续训练。此外TensorFlowRS通过zk生成cluster配置，支持了动态组网的Failover。新的Failover机制可以保证任意角色挂掉的情况下，系统都能在分钟级完成Failover，并且不多算和漏算数据。</p>\n<p>TensorFlowRS的整体架构</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/tfrs_instruction.jpg\" alt=\"TensorFlowRS的整体架构\"></p>\n<h2 id=\"PS-Plus\"><a href=\"#PS-Plus\" class=\"headerlink\" title=\"PS-Plus\"></a>PS-Plus</h2><p>PS-Plus相对于传统的ParameterServer有如下特点：</p>\n<p>(1)高性能：PS-Plus通过智能参数分配，零拷贝，seastar等多项技术，进一步提升了单台server的服务能力和系统整体的水平扩展能力。在实测中，在64core的机器上单个server能轻松用满55+的核心，在dense场景下io能打满双25G网卡，系统整体在 1~4000 worker 的范围内都具有近似线性的水平扩展能力</p>\n<p>(2)高度灵活：PS-Plus拥有完善的UDF接口，用户可使用SDK开发定制化的UDF插件，并且可以通过简单的C++以及Python接口进行调用。</p>\n<p>(3)完备的在线学习支持：PS-Plus支持非ID化特征训练，特征动态增删，以及模型增量实时导出等支撑在线学习的重要特性。</p>\n<p>下面从中选取几点做比较详细的介绍：</p>\n<ol>\n<li>智能参数分配</li>\n</ol>\n<p>参数分配策略(variable placement)，决定了如何将一个参数切分并放置到不同的server上。placement策略的好坏在高并发的情况下对PS的整体性能有着重大的影响。传统ParameterServer的placement方案是由系统预先实现几种常见的placement算法（比如平均切分+roundrobin），或者由用户在创建参数的时候手工划分，往往没有综合考虑全局的参数规模、Server的负载等。</p>\n<p>PS-Plus实现了基于模拟退火算法的启发式参数分配策略，后续也在考虑实现基于运行时负载，动态rebalance的placement策略。PS-Plus的placement设计有如下优点：</p>\n<ul>\n<li>综合考虑了全局参数的shape信息，在cpu，内存，网络带宽等限制条件下给出了近似最优的placement方案，避免了手工分配造成的不均匀、热点等问题。</li>\n<li>整个参数分配过程由系统内部自动完成，用户无需配置即可获得接近最优的性能，用户无需了解PS底层实现的具体细节。</li>\n<li>Partition由框架自动完成，在上层算法代码，如TF代码中，不需要额外使用PartitionedVariable等机制，使用简单方便。</li>\n</ul>\n<ol>\n<li>去ID化特征支持</li>\n</ol>\n<p>目前主流的深度学习框架都是以连续的内存来存储训练参数，通过偏移量（ID值）来寻址到具体的权重。为了避免内存的浪费，需要对特征做从0开始的连续ID化编码，这一过程我们称之为特征ID化。特征ID化是一个非常复杂的过程，尤其是当样本和特征数量非常庞大的时候，特征ID化会占用大量的时间和机器资源，给样本构建带来了很大的复杂度。</p>\n<p>PS-Plus内部实现了一个定制化的hashmap，针对参数交换场景做了专门的优化，在支持特征动态增删的同时提供了超高的性能。通过hashmap，PS-Plus直接实现了对非ID特征的支持，极大的简化了样本构建的复杂度。</p>\n<ol>\n<li>通信层优化</li>\n</ol>\n<p>对于Parameter Server架构，延迟是影响整体性能的重要原因。尤其是在模型复杂度不高的情况下，模型计算部分往往在10~100ms量级，那么总体通信的延迟就成为一个关键因素。</p>\n<p>在传统的pipeline线程模型，高并发情况下中断和线程上下文切换会导致很大的开销，同时会引起大量的cache-line miss。此外，高频的锁竞争是带来延迟的最主要原因之一，即便是各类SpinLock、读写锁等优化也并不能有效消除这个问题。我们认为polling + run to completion是一个正确的选择，并且设计了我们的整体通信层架构。在新的通信层中，我们使用了Seastar作为底层的框架。对于Server、Worker上的connection，都严格保证connection绑定到固定的线程，同时线程与CPU核心绑定。Request、response直接采用run to completion的方式在当前线程处理。</p>\n<p>整体架构如下图所示：</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/ps-plus.jpg\" alt=\"ps-plus架构\"></p>\n<p>在Seastar的基础上，我们做了很多功能、性能的改进和优化，这里做一些简要的介绍。</p>\n<p>外部线程交互队列。我们借鉴Seastar核心之间的交互机制，提供了一个 M:N 无锁生产者消费者队列，用于外部线程与Seastar内部线程进行交互。相比传统队列性能有极大的提升。</p>\n<p>写请求顺序调度。从外部线程poll到的写请求，如果直接调用Seastar的写接口，会导致写buffer无法保证有序。我们通过队列机制的改造，自动保证了写顺序，同时基本不损失多connection的并发写的性能。</p>\n<p>灵活的编解码层。我们提供了一套编解码层的抽象接口，方便用户使用，从而不需要借助protobuf等传统的序列化、反序列化的第三方库，同时也避免了protobuf的一些性能问题。</p>\n<h2 id=\"在线学习\"><a href=\"#在线学习\" class=\"headerlink\" title=\"在线学习\"></a>在线学习</h2><ol>\n<li>非ID化特征支持</li>\n<li>特征动态增删</li>\n<li>模型增量实时导出</li>\n<li>AUC Decay</li>\n</ol>\n<h2 id=\"大规模训练场景下的收敛效果优化\"><a href=\"#大规模训练场景下的收敛效果优化\" class=\"headerlink\" title=\"大规模训练场景下的收敛效果优化\"></a>大规模训练场景下的收敛效果优化</h2><p>boost 方法解决分布式并行训练中梯度和模型不一致的问题。</p>\n<h2 id=\"高级训练模式\"><a href=\"#高级训练模式\" class=\"headerlink\" title=\"高级训练模式\"></a>高级训练模式</h2><p>TFRS中集成了多种高阶训练模式，例如Graph Embedding，Memory Network，Cross Media Training等。</p>\n<h2 id=\"可视化模型分析系统DeepInsight\"><a href=\"#可视化模型分析系统DeepInsight\" class=\"headerlink\" title=\"可视化模型分析系统DeepInsight\"></a>可视化模型分析系统DeepInsight</h2><p>DeepInsight是一个深度学习可视化质量评估系统，支持训练阶段模型内部数据的全面透出与可视化分析，用以解决模型评估、分析、调试等一系列问题，提高深度模型的可解释性。</p>\n<h1 id=\"tensorflow-issue\"><a href=\"#tensorflow-issue\" class=\"headerlink\" title=\"tensorflow issue\"></a>tensorflow issue</h1><p>API: sparse_column_with_hash_bucket.<br>params: hash_keys<br>source: <a href=\"https://github.com/tensorflow/tensorflow/issues/19324#issuecomment-394597155\" target=\"_blank\" rel=\"noopener\">https://github.com/tensorflow/tensorflow/issues/19324#issuecomment-394597155</a></p>\n"},{"title":"tensorflow data generation","date":"2018-06-03T08:18:12.000Z","_content":"\n[tensorflow 数据读取 office guide](http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/reading_data.html#AUTOGENERATED-preloaded-data)\n\n[十图详解tensorflow数据读取机制（附代码）](https://zhuanlan.zhihu.com/p/27238630)\n\n[tf.train.batch和tf.train.shuffle_batch的理解](https://blog.csdn.net/ying86615791/article/details/73864381)\n\n\n\n[如何使用TensorFlow中的高级API：Estimator、Experiment和Dataset](https://zhuanlan.zhihu.com/p/29210791)\n\n\n\ntensorflow架构\n\n[tensorflow架构](https://blog.csdn.net/stdcoutzyx/article/details/51645396)\n\n[Tensoflow 分布式部署简介](https://blog.csdn.net/sydpz1987/article/details/51340277)\n\n[TensorFlow分布式全套（原理，部署，实例）](https://blog.csdn.net/CodeMaster_/article/details/76223835)\n","source":"_posts/201806-tensorflow-data-generation.md","raw":"---\ntitle: tensorflow data generation\ndate: 2018-06-03 16:18:12\ntags:\n---\n\n[tensorflow 数据读取 office guide](http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/reading_data.html#AUTOGENERATED-preloaded-data)\n\n[十图详解tensorflow数据读取机制（附代码）](https://zhuanlan.zhihu.com/p/27238630)\n\n[tf.train.batch和tf.train.shuffle_batch的理解](https://blog.csdn.net/ying86615791/article/details/73864381)\n\n\n\n[如何使用TensorFlow中的高级API：Estimator、Experiment和Dataset](https://zhuanlan.zhihu.com/p/29210791)\n\n\n\ntensorflow架构\n\n[tensorflow架构](https://blog.csdn.net/stdcoutzyx/article/details/51645396)\n\n[Tensoflow 分布式部署简介](https://blog.csdn.net/sydpz1987/article/details/51340277)\n\n[TensorFlow分布式全套（原理，部署，实例）](https://blog.csdn.net/CodeMaster_/article/details/76223835)\n","slug":"tensorflow-data-generation","published":1,"updated":"2018-06-03T08:34:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xq000qn61dlnrba6ef","content":"<p><a href=\"http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/reading_data.html#AUTOGENERATED-preloaded-data\" target=\"_blank\" rel=\"noopener\">tensorflow 数据读取 office guide</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/27238630\" target=\"_blank\" rel=\"noopener\">十图详解tensorflow数据读取机制（附代码）</a></p>\n<p><a href=\"https://blog.csdn.net/ying86615791/article/details/73864381\" target=\"_blank\" rel=\"noopener\">tf.train.batch和tf.train.shuffle_batch的理解</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/29210791\" target=\"_blank\" rel=\"noopener\">如何使用TensorFlow中的高级API：Estimator、Experiment和Dataset</a></p>\n<p>tensorflow架构</p>\n<p><a href=\"https://blog.csdn.net/stdcoutzyx/article/details/51645396\" target=\"_blank\" rel=\"noopener\">tensorflow架构</a></p>\n<p><a href=\"https://blog.csdn.net/sydpz1987/article/details/51340277\" target=\"_blank\" rel=\"noopener\">Tensoflow 分布式部署简介</a></p>\n<p><a href=\"https://blog.csdn.net/CodeMaster_/article/details/76223835\" target=\"_blank\" rel=\"noopener\">TensorFlow分布式全套（原理，部署，实例）</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/reading_data.html#AUTOGENERATED-preloaded-data\" target=\"_blank\" rel=\"noopener\">tensorflow 数据读取 office guide</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/27238630\" target=\"_blank\" rel=\"noopener\">十图详解tensorflow数据读取机制（附代码）</a></p>\n<p><a href=\"https://blog.csdn.net/ying86615791/article/details/73864381\" target=\"_blank\" rel=\"noopener\">tf.train.batch和tf.train.shuffle_batch的理解</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/29210791\" target=\"_blank\" rel=\"noopener\">如何使用TensorFlow中的高级API：Estimator、Experiment和Dataset</a></p>\n<p>tensorflow架构</p>\n<p><a href=\"https://blog.csdn.net/stdcoutzyx/article/details/51645396\" target=\"_blank\" rel=\"noopener\">tensorflow架构</a></p>\n<p><a href=\"https://blog.csdn.net/sydpz1987/article/details/51340277\" target=\"_blank\" rel=\"noopener\">Tensoflow 分布式部署简介</a></p>\n<p><a href=\"https://blog.csdn.net/CodeMaster_/article/details/76223835\" target=\"_blank\" rel=\"noopener\">TensorFlow分布式全套（原理，部署，实例）</a></p>\n"},{"title":"tensorflow中损失函数加正则项","date":"2018-06-03T08:01:26.000Z","_content":"\n# 概述\n\n在损失函数上加上正则项（结构风险最小化）是防止过拟合的一个重要方法,下面介绍如何在TensorFlow中使用正则项.\n\ntensorflow中对参数使用正则项分为两步: \n\n1. 创建一个正则方法(函数/对象) \n2. 将这个正则方法(函数/对象),应用到参数上\n\n# 创建正则项\n\n## l1 正则\n\n`tf.contrib.layers.l1_regularizer(scale, scope=None)`\n\n返回一个用来执行L1正则化的函数,函数的签名是func(weights). \n参数:\n\n- scale: 正则项的系数.\n- scope: 可选的scope name\n\n## l2 正则\n`tf.contrib.layers.l2_regularizer(scale, scope=None)`\n\n返回一个执行L2正则化的函数.\n\n## 多正则\n\n`tf.contrib.layers.sum_regularizer(regularizer_list, scope=None)`\n\n返回一个可以执行多种(个)正则化的函数.意思是,创建一个正则化方法,这个方法是多个正则化方法的混合体.\n\n参数: \n- regularizer_list: regulizer的列表\n\n# 应用正则方法\n\n`tf.contrib.layers.apply_regularization(regularizer, weights_list=None)`\n\n参数\n\n- regularizer:就是我们上一步创建的正则化方法\n- weights_list: 想要执行正则化方法的参数列表,如果为None的话,就取GraphKeys.WEIGHTS中的weights.\n\n函数返回一个标量Tensor,同时,这个标量Tensor也会保存到GraphKeys.REGULARIZATION_LOSSES中.这个Tensor保存了计算正则项损失的方法.\n\n现在,我们只需将这个正则项损失加到我们的损失函数上就可以了.\n\n> 如果是自己手动定义weight的话,需要手动将weight保存到GraphKeys.WEIGHTS中,但是如果使用layer的话,就不用这么麻烦了,别人已经帮你考虑好了.(最好自己验证一下tf.GraphKeys.WEIGHTS中是否包含了所有的weights,防止被坑)\n\n# 其它\n\n在使用tf.get_variable()和tf.variable_scope()的时候,你会发现,它们俩中有regularizer形参.如果传入这个参数的话,那么variable_scope内的weights的正则化损失,或者weights的正则化损失就会被添加到GraphKeys.REGULARIZATION_LOSSES中. \n示例:\n\n``` python\nimport tensorflow as tf\nfrom tensorflow.contrib import layers\n\nregularizer = layers.l1_regularizer(0.1)\n\nwith tf.variable_scope('var', initializer=tf.random_normal_initializer(), \nregularizer=regularizer):\n    weight = tf.get_variable('weight', shape=[8], initializer=tf.ones_initializer())\nwith tf.variable_scope('var2', initializer=tf.random_normal_initializer(), \nregularizer=regularizer):\n    weight2 = tf.get_variable('weight', shape=[8], initializer=tf.ones_initializer())\n\nregularization_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n```","source":"_posts/201806-tensorflow-loss-and-regularizer.md","raw":"---\ntitle: tensorflow中损失函数加正则项\ndate: 2018-06-03 16:01:26\ntags:\n---\n\n# 概述\n\n在损失函数上加上正则项（结构风险最小化）是防止过拟合的一个重要方法,下面介绍如何在TensorFlow中使用正则项.\n\ntensorflow中对参数使用正则项分为两步: \n\n1. 创建一个正则方法(函数/对象) \n2. 将这个正则方法(函数/对象),应用到参数上\n\n# 创建正则项\n\n## l1 正则\n\n`tf.contrib.layers.l1_regularizer(scale, scope=None)`\n\n返回一个用来执行L1正则化的函数,函数的签名是func(weights). \n参数:\n\n- scale: 正则项的系数.\n- scope: 可选的scope name\n\n## l2 正则\n`tf.contrib.layers.l2_regularizer(scale, scope=None)`\n\n返回一个执行L2正则化的函数.\n\n## 多正则\n\n`tf.contrib.layers.sum_regularizer(regularizer_list, scope=None)`\n\n返回一个可以执行多种(个)正则化的函数.意思是,创建一个正则化方法,这个方法是多个正则化方法的混合体.\n\n参数: \n- regularizer_list: regulizer的列表\n\n# 应用正则方法\n\n`tf.contrib.layers.apply_regularization(regularizer, weights_list=None)`\n\n参数\n\n- regularizer:就是我们上一步创建的正则化方法\n- weights_list: 想要执行正则化方法的参数列表,如果为None的话,就取GraphKeys.WEIGHTS中的weights.\n\n函数返回一个标量Tensor,同时,这个标量Tensor也会保存到GraphKeys.REGULARIZATION_LOSSES中.这个Tensor保存了计算正则项损失的方法.\n\n现在,我们只需将这个正则项损失加到我们的损失函数上就可以了.\n\n> 如果是自己手动定义weight的话,需要手动将weight保存到GraphKeys.WEIGHTS中,但是如果使用layer的话,就不用这么麻烦了,别人已经帮你考虑好了.(最好自己验证一下tf.GraphKeys.WEIGHTS中是否包含了所有的weights,防止被坑)\n\n# 其它\n\n在使用tf.get_variable()和tf.variable_scope()的时候,你会发现,它们俩中有regularizer形参.如果传入这个参数的话,那么variable_scope内的weights的正则化损失,或者weights的正则化损失就会被添加到GraphKeys.REGULARIZATION_LOSSES中. \n示例:\n\n``` python\nimport tensorflow as tf\nfrom tensorflow.contrib import layers\n\nregularizer = layers.l1_regularizer(0.1)\n\nwith tf.variable_scope('var', initializer=tf.random_normal_initializer(), \nregularizer=regularizer):\n    weight = tf.get_variable('weight', shape=[8], initializer=tf.ones_initializer())\nwith tf.variable_scope('var2', initializer=tf.random_normal_initializer(), \nregularizer=regularizer):\n    weight2 = tf.get_variable('weight', shape=[8], initializer=tf.ones_initializer())\n\nregularization_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n```","slug":"tensorflow-loss-and-regularizer","published":1,"updated":"2018-06-03T08:09:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xr000rn61dgqpfehrn","content":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>在损失函数上加上正则项（结构风险最小化）是防止过拟合的一个重要方法,下面介绍如何在TensorFlow中使用正则项.</p>\n<p>tensorflow中对参数使用正则项分为两步: </p>\n<ol>\n<li>创建一个正则方法(函数/对象) </li>\n<li>将这个正则方法(函数/对象),应用到参数上</li>\n</ol>\n<h1 id=\"创建正则项\"><a href=\"#创建正则项\" class=\"headerlink\" title=\"创建正则项\"></a>创建正则项</h1><h2 id=\"l1-正则\"><a href=\"#l1-正则\" class=\"headerlink\" title=\"l1 正则\"></a>l1 正则</h2><p><code>tf.contrib.layers.l1_regularizer(scale, scope=None)</code></p>\n<p>返回一个用来执行L1正则化的函数,函数的签名是func(weights).<br>参数:</p>\n<ul>\n<li>scale: 正则项的系数.</li>\n<li>scope: 可选的scope name</li>\n</ul>\n<h2 id=\"l2-正则\"><a href=\"#l2-正则\" class=\"headerlink\" title=\"l2 正则\"></a>l2 正则</h2><p><code>tf.contrib.layers.l2_regularizer(scale, scope=None)</code></p>\n<p>返回一个执行L2正则化的函数.</p>\n<h2 id=\"多正则\"><a href=\"#多正则\" class=\"headerlink\" title=\"多正则\"></a>多正则</h2><p><code>tf.contrib.layers.sum_regularizer(regularizer_list, scope=None)</code></p>\n<p>返回一个可以执行多种(个)正则化的函数.意思是,创建一个正则化方法,这个方法是多个正则化方法的混合体.</p>\n<p>参数: </p>\n<ul>\n<li>regularizer_list: regulizer的列表</li>\n</ul>\n<h1 id=\"应用正则方法\"><a href=\"#应用正则方法\" class=\"headerlink\" title=\"应用正则方法\"></a>应用正则方法</h1><p><code>tf.contrib.layers.apply_regularization(regularizer, weights_list=None)</code></p>\n<p>参数</p>\n<ul>\n<li>regularizer:就是我们上一步创建的正则化方法</li>\n<li>weights_list: 想要执行正则化方法的参数列表,如果为None的话,就取GraphKeys.WEIGHTS中的weights.</li>\n</ul>\n<p>函数返回一个标量Tensor,同时,这个标量Tensor也会保存到GraphKeys.REGULARIZATION_LOSSES中.这个Tensor保存了计算正则项损失的方法.</p>\n<p>现在,我们只需将这个正则项损失加到我们的损失函数上就可以了.</p>\n<blockquote>\n<p>如果是自己手动定义weight的话,需要手动将weight保存到GraphKeys.WEIGHTS中,但是如果使用layer的话,就不用这么麻烦了,别人已经帮你考虑好了.(最好自己验证一下tf.GraphKeys.WEIGHTS中是否包含了所有的weights,防止被坑)</p>\n</blockquote>\n<h1 id=\"其它\"><a href=\"#其它\" class=\"headerlink\" title=\"其它\"></a>其它</h1><p>在使用tf.get_variable()和tf.variable_scope()的时候,你会发现,它们俩中有regularizer形参.如果传入这个参数的话,那么variable_scope内的weights的正则化损失,或者weights的正则化损失就会被添加到GraphKeys.REGULARIZATION_LOSSES中.<br>示例:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorflow.contrib <span class=\"keyword\">import</span> layers</span><br><span class=\"line\"></span><br><span class=\"line\">regularizer = layers.l1_regularizer(<span class=\"number\">0.1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.variable_scope(<span class=\"string\">'var'</span>, initializer=tf.random_normal_initializer(), </span><br><span class=\"line\">regularizer=regularizer):</span><br><span class=\"line\">    weight = tf.get_variable(<span class=\"string\">'weight'</span>, shape=[<span class=\"number\">8</span>], initializer=tf.ones_initializer())</span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.variable_scope(<span class=\"string\">'var2'</span>, initializer=tf.random_normal_initializer(), </span><br><span class=\"line\">regularizer=regularizer):</span><br><span class=\"line\">    weight2 = tf.get_variable(<span class=\"string\">'weight'</span>, shape=[<span class=\"number\">8</span>], initializer=tf.ones_initializer())</span><br><span class=\"line\"></span><br><span class=\"line\">regularization_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>在损失函数上加上正则项（结构风险最小化）是防止过拟合的一个重要方法,下面介绍如何在TensorFlow中使用正则项.</p>\n<p>tensorflow中对参数使用正则项分为两步: </p>\n<ol>\n<li>创建一个正则方法(函数/对象) </li>\n<li>将这个正则方法(函数/对象),应用到参数上</li>\n</ol>\n<h1 id=\"创建正则项\"><a href=\"#创建正则项\" class=\"headerlink\" title=\"创建正则项\"></a>创建正则项</h1><h2 id=\"l1-正则\"><a href=\"#l1-正则\" class=\"headerlink\" title=\"l1 正则\"></a>l1 正则</h2><p><code>tf.contrib.layers.l1_regularizer(scale, scope=None)</code></p>\n<p>返回一个用来执行L1正则化的函数,函数的签名是func(weights).<br>参数:</p>\n<ul>\n<li>scale: 正则项的系数.</li>\n<li>scope: 可选的scope name</li>\n</ul>\n<h2 id=\"l2-正则\"><a href=\"#l2-正则\" class=\"headerlink\" title=\"l2 正则\"></a>l2 正则</h2><p><code>tf.contrib.layers.l2_regularizer(scale, scope=None)</code></p>\n<p>返回一个执行L2正则化的函数.</p>\n<h2 id=\"多正则\"><a href=\"#多正则\" class=\"headerlink\" title=\"多正则\"></a>多正则</h2><p><code>tf.contrib.layers.sum_regularizer(regularizer_list, scope=None)</code></p>\n<p>返回一个可以执行多种(个)正则化的函数.意思是,创建一个正则化方法,这个方法是多个正则化方法的混合体.</p>\n<p>参数: </p>\n<ul>\n<li>regularizer_list: regulizer的列表</li>\n</ul>\n<h1 id=\"应用正则方法\"><a href=\"#应用正则方法\" class=\"headerlink\" title=\"应用正则方法\"></a>应用正则方法</h1><p><code>tf.contrib.layers.apply_regularization(regularizer, weights_list=None)</code></p>\n<p>参数</p>\n<ul>\n<li>regularizer:就是我们上一步创建的正则化方法</li>\n<li>weights_list: 想要执行正则化方法的参数列表,如果为None的话,就取GraphKeys.WEIGHTS中的weights.</li>\n</ul>\n<p>函数返回一个标量Tensor,同时,这个标量Tensor也会保存到GraphKeys.REGULARIZATION_LOSSES中.这个Tensor保存了计算正则项损失的方法.</p>\n<p>现在,我们只需将这个正则项损失加到我们的损失函数上就可以了.</p>\n<blockquote>\n<p>如果是自己手动定义weight的话,需要手动将weight保存到GraphKeys.WEIGHTS中,但是如果使用layer的话,就不用这么麻烦了,别人已经帮你考虑好了.(最好自己验证一下tf.GraphKeys.WEIGHTS中是否包含了所有的weights,防止被坑)</p>\n</blockquote>\n<h1 id=\"其它\"><a href=\"#其它\" class=\"headerlink\" title=\"其它\"></a>其它</h1><p>在使用tf.get_variable()和tf.variable_scope()的时候,你会发现,它们俩中有regularizer形参.如果传入这个参数的话,那么variable_scope内的weights的正则化损失,或者weights的正则化损失就会被添加到GraphKeys.REGULARIZATION_LOSSES中.<br>示例:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorflow.contrib <span class=\"keyword\">import</span> layers</span><br><span class=\"line\"></span><br><span class=\"line\">regularizer = layers.l1_regularizer(<span class=\"number\">0.1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.variable_scope(<span class=\"string\">'var'</span>, initializer=tf.random_normal_initializer(), </span><br><span class=\"line\">regularizer=regularizer):</span><br><span class=\"line\">    weight = tf.get_variable(<span class=\"string\">'weight'</span>, shape=[<span class=\"number\">8</span>], initializer=tf.ones_initializer())</span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.variable_scope(<span class=\"string\">'var2'</span>, initializer=tf.random_normal_initializer(), </span><br><span class=\"line\">regularizer=regularizer):</span><br><span class=\"line\">    weight2 = tf.get_variable(<span class=\"string\">'weight'</span>, shape=[<span class=\"number\">8</span>], initializer=tf.ones_initializer())</span><br><span class=\"line\"></span><br><span class=\"line\">regularization_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))</span><br></pre></td></tr></table></figure>"},{"title":"机器学习中的embedding原理及tf.nn.embedding_lookup_sparse等API的理解","date":"2018-06-01T06:57:00.000Z","mathjax":true,"_content":"\n# \b\b概述\n\n本文主要讲解tensorflow中涉及embedding的API。之前看了一些文章，写的云山雾绕，花了好长时间才搞懂，太笨了。\n\b\nembedding 算法主要用于处理稀疏\b特征，应用于\b\bNLP、推荐、广告等领域。所以word2vec 只是embbeding 思想的一个应用，而不是全部。\n\n代码地址：git@github.com:gshtime/tensorflow-api.git\n\n# embedding原理\n\n常见的特征降维方法主要有PCA、SVD等。\n\n而embedding的主要目的也是对（稀疏）特征进行降维，\b它降维的方式可以类比为一个全连接层（没有激活函数），通过\b embedding 层的权重矩阵计算来降低维度。\n\n假设：\n- feature_num : 原始特征数\n- embedding_size: embedding之后的特征数\n- [feature_num, embedding_size]  权重矩阵shape\n- [m, feature_num]  输入矩阵shape，m为样本数\n- [m, embedding_size]  \b输出矩阵shape，m为样本数\n\n![稀疏向量的选择](http://p8vrqzrnj.bkt.clouddn.com/WX20180601-155344.png)\n\n应用中一般将物体嵌入到一个低维空间 $R^{embedding-size} (embedding-size << feature_num)$ ，只需要再compose 上一个从 $R^{feature-num}$ 到 $R^{embedding-size}$ 的线性映射就好了。每一个shape为 $feature-num \\times embedding-size$ 的矩阵M(embedding矩阵) 都定义了 $R^{feature-num}$ 到 $R^{embedding-size}$ 的一个线性映射: $x \\mapsto Mx$ 。当 $x$ 是一个标准基向量的时候，$Mx$对应矩阵 $M$ 中的一列，这就是对应 $id$ 的向量表示。\n\n![连接层](http://p8vrqzrnj.bkt.clouddn.com/20170814220528829.jpg)\n\n从id(索引)找到对应的 One-hot encoding ，然后红色的weight就直接对应了输出节点的值(注意这里没有 activation function)，也就是对应的embedding向量。\n\n# tensorflow API\n\n## 基础： tf.SparseTensor\n\n构造稀疏向量矩阵，\b\b【未求证】\b使用上每一行为一个样本\n\nSparseTensor(indices, values, dense_shape)\n\nparams:\n\n- indices: A 2-D int64 tensor of dense_shape [N, ndims], which specifies the indices of the elements in the sparse tensor that contain nonzero values (elements are zero-indexed). For example, indices=[[1,3], [2,4]] specifies that the elements with indexes of [1,3] and [2,4] have nonzero values. 是dense_shape这个矩阵中所有values值的位置，与values一一对应。\n- values: A 1-D tensor of any type and dense_shape [N], which supplies the values for each element in indices. For example, given indices=[[1,3], [2,4]], the parameter values=[18, 3.6] specifies that element [1,3] of the sparse tensor has a value of 18, and element [2,4] of the tensor has a value of 3.6. \b每一个稀疏值，与其位置indices\b一一对应。\n- dense_shape: A 1-D int64 tensor of dense_shape [ndims], which specifies the dense_shape of the sparse tensor. Takes a list indicating the number of elements in each dimension. For example, dense_shape=[3,6] specifies a two-dimensional 3x6 tensor, dense_shape=[2,3,4] specifies a three-dimensional 2x3x4 tensor, and dense_shape=[9] specifies a one-dimensional tensor with 9 elements. 稀疏向量矩阵的shape\n\nExample: The sparse tensor\n\n``` python\nSparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n\n# represents the dense tensor\n\n# [[1, 0, 0, 0]\n#  [0, 0, 2, 0]\n#  [0, 0, 0, 0]]\n```\n## tf.nn.embedding_lookup 和 partition_strategy 参数\n\n``` python\n# Signature:\ntf.nn.embedding_lookup(params, ids, partition_strategy='mod', name=None, validate_indices=True, max_norm=None)\n# Docstring:\n# Looks up `ids` in a list of embedding tensors.\n```\n\n是根据 `ids` 中的id，寻找 `params` 中的第id行。比如 `ids=[1,3,5]`，则找出`params`中第1，3，5行，组成一个tensor返回。\n\nembedding_lookup不是简单的查表，`params` 对应的向量是可以训练的，训练参数个数应该是 feature_num * embedding_size，即前文表述的embedding层权重矩阵，就是说 lookup 的是一种全连接层。\n\n此外，以下要\b记录的几个API里，都有参数 partition_strategy （切分方式）, 这个参数是当len(params) > 1 时，才生效\b，即当params 以list [a, b, c] (a,b,c都是tensor) 输入多个tensor时，对\bparams的选择顺序进行切分，（而不是对ids进行切分，ids只有选择的作用，当然也决定了在return中次序）。\n\n### 输入为单个tensor时\n\n``` python \n# 当\b输入单个tensor时，partition_strategy不起作用，不做\b id（编号） 的切分\na = np.arange(20).reshape(5,4)\nprint (a)\n\n# 前面的编号是我手动加的，意思是不做切分的时候就顺序编号就行\n# 0#[[ 0  1  2  3]\n# 1# [ 4  5  6  7]\n# 2# [ 8  9 10 11]\n# 3# [12 13 14 15]\n# 4# [16 17 18 19]]\n\ntensor_a = tf.Variable(a)\nembedded_tensor = tf.nn.embedding_lookup(params=tensor_a, ids=[0,3,2,1])\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    embedded_tensor = sess.run(embedded_tensor)\n    print(embedded_tensor)\n# 根据 ids 参数做选择\n#[[ 0  1  2  3]  选择了 id 0\n# [12 13 14 15]  选择了 id 3\n# [ 8  9 10 11]  选择了 id 2\n# [ 4  5  6  7]] 选择了 id 1\n\n```\n### 输入为多个tensor时\n\npartition_strategy 开始起作用，开始对多个tensor 的第 0 维上的项进行编号，编号的方式有两种，\"mod\"（默认） 和 \"div\"。\n\n假设：一共有三个tensor [a,b,c] 作为params 参数，所有`tensor`的第 0 维上一共有 10 个项目（id 0 ~ 9）。\n\n- \"mod\" : (id) mod len(params) 得到\b多少就把 id 分到第几个tensor里面\n    - a 依次分到id： 0 3 6 9\n    - b 依次分到id： 1 4 7\n    - c 依次分到id： 2 5 8\n\n- \"div\" : (id) div len(params) 可以理解为依次排序，但是这两种切分方式在无法均匀切分的情况下都是将前(max_id+1)%len(params)个 partition 多分配一个元素.\n    - a 依次分到id： 0 1 2 3 \n    - b 依次分到id： 4 5 6\n    - c 依次分到id： 7 8 9\n\n\n``` python\n# partition_strategy='div' 的情况\na = tf.Variable(np.arange(8).reshape(2,4))\nb = tf.Variable(np.arange(8,12).reshape(1,4))\nc = tf.Variable(np.arange(12, 20).reshape(2,4))\n\nembedded_tensor = tf.nn.embedding_lookup(params=[a,b,c], ids=[1,2,4], partition_strategy='div', name=\"embedding\")\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    print (sess.run(a))\n    print (sess.run(b))\n    print (sess.run(c))\n    \n    print (\"########## embedded_tensor #########\")\n    print(sess.run(embedded_tensor))\n# [[0 1 2 3]    a\b分到 id 0\n#  [4 5 6 7]]   a分到 id 1\n\n# [[ 8  9 10 11]] b分到 id 2\n#                 b分到 id 3\n\n# [[12 13 14 15]  c分到 id 4\n#  [16 17 18 19]] (c 没分到id)\n# ########## embedded_tensor ######### 注：ids=[1,2,4]\n#[[ 4  5  6  7]   \b按 ids 选的 1\n# [ 8  9 10 11]   按 ids 选的 2\n# [12 13 14 15]]  按 ids 选的 4\n```\n注：如果ids 中 有 3，\b这个id 虽然被分给 b 这个tensor了，但是b没有，会报一个错误\n``` python\nInvalidArgumentError: indices[0] = 1 is not in [0, 1)\n\t [[Node: embedding_5/GatherV2_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_154/read, ConstantFolding/embedding_5/DynamicPartition-folded-1, embedding_5/GatherV2_1/axis)]]\n```\n\n## tf.gather()\n函数签名如下：\n``` python \ntf.gather(\n    params,\n    indices,\n    validate_indices=None,\n    name=None\n```\n参数说明：\n- params是一个tensor，\n- indices是个值为int的tensor用来指定要从params取得元素的第0维的index。\n\n该函数可看成是tf.nn.embedding_lookup()的特殊形式，所以功能与其类似，即将其看成是embedding_lookup函数的params参数内只有一个tensor时的情形。\n\n## tf.nn.embedding_lookup_sparse\n\n``` python\ntf.nn.embedding_lookup_sparse(\n    params,\n    sp_ids,\n    sp_weights,\n    partition_strategy='mod',\n    name=None,\n    combiner=None,\n    max_norm=None\n)\n```\n### 参数\n\n见官网\bAPI，不贴了：[python API](https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse)\n\n- params: A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors. Alternatively, a PartitionedVariable, created by partitioning along dimension 0. Each element must be appropriately sized for the given partition_strategy.\n\nReturns:\nA dense tensor representing the combined embeddings for the sparse ids. For each row in the dense tensor represented by sp_ids, the op looks up the embeddings for all ids in that row, multiplies them by the corresponding weight, and combines these embeddings as specified.\n\nIn other words, if\n\n- shape(combined params) = [p0, p1, ..., pm]\n\nand\n\n- shape(sp_ids) = shape(sp_weights) = [d0, d1, ..., dn]\n\nthen\n\n- shape(output) = [d0, d1, ..., dn-1, p1, ..., pm].\n\nFor instance, if params is a 10x20 matrix, and sp_ids / sp_weights are\n\n[0, 0]: id 1, weight 2.0 [0, 1]: id 3, weight 0.5 [1, 0]: id 0, weight 1.0 [2, 3]: id 1, weight 3.0\n\nwith combiner=\"mean\", then the output will be a 3x20 matrix where\n\noutput[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5) output[1, :] = (params[0, :] * 1.0) / 1.0 output[2, :] = (params[1, :] * 3.0) / 3.0\n\n### 示例：\n\n``` python\na = np.arange(8).reshape(2, 4)\nb = np.arange(8, 16).reshape(2, 4)\nc = np.arange(12, 20).reshape(2, 4)\nprint (\"a :\")\nprint (a)\nprint (\"b :\")\nprint (b)\nprint (\"c :\")\nprint (c)\na = tf.Variable(a, dtype=tf.float32)\nb = tf.Variable(b, dtype=tf.float32)\nc = tf.Variable(c, dtype=tf.float32)\nidx = tf.SparseTensor(indices=[[0,0], [0,2], [1,0], [1, 1]], values=[1,2,2,0], dense_shape=(2,3))\nresult = tf.nn.embedding_lookup_sparse([a,c,b], idx, None, partition_strategy='mod', combiner=\"sum\")\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    res = sess.run(result)\n    print (\"\\n# result here\")\n    print(res)\n\n# a :\n# [[0 1 2 3]    id 0\n#  [4 5 6 7]]   id 3\n# b :\n# [[ 8  9 10 11]  id 1\n#  [12 13 14 15]] id 4\n# c :\n# [[16 17 18 19] id 2\n#  [20 21 22 23]] id 5\n\n# result here\n# [[24. 26. 28. 30.]  \n#  [16. 18. 20. 22.]]\n```\n解释：\n``` python\n#idx = tf.SparseTensor(indices=[[0,0], [0,2], [1,0], [1, 1]], values=[1,2,2,0], dense_shape=(2,3))\n构造如下稀疏向量矩阵，每一行视为一个样本的特征向量\n[\n    [[1], [], [2]],\n    [[2], [0], []]\n]\n以第一个样本 [[1], [], [2]] 为例：选择id 1 和id 2：\n# [[ 8  9 10 11]  id 1\n# [[16 17 18 19] id 2\n根据 combiner=\"sum\" ，把上面两个向量 按 axis=0 加到一起，得到：\n# [24. 26. 28. 30.]\n即 为第一个样本的 dense 向量\n```\n\n如果len(params) == 1, 就是不存在 partition 了，比较好理解，不再赘述。\n\n喝最烈的果粒橙，钻最深的牛角尖。\nend.","source":"_posts/201806-tensorflow-embedding-lookup-sparse.md","raw":"---\ntitle: 机器学习中的embedding原理及tf.nn.embedding_lookup_sparse等API的理解\ndate: 2018-06-01 14:57:00\nmathjax: true\ntags: embedding_lookup, tf.gather, embedding_lookup_sparse\n---\n\n# \b\b概述\n\n本文主要讲解tensorflow中涉及embedding的API。之前看了一些文章，写的云山雾绕，花了好长时间才搞懂，太笨了。\n\b\nembedding 算法主要用于处理稀疏\b特征，应用于\b\bNLP、推荐、广告等领域。所以word2vec 只是embbeding 思想的一个应用，而不是全部。\n\n代码地址：git@github.com:gshtime/tensorflow-api.git\n\n# embedding原理\n\n常见的特征降维方法主要有PCA、SVD等。\n\n而embedding的主要目的也是对（稀疏）特征进行降维，\b它降维的方式可以类比为一个全连接层（没有激活函数），通过\b embedding 层的权重矩阵计算来降低维度。\n\n假设：\n- feature_num : 原始特征数\n- embedding_size: embedding之后的特征数\n- [feature_num, embedding_size]  权重矩阵shape\n- [m, feature_num]  输入矩阵shape，m为样本数\n- [m, embedding_size]  \b输出矩阵shape，m为样本数\n\n![稀疏向量的选择](http://p8vrqzrnj.bkt.clouddn.com/WX20180601-155344.png)\n\n应用中一般将物体嵌入到一个低维空间 $R^{embedding-size} (embedding-size << feature_num)$ ，只需要再compose 上一个从 $R^{feature-num}$ 到 $R^{embedding-size}$ 的线性映射就好了。每一个shape为 $feature-num \\times embedding-size$ 的矩阵M(embedding矩阵) 都定义了 $R^{feature-num}$ 到 $R^{embedding-size}$ 的一个线性映射: $x \\mapsto Mx$ 。当 $x$ 是一个标准基向量的时候，$Mx$对应矩阵 $M$ 中的一列，这就是对应 $id$ 的向量表示。\n\n![连接层](http://p8vrqzrnj.bkt.clouddn.com/20170814220528829.jpg)\n\n从id(索引)找到对应的 One-hot encoding ，然后红色的weight就直接对应了输出节点的值(注意这里没有 activation function)，也就是对应的embedding向量。\n\n# tensorflow API\n\n## 基础： tf.SparseTensor\n\n构造稀疏向量矩阵，\b\b【未求证】\b使用上每一行为一个样本\n\nSparseTensor(indices, values, dense_shape)\n\nparams:\n\n- indices: A 2-D int64 tensor of dense_shape [N, ndims], which specifies the indices of the elements in the sparse tensor that contain nonzero values (elements are zero-indexed). For example, indices=[[1,3], [2,4]] specifies that the elements with indexes of [1,3] and [2,4] have nonzero values. 是dense_shape这个矩阵中所有values值的位置，与values一一对应。\n- values: A 1-D tensor of any type and dense_shape [N], which supplies the values for each element in indices. For example, given indices=[[1,3], [2,4]], the parameter values=[18, 3.6] specifies that element [1,3] of the sparse tensor has a value of 18, and element [2,4] of the tensor has a value of 3.6. \b每一个稀疏值，与其位置indices\b一一对应。\n- dense_shape: A 1-D int64 tensor of dense_shape [ndims], which specifies the dense_shape of the sparse tensor. Takes a list indicating the number of elements in each dimension. For example, dense_shape=[3,6] specifies a two-dimensional 3x6 tensor, dense_shape=[2,3,4] specifies a three-dimensional 2x3x4 tensor, and dense_shape=[9] specifies a one-dimensional tensor with 9 elements. 稀疏向量矩阵的shape\n\nExample: The sparse tensor\n\n``` python\nSparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n\n# represents the dense tensor\n\n# [[1, 0, 0, 0]\n#  [0, 0, 2, 0]\n#  [0, 0, 0, 0]]\n```\n## tf.nn.embedding_lookup 和 partition_strategy 参数\n\n``` python\n# Signature:\ntf.nn.embedding_lookup(params, ids, partition_strategy='mod', name=None, validate_indices=True, max_norm=None)\n# Docstring:\n# Looks up `ids` in a list of embedding tensors.\n```\n\n是根据 `ids` 中的id，寻找 `params` 中的第id行。比如 `ids=[1,3,5]`，则找出`params`中第1，3，5行，组成一个tensor返回。\n\nembedding_lookup不是简单的查表，`params` 对应的向量是可以训练的，训练参数个数应该是 feature_num * embedding_size，即前文表述的embedding层权重矩阵，就是说 lookup 的是一种全连接层。\n\n此外，以下要\b记录的几个API里，都有参数 partition_strategy （切分方式）, 这个参数是当len(params) > 1 时，才生效\b，即当params 以list [a, b, c] (a,b,c都是tensor) 输入多个tensor时，对\bparams的选择顺序进行切分，（而不是对ids进行切分，ids只有选择的作用，当然也决定了在return中次序）。\n\n### 输入为单个tensor时\n\n``` python \n# 当\b输入单个tensor时，partition_strategy不起作用，不做\b id（编号） 的切分\na = np.arange(20).reshape(5,4)\nprint (a)\n\n# 前面的编号是我手动加的，意思是不做切分的时候就顺序编号就行\n# 0#[[ 0  1  2  3]\n# 1# [ 4  5  6  7]\n# 2# [ 8  9 10 11]\n# 3# [12 13 14 15]\n# 4# [16 17 18 19]]\n\ntensor_a = tf.Variable(a)\nembedded_tensor = tf.nn.embedding_lookup(params=tensor_a, ids=[0,3,2,1])\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    embedded_tensor = sess.run(embedded_tensor)\n    print(embedded_tensor)\n# 根据 ids 参数做选择\n#[[ 0  1  2  3]  选择了 id 0\n# [12 13 14 15]  选择了 id 3\n# [ 8  9 10 11]  选择了 id 2\n# [ 4  5  6  7]] 选择了 id 1\n\n```\n### 输入为多个tensor时\n\npartition_strategy 开始起作用，开始对多个tensor 的第 0 维上的项进行编号，编号的方式有两种，\"mod\"（默认） 和 \"div\"。\n\n假设：一共有三个tensor [a,b,c] 作为params 参数，所有`tensor`的第 0 维上一共有 10 个项目（id 0 ~ 9）。\n\n- \"mod\" : (id) mod len(params) 得到\b多少就把 id 分到第几个tensor里面\n    - a 依次分到id： 0 3 6 9\n    - b 依次分到id： 1 4 7\n    - c 依次分到id： 2 5 8\n\n- \"div\" : (id) div len(params) 可以理解为依次排序，但是这两种切分方式在无法均匀切分的情况下都是将前(max_id+1)%len(params)个 partition 多分配一个元素.\n    - a 依次分到id： 0 1 2 3 \n    - b 依次分到id： 4 5 6\n    - c 依次分到id： 7 8 9\n\n\n``` python\n# partition_strategy='div' 的情况\na = tf.Variable(np.arange(8).reshape(2,4))\nb = tf.Variable(np.arange(8,12).reshape(1,4))\nc = tf.Variable(np.arange(12, 20).reshape(2,4))\n\nembedded_tensor = tf.nn.embedding_lookup(params=[a,b,c], ids=[1,2,4], partition_strategy='div', name=\"embedding\")\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    print (sess.run(a))\n    print (sess.run(b))\n    print (sess.run(c))\n    \n    print (\"########## embedded_tensor #########\")\n    print(sess.run(embedded_tensor))\n# [[0 1 2 3]    a\b分到 id 0\n#  [4 5 6 7]]   a分到 id 1\n\n# [[ 8  9 10 11]] b分到 id 2\n#                 b分到 id 3\n\n# [[12 13 14 15]  c分到 id 4\n#  [16 17 18 19]] (c 没分到id)\n# ########## embedded_tensor ######### 注：ids=[1,2,4]\n#[[ 4  5  6  7]   \b按 ids 选的 1\n# [ 8  9 10 11]   按 ids 选的 2\n# [12 13 14 15]]  按 ids 选的 4\n```\n注：如果ids 中 有 3，\b这个id 虽然被分给 b 这个tensor了，但是b没有，会报一个错误\n``` python\nInvalidArgumentError: indices[0] = 1 is not in [0, 1)\n\t [[Node: embedding_5/GatherV2_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable_154/read, ConstantFolding/embedding_5/DynamicPartition-folded-1, embedding_5/GatherV2_1/axis)]]\n```\n\n## tf.gather()\n函数签名如下：\n``` python \ntf.gather(\n    params,\n    indices,\n    validate_indices=None,\n    name=None\n```\n参数说明：\n- params是一个tensor，\n- indices是个值为int的tensor用来指定要从params取得元素的第0维的index。\n\n该函数可看成是tf.nn.embedding_lookup()的特殊形式，所以功能与其类似，即将其看成是embedding_lookup函数的params参数内只有一个tensor时的情形。\n\n## tf.nn.embedding_lookup_sparse\n\n``` python\ntf.nn.embedding_lookup_sparse(\n    params,\n    sp_ids,\n    sp_weights,\n    partition_strategy='mod',\n    name=None,\n    combiner=None,\n    max_norm=None\n)\n```\n### 参数\n\n见官网\bAPI，不贴了：[python API](https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse)\n\n- params: A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors. Alternatively, a PartitionedVariable, created by partitioning along dimension 0. Each element must be appropriately sized for the given partition_strategy.\n\nReturns:\nA dense tensor representing the combined embeddings for the sparse ids. For each row in the dense tensor represented by sp_ids, the op looks up the embeddings for all ids in that row, multiplies them by the corresponding weight, and combines these embeddings as specified.\n\nIn other words, if\n\n- shape(combined params) = [p0, p1, ..., pm]\n\nand\n\n- shape(sp_ids) = shape(sp_weights) = [d0, d1, ..., dn]\n\nthen\n\n- shape(output) = [d0, d1, ..., dn-1, p1, ..., pm].\n\nFor instance, if params is a 10x20 matrix, and sp_ids / sp_weights are\n\n[0, 0]: id 1, weight 2.0 [0, 1]: id 3, weight 0.5 [1, 0]: id 0, weight 1.0 [2, 3]: id 1, weight 3.0\n\nwith combiner=\"mean\", then the output will be a 3x20 matrix where\n\noutput[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5) output[1, :] = (params[0, :] * 1.0) / 1.0 output[2, :] = (params[1, :] * 3.0) / 3.0\n\n### 示例：\n\n``` python\na = np.arange(8).reshape(2, 4)\nb = np.arange(8, 16).reshape(2, 4)\nc = np.arange(12, 20).reshape(2, 4)\nprint (\"a :\")\nprint (a)\nprint (\"b :\")\nprint (b)\nprint (\"c :\")\nprint (c)\na = tf.Variable(a, dtype=tf.float32)\nb = tf.Variable(b, dtype=tf.float32)\nc = tf.Variable(c, dtype=tf.float32)\nidx = tf.SparseTensor(indices=[[0,0], [0,2], [1,0], [1, 1]], values=[1,2,2,0], dense_shape=(2,3))\nresult = tf.nn.embedding_lookup_sparse([a,c,b], idx, None, partition_strategy='mod', combiner=\"sum\")\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    res = sess.run(result)\n    print (\"\\n# result here\")\n    print(res)\n\n# a :\n# [[0 1 2 3]    id 0\n#  [4 5 6 7]]   id 3\n# b :\n# [[ 8  9 10 11]  id 1\n#  [12 13 14 15]] id 4\n# c :\n# [[16 17 18 19] id 2\n#  [20 21 22 23]] id 5\n\n# result here\n# [[24. 26. 28. 30.]  \n#  [16. 18. 20. 22.]]\n```\n解释：\n``` python\n#idx = tf.SparseTensor(indices=[[0,0], [0,2], [1,0], [1, 1]], values=[1,2,2,0], dense_shape=(2,3))\n构造如下稀疏向量矩阵，每一行视为一个样本的特征向量\n[\n    [[1], [], [2]],\n    [[2], [0], []]\n]\n以第一个样本 [[1], [], [2]] 为例：选择id 1 和id 2：\n# [[ 8  9 10 11]  id 1\n# [[16 17 18 19] id 2\n根据 combiner=\"sum\" ，把上面两个向量 按 axis=0 加到一起，得到：\n# [24. 26. 28. 30.]\n即 为第一个样本的 dense 向量\n```\n\n如果len(params) == 1, 就是不存在 partition 了，比较好理解，不再赘述。\n\n喝最烈的果粒橙，钻最深的牛角尖。\nend.","slug":"tensorflow-embedding-lookup-sparse","published":1,"updated":"2018-06-02T06:46:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xs000sn61dap4mjdgn","content":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"\b\b概述\"></a>\b\b概述</h1><p>本文主要讲解tensorflow中涉及embedding的API。之前看了一些文章，写的云山雾绕，花了好长时间才搞懂，太笨了。<br>\b<br>embedding 算法主要用于处理稀疏\b特征，应用于\b\bNLP、推荐、广告等领域。所以word2vec 只是embbeding 思想的一个应用，而不是全部。</p>\n<p>代码地址：git@github.com:gshtime/tensorflow-api.git</p>\n<h1 id=\"embedding原理\"><a href=\"#embedding原理\" class=\"headerlink\" title=\"embedding原理\"></a>embedding原理</h1><p>常见的特征降维方法主要有PCA、SVD等。</p>\n<p>而embedding的主要目的也是对（稀疏）特征进行降维，\b它降维的方式可以类比为一个全连接层（没有激活函数），通过\b embedding 层的权重矩阵计算来降低维度。</p>\n<p>假设：</p>\n<ul>\n<li>feature_num : 原始特征数</li>\n<li>embedding_size: embedding之后的特征数</li>\n<li>[feature_num, embedding_size]  权重矩阵shape</li>\n<li>[m, feature_num]  输入矩阵shape，m为样本数</li>\n<li>[m, embedding_size]  \b输出矩阵shape，m为样本数</li>\n</ul>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/WX20180601-155344.png\" alt=\"稀疏向量的选择\"></p>\n<p>应用中一般将物体嵌入到一个低维空间 $R^{embedding-size} (embedding-size &lt;&lt; feature_num)$ ，只需要再compose 上一个从 $R^{feature-num}$ 到 $R^{embedding-size}$ 的线性映射就好了。每一个shape为 $feature-num \\times embedding-size$ 的矩阵M(embedding矩阵) 都定义了 $R^{feature-num}$ 到 $R^{embedding-size}$ 的一个线性映射: $x \\mapsto Mx$ 。当 $x$ 是一个标准基向量的时候，$Mx$对应矩阵 $M$ 中的一列，这就是对应 $id$ 的向量表示。</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/20170814220528829.jpg\" alt=\"连接层\"></p>\n<p>从id(索引)找到对应的 One-hot encoding ，然后红色的weight就直接对应了输出节点的值(注意这里没有 activation function)，也就是对应的embedding向量。</p>\n<h1 id=\"tensorflow-API\"><a href=\"#tensorflow-API\" class=\"headerlink\" title=\"tensorflow API\"></a>tensorflow API</h1><h2 id=\"基础：-tf-SparseTensor\"><a href=\"#基础：-tf-SparseTensor\" class=\"headerlink\" title=\"基础： tf.SparseTensor\"></a>基础： tf.SparseTensor</h2><p>构造稀疏向量矩阵，\b\b【未求证】\b使用上每一行为一个样本</p>\n<p>SparseTensor(indices, values, dense_shape)</p>\n<p>params:</p>\n<ul>\n<li>indices: A 2-D int64 tensor of dense_shape [N, ndims], which specifies the indices of the elements in the sparse tensor that contain nonzero values (elements are zero-indexed). For example, indices=[[1,3], [2,4]] specifies that the elements with indexes of [1,3] and [2,4] have nonzero values. 是dense_shape这个矩阵中所有values值的位置，与values一一对应。</li>\n<li>values: A 1-D tensor of any type and dense_shape [N], which supplies the values for each element in indices. For example, given indices=[[1,3], [2,4]], the parameter values=[18, 3.6] specifies that element [1,3] of the sparse tensor has a value of 18, and element [2,4] of the tensor has a value of 3.6. \b每一个稀疏值，与其位置indices\b一一对应。</li>\n<li>dense_shape: A 1-D int64 tensor of dense_shape [ndims], which specifies the dense_shape of the sparse tensor. Takes a list indicating the number of elements in each dimension. For example, dense_shape=[3,6] specifies a two-dimensional 3x6 tensor, dense_shape=[2,3,4] specifies a three-dimensional 2x3x4 tensor, and dense_shape=[9] specifies a one-dimensional tensor with 9 elements. 稀疏向量矩阵的shape</li>\n</ul>\n<p>Example: The sparse tensor</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SparseTensor(indices=[[<span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">1</span>, <span class=\"number\">2</span>]], values=[<span class=\"number\">1</span>, <span class=\"number\">2</span>], dense_shape=[<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># represents the dense tensor</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># [[1, 0, 0, 0]</span></span><br><span class=\"line\"><span class=\"comment\">#  [0, 0, 2, 0]</span></span><br><span class=\"line\"><span class=\"comment\">#  [0, 0, 0, 0]]</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"tf-nn-embedding-lookup-和-partition-strategy-参数\"><a href=\"#tf-nn-embedding-lookup-和-partition-strategy-参数\" class=\"headerlink\" title=\"tf.nn.embedding_lookup 和 partition_strategy 参数\"></a>tf.nn.embedding_lookup 和 partition_strategy 参数</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Signature:</span></span><br><span class=\"line\">tf.nn.embedding_lookup(params, ids, partition_strategy=<span class=\"string\">'mod'</span>, name=<span class=\"keyword\">None</span>, validate_indices=<span class=\"keyword\">True</span>, max_norm=<span class=\"keyword\">None</span>)</span><br><span class=\"line\"><span class=\"comment\"># Docstring:</span></span><br><span class=\"line\"><span class=\"comment\"># Looks up `ids` in a list of embedding tensors.</span></span><br></pre></td></tr></table></figure>\n<p>是根据 <code>ids</code> 中的id，寻找 <code>params</code> 中的第id行。比如 <code>ids=[1,3,5]</code>，则找出<code>params</code>中第1，3，5行，组成一个tensor返回。</p>\n<p>embedding_lookup不是简单的查表，<code>params</code> 对应的向量是可以训练的，训练参数个数应该是 feature_num * embedding_size，即前文表述的embedding层权重矩阵，就是说 lookup 的是一种全连接层。</p>\n<p>此外，以下要\b记录的几个API里，都有参数 partition_strategy （切分方式）, 这个参数是当len(params) &gt; 1 时，才生效\b，即当params 以list [a, b, c] (a,b,c都是tensor) 输入多个tensor时，对\bparams的选择顺序进行切分，（而不是对ids进行切分，ids只有选择的作用，当然也决定了在return中次序）。</p>\n<h3 id=\"输入为单个tensor时\"><a href=\"#输入为单个tensor时\" class=\"headerlink\" title=\"输入为单个tensor时\"></a>输入为单个tensor时</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 当\b输入单个tensor时，partition_strategy不起作用，不做\b id（编号） 的切分</span></span><br><span class=\"line\">a = np.arange(<span class=\"number\">20</span>).reshape(<span class=\"number\">5</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (a)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 前面的编号是我手动加的，意思是不做切分的时候就顺序编号就行</span></span><br><span class=\"line\"><span class=\"comment\"># 0#[[ 0  1  2  3]</span></span><br><span class=\"line\"><span class=\"comment\"># 1# [ 4  5  6  7]</span></span><br><span class=\"line\"><span class=\"comment\"># 2# [ 8  9 10 11]</span></span><br><span class=\"line\"><span class=\"comment\"># 3# [12 13 14 15]</span></span><br><span class=\"line\"><span class=\"comment\"># 4# [16 17 18 19]]</span></span><br><span class=\"line\"></span><br><span class=\"line\">tensor_a = tf.Variable(a)</span><br><span class=\"line\">embedded_tensor = tf.nn.embedding_lookup(params=tensor_a, ids=[<span class=\"number\">0</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\">init = tf.global_variables_initializer()</span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    sess.run(init)</span><br><span class=\"line\">    embedded_tensor = sess.run(embedded_tensor)</span><br><span class=\"line\">    print(embedded_tensor)</span><br><span class=\"line\"><span class=\"comment\"># 根据 ids 参数做选择</span></span><br><span class=\"line\"><span class=\"comment\">#[[ 0  1  2  3]  选择了 id 0</span></span><br><span class=\"line\"><span class=\"comment\"># [12 13 14 15]  选择了 id 3</span></span><br><span class=\"line\"><span class=\"comment\"># [ 8  9 10 11]  选择了 id 2</span></span><br><span class=\"line\"><span class=\"comment\"># [ 4  5  6  7]] 选择了 id 1</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"输入为多个tensor时\"><a href=\"#输入为多个tensor时\" class=\"headerlink\" title=\"输入为多个tensor时\"></a>输入为多个tensor时</h3><p>partition_strategy 开始起作用，开始对多个tensor 的第 0 维上的项进行编号，编号的方式有两种，”mod”（默认） 和 “div”。</p>\n<p>假设：一共有三个tensor [a,b,c] 作为params 参数，所有<code>tensor</code>的第 0 维上一共有 10 个项目（id 0 ~ 9）。</p>\n<ul>\n<li><p>“mod” : (id) mod len(params) 得到\b多少就把 id 分到第几个tensor里面</p>\n<ul>\n<li>a 依次分到id： 0 3 6 9</li>\n<li>b 依次分到id： 1 4 7</li>\n<li>c 依次分到id： 2 5 8</li>\n</ul>\n</li>\n<li><p>“div” : (id) div len(params) 可以理解为依次排序，但是这两种切分方式在无法均匀切分的情况下都是将前(max_id+1)%len(params)个 partition 多分配一个元素.</p>\n<ul>\n<li>a 依次分到id： 0 1 2 3 </li>\n<li>b 依次分到id： 4 5 6</li>\n<li>c 依次分到id： 7 8 9</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># partition_strategy='div' 的情况</span></span><br><span class=\"line\">a = tf.Variable(np.arange(<span class=\"number\">8</span>).reshape(<span class=\"number\">2</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">b = tf.Variable(np.arange(<span class=\"number\">8</span>,<span class=\"number\">12</span>).reshape(<span class=\"number\">1</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">c = tf.Variable(np.arange(<span class=\"number\">12</span>, <span class=\"number\">20</span>).reshape(<span class=\"number\">2</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">embedded_tensor = tf.nn.embedding_lookup(params=[a,b,c], ids=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">4</span>], partition_strategy=<span class=\"string\">'div'</span>, name=<span class=\"string\">\"embedding\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">init = tf.global_variables_initializer()</span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    sess.run(init)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> (sess.run(a))</span><br><span class=\"line\">    <span class=\"keyword\">print</span> (sess.run(b))</span><br><span class=\"line\">    <span class=\"keyword\">print</span> (sess.run(c))</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">print</span> (<span class=\"string\">\"########## embedded_tensor #########\"</span>)</span><br><span class=\"line\">    print(sess.run(embedded_tensor))</span><br><span class=\"line\"><span class=\"comment\"># [[0 1 2 3]    a\b分到 id 0</span></span><br><span class=\"line\"><span class=\"comment\">#  [4 5 6 7]]   a分到 id 1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># [[ 8  9 10 11]] b分到 id 2</span></span><br><span class=\"line\"><span class=\"comment\">#                 b分到 id 3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># [[12 13 14 15]  c分到 id 4</span></span><br><span class=\"line\"><span class=\"comment\">#  [16 17 18 19]] (c 没分到id)</span></span><br><span class=\"line\"><span class=\"comment\"># ########## embedded_tensor ######### 注：ids=[1,2,4]</span></span><br><span class=\"line\"><span class=\"comment\">#[[ 4  5  6  7]   \b按 ids 选的 1</span></span><br><span class=\"line\"><span class=\"comment\"># [ 8  9 10 11]   按 ids 选的 2</span></span><br><span class=\"line\"><span class=\"comment\"># [12 13 14 15]]  按 ids 选的 4</span></span><br></pre></td></tr></table></figure>\n<p>注：如果ids 中 有 3，\b这个id 虽然被分给 b 这个tensor了，但是b没有，会报一个错误<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">InvalidArgumentError: indices[<span class=\"number\">0</span>] = <span class=\"number\">1</span> <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> [<span class=\"number\">0</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t [[Node: embedding_5/GatherV2_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_INT64, _device=<span class=\"string\">\"/job:localhost/replica:0/task:0/device:CPU:0\"</span>](Variable_154/read, ConstantFolding/embedding_5/DynamicPartition-folded<span class=\"number\">-1</span>, embedding_5/GatherV2_1/axis)]]</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"tf-gather\"><a href=\"#tf-gather\" class=\"headerlink\" title=\"tf.gather()\"></a>tf.gather()</h2><p>函数签名如下：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.gather(</span><br><span class=\"line\">    params,</span><br><span class=\"line\">    indices,</span><br><span class=\"line\">    validate_indices=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">    name=<span class=\"keyword\">None</span></span><br></pre></td></tr></table></figure></p>\n<p>参数说明：</p>\n<ul>\n<li>params是一个tensor，</li>\n<li>indices是个值为int的tensor用来指定要从params取得元素的第0维的index。</li>\n</ul>\n<p>该函数可看成是tf.nn.embedding_lookup()的特殊形式，所以功能与其类似，即将其看成是embedding_lookup函数的params参数内只有一个tensor时的情形。</p>\n<h2 id=\"tf-nn-embedding-lookup-sparse\"><a href=\"#tf-nn-embedding-lookup-sparse\" class=\"headerlink\" title=\"tf.nn.embedding_lookup_sparse\"></a>tf.nn.embedding_lookup_sparse</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.nn.embedding_lookup_sparse(</span><br><span class=\"line\">    params,</span><br><span class=\"line\">    sp_ids,</span><br><span class=\"line\">    sp_weights,</span><br><span class=\"line\">    partition_strategy=<span class=\"string\">'mod'</span>,</span><br><span class=\"line\">    name=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">    combiner=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">    max_norm=<span class=\"keyword\">None</span></span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<h3 id=\"参数\"><a href=\"#参数\" class=\"headerlink\" title=\"参数\"></a>参数</h3><p>见官网\bAPI，不贴了：<a href=\"https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse\" target=\"_blank\" rel=\"noopener\">python API</a></p>\n<ul>\n<li>params: A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors. Alternatively, a PartitionedVariable, created by partitioning along dimension 0. Each element must be appropriately sized for the given partition_strategy.</li>\n</ul>\n<p>Returns:<br>A dense tensor representing the combined embeddings for the sparse ids. For each row in the dense tensor represented by sp_ids, the op looks up the embeddings for all ids in that row, multiplies them by the corresponding weight, and combines these embeddings as specified.</p>\n<p>In other words, if</p>\n<ul>\n<li>shape(combined params) = [p0, p1, …, pm]</li>\n</ul>\n<p>and</p>\n<ul>\n<li>shape(sp_ids) = shape(sp_weights) = [d0, d1, …, dn]</li>\n</ul>\n<p>then</p>\n<ul>\n<li>shape(output) = [d0, d1, …, dn-1, p1, …, pm].</li>\n</ul>\n<p>For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are</p>\n<p>[0, 0]: id 1, weight 2.0 [0, 1]: id 3, weight 0.5 [1, 0]: id 0, weight 1.0 [2, 3]: id 1, weight 3.0</p>\n<p>with combiner=”mean”, then the output will be a 3x20 matrix where</p>\n<p>output[0, :] = (params[1, :] <em> 2.0 + params[3, :] </em> 0.5) / (2.0 + 0.5) output[1, :] = (params[0, :] <em> 1.0) / 1.0 output[2, :] = (params[1, :] </em> 3.0) / 3.0</p>\n<h3 id=\"示例：\"><a href=\"#示例：\" class=\"headerlink\" title=\"示例：\"></a>示例：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = np.arange(<span class=\"number\">8</span>).reshape(<span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">b = np.arange(<span class=\"number\">8</span>, <span class=\"number\">16</span>).reshape(<span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">c = np.arange(<span class=\"number\">12</span>, <span class=\"number\">20</span>).reshape(<span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"a :\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (a)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"b :\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (b)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"c :\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (c)</span><br><span class=\"line\">a = tf.Variable(a, dtype=tf.float32)</span><br><span class=\"line\">b = tf.Variable(b, dtype=tf.float32)</span><br><span class=\"line\">c = tf.Variable(c, dtype=tf.float32)</span><br><span class=\"line\">idx = tf.SparseTensor(indices=[[<span class=\"number\">0</span>,<span class=\"number\">0</span>], [<span class=\"number\">0</span>,<span class=\"number\">2</span>], [<span class=\"number\">1</span>,<span class=\"number\">0</span>], [<span class=\"number\">1</span>, <span class=\"number\">1</span>]], values=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">0</span>], dense_shape=(<span class=\"number\">2</span>,<span class=\"number\">3</span>))</span><br><span class=\"line\">result = tf.nn.embedding_lookup_sparse([a,c,b], idx, <span class=\"keyword\">None</span>, partition_strategy=<span class=\"string\">'mod'</span>, combiner=<span class=\"string\">\"sum\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">init = tf.global_variables_initializer()</span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    sess.run(init)</span><br><span class=\"line\">    res = sess.run(result)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> (<span class=\"string\">\"\\n# result here\"</span>)</span><br><span class=\"line\">    print(res)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># a :</span></span><br><span class=\"line\"><span class=\"comment\"># [[0 1 2 3]    id 0</span></span><br><span class=\"line\"><span class=\"comment\">#  [4 5 6 7]]   id 3</span></span><br><span class=\"line\"><span class=\"comment\"># b :</span></span><br><span class=\"line\"><span class=\"comment\"># [[ 8  9 10 11]  id 1</span></span><br><span class=\"line\"><span class=\"comment\">#  [12 13 14 15]] id 4</span></span><br><span class=\"line\"><span class=\"comment\"># c :</span></span><br><span class=\"line\"><span class=\"comment\"># [[16 17 18 19] id 2</span></span><br><span class=\"line\"><span class=\"comment\">#  [20 21 22 23]] id 5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># result here</span></span><br><span class=\"line\"><span class=\"comment\"># [[24. 26. 28. 30.]  </span></span><br><span class=\"line\"><span class=\"comment\">#  [16. 18. 20. 22.]]</span></span><br></pre></td></tr></table></figure>\n<p>解释：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#idx = tf.SparseTensor(indices=[[0,0], [0,2], [1,0], [1, 1]], values=[1,2,2,0], dense_shape=(2,3))</span></span><br><span class=\"line\">构造如下稀疏向量矩阵，每一行视为一个样本的特征向量</span><br><span class=\"line\">[</span><br><span class=\"line\">    [[<span class=\"number\">1</span>], [], [<span class=\"number\">2</span>]],</span><br><span class=\"line\">    [[<span class=\"number\">2</span>], [<span class=\"number\">0</span>], []]</span><br><span class=\"line\">]</span><br><span class=\"line\">以第一个样本 [[<span class=\"number\">1</span>], [], [<span class=\"number\">2</span>]] 为例：选择id <span class=\"number\">1</span> 和id <span class=\"number\">2</span>：</span><br><span class=\"line\"><span class=\"comment\"># [[ 8  9 10 11]  id 1</span></span><br><span class=\"line\"><span class=\"comment\"># [[16 17 18 19] id 2</span></span><br><span class=\"line\">根据 combiner=<span class=\"string\">\"sum\"</span> ，把上面两个向量 按 axis=<span class=\"number\">0</span> 加到一起，得到：</span><br><span class=\"line\"><span class=\"comment\"># [24. 26. 28. 30.]</span></span><br><span class=\"line\">即 为第一个样本的 dense 向量</span><br></pre></td></tr></table></figure></p>\n<p>如果len(params) == 1, 就是不存在 partition 了，比较好理解，不再赘述。</p>\n<p>喝最烈的果粒橙，钻最深的牛角尖。<br>end.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"\b\b概述\"></a>\b\b概述</h1><p>本文主要讲解tensorflow中涉及embedding的API。之前看了一些文章，写的云山雾绕，花了好长时间才搞懂，太笨了。<br>\b<br>embedding 算法主要用于处理稀疏\b特征，应用于\b\bNLP、推荐、广告等领域。所以word2vec 只是embbeding 思想的一个应用，而不是全部。</p>\n<p>代码地址：git@github.com:gshtime/tensorflow-api.git</p>\n<h1 id=\"embedding原理\"><a href=\"#embedding原理\" class=\"headerlink\" title=\"embedding原理\"></a>embedding原理</h1><p>常见的特征降维方法主要有PCA、SVD等。</p>\n<p>而embedding的主要目的也是对（稀疏）特征进行降维，\b它降维的方式可以类比为一个全连接层（没有激活函数），通过\b embedding 层的权重矩阵计算来降低维度。</p>\n<p>假设：</p>\n<ul>\n<li>feature_num : 原始特征数</li>\n<li>embedding_size: embedding之后的特征数</li>\n<li>[feature_num, embedding_size]  权重矩阵shape</li>\n<li>[m, feature_num]  输入矩阵shape，m为样本数</li>\n<li>[m, embedding_size]  \b输出矩阵shape，m为样本数</li>\n</ul>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/WX20180601-155344.png\" alt=\"稀疏向量的选择\"></p>\n<p>应用中一般将物体嵌入到一个低维空间 $R^{embedding-size} (embedding-size &lt;&lt; feature_num)$ ，只需要再compose 上一个从 $R^{feature-num}$ 到 $R^{embedding-size}$ 的线性映射就好了。每一个shape为 $feature-num \\times embedding-size$ 的矩阵M(embedding矩阵) 都定义了 $R^{feature-num}$ 到 $R^{embedding-size}$ 的一个线性映射: $x \\mapsto Mx$ 。当 $x$ 是一个标准基向量的时候，$Mx$对应矩阵 $M$ 中的一列，这就是对应 $id$ 的向量表示。</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/20170814220528829.jpg\" alt=\"连接层\"></p>\n<p>从id(索引)找到对应的 One-hot encoding ，然后红色的weight就直接对应了输出节点的值(注意这里没有 activation function)，也就是对应的embedding向量。</p>\n<h1 id=\"tensorflow-API\"><a href=\"#tensorflow-API\" class=\"headerlink\" title=\"tensorflow API\"></a>tensorflow API</h1><h2 id=\"基础：-tf-SparseTensor\"><a href=\"#基础：-tf-SparseTensor\" class=\"headerlink\" title=\"基础： tf.SparseTensor\"></a>基础： tf.SparseTensor</h2><p>构造稀疏向量矩阵，\b\b【未求证】\b使用上每一行为一个样本</p>\n<p>SparseTensor(indices, values, dense_shape)</p>\n<p>params:</p>\n<ul>\n<li>indices: A 2-D int64 tensor of dense_shape [N, ndims], which specifies the indices of the elements in the sparse tensor that contain nonzero values (elements are zero-indexed). For example, indices=[[1,3], [2,4]] specifies that the elements with indexes of [1,3] and [2,4] have nonzero values. 是dense_shape这个矩阵中所有values值的位置，与values一一对应。</li>\n<li>values: A 1-D tensor of any type and dense_shape [N], which supplies the values for each element in indices. For example, given indices=[[1,3], [2,4]], the parameter values=[18, 3.6] specifies that element [1,3] of the sparse tensor has a value of 18, and element [2,4] of the tensor has a value of 3.6. \b每一个稀疏值，与其位置indices\b一一对应。</li>\n<li>dense_shape: A 1-D int64 tensor of dense_shape [ndims], which specifies the dense_shape of the sparse tensor. Takes a list indicating the number of elements in each dimension. For example, dense_shape=[3,6] specifies a two-dimensional 3x6 tensor, dense_shape=[2,3,4] specifies a three-dimensional 2x3x4 tensor, and dense_shape=[9] specifies a one-dimensional tensor with 9 elements. 稀疏向量矩阵的shape</li>\n</ul>\n<p>Example: The sparse tensor</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SparseTensor(indices=[[<span class=\"number\">0</span>, <span class=\"number\">0</span>], [<span class=\"number\">1</span>, <span class=\"number\">2</span>]], values=[<span class=\"number\">1</span>, <span class=\"number\">2</span>], dense_shape=[<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># represents the dense tensor</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># [[1, 0, 0, 0]</span></span><br><span class=\"line\"><span class=\"comment\">#  [0, 0, 2, 0]</span></span><br><span class=\"line\"><span class=\"comment\">#  [0, 0, 0, 0]]</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"tf-nn-embedding-lookup-和-partition-strategy-参数\"><a href=\"#tf-nn-embedding-lookup-和-partition-strategy-参数\" class=\"headerlink\" title=\"tf.nn.embedding_lookup 和 partition_strategy 参数\"></a>tf.nn.embedding_lookup 和 partition_strategy 参数</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Signature:</span></span><br><span class=\"line\">tf.nn.embedding_lookup(params, ids, partition_strategy=<span class=\"string\">'mod'</span>, name=<span class=\"keyword\">None</span>, validate_indices=<span class=\"keyword\">True</span>, max_norm=<span class=\"keyword\">None</span>)</span><br><span class=\"line\"><span class=\"comment\"># Docstring:</span></span><br><span class=\"line\"><span class=\"comment\"># Looks up `ids` in a list of embedding tensors.</span></span><br></pre></td></tr></table></figure>\n<p>是根据 <code>ids</code> 中的id，寻找 <code>params</code> 中的第id行。比如 <code>ids=[1,3,5]</code>，则找出<code>params</code>中第1，3，5行，组成一个tensor返回。</p>\n<p>embedding_lookup不是简单的查表，<code>params</code> 对应的向量是可以训练的，训练参数个数应该是 feature_num * embedding_size，即前文表述的embedding层权重矩阵，就是说 lookup 的是一种全连接层。</p>\n<p>此外，以下要\b记录的几个API里，都有参数 partition_strategy （切分方式）, 这个参数是当len(params) &gt; 1 时，才生效\b，即当params 以list [a, b, c] (a,b,c都是tensor) 输入多个tensor时，对\bparams的选择顺序进行切分，（而不是对ids进行切分，ids只有选择的作用，当然也决定了在return中次序）。</p>\n<h3 id=\"输入为单个tensor时\"><a href=\"#输入为单个tensor时\" class=\"headerlink\" title=\"输入为单个tensor时\"></a>输入为单个tensor时</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 当\b输入单个tensor时，partition_strategy不起作用，不做\b id（编号） 的切分</span></span><br><span class=\"line\">a = np.arange(<span class=\"number\">20</span>).reshape(<span class=\"number\">5</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (a)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 前面的编号是我手动加的，意思是不做切分的时候就顺序编号就行</span></span><br><span class=\"line\"><span class=\"comment\"># 0#[[ 0  1  2  3]</span></span><br><span class=\"line\"><span class=\"comment\"># 1# [ 4  5  6  7]</span></span><br><span class=\"line\"><span class=\"comment\"># 2# [ 8  9 10 11]</span></span><br><span class=\"line\"><span class=\"comment\"># 3# [12 13 14 15]</span></span><br><span class=\"line\"><span class=\"comment\"># 4# [16 17 18 19]]</span></span><br><span class=\"line\"></span><br><span class=\"line\">tensor_a = tf.Variable(a)</span><br><span class=\"line\">embedded_tensor = tf.nn.embedding_lookup(params=tensor_a, ids=[<span class=\"number\">0</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\">init = tf.global_variables_initializer()</span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    sess.run(init)</span><br><span class=\"line\">    embedded_tensor = sess.run(embedded_tensor)</span><br><span class=\"line\">    print(embedded_tensor)</span><br><span class=\"line\"><span class=\"comment\"># 根据 ids 参数做选择</span></span><br><span class=\"line\"><span class=\"comment\">#[[ 0  1  2  3]  选择了 id 0</span></span><br><span class=\"line\"><span class=\"comment\"># [12 13 14 15]  选择了 id 3</span></span><br><span class=\"line\"><span class=\"comment\"># [ 8  9 10 11]  选择了 id 2</span></span><br><span class=\"line\"><span class=\"comment\"># [ 4  5  6  7]] 选择了 id 1</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"输入为多个tensor时\"><a href=\"#输入为多个tensor时\" class=\"headerlink\" title=\"输入为多个tensor时\"></a>输入为多个tensor时</h3><p>partition_strategy 开始起作用，开始对多个tensor 的第 0 维上的项进行编号，编号的方式有两种，”mod”（默认） 和 “div”。</p>\n<p>假设：一共有三个tensor [a,b,c] 作为params 参数，所有<code>tensor</code>的第 0 维上一共有 10 个项目（id 0 ~ 9）。</p>\n<ul>\n<li><p>“mod” : (id) mod len(params) 得到\b多少就把 id 分到第几个tensor里面</p>\n<ul>\n<li>a 依次分到id： 0 3 6 9</li>\n<li>b 依次分到id： 1 4 7</li>\n<li>c 依次分到id： 2 5 8</li>\n</ul>\n</li>\n<li><p>“div” : (id) div len(params) 可以理解为依次排序，但是这两种切分方式在无法均匀切分的情况下都是将前(max_id+1)%len(params)个 partition 多分配一个元素.</p>\n<ul>\n<li>a 依次分到id： 0 1 2 3 </li>\n<li>b 依次分到id： 4 5 6</li>\n<li>c 依次分到id： 7 8 9</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># partition_strategy='div' 的情况</span></span><br><span class=\"line\">a = tf.Variable(np.arange(<span class=\"number\">8</span>).reshape(<span class=\"number\">2</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">b = tf.Variable(np.arange(<span class=\"number\">8</span>,<span class=\"number\">12</span>).reshape(<span class=\"number\">1</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">c = tf.Variable(np.arange(<span class=\"number\">12</span>, <span class=\"number\">20</span>).reshape(<span class=\"number\">2</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">embedded_tensor = tf.nn.embedding_lookup(params=[a,b,c], ids=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">4</span>], partition_strategy=<span class=\"string\">'div'</span>, name=<span class=\"string\">\"embedding\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">init = tf.global_variables_initializer()</span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    sess.run(init)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> (sess.run(a))</span><br><span class=\"line\">    <span class=\"keyword\">print</span> (sess.run(b))</span><br><span class=\"line\">    <span class=\"keyword\">print</span> (sess.run(c))</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">print</span> (<span class=\"string\">\"########## embedded_tensor #########\"</span>)</span><br><span class=\"line\">    print(sess.run(embedded_tensor))</span><br><span class=\"line\"><span class=\"comment\"># [[0 1 2 3]    a\b分到 id 0</span></span><br><span class=\"line\"><span class=\"comment\">#  [4 5 6 7]]   a分到 id 1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># [[ 8  9 10 11]] b分到 id 2</span></span><br><span class=\"line\"><span class=\"comment\">#                 b分到 id 3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># [[12 13 14 15]  c分到 id 4</span></span><br><span class=\"line\"><span class=\"comment\">#  [16 17 18 19]] (c 没分到id)</span></span><br><span class=\"line\"><span class=\"comment\"># ########## embedded_tensor ######### 注：ids=[1,2,4]</span></span><br><span class=\"line\"><span class=\"comment\">#[[ 4  5  6  7]   \b按 ids 选的 1</span></span><br><span class=\"line\"><span class=\"comment\"># [ 8  9 10 11]   按 ids 选的 2</span></span><br><span class=\"line\"><span class=\"comment\"># [12 13 14 15]]  按 ids 选的 4</span></span><br></pre></td></tr></table></figure>\n<p>注：如果ids 中 有 3，\b这个id 虽然被分给 b 这个tensor了，但是b没有，会报一个错误<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">InvalidArgumentError: indices[<span class=\"number\">0</span>] = <span class=\"number\">1</span> <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> [<span class=\"number\">0</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t [[Node: embedding_5/GatherV2_1 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_INT64, _device=<span class=\"string\">\"/job:localhost/replica:0/task:0/device:CPU:0\"</span>](Variable_154/read, ConstantFolding/embedding_5/DynamicPartition-folded<span class=\"number\">-1</span>, embedding_5/GatherV2_1/axis)]]</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"tf-gather\"><a href=\"#tf-gather\" class=\"headerlink\" title=\"tf.gather()\"></a>tf.gather()</h2><p>函数签名如下：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.gather(</span><br><span class=\"line\">    params,</span><br><span class=\"line\">    indices,</span><br><span class=\"line\">    validate_indices=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">    name=<span class=\"keyword\">None</span></span><br></pre></td></tr></table></figure></p>\n<p>参数说明：</p>\n<ul>\n<li>params是一个tensor，</li>\n<li>indices是个值为int的tensor用来指定要从params取得元素的第0维的index。</li>\n</ul>\n<p>该函数可看成是tf.nn.embedding_lookup()的特殊形式，所以功能与其类似，即将其看成是embedding_lookup函数的params参数内只有一个tensor时的情形。</p>\n<h2 id=\"tf-nn-embedding-lookup-sparse\"><a href=\"#tf-nn-embedding-lookup-sparse\" class=\"headerlink\" title=\"tf.nn.embedding_lookup_sparse\"></a>tf.nn.embedding_lookup_sparse</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.nn.embedding_lookup_sparse(</span><br><span class=\"line\">    params,</span><br><span class=\"line\">    sp_ids,</span><br><span class=\"line\">    sp_weights,</span><br><span class=\"line\">    partition_strategy=<span class=\"string\">'mod'</span>,</span><br><span class=\"line\">    name=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">    combiner=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">    max_norm=<span class=\"keyword\">None</span></span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<h3 id=\"参数\"><a href=\"#参数\" class=\"headerlink\" title=\"参数\"></a>参数</h3><p>见官网\bAPI，不贴了：<a href=\"https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse\" target=\"_blank\" rel=\"noopener\">python API</a></p>\n<ul>\n<li>params: A single tensor representing the complete embedding tensor, or a list of P tensors all of same shape except for the first dimension, representing sharded embedding tensors. Alternatively, a PartitionedVariable, created by partitioning along dimension 0. Each element must be appropriately sized for the given partition_strategy.</li>\n</ul>\n<p>Returns:<br>A dense tensor representing the combined embeddings for the sparse ids. For each row in the dense tensor represented by sp_ids, the op looks up the embeddings for all ids in that row, multiplies them by the corresponding weight, and combines these embeddings as specified.</p>\n<p>In other words, if</p>\n<ul>\n<li>shape(combined params) = [p0, p1, …, pm]</li>\n</ul>\n<p>and</p>\n<ul>\n<li>shape(sp_ids) = shape(sp_weights) = [d0, d1, …, dn]</li>\n</ul>\n<p>then</p>\n<ul>\n<li>shape(output) = [d0, d1, …, dn-1, p1, …, pm].</li>\n</ul>\n<p>For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are</p>\n<p>[0, 0]: id 1, weight 2.0 [0, 1]: id 3, weight 0.5 [1, 0]: id 0, weight 1.0 [2, 3]: id 1, weight 3.0</p>\n<p>with combiner=”mean”, then the output will be a 3x20 matrix where</p>\n<p>output[0, :] = (params[1, :] <em> 2.0 + params[3, :] </em> 0.5) / (2.0 + 0.5) output[1, :] = (params[0, :] <em> 1.0) / 1.0 output[2, :] = (params[1, :] </em> 3.0) / 3.0</p>\n<h3 id=\"示例：\"><a href=\"#示例：\" class=\"headerlink\" title=\"示例：\"></a>示例：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = np.arange(<span class=\"number\">8</span>).reshape(<span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">b = np.arange(<span class=\"number\">8</span>, <span class=\"number\">16</span>).reshape(<span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">c = np.arange(<span class=\"number\">12</span>, <span class=\"number\">20</span>).reshape(<span class=\"number\">2</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"a :\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (a)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"b :\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (b)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"c :\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">print</span> (c)</span><br><span class=\"line\">a = tf.Variable(a, dtype=tf.float32)</span><br><span class=\"line\">b = tf.Variable(b, dtype=tf.float32)</span><br><span class=\"line\">c = tf.Variable(c, dtype=tf.float32)</span><br><span class=\"line\">idx = tf.SparseTensor(indices=[[<span class=\"number\">0</span>,<span class=\"number\">0</span>], [<span class=\"number\">0</span>,<span class=\"number\">2</span>], [<span class=\"number\">1</span>,<span class=\"number\">0</span>], [<span class=\"number\">1</span>, <span class=\"number\">1</span>]], values=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">0</span>], dense_shape=(<span class=\"number\">2</span>,<span class=\"number\">3</span>))</span><br><span class=\"line\">result = tf.nn.embedding_lookup_sparse([a,c,b], idx, <span class=\"keyword\">None</span>, partition_strategy=<span class=\"string\">'mod'</span>, combiner=<span class=\"string\">\"sum\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">init = tf.global_variables_initializer()</span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    sess.run(init)</span><br><span class=\"line\">    res = sess.run(result)</span><br><span class=\"line\">    <span class=\"keyword\">print</span> (<span class=\"string\">\"\\n# result here\"</span>)</span><br><span class=\"line\">    print(res)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># a :</span></span><br><span class=\"line\"><span class=\"comment\"># [[0 1 2 3]    id 0</span></span><br><span class=\"line\"><span class=\"comment\">#  [4 5 6 7]]   id 3</span></span><br><span class=\"line\"><span class=\"comment\"># b :</span></span><br><span class=\"line\"><span class=\"comment\"># [[ 8  9 10 11]  id 1</span></span><br><span class=\"line\"><span class=\"comment\">#  [12 13 14 15]] id 4</span></span><br><span class=\"line\"><span class=\"comment\"># c :</span></span><br><span class=\"line\"><span class=\"comment\"># [[16 17 18 19] id 2</span></span><br><span class=\"line\"><span class=\"comment\">#  [20 21 22 23]] id 5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># result here</span></span><br><span class=\"line\"><span class=\"comment\"># [[24. 26. 28. 30.]  </span></span><br><span class=\"line\"><span class=\"comment\">#  [16. 18. 20. 22.]]</span></span><br></pre></td></tr></table></figure>\n<p>解释：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#idx = tf.SparseTensor(indices=[[0,0], [0,2], [1,0], [1, 1]], values=[1,2,2,0], dense_shape=(2,3))</span></span><br><span class=\"line\">构造如下稀疏向量矩阵，每一行视为一个样本的特征向量</span><br><span class=\"line\">[</span><br><span class=\"line\">    [[<span class=\"number\">1</span>], [], [<span class=\"number\">2</span>]],</span><br><span class=\"line\">    [[<span class=\"number\">2</span>], [<span class=\"number\">0</span>], []]</span><br><span class=\"line\">]</span><br><span class=\"line\">以第一个样本 [[<span class=\"number\">1</span>], [], [<span class=\"number\">2</span>]] 为例：选择id <span class=\"number\">1</span> 和id <span class=\"number\">2</span>：</span><br><span class=\"line\"><span class=\"comment\"># [[ 8  9 10 11]  id 1</span></span><br><span class=\"line\"><span class=\"comment\"># [[16 17 18 19] id 2</span></span><br><span class=\"line\">根据 combiner=<span class=\"string\">\"sum\"</span> ，把上面两个向量 按 axis=<span class=\"number\">0</span> 加到一起，得到：</span><br><span class=\"line\"><span class=\"comment\"># [24. 26. 28. 30.]</span></span><br><span class=\"line\">即 为第一个样本的 dense 向量</span><br></pre></td></tr></table></figure></p>\n<p>如果len(params) == 1, 就是不存在 partition 了，比较好理解，不再赘述。</p>\n<p>喝最烈的果粒橙，钻最深的牛角尖。<br>end.</p>\n"},{"title":"vscode 快捷键 MAC版","date":"2018-06-13T15:49:14.000Z","_content":"\n# 常用 General\n\n| 按 Press             | 功能 Function |\n| -------------------- | ------------- |\n| command + Shift + P，F1 | 显示命令面板  |\n| command + P             | 快速打开      |\n| command + Shift + N     | 新窗口/实例   |\n| command + Shift + W     | 关闭窗口/实例 |\n\n#基础编辑 Basic editing\n\n| 按 Press          | 功能 Function            |\n| ----------------- | ------------------------ |\n| Ctrl+X            | 剪切行（空选定）         |\n| Ctrl+C            | 复制行（空选定）         |\n| Alt+ ↑ / ↓        | 向上/向下移动行          |\n| Shift+Alt + ↓ / ↑ | 向上/向下复制行          |\n| Ctrl+Shift+K      | 删除行                   |\n| Ctrl+Enter        | 在下面插入行             |\n| Ctrl+Shift+Enter  | 在上面插入行             |\n| Ctrl+Shift+\\      | 跳到匹配的括号           |\n| Ctrl+] / [        | 缩进/缩进行              |\n| Home              | 转到行首                 |\n| End               | 转到行尾                 |\n| Ctrl+Home         | 转到文件开头             |\n| Ctrl+End          | 转到文件末尾             |\n| Ctrl+↑ / ↓        | 向上/向下滚动行          |\n| Alt+PgUp / PgDown | 向上/向下滚动页面        |\n| Ctrl+Shift+[      | 折叠（折叠）区域         |\n| Ctrl+Shift+]      | 展开（未折叠）区域       |\n| Ctrl+K Ctrl+[     | 折叠（未折叠）所有子区域 |\n| Ctrl+K Ctrl+]     | 展开（未折叠）所有子区域 |\n| Ctrl+K Ctrl+0     | 折叠（折叠）所有区域     |\n| Ctrl+K Ctrl+J     | 展开（未折叠）所有区域   |\n| Ctrl+K Ctrl+C     | 添加行注释               |\n| Ctrl+K Ctrl+U     | 删除行注释               |\n| Ctrl+/            | 切换行注释               |\n| Shift+Alt+A       | 切换块注释               |\n| Alt+Z             | 切换换行                 |\n\n# 导航 \n\n| 按 Press           | 功能 Function        |\n| ------------------ | -------------------- |\n| Ctrl + T           | 显示所有符号         |\n| Ctrl + G           | 转到行...            |\n| Ctrl + P           | 转到文件...          |\n| Ctrl + Shift + O   | 转到符号...          |\n| Ctrl + Shift + M   | 显示问题面板         |\n| F8                 | 转到下一个错误或警告 |\n| Shift + F8         | 转到上一个错误或警告 |\n| Ctrl + Shift + Tab | 导航编辑器组历史记录 |\nAlt + ←/→\t返回/前进 Go back / forward\nCtrl + M\t切换选项卡移动焦点 Toggle Tab moves focus\n\n# 搜索和替换 Search and replace\n\n| 按 Press          | 功能 Function                      |\n| ----------------- | ---------------------------------- |\n| Ctrl + F          | 查找                               |\n| Ctrl + H          | 替换                               |\n| F3 / Shift + F3   | 查找下一个/上一个                  |\n| Alt + Enter       | 选择查找匹配的所有出现             |\n| Ctrl + D          | 将选择添加到下一个查找匹配         |\n| Ctrl + K Ctrl + D | 将最后一个选择移至下一个查找匹配项 |\n| Alt + C / R / W   | 切换区分大小写/正则表达式/整个词   |\n\n# 多光标和选择 Multi-cursor and selection\n| 按 Press                           | 功能                         |\n| ---------------------------------- | ---------------------------- |\n| Alt +单击                          | 插入光标                     |\n| Ctrl + Alt +↑/↓                    | 在上/下插入光标              |\n| Ctrl + U                           | 撤消上一个光标操作           |\n| Shift + Alt + I                    | 在选定的每一行的末尾插入光标 |\n| Ctrl + I                           | 选择当前行                   |\n| Ctrl + Shift + L                   | 选择当前选择的所有出现       |\n| Ctrl + F2                          | 选择当前字的所有出现         |\n| Shift + Alt + →                    | 展开选择                     |\n| Shift + Alt + ←                    | 缩小选择                     |\n| Shift + Alt + （拖动鼠标）         | 列（框）选择                 |\n| Ctrl + Shift + Alt +（箭头键）     | 列（框）选择                 |\n| Ctrl + Shift + Alt + PgUp / PgDown | 列（框）选择页上/下          |\n\n# 丰富的语言编辑 \n\n| 按 Press             | 功能 Function         |\n| -------------------- | --------------------- |\n| Ctrl + 空格          | 触发建议              |\n| Ctrl + Shift + Space | 触发器参数提示        |\n| Tab\tEmmet            | 展开缩写              |\n| Shift + Alt + F      | 格式化文档            |\n| Ctrl + K Ctrl + F    | 格式选定区域          |\n| F12                  | 转到定义              |\n| Alt + F12            | Peek定义              |\n| Ctrl + K F12         | 打开定义到边          |\n| Ctrl + .             | 快速解决              |\n| Shift + F12          | 显示引用              |\n| F2                   | 重命名符号            |\n| Ctrl + Shift + . /， | 替换为下一个/上一个值 |\n| Ctrl + K Ctrl + X    | 修剪尾随空格          |\n| Ctrl + K M           | 更改文件语言          |\n\n# 编辑器管理 Editor management\n\n| 按 Press                 | 功能 Function               |\n| ------------------------ | --------------------------- |\n| Ctrl+F4, Ctrl+W          | 关闭编辑器                  |\n| Ctrl+K F                 | 关闭文件夹                  |\n| Ctrl+\\|\t拆分编辑器       |\n| Ctrl+ 1 / 2 / 3          | 聚焦到第1，第2或第3编辑器组 |\n| Ctrl+K Ctrl+ ←/→         | 聚焦到上一个/下一个编辑器组 |\n| Ctrl+Shift+PgUp / PgDown | 向左/向右移动编辑器         |\n| Ctrl+K ← / →             | 移动活动编辑器组            |\n\n# 文件管理 File management\n\n| 按 Press       | 功能 Function                                |\n| -------------- | -------------------------------------------- |\n| Ctrl+N         | 新文件                                       |\n| Ctrl+O         | 打开文件...                                  |\n| Ctrl+S         | 保存                                         |\n| Ctrl+Shift+S   | 另存为...                                    |\n| Ctrl+K S       | 全部保存                                     |\n| Ctrl+F4        | 关闭                                         |\n| Ctrl+K Ctrl+W  | 关闭所有                                     |\n| Ctrl+Shift+T   | 重新打开关闭的编辑器                         |\n| Ctrl+K         | 输入保持打开                                 |\n| Ctrl+Tab       | 打开下一个                                   |\n| Ctrl+Shift+Tab | 打开上一个                                   |\n| Ctrl+K P       | 复制活动文件的路径                           |\n| Ctrl+K R       | 显示资源管理器中的活动文件                   |\n| Ctrl+K O       | 显示新窗口/实例中的活动文件   |\n\n# 显示 Display\n\n| 按 Press     | 功能 Function          |\n| ------------ | ---------------------- |\n| F11          | 切换全屏               |\n| Shift+Alt+1  | 切换编辑器布局         |\n| Ctrl+ = / -  | 放大/缩小              |n\n| Ctrl+B       | 切换侧栏可见性         |\n| Ctrl+Shift+E | 显示浏览器/切换焦点    |\n| Ctrl+Shift+F | 显示搜索               |\n| Ctrl+Shift+G | 显示Git                |\n| Ctrl+Shift+D | 显示调试               |\n| Ctrl+Shift+X | 显示扩展               |\n| Ctrl+Shift+H | 替换文件               |\n| Ctrl+Shift+J | 切换搜索详细信息       |\n| Ctrl+Shift+C | 打开新命令提示符/终端  |\n| Ctrl+Shift+U | 显示输出面板           |\n| Ctrl+Shift+V | 切换Markdown预览       |\n| Ctrl+K V     | 从旁边打开Markdown预览 |\n\n# 调试 Debug\n\n| 按 Press        | 功能 Function |\n| --------------- | ------------- |\n| F9              | 切换断点      |\n| F5              | 开始/继续     |\n| Shift+F5        | 停止          |\n| F11 / Shift+F11 | 下一步/上一步 |\n| F10             | 跳过          |\n| Ctrl+K Ctrl+I   | 显示悬停      |\n\n# 集成终端 Integrated terminal\n| 按 Press            | 功能 Function     |\n| ------------------- | ----------------- |\n| Ctrl+`              | 显示集成终端      |\n| Ctrl+Shift+`        | 创建新终端        |\n| Ctrl+Shift+C        | 复制选定          |\n| Ctrl+Shift+V        | 粘贴到活动端子    |\n| Ctrl+↑ / ↓          | 向上/向下滚动     |\n| Shift+PgUp / PgDown | 向上/向下滚动页面 |\n| Ctrl+Home / End     | 滚动到顶部/底部   |\n","source":"_posts/201806-vscode-shortcuts.md","raw":"---\ntitle: vscode 快捷键 MAC版 \ndate: 2018-06-13 23:49:14\ntags: vscode shortcut mac os\n---\n\n# 常用 General\n\n| 按 Press             | 功能 Function |\n| -------------------- | ------------- |\n| command + Shift + P，F1 | 显示命令面板  |\n| command + P             | 快速打开      |\n| command + Shift + N     | 新窗口/实例   |\n| command + Shift + W     | 关闭窗口/实例 |\n\n#基础编辑 Basic editing\n\n| 按 Press          | 功能 Function            |\n| ----------------- | ------------------------ |\n| Ctrl+X            | 剪切行（空选定）         |\n| Ctrl+C            | 复制行（空选定）         |\n| Alt+ ↑ / ↓        | 向上/向下移动行          |\n| Shift+Alt + ↓ / ↑ | 向上/向下复制行          |\n| Ctrl+Shift+K      | 删除行                   |\n| Ctrl+Enter        | 在下面插入行             |\n| Ctrl+Shift+Enter  | 在上面插入行             |\n| Ctrl+Shift+\\      | 跳到匹配的括号           |\n| Ctrl+] / [        | 缩进/缩进行              |\n| Home              | 转到行首                 |\n| End               | 转到行尾                 |\n| Ctrl+Home         | 转到文件开头             |\n| Ctrl+End          | 转到文件末尾             |\n| Ctrl+↑ / ↓        | 向上/向下滚动行          |\n| Alt+PgUp / PgDown | 向上/向下滚动页面        |\n| Ctrl+Shift+[      | 折叠（折叠）区域         |\n| Ctrl+Shift+]      | 展开（未折叠）区域       |\n| Ctrl+K Ctrl+[     | 折叠（未折叠）所有子区域 |\n| Ctrl+K Ctrl+]     | 展开（未折叠）所有子区域 |\n| Ctrl+K Ctrl+0     | 折叠（折叠）所有区域     |\n| Ctrl+K Ctrl+J     | 展开（未折叠）所有区域   |\n| Ctrl+K Ctrl+C     | 添加行注释               |\n| Ctrl+K Ctrl+U     | 删除行注释               |\n| Ctrl+/            | 切换行注释               |\n| Shift+Alt+A       | 切换块注释               |\n| Alt+Z             | 切换换行                 |\n\n# 导航 \n\n| 按 Press           | 功能 Function        |\n| ------------------ | -------------------- |\n| Ctrl + T           | 显示所有符号         |\n| Ctrl + G           | 转到行...            |\n| Ctrl + P           | 转到文件...          |\n| Ctrl + Shift + O   | 转到符号...          |\n| Ctrl + Shift + M   | 显示问题面板         |\n| F8                 | 转到下一个错误或警告 |\n| Shift + F8         | 转到上一个错误或警告 |\n| Ctrl + Shift + Tab | 导航编辑器组历史记录 |\nAlt + ←/→\t返回/前进 Go back / forward\nCtrl + M\t切换选项卡移动焦点 Toggle Tab moves focus\n\n# 搜索和替换 Search and replace\n\n| 按 Press          | 功能 Function                      |\n| ----------------- | ---------------------------------- |\n| Ctrl + F          | 查找                               |\n| Ctrl + H          | 替换                               |\n| F3 / Shift + F3   | 查找下一个/上一个                  |\n| Alt + Enter       | 选择查找匹配的所有出现             |\n| Ctrl + D          | 将选择添加到下一个查找匹配         |\n| Ctrl + K Ctrl + D | 将最后一个选择移至下一个查找匹配项 |\n| Alt + C / R / W   | 切换区分大小写/正则表达式/整个词   |\n\n# 多光标和选择 Multi-cursor and selection\n| 按 Press                           | 功能                         |\n| ---------------------------------- | ---------------------------- |\n| Alt +单击                          | 插入光标                     |\n| Ctrl + Alt +↑/↓                    | 在上/下插入光标              |\n| Ctrl + U                           | 撤消上一个光标操作           |\n| Shift + Alt + I                    | 在选定的每一行的末尾插入光标 |\n| Ctrl + I                           | 选择当前行                   |\n| Ctrl + Shift + L                   | 选择当前选择的所有出现       |\n| Ctrl + F2                          | 选择当前字的所有出现         |\n| Shift + Alt + →                    | 展开选择                     |\n| Shift + Alt + ←                    | 缩小选择                     |\n| Shift + Alt + （拖动鼠标）         | 列（框）选择                 |\n| Ctrl + Shift + Alt +（箭头键）     | 列（框）选择                 |\n| Ctrl + Shift + Alt + PgUp / PgDown | 列（框）选择页上/下          |\n\n# 丰富的语言编辑 \n\n| 按 Press             | 功能 Function         |\n| -------------------- | --------------------- |\n| Ctrl + 空格          | 触发建议              |\n| Ctrl + Shift + Space | 触发器参数提示        |\n| Tab\tEmmet            | 展开缩写              |\n| Shift + Alt + F      | 格式化文档            |\n| Ctrl + K Ctrl + F    | 格式选定区域          |\n| F12                  | 转到定义              |\n| Alt + F12            | Peek定义              |\n| Ctrl + K F12         | 打开定义到边          |\n| Ctrl + .             | 快速解决              |\n| Shift + F12          | 显示引用              |\n| F2                   | 重命名符号            |\n| Ctrl + Shift + . /， | 替换为下一个/上一个值 |\n| Ctrl + K Ctrl + X    | 修剪尾随空格          |\n| Ctrl + K M           | 更改文件语言          |\n\n# 编辑器管理 Editor management\n\n| 按 Press                 | 功能 Function               |\n| ------------------------ | --------------------------- |\n| Ctrl+F4, Ctrl+W          | 关闭编辑器                  |\n| Ctrl+K F                 | 关闭文件夹                  |\n| Ctrl+\\|\t拆分编辑器       |\n| Ctrl+ 1 / 2 / 3          | 聚焦到第1，第2或第3编辑器组 |\n| Ctrl+K Ctrl+ ←/→         | 聚焦到上一个/下一个编辑器组 |\n| Ctrl+Shift+PgUp / PgDown | 向左/向右移动编辑器         |\n| Ctrl+K ← / →             | 移动活动编辑器组            |\n\n# 文件管理 File management\n\n| 按 Press       | 功能 Function                                |\n| -------------- | -------------------------------------------- |\n| Ctrl+N         | 新文件                                       |\n| Ctrl+O         | 打开文件...                                  |\n| Ctrl+S         | 保存                                         |\n| Ctrl+Shift+S   | 另存为...                                    |\n| Ctrl+K S       | 全部保存                                     |\n| Ctrl+F4        | 关闭                                         |\n| Ctrl+K Ctrl+W  | 关闭所有                                     |\n| Ctrl+Shift+T   | 重新打开关闭的编辑器                         |\n| Ctrl+K         | 输入保持打开                                 |\n| Ctrl+Tab       | 打开下一个                                   |\n| Ctrl+Shift+Tab | 打开上一个                                   |\n| Ctrl+K P       | 复制活动文件的路径                           |\n| Ctrl+K R       | 显示资源管理器中的活动文件                   |\n| Ctrl+K O       | 显示新窗口/实例中的活动文件   |\n\n# 显示 Display\n\n| 按 Press     | 功能 Function          |\n| ------------ | ---------------------- |\n| F11          | 切换全屏               |\n| Shift+Alt+1  | 切换编辑器布局         |\n| Ctrl+ = / -  | 放大/缩小              |n\n| Ctrl+B       | 切换侧栏可见性         |\n| Ctrl+Shift+E | 显示浏览器/切换焦点    |\n| Ctrl+Shift+F | 显示搜索               |\n| Ctrl+Shift+G | 显示Git                |\n| Ctrl+Shift+D | 显示调试               |\n| Ctrl+Shift+X | 显示扩展               |\n| Ctrl+Shift+H | 替换文件               |\n| Ctrl+Shift+J | 切换搜索详细信息       |\n| Ctrl+Shift+C | 打开新命令提示符/终端  |\n| Ctrl+Shift+U | 显示输出面板           |\n| Ctrl+Shift+V | 切换Markdown预览       |\n| Ctrl+K V     | 从旁边打开Markdown预览 |\n\n# 调试 Debug\n\n| 按 Press        | 功能 Function |\n| --------------- | ------------- |\n| F9              | 切换断点      |\n| F5              | 开始/继续     |\n| Shift+F5        | 停止          |\n| F11 / Shift+F11 | 下一步/上一步 |\n| F10             | 跳过          |\n| Ctrl+K Ctrl+I   | 显示悬停      |\n\n# 集成终端 Integrated terminal\n| 按 Press            | 功能 Function     |\n| ------------------- | ----------------- |\n| Ctrl+`              | 显示集成终端      |\n| Ctrl+Shift+`        | 创建新终端        |\n| Ctrl+Shift+C        | 复制选定          |\n| Ctrl+Shift+V        | 粘贴到活动端子    |\n| Ctrl+↑ / ↓          | 向上/向下滚动     |\n| Shift+PgUp / PgDown | 向上/向下滚动页面 |\n| Ctrl+Home / End     | 滚动到顶部/底部   |\n","slug":"vscode-shortcuts","published":1,"updated":"2018-06-13T16:13:41.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xt000un61dz8nkl94x","content":"<h1 id=\"常用-General\"><a href=\"#常用-General\" class=\"headerlink\" title=\"常用 General\"></a>常用 General</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>command + Shift + P，F1</td>\n<td>显示命令面板</td>\n</tr>\n<tr>\n<td>command + P</td>\n<td>快速打开</td>\n</tr>\n<tr>\n<td>command + Shift + N</td>\n<td>新窗口/实例</td>\n</tr>\n<tr>\n<td>command + Shift + W</td>\n<td>关闭窗口/实例</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"基础编辑-Basic-editing\"><a href=\"#基础编辑-Basic-editing\" class=\"headerlink\" title=\"基础编辑 Basic editing\"></a>基础编辑 Basic editing</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+X</td>\n<td>剪切行（空选定）</td>\n</tr>\n<tr>\n<td>Ctrl+C</td>\n<td>复制行（空选定）</td>\n</tr>\n<tr>\n<td>Alt+ ↑ / ↓</td>\n<td>向上/向下移动行</td>\n</tr>\n<tr>\n<td>Shift+Alt + ↓ / ↑</td>\n<td>向上/向下复制行</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+K</td>\n<td>删除行</td>\n</tr>\n<tr>\n<td>Ctrl+Enter</td>\n<td>在下面插入行</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+Enter</td>\n<td>在上面插入行</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+\\</td>\n<td>跳到匹配的括号</td>\n</tr>\n<tr>\n<td>Ctrl+] / [</td>\n<td>缩进/缩进行</td>\n</tr>\n<tr>\n<td>Home</td>\n<td>转到行首</td>\n</tr>\n<tr>\n<td>End</td>\n<td>转到行尾</td>\n</tr>\n<tr>\n<td>Ctrl+Home</td>\n<td>转到文件开头</td>\n</tr>\n<tr>\n<td>Ctrl+End</td>\n<td>转到文件末尾</td>\n</tr>\n<tr>\n<td>Ctrl+↑ / ↓</td>\n<td>向上/向下滚动行</td>\n</tr>\n<tr>\n<td>Alt+PgUp / PgDown</td>\n<td>向上/向下滚动页面</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+[</td>\n<td>折叠（折叠）区域</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+]</td>\n<td>展开（未折叠）区域</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+[</td>\n<td>折叠（未折叠）所有子区域</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+]</td>\n<td>展开（未折叠）所有子区域</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+0</td>\n<td>折叠（折叠）所有区域</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+J</td>\n<td>展开（未折叠）所有区域</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+C</td>\n<td>添加行注释</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+U</td>\n<td>删除行注释</td>\n</tr>\n<tr>\n<td>Ctrl+/</td>\n<td>切换行注释</td>\n</tr>\n<tr>\n<td>Shift+Alt+A</td>\n<td>切换块注释</td>\n</tr>\n<tr>\n<td>Alt+Z</td>\n<td>切换换行</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"导航\"><a href=\"#导航\" class=\"headerlink\" title=\"导航\"></a>导航</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl + T</td>\n<td>显示所有符号</td>\n</tr>\n<tr>\n<td>Ctrl + G</td>\n<td>转到行…</td>\n</tr>\n<tr>\n<td>Ctrl + P</td>\n<td>转到文件…</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + O</td>\n<td>转到符号…</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + M</td>\n<td>显示问题面板</td>\n</tr>\n<tr>\n<td>F8</td>\n<td>转到下一个错误或警告</td>\n</tr>\n<tr>\n<td>Shift + F8</td>\n<td>转到上一个错误或警告</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + Tab</td>\n<td>导航编辑器组历史记录</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>Alt + ←/→    返回/前进 Go back / forward<br>Ctrl + M    切换选项卡移动焦点 Toggle Tab moves focus</p>\n<h1 id=\"搜索和替换-Search-and-replace\"><a href=\"#搜索和替换-Search-and-replace\" class=\"headerlink\" title=\"搜索和替换 Search and replace\"></a>搜索和替换 Search and replace</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl + F</td>\n<td>查找</td>\n</tr>\n<tr>\n<td>Ctrl + H</td>\n<td>替换</td>\n</tr>\n<tr>\n<td>F3 / Shift + F3</td>\n<td>查找下一个/上一个</td>\n</tr>\n<tr>\n<td>Alt + Enter</td>\n<td>选择查找匹配的所有出现</td>\n</tr>\n<tr>\n<td>Ctrl + D</td>\n<td>将选择添加到下一个查找匹配</td>\n</tr>\n<tr>\n<td>Ctrl + K Ctrl + D</td>\n<td>将最后一个选择移至下一个查找匹配项</td>\n</tr>\n<tr>\n<td>Alt + C / R / W</td>\n<td>切换区分大小写/正则表达式/整个词</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"多光标和选择-Multi-cursor-and-selection\"><a href=\"#多光标和选择-Multi-cursor-and-selection\" class=\"headerlink\" title=\"多光标和选择 Multi-cursor and selection\"></a>多光标和选择 Multi-cursor and selection</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Alt +单击</td>\n<td>插入光标</td>\n</tr>\n<tr>\n<td>Ctrl + Alt +↑/↓</td>\n<td>在上/下插入光标</td>\n</tr>\n<tr>\n<td>Ctrl + U</td>\n<td>撤消上一个光标操作</td>\n</tr>\n<tr>\n<td>Shift + Alt + I</td>\n<td>在选定的每一行的末尾插入光标</td>\n</tr>\n<tr>\n<td>Ctrl + I</td>\n<td>选择当前行</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + L</td>\n<td>选择当前选择的所有出现</td>\n</tr>\n<tr>\n<td>Ctrl + F2</td>\n<td>选择当前字的所有出现</td>\n</tr>\n<tr>\n<td>Shift + Alt + →</td>\n<td>展开选择</td>\n</tr>\n<tr>\n<td>Shift + Alt + ←</td>\n<td>缩小选择</td>\n</tr>\n<tr>\n<td>Shift + Alt + （拖动鼠标）</td>\n<td>列（框）选择</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + Alt +（箭头键）</td>\n<td>列（框）选择</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + Alt + PgUp / PgDown</td>\n<td>列（框）选择页上/下</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"丰富的语言编辑\"><a href=\"#丰富的语言编辑\" class=\"headerlink\" title=\"丰富的语言编辑\"></a>丰富的语言编辑</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl + 空格</td>\n<td>触发建议</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + Space</td>\n<td>触发器参数提示</td>\n</tr>\n<tr>\n<td>Tab    Emmet</td>\n<td>展开缩写</td>\n</tr>\n<tr>\n<td>Shift + Alt + F</td>\n<td>格式化文档</td>\n</tr>\n<tr>\n<td>Ctrl + K Ctrl + F</td>\n<td>格式选定区域</td>\n</tr>\n<tr>\n<td>F12</td>\n<td>转到定义</td>\n</tr>\n<tr>\n<td>Alt + F12</td>\n<td>Peek定义</td>\n</tr>\n<tr>\n<td>Ctrl + K F12</td>\n<td>打开定义到边</td>\n</tr>\n<tr>\n<td>Ctrl + .</td>\n<td>快速解决</td>\n</tr>\n<tr>\n<td>Shift + F12</td>\n<td>显示引用</td>\n</tr>\n<tr>\n<td>F2</td>\n<td>重命名符号</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + . /，</td>\n<td>替换为下一个/上一个值</td>\n</tr>\n<tr>\n<td>Ctrl + K Ctrl + X</td>\n<td>修剪尾随空格</td>\n</tr>\n<tr>\n<td>Ctrl + K M</td>\n<td>更改文件语言</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"编辑器管理-Editor-management\"><a href=\"#编辑器管理-Editor-management\" class=\"headerlink\" title=\"编辑器管理 Editor management\"></a>编辑器管理 Editor management</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+F4, Ctrl+W</td>\n<td>关闭编辑器</td>\n</tr>\n<tr>\n<td>Ctrl+K F</td>\n<td>关闭文件夹</td>\n</tr>\n<tr>\n<td>Ctrl+\\</td>\n<td>拆分编辑器</td>\n</tr>\n<tr>\n<td>Ctrl+ 1 / 2 / 3</td>\n<td>聚焦到第1，第2或第3编辑器组</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+ ←/→</td>\n<td>聚焦到上一个/下一个编辑器组</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+PgUp / PgDown</td>\n<td>向左/向右移动编辑器</td>\n</tr>\n<tr>\n<td>Ctrl+K ← / →</td>\n<td>移动活动编辑器组</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"文件管理-File-management\"><a href=\"#文件管理-File-management\" class=\"headerlink\" title=\"文件管理 File management\"></a>文件管理 File management</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+N</td>\n<td>新文件</td>\n</tr>\n<tr>\n<td>Ctrl+O</td>\n<td>打开文件…</td>\n</tr>\n<tr>\n<td>Ctrl+S</td>\n<td>保存</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+S</td>\n<td>另存为…</td>\n</tr>\n<tr>\n<td>Ctrl+K S</td>\n<td>全部保存</td>\n</tr>\n<tr>\n<td>Ctrl+F4</td>\n<td>关闭</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+W</td>\n<td>关闭所有</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+T</td>\n<td>重新打开关闭的编辑器</td>\n</tr>\n<tr>\n<td>Ctrl+K</td>\n<td>输入保持打开</td>\n</tr>\n<tr>\n<td>Ctrl+Tab</td>\n<td>打开下一个</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+Tab</td>\n<td>打开上一个</td>\n</tr>\n<tr>\n<td>Ctrl+K P</td>\n<td>复制活动文件的路径</td>\n</tr>\n<tr>\n<td>Ctrl+K R</td>\n<td>显示资源管理器中的活动文件</td>\n</tr>\n<tr>\n<td>Ctrl+K O</td>\n<td>显示新窗口/实例中的活动文件</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"显示-Display\"><a href=\"#显示-Display\" class=\"headerlink\" title=\"显示 Display\"></a>显示 Display</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>F11</td>\n<td>切换全屏</td>\n</tr>\n<tr>\n<td>Shift+Alt+1</td>\n<td>切换编辑器布局</td>\n</tr>\n<tr>\n<td>Ctrl+ = / -</td>\n<td>放大/缩小</td>\n<td>n</td>\n</tr>\n<tr>\n<td>Ctrl+B</td>\n<td>切换侧栏可见性</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+E</td>\n<td>显示浏览器/切换焦点</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+F</td>\n<td>显示搜索</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+G</td>\n<td>显示Git</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+D</td>\n<td>显示调试</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+X</td>\n<td>显示扩展</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+H</td>\n<td>替换文件</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+J</td>\n<td>切换搜索详细信息</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+C</td>\n<td>打开新命令提示符/终端</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+U</td>\n<td>显示输出面板</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+V</td>\n<td>切换Markdown预览</td>\n</tr>\n<tr>\n<td>Ctrl+K V</td>\n<td>从旁边打开Markdown预览</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"调试-Debug\"><a href=\"#调试-Debug\" class=\"headerlink\" title=\"调试 Debug\"></a>调试 Debug</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>F9</td>\n<td>切换断点</td>\n</tr>\n<tr>\n<td>F5</td>\n<td>开始/继续</td>\n</tr>\n<tr>\n<td>Shift+F5</td>\n<td>停止</td>\n</tr>\n<tr>\n<td>F11 / Shift+F11</td>\n<td>下一步/上一步</td>\n</tr>\n<tr>\n<td>F10</td>\n<td>跳过</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+I</td>\n<td>显示悬停</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"集成终端-Integrated-terminal\"><a href=\"#集成终端-Integrated-terminal\" class=\"headerlink\" title=\"集成终端 Integrated terminal\"></a>集成终端 Integrated terminal</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+`</td>\n<td>显示集成终端</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+`</td>\n<td>创建新终端</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+C</td>\n<td>复制选定</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+V</td>\n<td>粘贴到活动端子</td>\n</tr>\n<tr>\n<td>Ctrl+↑ / ↓</td>\n<td>向上/向下滚动</td>\n</tr>\n<tr>\n<td>Shift+PgUp / PgDown</td>\n<td>向上/向下滚动页面</td>\n</tr>\n<tr>\n<td>Ctrl+Home / End</td>\n<td>滚动到顶部/底部</td>\n</tr>\n</tbody>\n</table>\n</div>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"常用-General\"><a href=\"#常用-General\" class=\"headerlink\" title=\"常用 General\"></a>常用 General</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>command + Shift + P，F1</td>\n<td>显示命令面板</td>\n</tr>\n<tr>\n<td>command + P</td>\n<td>快速打开</td>\n</tr>\n<tr>\n<td>command + Shift + N</td>\n<td>新窗口/实例</td>\n</tr>\n<tr>\n<td>command + Shift + W</td>\n<td>关闭窗口/实例</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"基础编辑-Basic-editing\"><a href=\"#基础编辑-Basic-editing\" class=\"headerlink\" title=\"基础编辑 Basic editing\"></a>基础编辑 Basic editing</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+X</td>\n<td>剪切行（空选定）</td>\n</tr>\n<tr>\n<td>Ctrl+C</td>\n<td>复制行（空选定）</td>\n</tr>\n<tr>\n<td>Alt+ ↑ / ↓</td>\n<td>向上/向下移动行</td>\n</tr>\n<tr>\n<td>Shift+Alt + ↓ / ↑</td>\n<td>向上/向下复制行</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+K</td>\n<td>删除行</td>\n</tr>\n<tr>\n<td>Ctrl+Enter</td>\n<td>在下面插入行</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+Enter</td>\n<td>在上面插入行</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+\\</td>\n<td>跳到匹配的括号</td>\n</tr>\n<tr>\n<td>Ctrl+] / [</td>\n<td>缩进/缩进行</td>\n</tr>\n<tr>\n<td>Home</td>\n<td>转到行首</td>\n</tr>\n<tr>\n<td>End</td>\n<td>转到行尾</td>\n</tr>\n<tr>\n<td>Ctrl+Home</td>\n<td>转到文件开头</td>\n</tr>\n<tr>\n<td>Ctrl+End</td>\n<td>转到文件末尾</td>\n</tr>\n<tr>\n<td>Ctrl+↑ / ↓</td>\n<td>向上/向下滚动行</td>\n</tr>\n<tr>\n<td>Alt+PgUp / PgDown</td>\n<td>向上/向下滚动页面</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+[</td>\n<td>折叠（折叠）区域</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+]</td>\n<td>展开（未折叠）区域</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+[</td>\n<td>折叠（未折叠）所有子区域</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+]</td>\n<td>展开（未折叠）所有子区域</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+0</td>\n<td>折叠（折叠）所有区域</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+J</td>\n<td>展开（未折叠）所有区域</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+C</td>\n<td>添加行注释</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+U</td>\n<td>删除行注释</td>\n</tr>\n<tr>\n<td>Ctrl+/</td>\n<td>切换行注释</td>\n</tr>\n<tr>\n<td>Shift+Alt+A</td>\n<td>切换块注释</td>\n</tr>\n<tr>\n<td>Alt+Z</td>\n<td>切换换行</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"导航\"><a href=\"#导航\" class=\"headerlink\" title=\"导航\"></a>导航</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl + T</td>\n<td>显示所有符号</td>\n</tr>\n<tr>\n<td>Ctrl + G</td>\n<td>转到行…</td>\n</tr>\n<tr>\n<td>Ctrl + P</td>\n<td>转到文件…</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + O</td>\n<td>转到符号…</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + M</td>\n<td>显示问题面板</td>\n</tr>\n<tr>\n<td>F8</td>\n<td>转到下一个错误或警告</td>\n</tr>\n<tr>\n<td>Shift + F8</td>\n<td>转到上一个错误或警告</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + Tab</td>\n<td>导航编辑器组历史记录</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>Alt + ←/→    返回/前进 Go back / forward<br>Ctrl + M    切换选项卡移动焦点 Toggle Tab moves focus</p>\n<h1 id=\"搜索和替换-Search-and-replace\"><a href=\"#搜索和替换-Search-and-replace\" class=\"headerlink\" title=\"搜索和替换 Search and replace\"></a>搜索和替换 Search and replace</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl + F</td>\n<td>查找</td>\n</tr>\n<tr>\n<td>Ctrl + H</td>\n<td>替换</td>\n</tr>\n<tr>\n<td>F3 / Shift + F3</td>\n<td>查找下一个/上一个</td>\n</tr>\n<tr>\n<td>Alt + Enter</td>\n<td>选择查找匹配的所有出现</td>\n</tr>\n<tr>\n<td>Ctrl + D</td>\n<td>将选择添加到下一个查找匹配</td>\n</tr>\n<tr>\n<td>Ctrl + K Ctrl + D</td>\n<td>将最后一个选择移至下一个查找匹配项</td>\n</tr>\n<tr>\n<td>Alt + C / R / W</td>\n<td>切换区分大小写/正则表达式/整个词</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"多光标和选择-Multi-cursor-and-selection\"><a href=\"#多光标和选择-Multi-cursor-and-selection\" class=\"headerlink\" title=\"多光标和选择 Multi-cursor and selection\"></a>多光标和选择 Multi-cursor and selection</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Alt +单击</td>\n<td>插入光标</td>\n</tr>\n<tr>\n<td>Ctrl + Alt +↑/↓</td>\n<td>在上/下插入光标</td>\n</tr>\n<tr>\n<td>Ctrl + U</td>\n<td>撤消上一个光标操作</td>\n</tr>\n<tr>\n<td>Shift + Alt + I</td>\n<td>在选定的每一行的末尾插入光标</td>\n</tr>\n<tr>\n<td>Ctrl + I</td>\n<td>选择当前行</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + L</td>\n<td>选择当前选择的所有出现</td>\n</tr>\n<tr>\n<td>Ctrl + F2</td>\n<td>选择当前字的所有出现</td>\n</tr>\n<tr>\n<td>Shift + Alt + →</td>\n<td>展开选择</td>\n</tr>\n<tr>\n<td>Shift + Alt + ←</td>\n<td>缩小选择</td>\n</tr>\n<tr>\n<td>Shift + Alt + （拖动鼠标）</td>\n<td>列（框）选择</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + Alt +（箭头键）</td>\n<td>列（框）选择</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + Alt + PgUp / PgDown</td>\n<td>列（框）选择页上/下</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"丰富的语言编辑\"><a href=\"#丰富的语言编辑\" class=\"headerlink\" title=\"丰富的语言编辑\"></a>丰富的语言编辑</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl + 空格</td>\n<td>触发建议</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + Space</td>\n<td>触发器参数提示</td>\n</tr>\n<tr>\n<td>Tab    Emmet</td>\n<td>展开缩写</td>\n</tr>\n<tr>\n<td>Shift + Alt + F</td>\n<td>格式化文档</td>\n</tr>\n<tr>\n<td>Ctrl + K Ctrl + F</td>\n<td>格式选定区域</td>\n</tr>\n<tr>\n<td>F12</td>\n<td>转到定义</td>\n</tr>\n<tr>\n<td>Alt + F12</td>\n<td>Peek定义</td>\n</tr>\n<tr>\n<td>Ctrl + K F12</td>\n<td>打开定义到边</td>\n</tr>\n<tr>\n<td>Ctrl + .</td>\n<td>快速解决</td>\n</tr>\n<tr>\n<td>Shift + F12</td>\n<td>显示引用</td>\n</tr>\n<tr>\n<td>F2</td>\n<td>重命名符号</td>\n</tr>\n<tr>\n<td>Ctrl + Shift + . /，</td>\n<td>替换为下一个/上一个值</td>\n</tr>\n<tr>\n<td>Ctrl + K Ctrl + X</td>\n<td>修剪尾随空格</td>\n</tr>\n<tr>\n<td>Ctrl + K M</td>\n<td>更改文件语言</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"编辑器管理-Editor-management\"><a href=\"#编辑器管理-Editor-management\" class=\"headerlink\" title=\"编辑器管理 Editor management\"></a>编辑器管理 Editor management</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+F4, Ctrl+W</td>\n<td>关闭编辑器</td>\n</tr>\n<tr>\n<td>Ctrl+K F</td>\n<td>关闭文件夹</td>\n</tr>\n<tr>\n<td>Ctrl+\\</td>\n<td>拆分编辑器</td>\n</tr>\n<tr>\n<td>Ctrl+ 1 / 2 / 3</td>\n<td>聚焦到第1，第2或第3编辑器组</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+ ←/→</td>\n<td>聚焦到上一个/下一个编辑器组</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+PgUp / PgDown</td>\n<td>向左/向右移动编辑器</td>\n</tr>\n<tr>\n<td>Ctrl+K ← / →</td>\n<td>移动活动编辑器组</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"文件管理-File-management\"><a href=\"#文件管理-File-management\" class=\"headerlink\" title=\"文件管理 File management\"></a>文件管理 File management</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+N</td>\n<td>新文件</td>\n</tr>\n<tr>\n<td>Ctrl+O</td>\n<td>打开文件…</td>\n</tr>\n<tr>\n<td>Ctrl+S</td>\n<td>保存</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+S</td>\n<td>另存为…</td>\n</tr>\n<tr>\n<td>Ctrl+K S</td>\n<td>全部保存</td>\n</tr>\n<tr>\n<td>Ctrl+F4</td>\n<td>关闭</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+W</td>\n<td>关闭所有</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+T</td>\n<td>重新打开关闭的编辑器</td>\n</tr>\n<tr>\n<td>Ctrl+K</td>\n<td>输入保持打开</td>\n</tr>\n<tr>\n<td>Ctrl+Tab</td>\n<td>打开下一个</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+Tab</td>\n<td>打开上一个</td>\n</tr>\n<tr>\n<td>Ctrl+K P</td>\n<td>复制活动文件的路径</td>\n</tr>\n<tr>\n<td>Ctrl+K R</td>\n<td>显示资源管理器中的活动文件</td>\n</tr>\n<tr>\n<td>Ctrl+K O</td>\n<td>显示新窗口/实例中的活动文件</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"显示-Display\"><a href=\"#显示-Display\" class=\"headerlink\" title=\"显示 Display\"></a>显示 Display</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>F11</td>\n<td>切换全屏</td>\n</tr>\n<tr>\n<td>Shift+Alt+1</td>\n<td>切换编辑器布局</td>\n</tr>\n<tr>\n<td>Ctrl+ = / -</td>\n<td>放大/缩小</td>\n<td>n</td>\n</tr>\n<tr>\n<td>Ctrl+B</td>\n<td>切换侧栏可见性</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+E</td>\n<td>显示浏览器/切换焦点</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+F</td>\n<td>显示搜索</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+G</td>\n<td>显示Git</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+D</td>\n<td>显示调试</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+X</td>\n<td>显示扩展</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+H</td>\n<td>替换文件</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+J</td>\n<td>切换搜索详细信息</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+C</td>\n<td>打开新命令提示符/终端</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+U</td>\n<td>显示输出面板</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+V</td>\n<td>切换Markdown预览</td>\n</tr>\n<tr>\n<td>Ctrl+K V</td>\n<td>从旁边打开Markdown预览</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"调试-Debug\"><a href=\"#调试-Debug\" class=\"headerlink\" title=\"调试 Debug\"></a>调试 Debug</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>F9</td>\n<td>切换断点</td>\n</tr>\n<tr>\n<td>F5</td>\n<td>开始/继续</td>\n</tr>\n<tr>\n<td>Shift+F5</td>\n<td>停止</td>\n</tr>\n<tr>\n<td>F11 / Shift+F11</td>\n<td>下一步/上一步</td>\n</tr>\n<tr>\n<td>F10</td>\n<td>跳过</td>\n</tr>\n<tr>\n<td>Ctrl+K Ctrl+I</td>\n<td>显示悬停</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"集成终端-Integrated-terminal\"><a href=\"#集成终端-Integrated-terminal\" class=\"headerlink\" title=\"集成终端 Integrated terminal\"></a>集成终端 Integrated terminal</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>按 Press</th>\n<th>功能 Function</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+`</td>\n<td>显示集成终端</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+`</td>\n<td>创建新终端</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+C</td>\n<td>复制选定</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+V</td>\n<td>粘贴到活动端子</td>\n</tr>\n<tr>\n<td>Ctrl+↑ / ↓</td>\n<td>向上/向下滚动</td>\n</tr>\n<tr>\n<td>Shift+PgUp / PgDown</td>\n<td>向上/向下滚动页面</td>\n</tr>\n<tr>\n<td>Ctrl+Home / End</td>\n<td>滚动到顶部/底部</td>\n</tr>\n</tbody>\n</table>\n</div>\n"},{"title":"【设计模式】三种工厂模式及在c++中的实现","date":"2018-07-06T17:03:28.000Z","_content":"\n# 简单模式\n\n工厂模式中最简单的一种，用比较简单的方式隐藏创建对象的细节，一般只需要告诉工厂类所需要的类型，工厂类就会返回需要的产品类，但客户端看到的只是产品的抽象对象，无需关心到底是返回了哪个子类。\n\n客户端唯一需要知道的具体子类就是工厂子类。除了这点，基本是达到了依赖倒转原则的要求。\n\n疑问：如果每次用工厂类创建的类型都不相同，这样修改起来的时候还是需要大量的替换。所以简单工厂模式一般应该于程序中大部分地方都只使用其中一种产品，工厂类也不用频繁创建产品类的情况。这样修改的时候只需要修改有限的几个地方即可。\n\n![](http://p8vrqzrnj.bkt.clouddn.com/19100800-208864687d8a43c7afed3069bd0c3174.jpg)\n\n客户只需要知道SimpleFactory就可以了，使用的时候也是使用的AbstractFactory，这样客户端只在第一次创建工厂的时候是知道具体的细节的，其他时候它都只知道AbstractFactory，这样就完美的达到了依赖倒转的原则。\n\n## 常用的场景\n例如部署多种数据库的情况，可能在不同的地方要使用不同的数据库，此时只需要在配置文件中设定数据库的类型，每次再根据类型生成实例，这样，不管下面的数据库类型怎么变化，在客户端看来都是只有一个AbstractProduct，使用的时候根本无需修改代码。提供的类型也可以用比较便于识别的字符串，这样不用记很长的类名，还可以保存为配置文件。\n\n这样，每次只需要修改配置文件和添加新的产品子类即可。\n\n所以简单工厂模式一般应用于多种同类型类的情况，将这些类隐藏起来，再提供统一的接口，便于维护和修改。\n\n## 优点\n1. 隐藏了对象创建的细节，将产品的实例化推迟到子类中实现。\n2. 客户端基本不用关心使用的是哪个产品，只需要知道用哪个工厂就行了，提供的类型也可以用比较便于识别的字符串。\n3. 方便添加新的产品子类，每次只需要修改工厂类传递的类型值就行了。\n4. 遵循了依赖倒转原则。\n\n## 缺点\n1. 要求产品子类的类型差不多，使用的方法名都相同，如果类比较多，而所有的类又必须要添加一种方法，则会是非常麻烦的事情。或者是一种类另一种类有几种方法不相同，客户端无法知道是哪一个产品子类，也就无法调用这几个不相同的方法。\n2. 每添加一个产品子类，都必须在工厂类中添加一个判断分支，这违背了开放-封闭原则。\n\nhttps://www.cnblogs.com/cxjchen/p/3143633.html\nhttps://blog.csdn.net/kuaipengfei_/article/details/49590727","source":"_posts/201807-factory-model-in-cpp-programming.md","raw":"---\ntitle: 【设计模式】三种工厂模式及在c++中的实现\ndate: 2018-07-07 01:03:28\ntags: 设计模式 工程模式 代码 宏定义\n---\n\n# 简单模式\n\n工厂模式中最简单的一种，用比较简单的方式隐藏创建对象的细节，一般只需要告诉工厂类所需要的类型，工厂类就会返回需要的产品类，但客户端看到的只是产品的抽象对象，无需关心到底是返回了哪个子类。\n\n客户端唯一需要知道的具体子类就是工厂子类。除了这点，基本是达到了依赖倒转原则的要求。\n\n疑问：如果每次用工厂类创建的类型都不相同，这样修改起来的时候还是需要大量的替换。所以简单工厂模式一般应该于程序中大部分地方都只使用其中一种产品，工厂类也不用频繁创建产品类的情况。这样修改的时候只需要修改有限的几个地方即可。\n\n![](http://p8vrqzrnj.bkt.clouddn.com/19100800-208864687d8a43c7afed3069bd0c3174.jpg)\n\n客户只需要知道SimpleFactory就可以了，使用的时候也是使用的AbstractFactory，这样客户端只在第一次创建工厂的时候是知道具体的细节的，其他时候它都只知道AbstractFactory，这样就完美的达到了依赖倒转的原则。\n\n## 常用的场景\n例如部署多种数据库的情况，可能在不同的地方要使用不同的数据库，此时只需要在配置文件中设定数据库的类型，每次再根据类型生成实例，这样，不管下面的数据库类型怎么变化，在客户端看来都是只有一个AbstractProduct，使用的时候根本无需修改代码。提供的类型也可以用比较便于识别的字符串，这样不用记很长的类名，还可以保存为配置文件。\n\n这样，每次只需要修改配置文件和添加新的产品子类即可。\n\n所以简单工厂模式一般应用于多种同类型类的情况，将这些类隐藏起来，再提供统一的接口，便于维护和修改。\n\n## 优点\n1. 隐藏了对象创建的细节，将产品的实例化推迟到子类中实现。\n2. 客户端基本不用关心使用的是哪个产品，只需要知道用哪个工厂就行了，提供的类型也可以用比较便于识别的字符串。\n3. 方便添加新的产品子类，每次只需要修改工厂类传递的类型值就行了。\n4. 遵循了依赖倒转原则。\n\n## 缺点\n1. 要求产品子类的类型差不多，使用的方法名都相同，如果类比较多，而所有的类又必须要添加一种方法，则会是非常麻烦的事情。或者是一种类另一种类有几种方法不相同，客户端无法知道是哪一个产品子类，也就无法调用这几个不相同的方法。\n2. 每添加一个产品子类，都必须在工厂类中添加一个判断分支，这违背了开放-封闭原则。\n\nhttps://www.cnblogs.com/cxjchen/p/3143633.html\nhttps://blog.csdn.net/kuaipengfei_/article/details/49590727","slug":"factory-model-in-cpp-programming","published":1,"updated":"2018-07-09T16:25:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xu000vn61dm8qc9bz3","content":"<h1 id=\"简单模式\"><a href=\"#简单模式\" class=\"headerlink\" title=\"简单模式\"></a>简单模式</h1><p>工厂模式中最简单的一种，用比较简单的方式隐藏创建对象的细节，一般只需要告诉工厂类所需要的类型，工厂类就会返回需要的产品类，但客户端看到的只是产品的抽象对象，无需关心到底是返回了哪个子类。</p>\n<p>客户端唯一需要知道的具体子类就是工厂子类。除了这点，基本是达到了依赖倒转原则的要求。</p>\n<p>疑问：如果每次用工厂类创建的类型都不相同，这样修改起来的时候还是需要大量的替换。所以简单工厂模式一般应该于程序中大部分地方都只使用其中一种产品，工厂类也不用频繁创建产品类的情况。这样修改的时候只需要修改有限的几个地方即可。</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/19100800-208864687d8a43c7afed3069bd0c3174.jpg\" alt=\"\"></p>\n<p>客户只需要知道SimpleFactory就可以了，使用的时候也是使用的AbstractFactory，这样客户端只在第一次创建工厂的时候是知道具体的细节的，其他时候它都只知道AbstractFactory，这样就完美的达到了依赖倒转的原则。</p>\n<h2 id=\"常用的场景\"><a href=\"#常用的场景\" class=\"headerlink\" title=\"常用的场景\"></a>常用的场景</h2><p>例如部署多种数据库的情况，可能在不同的地方要使用不同的数据库，此时只需要在配置文件中设定数据库的类型，每次再根据类型生成实例，这样，不管下面的数据库类型怎么变化，在客户端看来都是只有一个AbstractProduct，使用的时候根本无需修改代码。提供的类型也可以用比较便于识别的字符串，这样不用记很长的类名，还可以保存为配置文件。</p>\n<p>这样，每次只需要修改配置文件和添加新的产品子类即可。</p>\n<p>所以简单工厂模式一般应用于多种同类型类的情况，将这些类隐藏起来，再提供统一的接口，便于维护和修改。</p>\n<h2 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h2><ol>\n<li>隐藏了对象创建的细节，将产品的实例化推迟到子类中实现。</li>\n<li>客户端基本不用关心使用的是哪个产品，只需要知道用哪个工厂就行了，提供的类型也可以用比较便于识别的字符串。</li>\n<li>方便添加新的产品子类，每次只需要修改工厂类传递的类型值就行了。</li>\n<li>遵循了依赖倒转原则。</li>\n</ol>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><ol>\n<li>要求产品子类的类型差不多，使用的方法名都相同，如果类比较多，而所有的类又必须要添加一种方法，则会是非常麻烦的事情。或者是一种类另一种类有几种方法不相同，客户端无法知道是哪一个产品子类，也就无法调用这几个不相同的方法。</li>\n<li>每添加一个产品子类，都必须在工厂类中添加一个判断分支，这违背了开放-封闭原则。</li>\n</ol>\n<p><a href=\"https://www.cnblogs.com/cxjchen/p/3143633.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/cxjchen/p/3143633.html</a><br><a href=\"https://blog.csdn.net/kuaipengfei_/article/details/49590727\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/kuaipengfei_/article/details/49590727</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"简单模式\"><a href=\"#简单模式\" class=\"headerlink\" title=\"简单模式\"></a>简单模式</h1><p>工厂模式中最简单的一种，用比较简单的方式隐藏创建对象的细节，一般只需要告诉工厂类所需要的类型，工厂类就会返回需要的产品类，但客户端看到的只是产品的抽象对象，无需关心到底是返回了哪个子类。</p>\n<p>客户端唯一需要知道的具体子类就是工厂子类。除了这点，基本是达到了依赖倒转原则的要求。</p>\n<p>疑问：如果每次用工厂类创建的类型都不相同，这样修改起来的时候还是需要大量的替换。所以简单工厂模式一般应该于程序中大部分地方都只使用其中一种产品，工厂类也不用频繁创建产品类的情况。这样修改的时候只需要修改有限的几个地方即可。</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/19100800-208864687d8a43c7afed3069bd0c3174.jpg\" alt=\"\"></p>\n<p>客户只需要知道SimpleFactory就可以了，使用的时候也是使用的AbstractFactory，这样客户端只在第一次创建工厂的时候是知道具体的细节的，其他时候它都只知道AbstractFactory，这样就完美的达到了依赖倒转的原则。</p>\n<h2 id=\"常用的场景\"><a href=\"#常用的场景\" class=\"headerlink\" title=\"常用的场景\"></a>常用的场景</h2><p>例如部署多种数据库的情况，可能在不同的地方要使用不同的数据库，此时只需要在配置文件中设定数据库的类型，每次再根据类型生成实例，这样，不管下面的数据库类型怎么变化，在客户端看来都是只有一个AbstractProduct，使用的时候根本无需修改代码。提供的类型也可以用比较便于识别的字符串，这样不用记很长的类名，还可以保存为配置文件。</p>\n<p>这样，每次只需要修改配置文件和添加新的产品子类即可。</p>\n<p>所以简单工厂模式一般应用于多种同类型类的情况，将这些类隐藏起来，再提供统一的接口，便于维护和修改。</p>\n<h2 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h2><ol>\n<li>隐藏了对象创建的细节，将产品的实例化推迟到子类中实现。</li>\n<li>客户端基本不用关心使用的是哪个产品，只需要知道用哪个工厂就行了，提供的类型也可以用比较便于识别的字符串。</li>\n<li>方便添加新的产品子类，每次只需要修改工厂类传递的类型值就行了。</li>\n<li>遵循了依赖倒转原则。</li>\n</ol>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><ol>\n<li>要求产品子类的类型差不多，使用的方法名都相同，如果类比较多，而所有的类又必须要添加一种方法，则会是非常麻烦的事情。或者是一种类另一种类有几种方法不相同，客户端无法知道是哪一个产品子类，也就无法调用这几个不相同的方法。</li>\n<li>每添加一个产品子类，都必须在工厂类中添加一个判断分支，这违背了开放-封闭原则。</li>\n</ol>\n<p><a href=\"https://www.cnblogs.com/cxjchen/p/3143633.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/cxjchen/p/3143633.html</a><br><a href=\"https://blog.csdn.net/kuaipengfei_/article/details/49590727\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/kuaipengfei_/article/details/49590727</a></p>\n"},{"title":"hadoop common warn and error","date":"2018-07-19T12:49:37.000Z","_content":"\n# \b\b常规报错\n\n不影响运行的错误\n\n### Container preempted by scheduler\n\n如果有fair scheduler 并且有很多不同的 queue ，高优的应用程序会把jobs杀掉\b。每个queue都有相应的优先级 Preemption，\n\nhttps://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.2/bk_yarn_resource_mgt/content/preemption.html\n\n解决方案：取决于对性能和效果的预期，好的方法是检查job和队列的优先级。","source":"_posts/201807-hadoop-common-warn-and-error.md","raw":"---\ntitle: hadoop common warn and error\ndate: 2018-07-19 20:49:37\ntags:\n---\n\n# \b\b常规报错\n\n不影响运行的错误\n\n### Container preempted by scheduler\n\n如果有fair scheduler 并且有很多不同的 queue ，高优的应用程序会把jobs杀掉\b。每个queue都有相应的优先级 Preemption，\n\nhttps://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.2/bk_yarn_resource_mgt/content/preemption.html\n\n解决方案：取决于对性能和效果的预期，好的方法是检查job和队列的优先级。","slug":"hadoop-common-warn-and-error","published":1,"updated":"2018-07-19T12:57:56.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xw000yn61d42vk4lxa","content":"<h1 id=\"常规报错\"><a href=\"#常规报错\" class=\"headerlink\" title=\"\b\b常规报错\"></a>\b\b常规报错</h1><p>不影响运行的错误</p>\n<h3 id=\"Container-preempted-by-scheduler\"><a href=\"#Container-preempted-by-scheduler\" class=\"headerlink\" title=\"Container preempted by scheduler\"></a>Container preempted by scheduler</h3><p>如果有fair scheduler 并且有很多不同的 queue ，高优的应用程序会把jobs杀掉\b。每个queue都有相应的优先级 Preemption，</p>\n<p><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.2/bk_yarn_resource_mgt/content/preemption.html\" target=\"_blank\" rel=\"noopener\">https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.2/bk_yarn_resource_mgt/content/preemption.html</a></p>\n<p>解决方案：取决于对性能和效果的预期，好的方法是检查job和队列的优先级。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"常规报错\"><a href=\"#常规报错\" class=\"headerlink\" title=\"\b\b常规报错\"></a>\b\b常规报错</h1><p>不影响运行的错误</p>\n<h3 id=\"Container-preempted-by-scheduler\"><a href=\"#Container-preempted-by-scheduler\" class=\"headerlink\" title=\"Container preempted by scheduler\"></a>Container preempted by scheduler</h3><p>如果有fair scheduler 并且有很多不同的 queue ，高优的应用程序会把jobs杀掉\b。每个queue都有相应的优先级 Preemption，</p>\n<p><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.2/bk_yarn_resource_mgt/content/preemption.html\" target=\"_blank\" rel=\"noopener\">https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.2/bk_yarn_resource_mgt/content/preemption.html</a></p>\n<p>解决方案：取决于对性能和效果的预期，好的方法是检查job和队列的优先级。</p>\n"},{"title":"hadoop 使用经验","date":"2018-07-31T15:43:25.000Z","_content":"\n生成并保持中间RDD，保存在hdfs上\n- 提高并行\n- 检查任务完成情况（运行完把中间文件删掉）","source":"_posts/201807-hadoop-experience.md","raw":"---\ntitle: hadoop 使用经验\ndate: 2018-07-31 23:43:25\ntags:\n---\n\n生成并保持中间RDD，保存在hdfs上\n- 提高并行\n- 检查任务完成情况（运行完把中间文件删掉）","slug":"hadoop-experience","published":1,"updated":"2018-07-31T15:50:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xx0010n61d1vucjzqc","content":"<p>生成并保持中间RDD，保存在hdfs上</p>\n<ul>\n<li>提高并行</li>\n<li>检查任务完成情况（运行完把中间文件删掉）</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>生成并保持中间RDD，保存在hdfs上</p>\n<ul>\n<li>提高并行</li>\n<li>检查任务完成情况（运行完把中间文件删掉）</li>\n</ul>\n"},{"title":"机器学习中的数学 资料整理","date":"2018-07-31T14:25:51.000Z","_content":"\n最近在准备秋招，发现了很多基础概念之前并没有理解，找了一些说人话的资料。\n\n联合分布\n[机器学习-联合概率分布笔记](https://blog.csdn.net/tiankong_/article/details/78332666)\n\n[应该如何理解概率分布函数和概率密度函数？](https://www.jianshu.com/p/b570b1ba92bb)","source":"_posts/201807-math-in-machine-learning.md","raw":"---\ntitle: 机器学习中的数学 资料整理\ndate: 2018-07-31 22:25:51\ntags:\n---\n\n最近在准备秋招，发现了很多基础概念之前并没有理解，找了一些说人话的资料。\n\n联合分布\n[机器学习-联合概率分布笔记](https://blog.csdn.net/tiankong_/article/details/78332666)\n\n[应该如何理解概率分布函数和概率密度函数？](https://www.jianshu.com/p/b570b1ba92bb)","slug":"math-in-machine-learning","published":1,"updated":"2018-07-31T15:50:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7xz0013n61d3p8sw64w","content":"<p>最近在准备秋招，发现了很多基础概念之前并没有理解，找了一些说人话的资料。</p>\n<p>联合分布<br><a href=\"https://blog.csdn.net/tiankong_/article/details/78332666\" target=\"_blank\" rel=\"noopener\">机器学习-联合概率分布笔记</a></p>\n<p><a href=\"https://www.jianshu.com/p/b570b1ba92bb\" target=\"_blank\" rel=\"noopener\">应该如何理解概率分布函数和概率密度函数？</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>最近在准备秋招，发现了很多基础概念之前并没有理解，找了一些说人话的资料。</p>\n<p>联合分布<br><a href=\"https://blog.csdn.net/tiankong_/article/details/78332666\" target=\"_blank\" rel=\"noopener\">机器学习-联合概率分布笔记</a></p>\n<p><a href=\"https://www.jianshu.com/p/b570b1ba92bb\" target=\"_blank\" rel=\"noopener\">应该如何理解概率分布函数和概率密度函数？</a></p>\n"},{"title":"magic machine leaning feature engineering","date":"2018-07-19T13:22:24.000Z","_content":"\n一篇特征工程的好文章\n《评分卡系列（二）：特征工程》\nhttps://www.cnblogs.com/gasongjian/p/8159501.html","source":"_posts/201807-magic-machine-leaning-feature-engineering.md","raw":"---\ntitle: magic machine leaning feature engineering\ndate: 2018-07-19 21:22:24\ntags:\n---\n\n一篇特征工程的好文章\n《评分卡系列（二）：特征工程》\nhttps://www.cnblogs.com/gasongjian/p/8159501.html","slug":"magic-machine-leaning-feature-engineering","published":1,"updated":"2018-07-19T13:23:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7y00015n61dtmwbeglq","content":"<p>一篇特征工程的好文章<br>《评分卡系列（二）：特征工程》<br><a href=\"https://www.cnblogs.com/gasongjian/p/8159501.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/gasongjian/p/8159501.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>一篇特征工程的好文章<br>《评分卡系列（二）：特征工程》<br><a href=\"https://www.cnblogs.com/gasongjian/p/8159501.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/gasongjian/p/8159501.html</a></p>\n"},{"title":"meituan ads deep learning","date":"2018-07-09T13:33:00.000Z","_content":"深度学习在美团搜索广告排序的应用实践\n\n链接：https://gitbook.cn/gitchat/activity/5b39e067353da7153271877e\n\nCTR/CVR 预估由机器学习向深度学习迁移的模型探索；\nCTR/CVR 预估基于深度学习模型的线下训练/线上预估的工程优化。\n\n# 交流环节\ntensorflow实时化会遇到过哪些问题？怎么处理？\n第一个是时效性问题。目前解决办法是小批量来模拟流式计算。\n第二个问题是如何处理新数据问题，因为embedding矩阵的size要在定义tensorflow图的时候确定，但是如果有新的数据进来，要扩充embedding矩阵的话应该如何操作。\n这个问题我们也咨询的Google的同学，他们也说目前安装tf的设计并没有直接解决的办法。但是可以通过在embedding之前根据经验加一个hashtable。相当于预留一些位置为新数据。\n\n3.拉模型到线上机器的组建详细讲解\n拉取模型我们目前是从hdfs上拉取的，直接使用的 httpfs 这个工具。\n主要是考虑模型的多版本存储、灰度发布、快速回滚以及模型更新时对内存、网络、磁盘的影响。 异常情况比如下载较慢时的处理。后面我们正在进行的优化是，通过类似bittorrent的方案提高模型的分发效率。主要是实现稳定可靠的将模型分发的线上服务机器上的目标。\n模型通过离线训练平台训练好以后，我们是保存在 hdfs 上。 之后通过前面提到的模型分发工具分发到线上机器。 线上部署的话，模型小的话，我们保存在本地。再大一点的模型，我们保存在我们这的模型服务，基于model sharding 的架构； 我们也有基于 ps架构的在线服务系统。\n\n\ntensorflow建模过程的预处理应注意哪些问题\ntensorflow建模过程的预处理，我理解的是对数据及特征的预处理。数据预处理包括清理脏数据，样本标注，样本权重等等。特征预处理包括对离散特征和连续特征等的预处理，包括特征频次过滤、缺失值处理、离散化，连续特征归一化等等。\n\n分布式深度学习系统的研究热点\n目前有两个热点，第一个是通用计算框架的底层扩展。比如如何拓展tensorflow的分布式扩展性，因为tf的通讯协议是grpc，而目前开源的grpc在以太网上性能一般，在大规模分布式情况下，性能较差。再比如扩展一些目前主流框架没有算子。或者基于ps-lite这种基础组件自己封装一个框架。\n第二个是基于已有的开源框架订制属于自己的上层wrapper。比如keras就是其中之一。还有早起比较活跃的tf.learn\n\n\n7.研究分布式深度学习系统是如何进行模型压缩与通信优化的？\n模型压缩主要是模型量化，以及降精度。量化的思路是用计算来换取空间\n通讯的优化目前主要思路是用rdma来替换tcp\n目前tensorflow1.5以上版本已经很好的支持rdma了。\n\n\n# REF\n\n![机器学习之特征选择常用方法](https://vimsky.com/article/362.html)\n\n频次\n\n频次这个比较简单，就是看某个特征在所有训练集中的出现次数。例如，我们有3000个训练集样本，统计发现某特征A只出现在5个样本中（无论是正例还是负例），那么特征A就是个超低频特征，对模型的预测性作用不大，可以直接踢掉。总之，我们可以统计训练集中每个特征的出现频次，将低频特征过滤掉。","source":"_posts/201807-meituan-ads-deep-learning.md","raw":"---\ntitle: meituan ads deep learning\ndate: 2018-07-09 21:33:00\ntags:\n---\n深度学习在美团搜索广告排序的应用实践\n\n链接：https://gitbook.cn/gitchat/activity/5b39e067353da7153271877e\n\nCTR/CVR 预估由机器学习向深度学习迁移的模型探索；\nCTR/CVR 预估基于深度学习模型的线下训练/线上预估的工程优化。\n\n# 交流环节\ntensorflow实时化会遇到过哪些问题？怎么处理？\n第一个是时效性问题。目前解决办法是小批量来模拟流式计算。\n第二个问题是如何处理新数据问题，因为embedding矩阵的size要在定义tensorflow图的时候确定，但是如果有新的数据进来，要扩充embedding矩阵的话应该如何操作。\n这个问题我们也咨询的Google的同学，他们也说目前安装tf的设计并没有直接解决的办法。但是可以通过在embedding之前根据经验加一个hashtable。相当于预留一些位置为新数据。\n\n3.拉模型到线上机器的组建详细讲解\n拉取模型我们目前是从hdfs上拉取的，直接使用的 httpfs 这个工具。\n主要是考虑模型的多版本存储、灰度发布、快速回滚以及模型更新时对内存、网络、磁盘的影响。 异常情况比如下载较慢时的处理。后面我们正在进行的优化是，通过类似bittorrent的方案提高模型的分发效率。主要是实现稳定可靠的将模型分发的线上服务机器上的目标。\n模型通过离线训练平台训练好以后，我们是保存在 hdfs 上。 之后通过前面提到的模型分发工具分发到线上机器。 线上部署的话，模型小的话，我们保存在本地。再大一点的模型，我们保存在我们这的模型服务，基于model sharding 的架构； 我们也有基于 ps架构的在线服务系统。\n\n\ntensorflow建模过程的预处理应注意哪些问题\ntensorflow建模过程的预处理，我理解的是对数据及特征的预处理。数据预处理包括清理脏数据，样本标注，样本权重等等。特征预处理包括对离散特征和连续特征等的预处理，包括特征频次过滤、缺失值处理、离散化，连续特征归一化等等。\n\n分布式深度学习系统的研究热点\n目前有两个热点，第一个是通用计算框架的底层扩展。比如如何拓展tensorflow的分布式扩展性，因为tf的通讯协议是grpc，而目前开源的grpc在以太网上性能一般，在大规模分布式情况下，性能较差。再比如扩展一些目前主流框架没有算子。或者基于ps-lite这种基础组件自己封装一个框架。\n第二个是基于已有的开源框架订制属于自己的上层wrapper。比如keras就是其中之一。还有早起比较活跃的tf.learn\n\n\n7.研究分布式深度学习系统是如何进行模型压缩与通信优化的？\n模型压缩主要是模型量化，以及降精度。量化的思路是用计算来换取空间\n通讯的优化目前主要思路是用rdma来替换tcp\n目前tensorflow1.5以上版本已经很好的支持rdma了。\n\n\n# REF\n\n![机器学习之特征选择常用方法](https://vimsky.com/article/362.html)\n\n频次\n\n频次这个比较简单，就是看某个特征在所有训练集中的出现次数。例如，我们有3000个训练集样本，统计发现某特征A只出现在5个样本中（无论是正例还是负例），那么特征A就是个超低频特征，对模型的预测性作用不大，可以直接踢掉。总之，我们可以统计训练集中每个特征的出现频次，将低频特征过滤掉。","slug":"meituan-ads-deep-learning","published":1,"updated":"2018-07-09T16:24:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7y10017n61d48l7e6lj","content":"<p>深度学习在美团搜索广告排序的应用实践</p>\n<p>链接：<a href=\"https://gitbook.cn/gitchat/activity/5b39e067353da7153271877e\" target=\"_blank\" rel=\"noopener\">https://gitbook.cn/gitchat/activity/5b39e067353da7153271877e</a></p>\n<p>CTR/CVR 预估由机器学习向深度学习迁移的模型探索；<br>CTR/CVR 预估基于深度学习模型的线下训练/线上预估的工程优化。</p>\n<h1 id=\"交流环节\"><a href=\"#交流环节\" class=\"headerlink\" title=\"交流环节\"></a>交流环节</h1><p>tensorflow实时化会遇到过哪些问题？怎么处理？<br>第一个是时效性问题。目前解决办法是小批量来模拟流式计算。<br>第二个问题是如何处理新数据问题，因为embedding矩阵的size要在定义tensorflow图的时候确定，但是如果有新的数据进来，要扩充embedding矩阵的话应该如何操作。<br>这个问题我们也咨询的Google的同学，他们也说目前安装tf的设计并没有直接解决的办法。但是可以通过在embedding之前根据经验加一个hashtable。相当于预留一些位置为新数据。</p>\n<p>3.拉模型到线上机器的组建详细讲解<br>拉取模型我们目前是从hdfs上拉取的，直接使用的 httpfs 这个工具。<br>主要是考虑模型的多版本存储、灰度发布、快速回滚以及模型更新时对内存、网络、磁盘的影响。 异常情况比如下载较慢时的处理。后面我们正在进行的优化是，通过类似bittorrent的方案提高模型的分发效率。主要是实现稳定可靠的将模型分发的线上服务机器上的目标。<br>模型通过离线训练平台训练好以后，我们是保存在 hdfs 上。 之后通过前面提到的模型分发工具分发到线上机器。 线上部署的话，模型小的话，我们保存在本地。再大一点的模型，我们保存在我们这的模型服务，基于model sharding 的架构； 我们也有基于 ps架构的在线服务系统。</p>\n<p>tensorflow建模过程的预处理应注意哪些问题<br>tensorflow建模过程的预处理，我理解的是对数据及特征的预处理。数据预处理包括清理脏数据，样本标注，样本权重等等。特征预处理包括对离散特征和连续特征等的预处理，包括特征频次过滤、缺失值处理、离散化，连续特征归一化等等。</p>\n<p>分布式深度学习系统的研究热点<br>目前有两个热点，第一个是通用计算框架的底层扩展。比如如何拓展tensorflow的分布式扩展性，因为tf的通讯协议是grpc，而目前开源的grpc在以太网上性能一般，在大规模分布式情况下，性能较差。再比如扩展一些目前主流框架没有算子。或者基于ps-lite这种基础组件自己封装一个框架。<br>第二个是基于已有的开源框架订制属于自己的上层wrapper。比如keras就是其中之一。还有早起比较活跃的tf.learn</p>\n<p>7.研究分布式深度学习系统是如何进行模型压缩与通信优化的？<br>模型压缩主要是模型量化，以及降精度。量化的思路是用计算来换取空间<br>通讯的优化目前主要思路是用rdma来替换tcp<br>目前tensorflow1.5以上版本已经很好的支持rdma了。</p>\n<h1 id=\"REF\"><a href=\"#REF\" class=\"headerlink\" title=\"REF\"></a>REF</h1><p><img src=\"https://vimsky.com/article/362.html\" alt=\"机器学习之特征选择常用方法\"></p>\n<p>频次</p>\n<p>频次这个比较简单，就是看某个特征在所有训练集中的出现次数。例如，我们有3000个训练集样本，统计发现某特征A只出现在5个样本中（无论是正例还是负例），那么特征A就是个超低频特征，对模型的预测性作用不大，可以直接踢掉。总之，我们可以统计训练集中每个特征的出现频次，将低频特征过滤掉。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>深度学习在美团搜索广告排序的应用实践</p>\n<p>链接：<a href=\"https://gitbook.cn/gitchat/activity/5b39e067353da7153271877e\" target=\"_blank\" rel=\"noopener\">https://gitbook.cn/gitchat/activity/5b39e067353da7153271877e</a></p>\n<p>CTR/CVR 预估由机器学习向深度学习迁移的模型探索；<br>CTR/CVR 预估基于深度学习模型的线下训练/线上预估的工程优化。</p>\n<h1 id=\"交流环节\"><a href=\"#交流环节\" class=\"headerlink\" title=\"交流环节\"></a>交流环节</h1><p>tensorflow实时化会遇到过哪些问题？怎么处理？<br>第一个是时效性问题。目前解决办法是小批量来模拟流式计算。<br>第二个问题是如何处理新数据问题，因为embedding矩阵的size要在定义tensorflow图的时候确定，但是如果有新的数据进来，要扩充embedding矩阵的话应该如何操作。<br>这个问题我们也咨询的Google的同学，他们也说目前安装tf的设计并没有直接解决的办法。但是可以通过在embedding之前根据经验加一个hashtable。相当于预留一些位置为新数据。</p>\n<p>3.拉模型到线上机器的组建详细讲解<br>拉取模型我们目前是从hdfs上拉取的，直接使用的 httpfs 这个工具。<br>主要是考虑模型的多版本存储、灰度发布、快速回滚以及模型更新时对内存、网络、磁盘的影响。 异常情况比如下载较慢时的处理。后面我们正在进行的优化是，通过类似bittorrent的方案提高模型的分发效率。主要是实现稳定可靠的将模型分发的线上服务机器上的目标。<br>模型通过离线训练平台训练好以后，我们是保存在 hdfs 上。 之后通过前面提到的模型分发工具分发到线上机器。 线上部署的话，模型小的话，我们保存在本地。再大一点的模型，我们保存在我们这的模型服务，基于model sharding 的架构； 我们也有基于 ps架构的在线服务系统。</p>\n<p>tensorflow建模过程的预处理应注意哪些问题<br>tensorflow建模过程的预处理，我理解的是对数据及特征的预处理。数据预处理包括清理脏数据，样本标注，样本权重等等。特征预处理包括对离散特征和连续特征等的预处理，包括特征频次过滤、缺失值处理、离散化，连续特征归一化等等。</p>\n<p>分布式深度学习系统的研究热点<br>目前有两个热点，第一个是通用计算框架的底层扩展。比如如何拓展tensorflow的分布式扩展性，因为tf的通讯协议是grpc，而目前开源的grpc在以太网上性能一般，在大规模分布式情况下，性能较差。再比如扩展一些目前主流框架没有算子。或者基于ps-lite这种基础组件自己封装一个框架。<br>第二个是基于已有的开源框架订制属于自己的上层wrapper。比如keras就是其中之一。还有早起比较活跃的tf.learn</p>\n<p>7.研究分布式深度学习系统是如何进行模型压缩与通信优化的？<br>模型压缩主要是模型量化，以及降精度。量化的思路是用计算来换取空间<br>通讯的优化目前主要思路是用rdma来替换tcp<br>目前tensorflow1.5以上版本已经很好的支持rdma了。</p>\n<h1 id=\"REF\"><a href=\"#REF\" class=\"headerlink\" title=\"REF\"></a>REF</h1><p><img src=\"https://vimsky.com/article/362.html\" alt=\"机器学习之特征选择常用方法\"></p>\n<p>频次</p>\n<p>频次这个比较简单，就是看某个特征在所有训练集中的出现次数。例如，我们有3000个训练集样本，统计发现某特征A只出现在5个样本中（无论是正例还是负例），那么特征A就是个超低频特征，对模型的预测性作用不大，可以直接踢掉。总之，我们可以统计训练集中每个特征的出现频次，将低频特征过滤掉。</p>\n"},{"title":"scons - cpp编译工具学习","date":"2018-07-09T16:05:12.000Z","_content":"\n# scons是什么 \n\n[office guide](https://scons.org/)\n\nSCons 是一个开放源代码、以 Python 语言编写的下一代的程序建造工具。功能上类似于make。 \n\n一个单个文件的程序是不需要scons和make之类的构建工具的，只要用gcc或者g++编译就好。但是一些相对较大的项目有多个文件，各个文件之间的依赖关系复杂，如果用g++来编译就会非常复杂，不仅要写的命令多，而且容易出错，所以就出现了make，但是make可能也存在某些问题，就出现了scons。\n\n总之，这两种工具解决构建的方法就是用一个配置文件来记录下各个文件之间的依赖关系，用到了那些库，配置好环境变量等等，然后直接构建。scons并不是和g++一样的编译工具，而是在g++的基础上的工具。\n\n# scons的优势\n\n- 使用 Python 脚本做为配置文件\n- 对于 C,C++ 和 Fortran, 内建支持可靠自动依赖分析 . 不用像 make 工具那样需要 执行”make depends”和”make clean”就可以获得所有的依赖关系。\n- 内建支持 C, C++, D, Java, Fortran, Yacc, Lex, Qt，SWIG 以及 Tex/Latex。 用户还可以根据自己的需要进行扩展以获得对需要编程语言的支持。\n- 支持 make -j 风格的并行建造。相比 make -j, SCons 可以同时运行 N 个工作，而 不用担心代码的层次结构。\n- 使用 Autoconf 风格查找头文件，函数库，函数和类型定义。 \n- 良好的夸平台性。SCons 可以运行在 Linux, AIX, BSD, HP/UX, IRIX, Solaris, Windows, Mac OS X 和 OS/2 上。\n\n# scons的配置文件\n\nSConstruct是scons的配置文件，是用python编写的，自然要遵守python语法\n\n``` bash \n# 指定SConstruct\nscons -f <SConstruct file>\n\n```\n\n# scons命令\n\n``` bash\nscons -Q # 减少编译时的由 scons 产生的冗余信息，关闭一些输出提示\nscons -c # scons -clean，根据SConstruct文件，执行清理任务\n```\n\n# SConstruct 文件常用函数\n\n## Program()：生成可执行文件\n\n``` python\nProgram(target, source, libs) \n\"\"\"\n编译hello.c并生成.o文件和可执行文件\ntarget:编译的目标文件名 \nsource:需要编译的文件组 \nlibs:  需要的所有库 \n\"\"\"\nProgram('hello.c')  # 编译hello.c为可执行文件,文件名为第一个文件名\nProgram('main', 'hello.c')  # 编译hello.c为可执行文件,文件名mian\nProgram('program', ['prog.c', 'file1.c', 'file2.c'])\n# 也可以利用Glob函数获得名字列表\n# Golb('*.c')返回规则匹配的string列表\n# 就是类似上面的'prog.c', 'file1.c', 'file2.c'\nProgram('program', Glob('*.c') )\n\nProgram(target = 'main', source = 'hello.c')  # 使用关键字指明编译对象\n```\n## Object()：生成目标文件。如：\n\n``` python\nObject('hello.c')          # 编译hello.c，但只生成生成.o文件\nObject('main', 'hello.c')  # 编译hello.c 为目标文件，文件名为main.o\n```\n\n## 生成库文件\n\n``` python\nLibrary()        # 生成库，默认为静态库。\n\nStaticLibrary()  # 生成静态库 .a\n\nShareLibrary()   # 生成动态库 .so\n\n```\n\n# scons 关键字\n\n编译相关关键字说明\n\n## 基本的编译关键字\n\n| 关键字     | 说明                                            |\n| ---------- | ----------------------------------------------- |\n| CXXFLAGS   | 编译参数                                        |\n| CPPDEFINES | 指定预编译器 CPPDEFINES={'RELEASE_BUILD' : '1'} |\n| LIBS       | 指定所需要链接的库文件                          |\n| LIBPATH    | 指定库文件(.lib)的搜索目录                      |\n| CPPPATH    | 指定[.h, .c, .cpp]等文件搜索路径，头文件路径    |\n\n## 指定编译选项\n\n``` python \nProgram(target = 'bind_test1',\n    source = [“bind_test1.cc”],\n    LIBS = ['boost_system','boost_filesystem', 'boost_thread'],\n    LIBPATH = ['./', '/usr/local/lib/' ],\n    CPPPATH = ['./', '/usr/local/include/'],\n    CCFLAGS = ['-g','-O3′] ,\n    CPPDEFINES={'RELEASE_BUILD' : '1'}\n)\n```\n\n> 注：LIBS和LIBPATH若为一个可以使用字符串，若为多个则使用列表\n\n# scons进阶\n\n对于scons来说，环境变量(Environment)是异常重要的，只有会用Environment，才能写出真正可以实际使用的scons脚本。\n\n## 构造环境变量\n\n由自己创建的环境变量，这个环境变量可以用来控制整个目标文件编译过程。\n\n一种构造环境变量的\b目的就是交叉编译器的设置，由于scons默认用的是gcc来编译系统，而嵌入式开发要使用指定的交叉编译器来编译目标文件，所以可通过构造环境变量来修改编译器。\n\na) 创建\n\n``` python\nenv = Environment(CC = 'arm-linux-gcc')\n```\n\nb) 使用\n\n用arm-linux-gcc编译执行文件\n\n`env.Program('hello.c')`\n\nc) 从构造环境变量获取值：\n\n`print \"CC is:\", env['CC']`\n\nd) 拷贝\n\n我们想使用gcc编译2个不同版本的debug/realse版本的程序，就可以通过拷贝创建2个环境变量\n\n``` python\ndebug = env.Clone(CCFLAGS = '-g')\n\nRealse = env.Clone(CCFLAGS = '-O2')\n\ndebug.Program('debug','hello.c')\n\ndebug.Program('realse','hello.c')\n```\n \ne) 追加到末尾：Append()\n\n`env.Append(CCFLAGS = '-DLAST')`\n\nf) 追加到开始位置：Prepend()\n\n`env.Prepend(CCLFAGS = '-DFIRST')`\n\n## Python的os模块使用\n\n使用os模块，需要在每个脚本文件添加`import os`\n\n``` python\nimport os\nos.name      # 获取当前正在使用的平台，linux显示为'posix',windows返回的是'nt'\nos.getcwd()  # 获取当前工作目录\nos.getenv()  # 读取环境变量\nos.putenv()  # 设置环境变量\nos.listdir() # 返回指定目录下的所有文件和目录\nos.remove()  # 删除一个文件\nos.system()  # 运行shell命令\n```\n\n# ARGUMENTS.get()\n\nValues of variables to be passed to the SConscript file(s) may be specified on the command line:\n\n``` bash\nscons debug=1 .\n```\n\nThese variables are available in SConscript files through the ARGUMENTS dictionary, and can be used in the SConscript file(s) to modify the build in any way:\n\n``` python\nif ARGUMENTS.get('debug', 0):\n    env = Environment(CCFLAGS = '-g')\nelse:\n    env = Environment()\n```\n\nThe command-line variable arguments are also available in the ARGLIST list, indexed by their order on the command line. This allows you to process them in order rather than by name, if necessary. ARGLIST[0] returns a tuple containing (argname, argvalue). A Python exception is thrown if you try to access a list member that does not exist.\n\n","source":"_posts/201807-scons-cpp-sconstruct-tool.md","raw":"---\ntitle: scons - cpp编译工具学习\ndate: 2018-07-10 00:05:12\ntags:\n---\n\n# scons是什么 \n\n[office guide](https://scons.org/)\n\nSCons 是一个开放源代码、以 Python 语言编写的下一代的程序建造工具。功能上类似于make。 \n\n一个单个文件的程序是不需要scons和make之类的构建工具的，只要用gcc或者g++编译就好。但是一些相对较大的项目有多个文件，各个文件之间的依赖关系复杂，如果用g++来编译就会非常复杂，不仅要写的命令多，而且容易出错，所以就出现了make，但是make可能也存在某些问题，就出现了scons。\n\n总之，这两种工具解决构建的方法就是用一个配置文件来记录下各个文件之间的依赖关系，用到了那些库，配置好环境变量等等，然后直接构建。scons并不是和g++一样的编译工具，而是在g++的基础上的工具。\n\n# scons的优势\n\n- 使用 Python 脚本做为配置文件\n- 对于 C,C++ 和 Fortran, 内建支持可靠自动依赖分析 . 不用像 make 工具那样需要 执行”make depends”和”make clean”就可以获得所有的依赖关系。\n- 内建支持 C, C++, D, Java, Fortran, Yacc, Lex, Qt，SWIG 以及 Tex/Latex。 用户还可以根据自己的需要进行扩展以获得对需要编程语言的支持。\n- 支持 make -j 风格的并行建造。相比 make -j, SCons 可以同时运行 N 个工作，而 不用担心代码的层次结构。\n- 使用 Autoconf 风格查找头文件，函数库，函数和类型定义。 \n- 良好的夸平台性。SCons 可以运行在 Linux, AIX, BSD, HP/UX, IRIX, Solaris, Windows, Mac OS X 和 OS/2 上。\n\n# scons的配置文件\n\nSConstruct是scons的配置文件，是用python编写的，自然要遵守python语法\n\n``` bash \n# 指定SConstruct\nscons -f <SConstruct file>\n\n```\n\n# scons命令\n\n``` bash\nscons -Q # 减少编译时的由 scons 产生的冗余信息，关闭一些输出提示\nscons -c # scons -clean，根据SConstruct文件，执行清理任务\n```\n\n# SConstruct 文件常用函数\n\n## Program()：生成可执行文件\n\n``` python\nProgram(target, source, libs) \n\"\"\"\n编译hello.c并生成.o文件和可执行文件\ntarget:编译的目标文件名 \nsource:需要编译的文件组 \nlibs:  需要的所有库 \n\"\"\"\nProgram('hello.c')  # 编译hello.c为可执行文件,文件名为第一个文件名\nProgram('main', 'hello.c')  # 编译hello.c为可执行文件,文件名mian\nProgram('program', ['prog.c', 'file1.c', 'file2.c'])\n# 也可以利用Glob函数获得名字列表\n# Golb('*.c')返回规则匹配的string列表\n# 就是类似上面的'prog.c', 'file1.c', 'file2.c'\nProgram('program', Glob('*.c') )\n\nProgram(target = 'main', source = 'hello.c')  # 使用关键字指明编译对象\n```\n## Object()：生成目标文件。如：\n\n``` python\nObject('hello.c')          # 编译hello.c，但只生成生成.o文件\nObject('main', 'hello.c')  # 编译hello.c 为目标文件，文件名为main.o\n```\n\n## 生成库文件\n\n``` python\nLibrary()        # 生成库，默认为静态库。\n\nStaticLibrary()  # 生成静态库 .a\n\nShareLibrary()   # 生成动态库 .so\n\n```\n\n# scons 关键字\n\n编译相关关键字说明\n\n## 基本的编译关键字\n\n| 关键字     | 说明                                            |\n| ---------- | ----------------------------------------------- |\n| CXXFLAGS   | 编译参数                                        |\n| CPPDEFINES | 指定预编译器 CPPDEFINES={'RELEASE_BUILD' : '1'} |\n| LIBS       | 指定所需要链接的库文件                          |\n| LIBPATH    | 指定库文件(.lib)的搜索目录                      |\n| CPPPATH    | 指定[.h, .c, .cpp]等文件搜索路径，头文件路径    |\n\n## 指定编译选项\n\n``` python \nProgram(target = 'bind_test1',\n    source = [“bind_test1.cc”],\n    LIBS = ['boost_system','boost_filesystem', 'boost_thread'],\n    LIBPATH = ['./', '/usr/local/lib/' ],\n    CPPPATH = ['./', '/usr/local/include/'],\n    CCFLAGS = ['-g','-O3′] ,\n    CPPDEFINES={'RELEASE_BUILD' : '1'}\n)\n```\n\n> 注：LIBS和LIBPATH若为一个可以使用字符串，若为多个则使用列表\n\n# scons进阶\n\n对于scons来说，环境变量(Environment)是异常重要的，只有会用Environment，才能写出真正可以实际使用的scons脚本。\n\n## 构造环境变量\n\n由自己创建的环境变量，这个环境变量可以用来控制整个目标文件编译过程。\n\n一种构造环境变量的\b目的就是交叉编译器的设置，由于scons默认用的是gcc来编译系统，而嵌入式开发要使用指定的交叉编译器来编译目标文件，所以可通过构造环境变量来修改编译器。\n\na) 创建\n\n``` python\nenv = Environment(CC = 'arm-linux-gcc')\n```\n\nb) 使用\n\n用arm-linux-gcc编译执行文件\n\n`env.Program('hello.c')`\n\nc) 从构造环境变量获取值：\n\n`print \"CC is:\", env['CC']`\n\nd) 拷贝\n\n我们想使用gcc编译2个不同版本的debug/realse版本的程序，就可以通过拷贝创建2个环境变量\n\n``` python\ndebug = env.Clone(CCFLAGS = '-g')\n\nRealse = env.Clone(CCFLAGS = '-O2')\n\ndebug.Program('debug','hello.c')\n\ndebug.Program('realse','hello.c')\n```\n \ne) 追加到末尾：Append()\n\n`env.Append(CCFLAGS = '-DLAST')`\n\nf) 追加到开始位置：Prepend()\n\n`env.Prepend(CCLFAGS = '-DFIRST')`\n\n## Python的os模块使用\n\n使用os模块，需要在每个脚本文件添加`import os`\n\n``` python\nimport os\nos.name      # 获取当前正在使用的平台，linux显示为'posix',windows返回的是'nt'\nos.getcwd()  # 获取当前工作目录\nos.getenv()  # 读取环境变量\nos.putenv()  # 设置环境变量\nos.listdir() # 返回指定目录下的所有文件和目录\nos.remove()  # 删除一个文件\nos.system()  # 运行shell命令\n```\n\n# ARGUMENTS.get()\n\nValues of variables to be passed to the SConscript file(s) may be specified on the command line:\n\n``` bash\nscons debug=1 .\n```\n\nThese variables are available in SConscript files through the ARGUMENTS dictionary, and can be used in the SConscript file(s) to modify the build in any way:\n\n``` python\nif ARGUMENTS.get('debug', 0):\n    env = Environment(CCFLAGS = '-g')\nelse:\n    env = Environment()\n```\n\nThe command-line variable arguments are also available in the ARGLIST list, indexed by their order on the command line. This allows you to process them in order rather than by name, if necessary. ARGLIST[0] returns a tuple containing (argname, argvalue). A Python exception is thrown if you try to access a list member that does not exist.\n\n","slug":"scons-cpp-sconstruct-tool","published":1,"updated":"2018-07-30T02:45:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7y20019n61dwktnbgn6","content":"<h1 id=\"scons是什么\"><a href=\"#scons是什么\" class=\"headerlink\" title=\"scons是什么\"></a>scons是什么</h1><p><a href=\"https://scons.org/\" target=\"_blank\" rel=\"noopener\">office guide</a></p>\n<p>SCons 是一个开放源代码、以 Python 语言编写的下一代的程序建造工具。功能上类似于make。 </p>\n<p>一个单个文件的程序是不需要scons和make之类的构建工具的，只要用gcc或者g++编译就好。但是一些相对较大的项目有多个文件，各个文件之间的依赖关系复杂，如果用g++来编译就会非常复杂，不仅要写的命令多，而且容易出错，所以就出现了make，但是make可能也存在某些问题，就出现了scons。</p>\n<p>总之，这两种工具解决构建的方法就是用一个配置文件来记录下各个文件之间的依赖关系，用到了那些库，配置好环境变量等等，然后直接构建。scons并不是和g++一样的编译工具，而是在g++的基础上的工具。</p>\n<h1 id=\"scons的优势\"><a href=\"#scons的优势\" class=\"headerlink\" title=\"scons的优势\"></a>scons的优势</h1><ul>\n<li>使用 Python 脚本做为配置文件</li>\n<li>对于 C,C++ 和 Fortran, 内建支持可靠自动依赖分析 . 不用像 make 工具那样需要 执行”make depends”和”make clean”就可以获得所有的依赖关系。</li>\n<li>内建支持 C, C++, D, Java, Fortran, Yacc, Lex, Qt，SWIG 以及 Tex/Latex。 用户还可以根据自己的需要进行扩展以获得对需要编程语言的支持。</li>\n<li>支持 make -j 风格的并行建造。相比 make -j, SCons 可以同时运行 N 个工作，而 不用担心代码的层次结构。</li>\n<li>使用 Autoconf 风格查找头文件，函数库，函数和类型定义。 </li>\n<li>良好的夸平台性。SCons 可以运行在 Linux, AIX, BSD, HP/UX, IRIX, Solaris, Windows, Mac OS X 和 OS/2 上。</li>\n</ul>\n<h1 id=\"scons的配置文件\"><a href=\"#scons的配置文件\" class=\"headerlink\" title=\"scons的配置文件\"></a>scons的配置文件</h1><p>SConstruct是scons的配置文件，是用python编写的，自然要遵守python语法</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 指定SConstruct</span></span><br><span class=\"line\">scons -f &lt;SConstruct file&gt;</span><br></pre></td></tr></table></figure>\n<h1 id=\"scons命令\"><a href=\"#scons命令\" class=\"headerlink\" title=\"scons命令\"></a>scons命令</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scons -Q <span class=\"comment\"># 减少编译时的由 scons 产生的冗余信息，关闭一些输出提示</span></span><br><span class=\"line\">scons -c <span class=\"comment\"># scons -clean，根据SConstruct文件，执行清理任务</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"SConstruct-文件常用函数\"><a href=\"#SConstruct-文件常用函数\" class=\"headerlink\" title=\"SConstruct 文件常用函数\"></a>SConstruct 文件常用函数</h1><h2 id=\"Program-：生成可执行文件\"><a href=\"#Program-：生成可执行文件\" class=\"headerlink\" title=\"Program()：生成可执行文件\"></a>Program()：生成可执行文件</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Program(target, source, libs) </span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">编译hello.c并生成.o文件和可执行文件</span></span><br><span class=\"line\"><span class=\"string\">target:编译的目标文件名 </span></span><br><span class=\"line\"><span class=\"string\">source:需要编译的文件组 </span></span><br><span class=\"line\"><span class=\"string\">libs:  需要的所有库 </span></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\">Program(<span class=\"string\">'hello.c'</span>)  <span class=\"comment\"># 编译hello.c为可执行文件,文件名为第一个文件名</span></span><br><span class=\"line\">Program(<span class=\"string\">'main'</span>, <span class=\"string\">'hello.c'</span>)  <span class=\"comment\"># 编译hello.c为可执行文件,文件名mian</span></span><br><span class=\"line\">Program(<span class=\"string\">'program'</span>, [<span class=\"string\">'prog.c'</span>, <span class=\"string\">'file1.c'</span>, <span class=\"string\">'file2.c'</span>])</span><br><span class=\"line\"><span class=\"comment\"># 也可以利用Glob函数获得名字列表</span></span><br><span class=\"line\"><span class=\"comment\"># Golb('*.c')返回规则匹配的string列表</span></span><br><span class=\"line\"><span class=\"comment\"># 就是类似上面的'prog.c', 'file1.c', 'file2.c'</span></span><br><span class=\"line\">Program(<span class=\"string\">'program'</span>, Glob(<span class=\"string\">'*.c'</span>) )</span><br><span class=\"line\"></span><br><span class=\"line\">Program(target = <span class=\"string\">'main'</span>, source = <span class=\"string\">'hello.c'</span>)  <span class=\"comment\"># 使用关键字指明编译对象</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"Object-：生成目标文件。如：\"><a href=\"#Object-：生成目标文件。如：\" class=\"headerlink\" title=\"Object()：生成目标文件。如：\"></a>Object()：生成目标文件。如：</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Object(<span class=\"string\">'hello.c'</span>)          <span class=\"comment\"># 编译hello.c，但只生成生成.o文件</span></span><br><span class=\"line\">Object(<span class=\"string\">'main'</span>, <span class=\"string\">'hello.c'</span>)  <span class=\"comment\"># 编译hello.c 为目标文件，文件名为main.o</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"生成库文件\"><a href=\"#生成库文件\" class=\"headerlink\" title=\"生成库文件\"></a>生成库文件</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Library()        <span class=\"comment\"># 生成库，默认为静态库。</span></span><br><span class=\"line\"></span><br><span class=\"line\">StaticLibrary()  <span class=\"comment\"># 生成静态库 .a</span></span><br><span class=\"line\"></span><br><span class=\"line\">ShareLibrary()   <span class=\"comment\"># 生成动态库 .so</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"scons-关键字\"><a href=\"#scons-关键字\" class=\"headerlink\" title=\"scons 关键字\"></a>scons 关键字</h1><p>编译相关关键字说明</p>\n<h2 id=\"基本的编译关键字\"><a href=\"#基本的编译关键字\" class=\"headerlink\" title=\"基本的编译关键字\"></a>基本的编译关键字</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>关键字</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CXXFLAGS</td>\n<td>编译参数</td>\n</tr>\n<tr>\n<td>CPPDEFINES</td>\n<td>指定预编译器 CPPDEFINES={‘RELEASE_BUILD’ : ‘1’}</td>\n</tr>\n<tr>\n<td>LIBS</td>\n<td>指定所需要链接的库文件</td>\n</tr>\n<tr>\n<td>LIBPATH</td>\n<td>指定库文件(.lib)的搜索目录</td>\n</tr>\n<tr>\n<td>CPPPATH</td>\n<td>指定[.h, .c, .cpp]等文件搜索路径，头文件路径</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"指定编译选项\"><a href=\"#指定编译选项\" class=\"headerlink\" title=\"指定编译选项\"></a>指定编译选项</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Program(target = <span class=\"string\">'bind_test1'</span>,</span><br><span class=\"line\">    source = [“bind_test1.cc”],</span><br><span class=\"line\">    LIBS = [<span class=\"string\">'boost_system'</span>,<span class=\"string\">'boost_filesystem'</span>, <span class=\"string\">'boost_thread'</span>],</span><br><span class=\"line\">    LIBPATH = [<span class=\"string\">'./'</span>, <span class=\"string\">'/usr/local/lib/'</span> ],</span><br><span class=\"line\">    CPPPATH = [<span class=\"string\">'./'</span>, <span class=\"string\">'/usr/local/include/'</span>],</span><br><span class=\"line\">    CCFLAGS = [<span class=\"string\">'-g'</span>,<span class=\"string\">'-O3′] ,</span></span><br><span class=\"line\"><span class=\"string\">    CPPDEFINES=&#123;'</span>RELEASE_BUILD<span class=\"string\">' : '</span><span class=\"number\">1</span><span class=\"string\">'&#125;</span></span><br><span class=\"line\"><span class=\"string\">)</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>注：LIBS和LIBPATH若为一个可以使用字符串，若为多个则使用列表</p>\n</blockquote>\n<h1 id=\"scons进阶\"><a href=\"#scons进阶\" class=\"headerlink\" title=\"scons进阶\"></a>scons进阶</h1><p>对于scons来说，环境变量(Environment)是异常重要的，只有会用Environment，才能写出真正可以实际使用的scons脚本。</p>\n<h2 id=\"构造环境变量\"><a href=\"#构造环境变量\" class=\"headerlink\" title=\"构造环境变量\"></a>构造环境变量</h2><p>由自己创建的环境变量，这个环境变量可以用来控制整个目标文件编译过程。</p>\n<p>一种构造环境变量的\b目的就是交叉编译器的设置，由于scons默认用的是gcc来编译系统，而嵌入式开发要使用指定的交叉编译器来编译目标文件，所以可通过构造环境变量来修改编译器。</p>\n<p>a) 创建</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">env = Environment(CC = <span class=\"string\">'arm-linux-gcc'</span>)</span><br></pre></td></tr></table></figure>\n<p>b) 使用</p>\n<p>用arm-linux-gcc编译执行文件</p>\n<p><code>env.Program(&#39;hello.c&#39;)</code></p>\n<p>c) 从构造环境变量获取值：</p>\n<p><code>print &quot;CC is:&quot;, env[&#39;CC&#39;]</code></p>\n<p>d) 拷贝</p>\n<p>我们想使用gcc编译2个不同版本的debug/realse版本的程序，就可以通过拷贝创建2个环境变量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">debug = env.Clone(CCFLAGS = <span class=\"string\">'-g'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">Realse = env.Clone(CCFLAGS = <span class=\"string\">'-O2'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">debug.Program(<span class=\"string\">'debug'</span>,<span class=\"string\">'hello.c'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">debug.Program(<span class=\"string\">'realse'</span>,<span class=\"string\">'hello.c'</span>)</span><br></pre></td></tr></table></figure>\n<p>e) 追加到末尾：Append()</p>\n<p><code>env.Append(CCFLAGS = &#39;-DLAST&#39;)</code></p>\n<p>f) 追加到开始位置：Prepend()</p>\n<p><code>env.Prepend(CCLFAGS = &#39;-DFIRST&#39;)</code></p>\n<h2 id=\"Python的os模块使用\"><a href=\"#Python的os模块使用\" class=\"headerlink\" title=\"Python的os模块使用\"></a>Python的os模块使用</h2><p>使用os模块，需要在每个脚本文件添加<code>import os</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.name      <span class=\"comment\"># 获取当前正在使用的平台，linux显示为'posix',windows返回的是'nt'</span></span><br><span class=\"line\">os.getcwd()  <span class=\"comment\"># 获取当前工作目录</span></span><br><span class=\"line\">os.getenv()  <span class=\"comment\"># 读取环境变量</span></span><br><span class=\"line\">os.putenv()  <span class=\"comment\"># 设置环境变量</span></span><br><span class=\"line\">os.listdir() <span class=\"comment\"># 返回指定目录下的所有文件和目录</span></span><br><span class=\"line\">os.remove()  <span class=\"comment\"># 删除一个文件</span></span><br><span class=\"line\">os.system()  <span class=\"comment\"># 运行shell命令</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"ARGUMENTS-get\"><a href=\"#ARGUMENTS-get\" class=\"headerlink\" title=\"ARGUMENTS.get()\"></a>ARGUMENTS.get()</h1><p>Values of variables to be passed to the SConscript file(s) may be specified on the command line:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scons debug=1 .</span><br></pre></td></tr></table></figure>\n<p>These variables are available in SConscript files through the ARGUMENTS dictionary, and can be used in the SConscript file(s) to modify the build in any way:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> ARGUMENTS.get(<span class=\"string\">'debug'</span>, <span class=\"number\">0</span>):</span><br><span class=\"line\">    env = Environment(CCFLAGS = <span class=\"string\">'-g'</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    env = Environment()</span><br></pre></td></tr></table></figure>\n<p>The command-line variable arguments are also available in the ARGLIST list, indexed by their order on the command line. This allows you to process them in order rather than by name, if necessary. ARGLIST[0] returns a tuple containing (argname, argvalue). A Python exception is thrown if you try to access a list member that does not exist.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"scons是什么\"><a href=\"#scons是什么\" class=\"headerlink\" title=\"scons是什么\"></a>scons是什么</h1><p><a href=\"https://scons.org/\" target=\"_blank\" rel=\"noopener\">office guide</a></p>\n<p>SCons 是一个开放源代码、以 Python 语言编写的下一代的程序建造工具。功能上类似于make。 </p>\n<p>一个单个文件的程序是不需要scons和make之类的构建工具的，只要用gcc或者g++编译就好。但是一些相对较大的项目有多个文件，各个文件之间的依赖关系复杂，如果用g++来编译就会非常复杂，不仅要写的命令多，而且容易出错，所以就出现了make，但是make可能也存在某些问题，就出现了scons。</p>\n<p>总之，这两种工具解决构建的方法就是用一个配置文件来记录下各个文件之间的依赖关系，用到了那些库，配置好环境变量等等，然后直接构建。scons并不是和g++一样的编译工具，而是在g++的基础上的工具。</p>\n<h1 id=\"scons的优势\"><a href=\"#scons的优势\" class=\"headerlink\" title=\"scons的优势\"></a>scons的优势</h1><ul>\n<li>使用 Python 脚本做为配置文件</li>\n<li>对于 C,C++ 和 Fortran, 内建支持可靠自动依赖分析 . 不用像 make 工具那样需要 执行”make depends”和”make clean”就可以获得所有的依赖关系。</li>\n<li>内建支持 C, C++, D, Java, Fortran, Yacc, Lex, Qt，SWIG 以及 Tex/Latex。 用户还可以根据自己的需要进行扩展以获得对需要编程语言的支持。</li>\n<li>支持 make -j 风格的并行建造。相比 make -j, SCons 可以同时运行 N 个工作，而 不用担心代码的层次结构。</li>\n<li>使用 Autoconf 风格查找头文件，函数库，函数和类型定义。 </li>\n<li>良好的夸平台性。SCons 可以运行在 Linux, AIX, BSD, HP/UX, IRIX, Solaris, Windows, Mac OS X 和 OS/2 上。</li>\n</ul>\n<h1 id=\"scons的配置文件\"><a href=\"#scons的配置文件\" class=\"headerlink\" title=\"scons的配置文件\"></a>scons的配置文件</h1><p>SConstruct是scons的配置文件，是用python编写的，自然要遵守python语法</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 指定SConstruct</span></span><br><span class=\"line\">scons -f &lt;SConstruct file&gt;</span><br></pre></td></tr></table></figure>\n<h1 id=\"scons命令\"><a href=\"#scons命令\" class=\"headerlink\" title=\"scons命令\"></a>scons命令</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scons -Q <span class=\"comment\"># 减少编译时的由 scons 产生的冗余信息，关闭一些输出提示</span></span><br><span class=\"line\">scons -c <span class=\"comment\"># scons -clean，根据SConstruct文件，执行清理任务</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"SConstruct-文件常用函数\"><a href=\"#SConstruct-文件常用函数\" class=\"headerlink\" title=\"SConstruct 文件常用函数\"></a>SConstruct 文件常用函数</h1><h2 id=\"Program-：生成可执行文件\"><a href=\"#Program-：生成可执行文件\" class=\"headerlink\" title=\"Program()：生成可执行文件\"></a>Program()：生成可执行文件</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Program(target, source, libs) </span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">编译hello.c并生成.o文件和可执行文件</span></span><br><span class=\"line\"><span class=\"string\">target:编译的目标文件名 </span></span><br><span class=\"line\"><span class=\"string\">source:需要编译的文件组 </span></span><br><span class=\"line\"><span class=\"string\">libs:  需要的所有库 </span></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\">Program(<span class=\"string\">'hello.c'</span>)  <span class=\"comment\"># 编译hello.c为可执行文件,文件名为第一个文件名</span></span><br><span class=\"line\">Program(<span class=\"string\">'main'</span>, <span class=\"string\">'hello.c'</span>)  <span class=\"comment\"># 编译hello.c为可执行文件,文件名mian</span></span><br><span class=\"line\">Program(<span class=\"string\">'program'</span>, [<span class=\"string\">'prog.c'</span>, <span class=\"string\">'file1.c'</span>, <span class=\"string\">'file2.c'</span>])</span><br><span class=\"line\"><span class=\"comment\"># 也可以利用Glob函数获得名字列表</span></span><br><span class=\"line\"><span class=\"comment\"># Golb('*.c')返回规则匹配的string列表</span></span><br><span class=\"line\"><span class=\"comment\"># 就是类似上面的'prog.c', 'file1.c', 'file2.c'</span></span><br><span class=\"line\">Program(<span class=\"string\">'program'</span>, Glob(<span class=\"string\">'*.c'</span>) )</span><br><span class=\"line\"></span><br><span class=\"line\">Program(target = <span class=\"string\">'main'</span>, source = <span class=\"string\">'hello.c'</span>)  <span class=\"comment\"># 使用关键字指明编译对象</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"Object-：生成目标文件。如：\"><a href=\"#Object-：生成目标文件。如：\" class=\"headerlink\" title=\"Object()：生成目标文件。如：\"></a>Object()：生成目标文件。如：</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Object(<span class=\"string\">'hello.c'</span>)          <span class=\"comment\"># 编译hello.c，但只生成生成.o文件</span></span><br><span class=\"line\">Object(<span class=\"string\">'main'</span>, <span class=\"string\">'hello.c'</span>)  <span class=\"comment\"># 编译hello.c 为目标文件，文件名为main.o</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"生成库文件\"><a href=\"#生成库文件\" class=\"headerlink\" title=\"生成库文件\"></a>生成库文件</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Library()        <span class=\"comment\"># 生成库，默认为静态库。</span></span><br><span class=\"line\"></span><br><span class=\"line\">StaticLibrary()  <span class=\"comment\"># 生成静态库 .a</span></span><br><span class=\"line\"></span><br><span class=\"line\">ShareLibrary()   <span class=\"comment\"># 生成动态库 .so</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"scons-关键字\"><a href=\"#scons-关键字\" class=\"headerlink\" title=\"scons 关键字\"></a>scons 关键字</h1><p>编译相关关键字说明</p>\n<h2 id=\"基本的编译关键字\"><a href=\"#基本的编译关键字\" class=\"headerlink\" title=\"基本的编译关键字\"></a>基本的编译关键字</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>关键字</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CXXFLAGS</td>\n<td>编译参数</td>\n</tr>\n<tr>\n<td>CPPDEFINES</td>\n<td>指定预编译器 CPPDEFINES={‘RELEASE_BUILD’ : ‘1’}</td>\n</tr>\n<tr>\n<td>LIBS</td>\n<td>指定所需要链接的库文件</td>\n</tr>\n<tr>\n<td>LIBPATH</td>\n<td>指定库文件(.lib)的搜索目录</td>\n</tr>\n<tr>\n<td>CPPPATH</td>\n<td>指定[.h, .c, .cpp]等文件搜索路径，头文件路径</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"指定编译选项\"><a href=\"#指定编译选项\" class=\"headerlink\" title=\"指定编译选项\"></a>指定编译选项</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Program(target = <span class=\"string\">'bind_test1'</span>,</span><br><span class=\"line\">    source = [“bind_test1.cc”],</span><br><span class=\"line\">    LIBS = [<span class=\"string\">'boost_system'</span>,<span class=\"string\">'boost_filesystem'</span>, <span class=\"string\">'boost_thread'</span>],</span><br><span class=\"line\">    LIBPATH = [<span class=\"string\">'./'</span>, <span class=\"string\">'/usr/local/lib/'</span> ],</span><br><span class=\"line\">    CPPPATH = [<span class=\"string\">'./'</span>, <span class=\"string\">'/usr/local/include/'</span>],</span><br><span class=\"line\">    CCFLAGS = [<span class=\"string\">'-g'</span>,<span class=\"string\">'-O3′] ,</span></span><br><span class=\"line\"><span class=\"string\">    CPPDEFINES=&#123;'</span>RELEASE_BUILD<span class=\"string\">' : '</span><span class=\"number\">1</span><span class=\"string\">'&#125;</span></span><br><span class=\"line\"><span class=\"string\">)</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>注：LIBS和LIBPATH若为一个可以使用字符串，若为多个则使用列表</p>\n</blockquote>\n<h1 id=\"scons进阶\"><a href=\"#scons进阶\" class=\"headerlink\" title=\"scons进阶\"></a>scons进阶</h1><p>对于scons来说，环境变量(Environment)是异常重要的，只有会用Environment，才能写出真正可以实际使用的scons脚本。</p>\n<h2 id=\"构造环境变量\"><a href=\"#构造环境变量\" class=\"headerlink\" title=\"构造环境变量\"></a>构造环境变量</h2><p>由自己创建的环境变量，这个环境变量可以用来控制整个目标文件编译过程。</p>\n<p>一种构造环境变量的\b目的就是交叉编译器的设置，由于scons默认用的是gcc来编译系统，而嵌入式开发要使用指定的交叉编译器来编译目标文件，所以可通过构造环境变量来修改编译器。</p>\n<p>a) 创建</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">env = Environment(CC = <span class=\"string\">'arm-linux-gcc'</span>)</span><br></pre></td></tr></table></figure>\n<p>b) 使用</p>\n<p>用arm-linux-gcc编译执行文件</p>\n<p><code>env.Program(&#39;hello.c&#39;)</code></p>\n<p>c) 从构造环境变量获取值：</p>\n<p><code>print &quot;CC is:&quot;, env[&#39;CC&#39;]</code></p>\n<p>d) 拷贝</p>\n<p>我们想使用gcc编译2个不同版本的debug/realse版本的程序，就可以通过拷贝创建2个环境变量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">debug = env.Clone(CCFLAGS = <span class=\"string\">'-g'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">Realse = env.Clone(CCFLAGS = <span class=\"string\">'-O2'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">debug.Program(<span class=\"string\">'debug'</span>,<span class=\"string\">'hello.c'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">debug.Program(<span class=\"string\">'realse'</span>,<span class=\"string\">'hello.c'</span>)</span><br></pre></td></tr></table></figure>\n<p>e) 追加到末尾：Append()</p>\n<p><code>env.Append(CCFLAGS = &#39;-DLAST&#39;)</code></p>\n<p>f) 追加到开始位置：Prepend()</p>\n<p><code>env.Prepend(CCLFAGS = &#39;-DFIRST&#39;)</code></p>\n<h2 id=\"Python的os模块使用\"><a href=\"#Python的os模块使用\" class=\"headerlink\" title=\"Python的os模块使用\"></a>Python的os模块使用</h2><p>使用os模块，需要在每个脚本文件添加<code>import os</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\">os.name      <span class=\"comment\"># 获取当前正在使用的平台，linux显示为'posix',windows返回的是'nt'</span></span><br><span class=\"line\">os.getcwd()  <span class=\"comment\"># 获取当前工作目录</span></span><br><span class=\"line\">os.getenv()  <span class=\"comment\"># 读取环境变量</span></span><br><span class=\"line\">os.putenv()  <span class=\"comment\"># 设置环境变量</span></span><br><span class=\"line\">os.listdir() <span class=\"comment\"># 返回指定目录下的所有文件和目录</span></span><br><span class=\"line\">os.remove()  <span class=\"comment\"># 删除一个文件</span></span><br><span class=\"line\">os.system()  <span class=\"comment\"># 运行shell命令</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"ARGUMENTS-get\"><a href=\"#ARGUMENTS-get\" class=\"headerlink\" title=\"ARGUMENTS.get()\"></a>ARGUMENTS.get()</h1><p>Values of variables to be passed to the SConscript file(s) may be specified on the command line:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scons debug=1 .</span><br></pre></td></tr></table></figure>\n<p>These variables are available in SConscript files through the ARGUMENTS dictionary, and can be used in the SConscript file(s) to modify the build in any way:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> ARGUMENTS.get(<span class=\"string\">'debug'</span>, <span class=\"number\">0</span>):</span><br><span class=\"line\">    env = Environment(CCFLAGS = <span class=\"string\">'-g'</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    env = Environment()</span><br></pre></td></tr></table></figure>\n<p>The command-line variable arguments are also available in the ARGLIST list, indexed by their order on the command line. This allows you to process them in order rather than by name, if necessary. ARGLIST[0] returns a tuple containing (argname, argvalue). A Python exception is thrown if you try to access a list member that does not exist.</p>\n"},{"title":"tensorflow spacial API ","date":"2018-07-19T16:33:38.000Z","_content":"\nhttps://www.jianshu.com/p/fceb64c790f3\n\nhttps://segmentfault.com/a/1190000014799038\n\n\ntf.stack()\nh","source":"_posts/201807-tensorflow-spacial-API.md","raw":"---\ntitle: 'tensorflow spacial API '\ndate: 2018-07-20 00:33:38\ntags:\n---\n\nhttps://www.jianshu.com/p/fceb64c790f3\n\nhttps://segmentfault.com/a/1190000014799038\n\n\ntf.stack()\nh","slug":"tensorflow-spacial-API","published":1,"updated":"2018-07-23T02:54:17.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7y3001an61da0v5uw20","content":"<p><a href=\"https://www.jianshu.com/p/fceb64c790f3\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/fceb64c790f3</a></p>\n<p><a href=\"https://segmentfault.com/a/1190000014799038\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000014799038</a></p>\n<p>tf.stack()<br>h</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.jianshu.com/p/fceb64c790f3\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/fceb64c790f3</a></p>\n<p><a href=\"https://segmentfault.com/a/1190000014799038\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000014799038</a></p>\n<p>tf.stack()<br>h</p>\n"},{"title":"spark 开发中遇到的一些问题总结","date":"2018-07-29T16:30:07.000Z","_content":"\n不知道spark怎么调bug，没有系统学习过，摸着石头过河吧。\n\n# 卡在一个excutor上，没有报错\n\n因为一台机器的内存分配给越多的executor，每个executor的内存就越小，以致出现过多的数据spill over甚至out of memory的情况。\n把这个参数调大些试试:spark.shuffle.memoryFraction\n\n参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。\n\n参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。\n\n设置了参数，如下，可以跑完，但是变得很慢。\n\n``` java\nSparkConf sc = new SparkConf()\n.setAppName(\"SparkCalculateSR\")\n.set(\"spark.storage.memoryFraction\", \"0.2\")\n.set(\"spark.default.parallelism\", \"20\")\n.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n.set(\"spark.shuffle.consolidateFiles\", \"true\")  // consolidateFiles这个参数是hashshuffle的时候用的\n.set(\"spark.reducer.maxSizeInFlight\", \"100m\")\n.set(\"spark.shuffle.file.buffer\", \"100k\")\n.set(\"spark.shuffle.io.maxRetries\", \"10\")\n.set(\"spark.shuffle.io.retryWait\", \"10s\");\n```\n\n继续建议：\n\n上边设置的参数可以提高shuffle的稳定性,所以是跑成功了.如果要增大shuffle使用executor内存可以调下边两个参数\n- num-executors 100 --这个调小\n- spark.shuffle.memoryFraction --这个调大 \n\n不知道具体慢在哪了,所以没法给具体的优化建议.你采用的是hashshuffle吗? consolidateFiles这个参数是hashshuffle的时候用的,要不改成SortShuffle试试,一般慢都慢在shuffle上了\n\n## ref\n\n[spark 卡住](https://bbs.csdn.net/topics/392142267)\n\n# spark 配置计算\n\n``` s\n--num-executors 100 \\\n--driver-memory 6g \\\n--executor-memory 6g \\\n--executor-cores 8 \\\n```\n\n100个executors  一个executor-memory 6G内存  8核cpu   那得多少内存多少cpu啊\n\n答案：600g内存， 800核\n\n# 参考：[开发中遇到的一些问题](https://www.cnblogs.com/arachis/p/Spark_prog.html) 文中有很多之前碰到的问题\n\n1.StackOverflowError\n\n问题：简单代码记录 :\n\nfor (day <- days){\n\n　　rdd = rdd.union(sc.textFile(/path/to/day) .... )\n\n}\n\n大概场景就是我想把数量比较多的文件合并成一个大rdd,从而导致了栈溢出；\n\n解决：很明显是方法递归调用太多，我之后改成了几个小任务进行了合并；这里union也会造成最终rdd分区数过多\n\n2.java.io.FileNotFoundException: /tmp/spark-90507c1d-e98 ..... temp_shuffle_98deadd9-f7c3-4a12(No such file or directory) 类似这种 \n\n报错：Exception in thread \"main\" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 76.0 failed 4 times, most recent failure: Lost task 0.3 in stage 76.0 (TID 341, 10.5.0.90): java.io.FileNotFoundException: /tmp/spark-90507c1d-e983-422d-9e01-74ff0a5a2806/executor-360151d5-6b83-4e3e-a0c6-6ddc955cb16c/blockmgr-bca2bde9-212f-4219-af8b-ef0415d60bfa/26/temp_shuffle_98deadd9-f7c3-4a12-9a30-7749f097b5c8 (No such file or directory)\n\n场景：大概代码和上面差不多：\n\nfor (day <- days){\n\n　　rdd = rdd.union(sc.textFile(/path/to/day) .... )\n\n}\n\nrdd.map( ... )\n\n解决：简单的map都会报错，怀疑是临时文件过多；查看一下rdd.partitions.length 果然有4k多个；基本思路就是减少分区数\n\n可以在union的时候就进行重分区：\n\nfor (day <- days){\n\n　　rdd = rdd.union(sc.textFile(/path/to/day,numPartitions) .... )\n\n　　rdd = rdd.coalesce(numPartitions)\n\n} //这里因为默认哈希分区，并且分区数相同；所有最终union的rdd的分区数不会增多,贴一下源码以防说错\n\n``` scala\n/** Build the union of a list of RDDs. */\n def union[T: ClassTag](rdds: Seq[RDD[T]]): RDD[T] = withScope {\n   val partitioners = rdds.flatMap(_.partitioner).toSet\n   if (rdds.forall(_.partitioner.isDefined) && partitioners.size == 1) {\n     /*这里如果rdd的分区函数都相同则会构建一个PartitionerAwareUnionRDD：m RDDs with p partitions each\n* will be unified to a single RDD with p partitions*/\n     new PartitionerAwareUnionRDD(this, rdds)\n   } else {\n     new UnionRDD(this, rdds)\n   }\n }\n```\n\n或者最后在重分区\n\nfor (day <- days){\n\n　　rdd = rdd.union(sc.textFile(/path/to/day) .... )\n\n} \n\nrdd.repartition(numPartitions)\n\n\n# Spark Shuffle FetchFailedException解决方案\n\n在大规模数据处理中，这是个比较常见的错误。\n\n报错提示\n\nSparkSQL shuffle操作带来的报错\n\n``` java\norg.apache.spark.shuffle.MetadataFetchFailedException: \nMissing an output location for shuffle 0\n\norg.apache.spark.shuffle.FetchFailedException:\nFailed to connect to hostname/192.168.xx.xxx:50268\n\nRDD的shuffle操作带来的报错\nWARN TaskSetManager: Lost task 17.1 in stage 4.1 (TID 1386, spark050013): java.io.FileNotFoundException: /data04/spark/tmp/blockmgr-817d372f-c359-4a00-96dd-8f6554aa19cd/2f/temp_shuffle_e22e013a-5392-4edb-9874-a196a1dad97c (没有那个文件或目录)\n\nFetchFailed(BlockManagerId(6083b277-119a-49e8-8a49-3539690a2a3f-S155, spark050013, 8533), shuffleId=1, mapId=143, reduceId=3, message=\norg.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/data04/spark/tmp/blockmgr-817d372f-c359-4a00-96dd-8f6554aa19cd/0e/shuffle_1_143_0.data, offset=997061, length=112503}\n```\n\n原因\n\nshuffle分为shuffle write和shuffle read两部分。 \nshuffle write的分区数由上一阶段的RDD分区数控制，shuffle read的分区数则是由Spark提供的一些参数控制。\n\nshuffle write可以简单理解为类似于saveAsLocalDiskFile的操作，将计算的中间结果按某种规则临时放到各个executor所在的本地磁盘上。\n\nshuffle read的时候数据的分区数则是由spark提供的一些参数控制。可以想到的是，如果这个参数值设置的很小，同时shuffle read的量很大，那么将会导致一个task需要处理的数据非常大。结果导致JVM crash，从而导致取shuffle数据失败，同时executor也丢失了，看到Failed to connect to host的错误，也就是executor lost的意思。有时候即使不会导致JVM crash也会造成长时间的gc。\n\n解决办法\n\n知道原因后问题就好解决了，主要从shuffle的数据量和处理shuffle数据的分区数两个角度入手。\n\n减少shuffle数据\n\n思考是否可以使用map side join或是broadcast join来规避shuffle的产生。\n\n将不必要的数据在shuffle前进行过滤，比如原始数据有20个字段，只要选取需要的字段进行处理即可，将会减少一定的shuffle数据。\n\nSparkSQL和DataFrame的join,group by等操作\n\n通过spark.sql.shuffle.partitions控制分区数，默认为200，根据shuffle的量以及计算的复杂度提高这个值。\n\nRdd的join,groupBy,reduceByKey等操作\n\n通过spark.default.parallelism控制shuffle read与reduce处理的分区数，默认为运行任务的core的总数（mesos细粒度模式为8个，local模式为本地的core总数），官方建议为设置成运行任务的core的2-3倍。\n\n提高executor的内存\n\n通过spark.executor.memory适当提高executor的memory值。\n\n是否存在数据倾斜的问题\n\n空值是否已经过滤？异常数据（某个key数据特别大）是否可以单独处理？考虑改变数据分区规则。\n\nspark 分区详解 shuffle过程\n\n\n1、报错：ERROR storage.DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /hadoop/application_1415632483774_448143/spark-local-20141127115224-9ca8/04/shuffle_1_1562_27\n\njava.io.FileNotFoundException: /hadoop/application_1415632483774_448143/spark-local-20141127115224-9ca8/04/shuffle_1_1562_27 (No such file or directory)\n\n　　表面上看是因为shuffle没有地方写了，如果后面的stack是local space 的问题，那么清一下磁盘就好了。上面这种问题，是因为一个excutor给分配的内存不够，此时，减少excutor-core的数量，加大excutor-memory的值应该就没有问题。\n\n2、报错：ERROR executor.CoarseGrainedExecutorBackend: Driver Disassociated [akka.tcp://sparkExecutor@pc-jfqdfx31:48586] -> [akka.tcp://sparkDriver@pc-jfqdfx30:41656] disassociated! Shutting down.\n15/07/23 10:50:56 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL 15: SIGTERM\n\n　　这个错误比较隐晦，从信息上看来不知道是什么问题，但是归根结底还是内存的问题，有两个方法可以解决这个错误，一是，如上面所说，加大excutor-memory的值，减少executor-cores的数量，问题可以解决。二是，加大executor.overhead的值，但是这样其实并没有解决掉根本的问题。所以如果集群的资源是支持的话，就用1的办法吧。\n\n　　另外，这个错误也出现在partitionBy(new HashPartition(partiton-num))时，如果partiton-num太大或者太小的时候会报这种错误，说白了也是内存的原因，不过这个时候增加内存和overhead没有什么用，得去调整这个partiton-num的值。\n\n配置详解","source":"_posts/201807-spark-common-error-in-development.md","raw":"---\ntitle: spark 开发中遇到的一些问题总结\ndate: 2018-07-30 00:30:07\ntags:\n---\n\n不知道spark怎么调bug，没有系统学习过，摸着石头过河吧。\n\n# 卡在一个excutor上，没有报错\n\n因为一台机器的内存分配给越多的executor，每个executor的内存就越小，以致出现过多的数据spill over甚至out of memory的情况。\n把这个参数调大些试试:spark.shuffle.memoryFraction\n\n参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。\n\n参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。\n\n设置了参数，如下，可以跑完，但是变得很慢。\n\n``` java\nSparkConf sc = new SparkConf()\n.setAppName(\"SparkCalculateSR\")\n.set(\"spark.storage.memoryFraction\", \"0.2\")\n.set(\"spark.default.parallelism\", \"20\")\n.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n.set(\"spark.shuffle.consolidateFiles\", \"true\")  // consolidateFiles这个参数是hashshuffle的时候用的\n.set(\"spark.reducer.maxSizeInFlight\", \"100m\")\n.set(\"spark.shuffle.file.buffer\", \"100k\")\n.set(\"spark.shuffle.io.maxRetries\", \"10\")\n.set(\"spark.shuffle.io.retryWait\", \"10s\");\n```\n\n继续建议：\n\n上边设置的参数可以提高shuffle的稳定性,所以是跑成功了.如果要增大shuffle使用executor内存可以调下边两个参数\n- num-executors 100 --这个调小\n- spark.shuffle.memoryFraction --这个调大 \n\n不知道具体慢在哪了,所以没法给具体的优化建议.你采用的是hashshuffle吗? consolidateFiles这个参数是hashshuffle的时候用的,要不改成SortShuffle试试,一般慢都慢在shuffle上了\n\n## ref\n\n[spark 卡住](https://bbs.csdn.net/topics/392142267)\n\n# spark 配置计算\n\n``` s\n--num-executors 100 \\\n--driver-memory 6g \\\n--executor-memory 6g \\\n--executor-cores 8 \\\n```\n\n100个executors  一个executor-memory 6G内存  8核cpu   那得多少内存多少cpu啊\n\n答案：600g内存， 800核\n\n# 参考：[开发中遇到的一些问题](https://www.cnblogs.com/arachis/p/Spark_prog.html) 文中有很多之前碰到的问题\n\n1.StackOverflowError\n\n问题：简单代码记录 :\n\nfor (day <- days){\n\n　　rdd = rdd.union(sc.textFile(/path/to/day) .... )\n\n}\n\n大概场景就是我想把数量比较多的文件合并成一个大rdd,从而导致了栈溢出；\n\n解决：很明显是方法递归调用太多，我之后改成了几个小任务进行了合并；这里union也会造成最终rdd分区数过多\n\n2.java.io.FileNotFoundException: /tmp/spark-90507c1d-e98 ..... temp_shuffle_98deadd9-f7c3-4a12(No such file or directory) 类似这种 \n\n报错：Exception in thread \"main\" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 76.0 failed 4 times, most recent failure: Lost task 0.3 in stage 76.0 (TID 341, 10.5.0.90): java.io.FileNotFoundException: /tmp/spark-90507c1d-e983-422d-9e01-74ff0a5a2806/executor-360151d5-6b83-4e3e-a0c6-6ddc955cb16c/blockmgr-bca2bde9-212f-4219-af8b-ef0415d60bfa/26/temp_shuffle_98deadd9-f7c3-4a12-9a30-7749f097b5c8 (No such file or directory)\n\n场景：大概代码和上面差不多：\n\nfor (day <- days){\n\n　　rdd = rdd.union(sc.textFile(/path/to/day) .... )\n\n}\n\nrdd.map( ... )\n\n解决：简单的map都会报错，怀疑是临时文件过多；查看一下rdd.partitions.length 果然有4k多个；基本思路就是减少分区数\n\n可以在union的时候就进行重分区：\n\nfor (day <- days){\n\n　　rdd = rdd.union(sc.textFile(/path/to/day,numPartitions) .... )\n\n　　rdd = rdd.coalesce(numPartitions)\n\n} //这里因为默认哈希分区，并且分区数相同；所有最终union的rdd的分区数不会增多,贴一下源码以防说错\n\n``` scala\n/** Build the union of a list of RDDs. */\n def union[T: ClassTag](rdds: Seq[RDD[T]]): RDD[T] = withScope {\n   val partitioners = rdds.flatMap(_.partitioner).toSet\n   if (rdds.forall(_.partitioner.isDefined) && partitioners.size == 1) {\n     /*这里如果rdd的分区函数都相同则会构建一个PartitionerAwareUnionRDD：m RDDs with p partitions each\n* will be unified to a single RDD with p partitions*/\n     new PartitionerAwareUnionRDD(this, rdds)\n   } else {\n     new UnionRDD(this, rdds)\n   }\n }\n```\n\n或者最后在重分区\n\nfor (day <- days){\n\n　　rdd = rdd.union(sc.textFile(/path/to/day) .... )\n\n} \n\nrdd.repartition(numPartitions)\n\n\n# Spark Shuffle FetchFailedException解决方案\n\n在大规模数据处理中，这是个比较常见的错误。\n\n报错提示\n\nSparkSQL shuffle操作带来的报错\n\n``` java\norg.apache.spark.shuffle.MetadataFetchFailedException: \nMissing an output location for shuffle 0\n\norg.apache.spark.shuffle.FetchFailedException:\nFailed to connect to hostname/192.168.xx.xxx:50268\n\nRDD的shuffle操作带来的报错\nWARN TaskSetManager: Lost task 17.1 in stage 4.1 (TID 1386, spark050013): java.io.FileNotFoundException: /data04/spark/tmp/blockmgr-817d372f-c359-4a00-96dd-8f6554aa19cd/2f/temp_shuffle_e22e013a-5392-4edb-9874-a196a1dad97c (没有那个文件或目录)\n\nFetchFailed(BlockManagerId(6083b277-119a-49e8-8a49-3539690a2a3f-S155, spark050013, 8533), shuffleId=1, mapId=143, reduceId=3, message=\norg.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer{file=/data04/spark/tmp/blockmgr-817d372f-c359-4a00-96dd-8f6554aa19cd/0e/shuffle_1_143_0.data, offset=997061, length=112503}\n```\n\n原因\n\nshuffle分为shuffle write和shuffle read两部分。 \nshuffle write的分区数由上一阶段的RDD分区数控制，shuffle read的分区数则是由Spark提供的一些参数控制。\n\nshuffle write可以简单理解为类似于saveAsLocalDiskFile的操作，将计算的中间结果按某种规则临时放到各个executor所在的本地磁盘上。\n\nshuffle read的时候数据的分区数则是由spark提供的一些参数控制。可以想到的是，如果这个参数值设置的很小，同时shuffle read的量很大，那么将会导致一个task需要处理的数据非常大。结果导致JVM crash，从而导致取shuffle数据失败，同时executor也丢失了，看到Failed to connect to host的错误，也就是executor lost的意思。有时候即使不会导致JVM crash也会造成长时间的gc。\n\n解决办法\n\n知道原因后问题就好解决了，主要从shuffle的数据量和处理shuffle数据的分区数两个角度入手。\n\n减少shuffle数据\n\n思考是否可以使用map side join或是broadcast join来规避shuffle的产生。\n\n将不必要的数据在shuffle前进行过滤，比如原始数据有20个字段，只要选取需要的字段进行处理即可，将会减少一定的shuffle数据。\n\nSparkSQL和DataFrame的join,group by等操作\n\n通过spark.sql.shuffle.partitions控制分区数，默认为200，根据shuffle的量以及计算的复杂度提高这个值。\n\nRdd的join,groupBy,reduceByKey等操作\n\n通过spark.default.parallelism控制shuffle read与reduce处理的分区数，默认为运行任务的core的总数（mesos细粒度模式为8个，local模式为本地的core总数），官方建议为设置成运行任务的core的2-3倍。\n\n提高executor的内存\n\n通过spark.executor.memory适当提高executor的memory值。\n\n是否存在数据倾斜的问题\n\n空值是否已经过滤？异常数据（某个key数据特别大）是否可以单独处理？考虑改变数据分区规则。\n\nspark 分区详解 shuffle过程\n\n\n1、报错：ERROR storage.DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /hadoop/application_1415632483774_448143/spark-local-20141127115224-9ca8/04/shuffle_1_1562_27\n\njava.io.FileNotFoundException: /hadoop/application_1415632483774_448143/spark-local-20141127115224-9ca8/04/shuffle_1_1562_27 (No such file or directory)\n\n　　表面上看是因为shuffle没有地方写了，如果后面的stack是local space 的问题，那么清一下磁盘就好了。上面这种问题，是因为一个excutor给分配的内存不够，此时，减少excutor-core的数量，加大excutor-memory的值应该就没有问题。\n\n2、报错：ERROR executor.CoarseGrainedExecutorBackend: Driver Disassociated [akka.tcp://sparkExecutor@pc-jfqdfx31:48586] -> [akka.tcp://sparkDriver@pc-jfqdfx30:41656] disassociated! Shutting down.\n15/07/23 10:50:56 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL 15: SIGTERM\n\n　　这个错误比较隐晦，从信息上看来不知道是什么问题，但是归根结底还是内存的问题，有两个方法可以解决这个错误，一是，如上面所说，加大excutor-memory的值，减少executor-cores的数量，问题可以解决。二是，加大executor.overhead的值，但是这样其实并没有解决掉根本的问题。所以如果集群的资源是支持的话，就用1的办法吧。\n\n　　另外，这个错误也出现在partitionBy(new HashPartition(partiton-num))时，如果partiton-num太大或者太小的时候会报这种错误，说白了也是内存的原因，不过这个时候增加内存和overhead没有什么用，得去调整这个partiton-num的值。\n\n配置详解","slug":"spark-common-error-in-development","published":1,"updated":"2018-08-09T16:43:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7y5001dn61dev1x8c0g","content":"<p>不知道spark怎么调bug，没有系统学习过，摸着石头过河吧。</p>\n<h1 id=\"卡在一个excutor上，没有报错\"><a href=\"#卡在一个excutor上，没有报错\" class=\"headerlink\" title=\"卡在一个excutor上，没有报错\"></a>卡在一个excutor上，没有报错</h1><p>因为一台机器的内存分配给越多的executor，每个executor的内存就越小，以致出现过多的数据spill over甚至out of memory的情况。<br>把这个参数调大些试试:spark.shuffle.memoryFraction</p>\n<p>参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</p>\n<p>参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>\n<p>设置了参数，如下，可以跑完，但是变得很慢。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SparkConf sc = <span class=\"keyword\">new</span> SparkConf()</span><br><span class=\"line\">.setAppName(<span class=\"string\">\"SparkCalculateSR\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.storage.memoryFraction\"</span>, <span class=\"string\">\"0.2\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.default.parallelism\"</span>, <span class=\"string\">\"20\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.serializer\"</span>, <span class=\"string\">\"org.apache.spark.serializer.KryoSerializer\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.shuffle.consolidateFiles\"</span>, <span class=\"string\">\"true\"</span>)  <span class=\"comment\">// consolidateFiles这个参数是hashshuffle的时候用的</span></span><br><span class=\"line\">.set(<span class=\"string\">\"spark.reducer.maxSizeInFlight\"</span>, <span class=\"string\">\"100m\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.shuffle.file.buffer\"</span>, <span class=\"string\">\"100k\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.shuffle.io.maxRetries\"</span>, <span class=\"string\">\"10\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.shuffle.io.retryWait\"</span>, <span class=\"string\">\"10s\"</span>);</span><br></pre></td></tr></table></figure>\n<p>继续建议：</p>\n<p>上边设置的参数可以提高shuffle的稳定性,所以是跑成功了.如果要增大shuffle使用executor内存可以调下边两个参数</p>\n<ul>\n<li>num-executors 100 —这个调小</li>\n<li>spark.shuffle.memoryFraction —这个调大 </li>\n</ul>\n<p>不知道具体慢在哪了,所以没法给具体的优化建议.你采用的是hashshuffle吗? consolidateFiles这个参数是hashshuffle的时候用的,要不改成SortShuffle试试,一般慢都慢在shuffle上了</p>\n<h2 id=\"ref\"><a href=\"#ref\" class=\"headerlink\" title=\"ref\"></a>ref</h2><p><a href=\"https://bbs.csdn.net/topics/392142267\" target=\"_blank\" rel=\"noopener\">spark 卡住</a></p>\n<h1 id=\"spark-配置计算\"><a href=\"#spark-配置计算\" class=\"headerlink\" title=\"spark 配置计算\"></a>spark 配置计算</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--num-executors 100 \\</span><br><span class=\"line\">--driver-memory 6g \\</span><br><span class=\"line\">--executor-memory 6g \\</span><br><span class=\"line\">--executor-cores 8 \\</span><br></pre></td></tr></table></figure>\n<p>100个executors  一个executor-memory 6G内存  8核cpu   那得多少内存多少cpu啊</p>\n<p>答案：600g内存， 800核</p>\n<h1 id=\"参考：开发中遇到的一些问题-文中有很多之前碰到的问题\"><a href=\"#参考：开发中遇到的一些问题-文中有很多之前碰到的问题\" class=\"headerlink\" title=\"参考：开发中遇到的一些问题 文中有很多之前碰到的问题\"></a>参考：<a href=\"https://www.cnblogs.com/arachis/p/Spark_prog.html\" target=\"_blank\" rel=\"noopener\">开发中遇到的一些问题</a> 文中有很多之前碰到的问题</h1><p>1.StackOverflowError</p>\n<p>问题：简单代码记录 :</p>\n<p>for (day &lt;- days){</p>\n<p>　　rdd = rdd.union(sc.textFile(/path/to/day) …. )</p>\n<p>}</p>\n<p>大概场景就是我想把数量比较多的文件合并成一个大rdd,从而导致了栈溢出；</p>\n<p>解决：很明显是方法递归调用太多，我之后改成了几个小任务进行了合并；这里union也会造成最终rdd分区数过多</p>\n<p>2.java.io.FileNotFoundException: /tmp/spark-90507c1d-e98 ….. temp_shuffle_98deadd9-f7c3-4a12(No such file or directory) 类似这种 </p>\n<p>报错：Exception in thread “main” org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 76.0 failed 4 times, most recent failure: Lost task 0.3 in stage 76.0 (TID 341, 10.5.0.90): java.io.FileNotFoundException: /tmp/spark-90507c1d-e983-422d-9e01-74ff0a5a2806/executor-360151d5-6b83-4e3e-a0c6-6ddc955cb16c/blockmgr-bca2bde9-212f-4219-af8b-ef0415d60bfa/26/temp_shuffle_98deadd9-f7c3-4a12-9a30-7749f097b5c8 (No such file or directory)</p>\n<p>场景：大概代码和上面差不多：</p>\n<p>for (day &lt;- days){</p>\n<p>　　rdd = rdd.union(sc.textFile(/path/to/day) …. )</p>\n<p>}</p>\n<p>rdd.map( … )</p>\n<p>解决：简单的map都会报错，怀疑是临时文件过多；查看一下rdd.partitions.length 果然有4k多个；基本思路就是减少分区数</p>\n<p>可以在union的时候就进行重分区：</p>\n<p>for (day &lt;- days){</p>\n<p>　　rdd = rdd.union(sc.textFile(/path/to/day,numPartitions) …. )</p>\n<p>　　rdd = rdd.coalesce(numPartitions)</p>\n<p>} //这里因为默认哈希分区，并且分区数相同；所有最终union的rdd的分区数不会增多,贴一下源码以防说错</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/** Build the union of a list of RDDs. */</span></span><br><span class=\"line\"> <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">union</span></span>[<span class=\"type\">T</span>: <span class=\"type\">ClassTag</span>](rdds: <span class=\"type\">Seq</span>[<span class=\"type\">RDD</span>[<span class=\"type\">T</span>]]): <span class=\"type\">RDD</span>[<span class=\"type\">T</span>] = withScope &#123;</span><br><span class=\"line\">   <span class=\"keyword\">val</span> partitioners = rdds.flatMap(_.partitioner).toSet</span><br><span class=\"line\">   <span class=\"keyword\">if</span> (rdds.forall(_.partitioner.isDefined) &amp;&amp; partitioners.size == <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">     <span class=\"comment\">/*这里如果rdd的分区函数都相同则会构建一个PartitionerAwareUnionRDD：m RDDs with p partitions each</span></span><br><span class=\"line\"><span class=\"comment\">* will be unified to a single RDD with p partitions*/</span></span><br><span class=\"line\">     <span class=\"keyword\">new</span> <span class=\"type\">PartitionerAwareUnionRDD</span>(<span class=\"keyword\">this</span>, rdds)</span><br><span class=\"line\">   &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">     <span class=\"keyword\">new</span> <span class=\"type\">UnionRDD</span>(<span class=\"keyword\">this</span>, rdds)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n<p>或者最后在重分区</p>\n<p>for (day &lt;- days){</p>\n<p>　　rdd = rdd.union(sc.textFile(/path/to/day) …. )</p>\n<p>} </p>\n<p>rdd.repartition(numPartitions)</p>\n<h1 id=\"Spark-Shuffle-FetchFailedException解决方案\"><a href=\"#Spark-Shuffle-FetchFailedException解决方案\" class=\"headerlink\" title=\"Spark Shuffle FetchFailedException解决方案\"></a>Spark Shuffle FetchFailedException解决方案</h1><p>在大规模数据处理中，这是个比较常见的错误。</p>\n<p>报错提示</p>\n<p>SparkSQL shuffle操作带来的报错</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">org.apache.spark.shuffle.MetadataFetchFailedException: </span><br><span class=\"line\">Missing an output location <span class=\"keyword\">for</span> shuffle <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">org.apache.spark.shuffle.FetchFailedException:</span><br><span class=\"line\">Failed to connect to hostname/<span class=\"number\">192.168</span>.xx.xxx:<span class=\"number\">50268</span></span><br><span class=\"line\"></span><br><span class=\"line\">RDD的shuffle操作带来的报错</span><br><span class=\"line\">WARN TaskSetManager: Lost task <span class=\"number\">17.1</span> in stage <span class=\"number\">4.1</span> (TID <span class=\"number\">1386</span>, spark050013): java.io.FileNotFoundException: /data04/spark/tmp/blockmgr-<span class=\"number\">817</span>d372f-c359-<span class=\"number\">4</span>a00-<span class=\"number\">96</span>dd-<span class=\"number\">8f</span>6554aa19cd/<span class=\"number\">2f</span>/temp_shuffle_e22e013a-<span class=\"number\">5392</span>-<span class=\"number\">4</span>edb-<span class=\"number\">9874</span>-a196a1dad97c (没有那个文件或目录)</span><br><span class=\"line\"></span><br><span class=\"line\">FetchFailed(BlockManagerId(<span class=\"number\">6083</span>b277-<span class=\"number\">119</span>a-<span class=\"number\">49e8</span>-<span class=\"number\">8</span>a49-<span class=\"number\">3539690</span>a2a3f-S155, spark050013, <span class=\"number\">8533</span>), shuffleId=<span class=\"number\">1</span>, mapId=<span class=\"number\">143</span>, reduceId=<span class=\"number\">3</span>, message=</span><br><span class=\"line\">org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer&#123;file=/data04/spark/tmp/blockmgr-<span class=\"number\">817</span>d372f-c359-<span class=\"number\">4</span>a00-<span class=\"number\">96</span>dd-<span class=\"number\">8f</span>6554aa19cd/<span class=\"number\">0</span>e/shuffle_1_143_0.data, offset=<span class=\"number\">997061</span>, length=<span class=\"number\">112503</span>&#125;</span><br></pre></td></tr></table></figure>\n<p>原因</p>\n<p>shuffle分为shuffle write和shuffle read两部分。<br>shuffle write的分区数由上一阶段的RDD分区数控制，shuffle read的分区数则是由Spark提供的一些参数控制。</p>\n<p>shuffle write可以简单理解为类似于saveAsLocalDiskFile的操作，将计算的中间结果按某种规则临时放到各个executor所在的本地磁盘上。</p>\n<p>shuffle read的时候数据的分区数则是由spark提供的一些参数控制。可以想到的是，如果这个参数值设置的很小，同时shuffle read的量很大，那么将会导致一个task需要处理的数据非常大。结果导致JVM crash，从而导致取shuffle数据失败，同时executor也丢失了，看到Failed to connect to host的错误，也就是executor lost的意思。有时候即使不会导致JVM crash也会造成长时间的gc。</p>\n<p>解决办法</p>\n<p>知道原因后问题就好解决了，主要从shuffle的数据量和处理shuffle数据的分区数两个角度入手。</p>\n<p>减少shuffle数据</p>\n<p>思考是否可以使用map side join或是broadcast join来规避shuffle的产生。</p>\n<p>将不必要的数据在shuffle前进行过滤，比如原始数据有20个字段，只要选取需要的字段进行处理即可，将会减少一定的shuffle数据。</p>\n<p>SparkSQL和DataFrame的join,group by等操作</p>\n<p>通过spark.sql.shuffle.partitions控制分区数，默认为200，根据shuffle的量以及计算的复杂度提高这个值。</p>\n<p>Rdd的join,groupBy,reduceByKey等操作</p>\n<p>通过spark.default.parallelism控制shuffle read与reduce处理的分区数，默认为运行任务的core的总数（mesos细粒度模式为8个，local模式为本地的core总数），官方建议为设置成运行任务的core的2-3倍。</p>\n<p>提高executor的内存</p>\n<p>通过spark.executor.memory适当提高executor的memory值。</p>\n<p>是否存在数据倾斜的问题</p>\n<p>空值是否已经过滤？异常数据（某个key数据特别大）是否可以单独处理？考虑改变数据分区规则。</p>\n<p>spark 分区详解 shuffle过程</p>\n<p>1、报错：ERROR storage.DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /hadoop/application_1415632483774_448143/spark-local-20141127115224-9ca8/04/shuffle_1_1562_27</p>\n<p>java.io.FileNotFoundException: /hadoop/application_1415632483774_448143/spark-local-20141127115224-9ca8/04/shuffle_1_1562_27 (No such file or directory)</p>\n<p>　　表面上看是因为shuffle没有地方写了，如果后面的stack是local space 的问题，那么清一下磁盘就好了。上面这种问题，是因为一个excutor给分配的内存不够，此时，减少excutor-core的数量，加大excutor-memory的值应该就没有问题。</p>\n<p>2、报错：ERROR executor.CoarseGrainedExecutorBackend: Driver Disassociated [akka.tcp://sparkExecutor@pc-jfqdfx31:48586] -&gt; [akka.tcp://sparkDriver@pc-jfqdfx30:41656] disassociated! Shutting down.<br>15/07/23 10:50:56 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL 15: SIGTERM</p>\n<p>　　这个错误比较隐晦，从信息上看来不知道是什么问题，但是归根结底还是内存的问题，有两个方法可以解决这个错误，一是，如上面所说，加大excutor-memory的值，减少executor-cores的数量，问题可以解决。二是，加大executor.overhead的值，但是这样其实并没有解决掉根本的问题。所以如果集群的资源是支持的话，就用1的办法吧。</p>\n<p>　　另外，这个错误也出现在partitionBy(new HashPartition(partiton-num))时，如果partiton-num太大或者太小的时候会报这种错误，说白了也是内存的原因，不过这个时候增加内存和overhead没有什么用，得去调整这个partiton-num的值。</p>\n<p>配置详解</p>\n","site":{"data":{}},"excerpt":"","more":"<p>不知道spark怎么调bug，没有系统学习过，摸着石头过河吧。</p>\n<h1 id=\"卡在一个excutor上，没有报错\"><a href=\"#卡在一个excutor上，没有报错\" class=\"headerlink\" title=\"卡在一个excutor上，没有报错\"></a>卡在一个excutor上，没有报错</h1><p>因为一台机器的内存分配给越多的executor，每个executor的内存就越小，以致出现过多的数据spill over甚至out of memory的情况。<br>把这个参数调大些试试:spark.shuffle.memoryFraction</p>\n<p>参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</p>\n<p>参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>\n<p>设置了参数，如下，可以跑完，但是变得很慢。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SparkConf sc = <span class=\"keyword\">new</span> SparkConf()</span><br><span class=\"line\">.setAppName(<span class=\"string\">\"SparkCalculateSR\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.storage.memoryFraction\"</span>, <span class=\"string\">\"0.2\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.default.parallelism\"</span>, <span class=\"string\">\"20\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.serializer\"</span>, <span class=\"string\">\"org.apache.spark.serializer.KryoSerializer\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.shuffle.consolidateFiles\"</span>, <span class=\"string\">\"true\"</span>)  <span class=\"comment\">// consolidateFiles这个参数是hashshuffle的时候用的</span></span><br><span class=\"line\">.set(<span class=\"string\">\"spark.reducer.maxSizeInFlight\"</span>, <span class=\"string\">\"100m\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.shuffle.file.buffer\"</span>, <span class=\"string\">\"100k\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.shuffle.io.maxRetries\"</span>, <span class=\"string\">\"10\"</span>)</span><br><span class=\"line\">.set(<span class=\"string\">\"spark.shuffle.io.retryWait\"</span>, <span class=\"string\">\"10s\"</span>);</span><br></pre></td></tr></table></figure>\n<p>继续建议：</p>\n<p>上边设置的参数可以提高shuffle的稳定性,所以是跑成功了.如果要增大shuffle使用executor内存可以调下边两个参数</p>\n<ul>\n<li>num-executors 100 —这个调小</li>\n<li>spark.shuffle.memoryFraction —这个调大 </li>\n</ul>\n<p>不知道具体慢在哪了,所以没法给具体的优化建议.你采用的是hashshuffle吗? consolidateFiles这个参数是hashshuffle的时候用的,要不改成SortShuffle试试,一般慢都慢在shuffle上了</p>\n<h2 id=\"ref\"><a href=\"#ref\" class=\"headerlink\" title=\"ref\"></a>ref</h2><p><a href=\"https://bbs.csdn.net/topics/392142267\" target=\"_blank\" rel=\"noopener\">spark 卡住</a></p>\n<h1 id=\"spark-配置计算\"><a href=\"#spark-配置计算\" class=\"headerlink\" title=\"spark 配置计算\"></a>spark 配置计算</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--num-executors 100 \\</span><br><span class=\"line\">--driver-memory 6g \\</span><br><span class=\"line\">--executor-memory 6g \\</span><br><span class=\"line\">--executor-cores 8 \\</span><br></pre></td></tr></table></figure>\n<p>100个executors  一个executor-memory 6G内存  8核cpu   那得多少内存多少cpu啊</p>\n<p>答案：600g内存， 800核</p>\n<h1 id=\"参考：开发中遇到的一些问题-文中有很多之前碰到的问题\"><a href=\"#参考：开发中遇到的一些问题-文中有很多之前碰到的问题\" class=\"headerlink\" title=\"参考：开发中遇到的一些问题 文中有很多之前碰到的问题\"></a>参考：<a href=\"https://www.cnblogs.com/arachis/p/Spark_prog.html\" target=\"_blank\" rel=\"noopener\">开发中遇到的一些问题</a> 文中有很多之前碰到的问题</h1><p>1.StackOverflowError</p>\n<p>问题：简单代码记录 :</p>\n<p>for (day &lt;- days){</p>\n<p>　　rdd = rdd.union(sc.textFile(/path/to/day) …. )</p>\n<p>}</p>\n<p>大概场景就是我想把数量比较多的文件合并成一个大rdd,从而导致了栈溢出；</p>\n<p>解决：很明显是方法递归调用太多，我之后改成了几个小任务进行了合并；这里union也会造成最终rdd分区数过多</p>\n<p>2.java.io.FileNotFoundException: /tmp/spark-90507c1d-e98 ….. temp_shuffle_98deadd9-f7c3-4a12(No such file or directory) 类似这种 </p>\n<p>报错：Exception in thread “main” org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 76.0 failed 4 times, most recent failure: Lost task 0.3 in stage 76.0 (TID 341, 10.5.0.90): java.io.FileNotFoundException: /tmp/spark-90507c1d-e983-422d-9e01-74ff0a5a2806/executor-360151d5-6b83-4e3e-a0c6-6ddc955cb16c/blockmgr-bca2bde9-212f-4219-af8b-ef0415d60bfa/26/temp_shuffle_98deadd9-f7c3-4a12-9a30-7749f097b5c8 (No such file or directory)</p>\n<p>场景：大概代码和上面差不多：</p>\n<p>for (day &lt;- days){</p>\n<p>　　rdd = rdd.union(sc.textFile(/path/to/day) …. )</p>\n<p>}</p>\n<p>rdd.map( … )</p>\n<p>解决：简单的map都会报错，怀疑是临时文件过多；查看一下rdd.partitions.length 果然有4k多个；基本思路就是减少分区数</p>\n<p>可以在union的时候就进行重分区：</p>\n<p>for (day &lt;- days){</p>\n<p>　　rdd = rdd.union(sc.textFile(/path/to/day,numPartitions) …. )</p>\n<p>　　rdd = rdd.coalesce(numPartitions)</p>\n<p>} //这里因为默认哈希分区，并且分区数相同；所有最终union的rdd的分区数不会增多,贴一下源码以防说错</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/** Build the union of a list of RDDs. */</span></span><br><span class=\"line\"> <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">union</span></span>[<span class=\"type\">T</span>: <span class=\"type\">ClassTag</span>](rdds: <span class=\"type\">Seq</span>[<span class=\"type\">RDD</span>[<span class=\"type\">T</span>]]): <span class=\"type\">RDD</span>[<span class=\"type\">T</span>] = withScope &#123;</span><br><span class=\"line\">   <span class=\"keyword\">val</span> partitioners = rdds.flatMap(_.partitioner).toSet</span><br><span class=\"line\">   <span class=\"keyword\">if</span> (rdds.forall(_.partitioner.isDefined) &amp;&amp; partitioners.size == <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">     <span class=\"comment\">/*这里如果rdd的分区函数都相同则会构建一个PartitionerAwareUnionRDD：m RDDs with p partitions each</span></span><br><span class=\"line\"><span class=\"comment\">* will be unified to a single RDD with p partitions*/</span></span><br><span class=\"line\">     <span class=\"keyword\">new</span> <span class=\"type\">PartitionerAwareUnionRDD</span>(<span class=\"keyword\">this</span>, rdds)</span><br><span class=\"line\">   &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">     <span class=\"keyword\">new</span> <span class=\"type\">UnionRDD</span>(<span class=\"keyword\">this</span>, rdds)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n<p>或者最后在重分区</p>\n<p>for (day &lt;- days){</p>\n<p>　　rdd = rdd.union(sc.textFile(/path/to/day) …. )</p>\n<p>} </p>\n<p>rdd.repartition(numPartitions)</p>\n<h1 id=\"Spark-Shuffle-FetchFailedException解决方案\"><a href=\"#Spark-Shuffle-FetchFailedException解决方案\" class=\"headerlink\" title=\"Spark Shuffle FetchFailedException解决方案\"></a>Spark Shuffle FetchFailedException解决方案</h1><p>在大规模数据处理中，这是个比较常见的错误。</p>\n<p>报错提示</p>\n<p>SparkSQL shuffle操作带来的报错</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">org.apache.spark.shuffle.MetadataFetchFailedException: </span><br><span class=\"line\">Missing an output location <span class=\"keyword\">for</span> shuffle <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">org.apache.spark.shuffle.FetchFailedException:</span><br><span class=\"line\">Failed to connect to hostname/<span class=\"number\">192.168</span>.xx.xxx:<span class=\"number\">50268</span></span><br><span class=\"line\"></span><br><span class=\"line\">RDD的shuffle操作带来的报错</span><br><span class=\"line\">WARN TaskSetManager: Lost task <span class=\"number\">17.1</span> in stage <span class=\"number\">4.1</span> (TID <span class=\"number\">1386</span>, spark050013): java.io.FileNotFoundException: /data04/spark/tmp/blockmgr-<span class=\"number\">817</span>d372f-c359-<span class=\"number\">4</span>a00-<span class=\"number\">96</span>dd-<span class=\"number\">8f</span>6554aa19cd/<span class=\"number\">2f</span>/temp_shuffle_e22e013a-<span class=\"number\">5392</span>-<span class=\"number\">4</span>edb-<span class=\"number\">9874</span>-a196a1dad97c (没有那个文件或目录)</span><br><span class=\"line\"></span><br><span class=\"line\">FetchFailed(BlockManagerId(<span class=\"number\">6083</span>b277-<span class=\"number\">119</span>a-<span class=\"number\">49e8</span>-<span class=\"number\">8</span>a49-<span class=\"number\">3539690</span>a2a3f-S155, spark050013, <span class=\"number\">8533</span>), shuffleId=<span class=\"number\">1</span>, mapId=<span class=\"number\">143</span>, reduceId=<span class=\"number\">3</span>, message=</span><br><span class=\"line\">org.apache.spark.shuffle.FetchFailedException: Error in opening FileSegmentManagedBuffer&#123;file=/data04/spark/tmp/blockmgr-<span class=\"number\">817</span>d372f-c359-<span class=\"number\">4</span>a00-<span class=\"number\">96</span>dd-<span class=\"number\">8f</span>6554aa19cd/<span class=\"number\">0</span>e/shuffle_1_143_0.data, offset=<span class=\"number\">997061</span>, length=<span class=\"number\">112503</span>&#125;</span><br></pre></td></tr></table></figure>\n<p>原因</p>\n<p>shuffle分为shuffle write和shuffle read两部分。<br>shuffle write的分区数由上一阶段的RDD分区数控制，shuffle read的分区数则是由Spark提供的一些参数控制。</p>\n<p>shuffle write可以简单理解为类似于saveAsLocalDiskFile的操作，将计算的中间结果按某种规则临时放到各个executor所在的本地磁盘上。</p>\n<p>shuffle read的时候数据的分区数则是由spark提供的一些参数控制。可以想到的是，如果这个参数值设置的很小，同时shuffle read的量很大，那么将会导致一个task需要处理的数据非常大。结果导致JVM crash，从而导致取shuffle数据失败，同时executor也丢失了，看到Failed to connect to host的错误，也就是executor lost的意思。有时候即使不会导致JVM crash也会造成长时间的gc。</p>\n<p>解决办法</p>\n<p>知道原因后问题就好解决了，主要从shuffle的数据量和处理shuffle数据的分区数两个角度入手。</p>\n<p>减少shuffle数据</p>\n<p>思考是否可以使用map side join或是broadcast join来规避shuffle的产生。</p>\n<p>将不必要的数据在shuffle前进行过滤，比如原始数据有20个字段，只要选取需要的字段进行处理即可，将会减少一定的shuffle数据。</p>\n<p>SparkSQL和DataFrame的join,group by等操作</p>\n<p>通过spark.sql.shuffle.partitions控制分区数，默认为200，根据shuffle的量以及计算的复杂度提高这个值。</p>\n<p>Rdd的join,groupBy,reduceByKey等操作</p>\n<p>通过spark.default.parallelism控制shuffle read与reduce处理的分区数，默认为运行任务的core的总数（mesos细粒度模式为8个，local模式为本地的core总数），官方建议为设置成运行任务的core的2-3倍。</p>\n<p>提高executor的内存</p>\n<p>通过spark.executor.memory适当提高executor的memory值。</p>\n<p>是否存在数据倾斜的问题</p>\n<p>空值是否已经过滤？异常数据（某个key数据特别大）是否可以单独处理？考虑改变数据分区规则。</p>\n<p>spark 分区详解 shuffle过程</p>\n<p>1、报错：ERROR storage.DiskBlockObjectWriter: Uncaught exception while reverting partial writes to file /hadoop/application_1415632483774_448143/spark-local-20141127115224-9ca8/04/shuffle_1_1562_27</p>\n<p>java.io.FileNotFoundException: /hadoop/application_1415632483774_448143/spark-local-20141127115224-9ca8/04/shuffle_1_1562_27 (No such file or directory)</p>\n<p>　　表面上看是因为shuffle没有地方写了，如果后面的stack是local space 的问题，那么清一下磁盘就好了。上面这种问题，是因为一个excutor给分配的内存不够，此时，减少excutor-core的数量，加大excutor-memory的值应该就没有问题。</p>\n<p>2、报错：ERROR executor.CoarseGrainedExecutorBackend: Driver Disassociated [akka.tcp://sparkExecutor@pc-jfqdfx31:48586] -&gt; [akka.tcp://sparkDriver@pc-jfqdfx30:41656] disassociated! Shutting down.<br>15/07/23 10:50:56 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL 15: SIGTERM</p>\n<p>　　这个错误比较隐晦，从信息上看来不知道是什么问题，但是归根结底还是内存的问题，有两个方法可以解决这个错误，一是，如上面所说，加大excutor-memory的值，减少executor-cores的数量，问题可以解决。二是，加大executor.overhead的值，但是这样其实并没有解决掉根本的问题。所以如果集群的资源是支持的话，就用1的办法吧。</p>\n<p>　　另外，这个错误也出现在partitionBy(new HashPartition(partiton-num))时，如果partiton-num太大或者太小的时候会报这种错误，说白了也是内存的原因，不过这个时候增加内存和overhead没有什么用，得去调整这个partiton-num的值。</p>\n<p>配置详解</p>\n"},{"title":"shell 脚本note","date":"2018-07-30T02:30:49.000Z","_content":"\n# shell中的带名参数\n\ngetopts\n\n语法格式：getopts [option[:]] [DESCPRITION] VARIABLE\noption：表示为某个脚本可以使用的选项\n\":\"：如果某个选项（option）后面出现了冒号（\":\"），则表示这个选项后面可以接参数（即一段描述信息DESCPRITION）\nVARIABLE：表示将某个选项保存在变量VARIABLE中\n\n``` bash\n\nwhile getopts \":a:b:c:\" opt\ndo\n    case $opt in\n        a)\n        echo \"参数a的值$OPTARG\"\n        ;;\n        b)\n        echo \"参数b的值$OPTARG\"\n        ;;\n        c)\n        echo \"参数c的值$OPTARG\"\n        ;;\n        ?)\n        echo \"未知参数\"\n        exit 1;;\n    esac\ndone\n```\n\n# Shell中逻辑运算\n\n常见错误\n``` bash\n-bash: [: missing `]' # [ 1 -gt 1 ] 括号两边都要有空格，不然就报这个错\n```\n\n## 一、逻辑运算符\n\n### 1.关于档案与目录的侦测逻辑卷标！\n| 逻辑卷标 | 表示意思                                          |\n| -------- | ------------------------------------------------- |\n| -f       | 常用！侦测『档案』是否存在 eg: if [ -f filename ] |\n| -d       | 常用！侦测『目录』是否存在                        |\n| -b       | 侦测是否为一个『 block 档案』                     |\n| -c       | 侦测是否为一个『 character 档案』                 |\n| -S       | 侦测是否为一个『 socket 标签档案』                |\n| -L       | 侦测是否为一个『 symbolic link 的档案』           |\n| -e       | 侦测『某个东西』是否存在！                        |\n\n### 2.关于程序的逻辑卷标！\n\n| 逻辑卷标 | 表示意思                                                                |\n| -------- | ----------------------------------------------------------------------- |\n| -G       | 侦测是否由 GID 所执行的程序所拥有                                       |\n| -O       | 侦测是否由 UID 所执行的程序所拥有                                       |\n| -p       | 侦测是否为程序间传送信息的 name pipe 或是 FIFO （老实说，这个不太懂！） |\n\n### 3.关于档案的属性侦测！\n\n| 逻辑卷标 | 表示意思                           |\n| -------- | ---------------------------------- |\n| -r       | 侦测是否为可读的属性               |\n| -w       | 侦测是否为可以写入的属性           |\n| -x       | 侦测是否为可执行的属性             |\n| -s       | 侦测是否为『非空白档案』           |\n| -u       | 侦测是否具有『 SUID 』的属性       |\n| -g       | 侦测是否具有『 SGID 』的属性       |\n| -k       | 侦测是否具有『 sticky bit 』的属性 |\n\n### 4.两个档案之间的判断与比较 ；例如[ test file1 -nt file2 ]\n\n| 逻辑卷标 | 表示意思                                               |\n| -------- | ------------------------------------------------------ |\n| -nt      | 第一个档案比第二个档案新                               |\n| -ot      | 第一个档案比第二个档案旧                               |\n| -ef      | 第一个档案与第二个档案为同一个档案（ link 之类的档案） |\n\n### 5.逻辑的『和(and)』『或(or)』\n\n| 逻辑卷标 | 表示意思          |\n| -------- | ----------------- |\n| &&       | 逻辑的 AND 的意思 |\n| \\|\\|     | 逻辑的 OR 的意思  |\n\n### 逻辑运算符\n\n| 运算符号 | 代表意义                                                    |\n| -------- | ----------------------------------------------------------- |\n| =        | 等于 应用于：整型或字符串比较 (如果在[] 中，只能是字符串)   |\n| !=       | 不等于 应用于：整型或字符串比较 (如果在[] 中，只能是字符串) |\n| <        | 小于 应用于：整型比较 (在[] 中，不能使用 表示字符串 )       |\n| >        | 大于 应用于：整型比较 (在[] 中，不能使用 表示字符串)        |\n| -eq      | 等于 应用于：整型比较                                       |\n| -ne      | 不等于 应用于：整型比较                                     |\n| -lt      | 小于 应用于：整型比较                                       |\n| -gt      | 大于 应用于：整型比较                                       |\n| -le      | 小于或等于 应用于：整型比较                                 |\n| -ge      | 大于或等于 应用于：整型比较                                 |\n| -a       | 双方都成立（and） 逻辑表达式 –a 逻辑表达式                  |\n| -o       | 单方成立（or） 逻辑表达式 –o 逻辑表达式                     |\n| -z       | 空字符串                                                    |\n| -n       | 非空字符串                                                  |\n\n## 二、逻辑表达式\n\n### test 命令\n使用方法：test EXPRESSION\n\n如：\n``` bash\ntest 1 = 1 && echo 'ok'\nok\ntest -d /etc/ && echo 'ok' \nok\ntest 1 -eq 1 && echo 'ok'\nok\nif test 1 = 1 ; then echo 'ok'; fi\nok\n```\n注意：所有字符 与逻辑运算符直接用“空格”分开，不能连到一起。\n\n### 精简表达式\n[] 表达式\n``` bash\n[ 1 -eq 1 ] && echo 'ok'  # ok\n[ 2 < 1 ] && echo 'ok'  # -bash: 1: No such file or directory\n[ 2 \\> 1 ] && echo 'ok'  # ok\n[ 2 -gt 1 -a 3 -lt 4 ] && echo 'ok'  # ok\n[ 2 -gt 1 && 3 -lt 4 ] && echo 'ok'  # 这么写不对 -bash: [: missing `]'\n[ 2 -gt 1 ] && [ 3 -lt 4 ] && echo 'ok'  # ok\n```\n注意：在[] 表达式中，常见的`>` 和 `<`需要加转义字符，表示字符串大小比较，以acill码 位置作为比较。 不直接支持<>运算符，还有逻辑运算符|| && 它需要用-a[and] –o[or]表示\n\n### [[]] 表达式\n\n``` bash\n[ 1 -eq 1 ] && echo 'ok' # ok\n[[ 2 < 3 ]] && echo 'ok' # ok\n[[ 2 < 3 && 4 < 5 ]] && echo 'ok'  # ok\n```\n\n注意：[[]] 运算符只是[]运算符的扩充。能够支持 `<` 和 `>` 符号运算不需要转义符，它还是以字符串比较大小。里面支持逻辑运算符：|| &&\n\n## 三、性能比较\n\nbash的条件表达式中有三个几乎等效的符号和命令：test，[]和[[]]。通常，大家习惯用if [];then这样的形式。而[[]]的出现，根据ABS所说，是为了兼容><之类的运算符。以下是比较它们性能，发现[[]]是最快的。\n\n``` bash\ntime (for m in {1..100000}; do test -d .;done;)\n#real    0m0.658s\n#user    0m0.558s\n#sys     0m0.100s\n\ntime (for m in {1..100000}; do [ -d . ];done;)\n#real    0m0.609s\n#user    0m0.524s\n#sys     0m0.085s\n\ntime (for m in {1..100000}; do [[ -d . ]];done;)\n#real    0m0.311s\n#user    0m0.275s\n#sys     0m0.036s\n```\n不考虑对低版本bash和对sh的兼容的情况下，用[[]]是兼容性强，而且性能比较快，在做条件运算时候，可以使用该运算符。\n\n# shell脚本参数\n\n$0 当前脚本的文件名\n\n``` bash\nif [ $# -gt 0 ]; then\n    data=$1 \nelse\n    data=`date +\"%Y-%m-%d\"`\nfi\n```\n\n# 2>&1\n\n配置spark每日例行任务时候，直接运行脚本可以输入spark任务的运行信息，可是一旦用crontab就不行了，原来spark的任务日志是linux“错误输出”，要加2>&1 才能从正常输出里面捕捉到，坑死了。\n\nref:[Linux 2>&1](https://www.cnblogs.com/zhenghongxin/p/7029173.html)\n\n# 获取当前脚本的路径\n\n``` bash\n$(cd `dirname $0`;pwd)\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\n# $() 和 `` 作用相同，字符串作为shell命令执行\n\n# BASH_SOURCE[0] 等价于 BASH_SOURCE， 取得当前执行的shell文件所在的路径及文件名。\n# 如/home/abc/test.sh 内容如下：\n\n#!/bin/sh\necho \"${BASH_SOURCE[0]}\"\necho \"${BASH_SOURCE]}\"\necho \"$( dirname \"${BASH_SOURCE[0]}\" )\"\nDIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\necho $DIR\n\n# 若当前目录在/home/,执行source ./abc/test.sh, 则输出：\n# ./abc/test.sh\n# ./abc/test.sh\n# ./abc/\n# /home/abc\n```\n总之：\n`DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\" `得到shell脚本文件所在完整路径（绝对路径）及文件名（无论source,sh,.三种调用方式），且不改变shell的当前目录。\n\n------------------------------------------------------------------------------------------------------------------\n\n# Linux 中的各种括号\n\n参考：https://www.jb51.net/article/123081.htm\n\n## 一、小括号，圆括号（）\n\n1、单小括号 ()\n\n①命令组。括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用。括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括号之间不必有空格。\n\n②命令替换。等同于`cmd`，shell扫描一遍命令行，发现了$(cmd)结构，便将$(cmd)中的cmd执行一次，得到其标准输出，再将此输出放到原来命令。有些shell不支持，如tcsh。\n\n③用于初始化数组。如：array=(a b c d)\n\n2、双小括号 (( ))\n\n①整数扩展。这种扩展计算是整数型的计算，不支持浮点型。((exp))结构扩展并计算一个算术表达式的值，如果表达式的结果为0，那么返回的退出状态码为1，或者 是\"假\"，而一个非零值的表达式所返回的退出状态码将为0，或者是\"true\"。若是逻辑判断，表达式exp为真则为1,假则为0。\n\n②只要括号中的运算符、表达式符合C语言运算规则，都可用在$((exp))中，甚至是三目运算符。作不同进位(如二进制、八进制、十六进制)运算时，输出结果全都自动转化成了十进制。如：echo $((16#5f)) 结果为95 (16进位转十进制)\n\n③单纯用 (( )) 也可重定义变量值，比如 a=5; ((a++)) 可将 $a 重定义为6\n\n④常用于算术运算比较，双括号中的变量可以不使用 `$` 符号前缀。括号内支持多个表达式用逗号分开。 只要括号中的表达式符合C语言运算规则,比如可以直接使用`for((i=0;i<5;i++))`, 如果不使用双括号, 则为``` for i in `seq 0 4` ```或者```for i in {0..4}```。再如可以直接使用if (($i<5)), 如果不使用双括号, 则为if [ $i -lt 5 ]。\n\n\n## 二、中括号，方括号[]\n\n1、单中括号 []\n\n①bash 的内部命令，[和test是等同的。如果我们不用绝对路径指明，通常我们用的都是bash自带的命令。if/test结构中的左中括号是调用test的命令标识，右中括号是关闭条件判断的。这个命令把它的参数作为比较表达式或者作为文件测试，并且根据比较的结果来返回一个退出状态码。if/test结构中并不是必须右中括号，但是新版的Bash中要求必须这样。\n\n②Test和[]中可用的比较运算符只有==和!=，两者都是用于字符串比较的，不可用于整数比较，整数比较只能使用-eq，-gt这种形式。无论是字符串比较还是整数比较都不支持大于号小于号。如果实在想用，对于字符串比较可以使用转义形式，如果比较\"ab\"和\"bc\"：[ ab \\< bc ]，结果为真，也就是返回状态为0。[ ]中的逻辑与和逻辑或使用-a 和-o 表示。\n\n③字符范围。用作正则表达式的一部分，描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。\n\n④在一个array 结构的上下文中，中括号用来引用数组中每个元素的编号。\n\n2、双中括号[[ ]]\n\n①[[是 bash 程序语言的关键字。并不是一个命令，[[ ]] 结构比[ ]结构更加通用。在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割，但是会发生参数扩展和命令替换。\n\n②支持字符串的模式匹配，使用=~操作符时甚至支持shell的正则表达式。字符串比较时可以把右边的作为一个模式，而不仅仅是一个字符串，比如[[ hello == hell? ]]，结果为真。[[ ]] 中匹配字符串或通配符，不需要引号。\n\n③使用[[ ... ]]条件判断结构，而不是[ ... ]，能够防止脚本中的许多逻辑错误。比如，&&、||、<和> 操作符能够正常存在于[[ ]]条件判断结构中，但是如果出现在[ ]结构中的话，会报错。比如可以直接使用if [[ $a != 1 && $a != 2 ]], 如果不适用双括号, 则为if [ $a -ne 1] && [ $a != 2 ]或者if [ $a -ne 1 -a $a != 2 ]。\n\n④bash把双中括号中的表达式看作一个单独的元素，并返回一个退出状态码。\n\n例子：\n``` bash\nif ($i<5) \nif [ $i -lt 5 ] \nif [ $a -ne 1 -a $a != 2 ] \nif [ $a -ne 1] && [ $a != 2 ] \nif [[ $a != 1 && $a != 2 ]] \nfor i in $(seq 0 4);do echo $i;done\nfor i in `seq 0 4`;do echo $i;done\nfor ((i=0;i<5;i++));do echo $i;done\nfor i in {0..4};do echo $i;done\n```\n\n## 三、大括号、花括号 {}\n\n1、常规用法\n\n①大括号拓展。(通配(globbing))将对大括号中的文件名做扩展。在大括号中，不允许有空白，除非这个空白被引用或转义。第一种：对大括号中的以逗号分割的文件列表进行拓展。如 touch {a,b}.txt 结果为a.txt b.txt。第二种：对大括号中以点点（..）分割的顺序文件列表起拓展作用，如：touch {a..d}.txt 结果为a.txt b.txt c.txt d.txt\n\n``` bash\nls {ex1,ex2}.sh \n# ex1.sh ex2.sh \nls {ex{1..3},ex4}.sh \n# ex1.sh ex2.sh ex3.sh ex4.sh \nls {ex[1-3],ex4}.sh \n# ex1.sh ex2.sh ex3.sh ex4.sh\n```\n\n②代码块，又被称为内部组，这个结构事实上创建了一个匿名函数 。与小括号中的命令不同，大括号内的命令不会新开一个子shell运行，即脚本余下部分仍可使用括号内变量。括号内的命令间用分号隔开，最后一个也必须有分号。{}的第一个命令和左括号之间必须要有一个空格。\n\n2、几种特殊的替换结构\n\n``` bash\n${var:-string},${var:+string},${var:=string},${var:?string}\n```\n①${var:-string}和${var:=string}:若变量var为空，则用在命令行中用string来替换${var:-string}，否则变量var不为空时，则用变量var的值来替换${var:-string}；对于${var:=string}的替换规则和${var:-string}是一样的，所不同之处是${var:=string}若var为空时，用string替换${var:=string}的同时，把string赋给变量var： ${var:=string}很常用的一种用法是，判断某个变量是否赋值，没有的话则给它赋上一个默认值。\n\n② ${var:+string}的替换规则和上面的相反，即只有当var不是空的时候才替换成string，若var为空时则不替换或者说是替换成变量 var的值，即空值。(因为变量var此时为空，所以这两种说法是等价的)\n\n③${var:?string}替换规则为：若变量var不为空，则用变量var的值来替换${var:?string}；若变量var为空，则把string输出到标准错误中，并从脚本中退出。我们可利用此特性来检查是否设置了变量的值。\n\n补充扩展：在上面这五种替换结构中string不一定是常值的，可用另外一个变量的值或是一种命令的输出。\n\n3、四种模式匹配替换结构\n\n模式匹配记忆方法：\n\n- # 是去掉左边(在键盘上#在$之左边)\n- % 是去掉右边(在键盘上%在$之右边)\n\n#和%中的单一符号是最小匹配，两个相同符号是最大匹配。\n\n``` bash\n${var%pattern},${var%%pattern},${var#pattern},${var##pattern}\n```\n\n第一种模式：${variable%pattern}，这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最短的匹配模式\n第二种模式： ${variable%%pattern}，这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式\n第三种模式：${variable#pattern} 这种模式时，shell在variable中查找，看它是否一给的模式pattern开始，如果是，就从命令行把variable中的内容去掉左边最短的匹配模式\n第四种模式： ${variable##pattern} 这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式\n\n这四种模式中都不会改变variable的值，其中，只有在pattern中使用了*匹配符号时，%和%%，#和##才有区别。结构中的pattern支持通配符，*表示零个或多个任意字符，?表示仅与一个任意字符匹配，[...]表示匹配中括号里面的字符，[!...]表示不匹配中括号里面的字符。\n``` bash\n# var=testcase \n# echo $var \ntestcase \n# echo ${var%s*e} \ntestca \n# echo $var \ntestcase \n# echo ${var%%s*e} \nte \n# echo ${var#?e} \nstcase \n# echo ${var##?e} \nstcase \n# echo ${var##*e}\n# echo ${var##*s} \ne \n# echo ${var##test} \ncase\n```\n\n4、字符串提取和替换\n``` bash\n${var:num},${var:num1:num2},${var/pattern/pattern},${var//pattern/pattern}\n```\n第一种模式：${var:num}，这种模式时，shell在var中提取第num个字符到末尾的所有字符。若num为正数，从左边0处开始；若num为负数，从右边开始提取字串，但必须使用在冒号后面加空格或一个数字或整个num加上括号，如${var: -2}、${var:1-3}或${var:(-2)}。\n\n第二种模式：${var:num1:num2}，num1是位置，num2是长度。表示从$var字符串的第$num1个位置开始提取长度为$num2的子串。不能为负数。\n\n第三种模式：${var/pattern/pattern}表示将var字符串的第一个匹配的pattern替换为另一个pattern。\n\n第四种模式：${var//pattern/pattern}表示将var字符串中的所有能匹配的pattern替换为另一个pattern。\n\n``` bash\nvar=/home/centos \necho $var \n#/home/centos\necho ${var:5} \n#/centos\necho ${var: -6} \n#centos \necho ${var:(-6)} \n#centos \necho ${var:1:4} \n#home \necho ${var/o/h} \n#/hhme/centos\necho ${var//o/h} \n#/hhme/cenths\n```\n\n## 四、符号$后的括号\n\n（1）${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。\n\n（2）$(cmd) 命令替换，和`cmd`效果相同，结果为shell命令cmd的输，过某些Shell版本不支持$()形式的命令替换, 如tcsh。\n\n（3）$((expression)) 和`exprexpression`效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。\n\n## 五、使用\n\n1、多条命令执行\n\n（1）单小括号，(cmd1;cmd2;cmd3) 新开一个子shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后可以没有分号。\n\n（2）单大括号，{ cmd1;cmd2;cmd3;} 在当前shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后必须有分号, 第一条命令和左括号之间必须用空格隔开。\n\n对{}和()而言, 括号中的重定向符只影响该条命令， 而括号外的重定向符影响到括号中的所有命令。\n\n------------------------------------------------------------------------------------------------------------------\n\n# Linux Shell中三种引号的用法及区别\n\nLinux Shell中有三种引号，分别为双引号（\" \"）、单引号(' ')以及反引号(\\` \\`)。\n\n单引号不进行替换，将字符串中所有字符作为普通字符输出，而反引号中字符串作为shell命令执行，并返回执行结果。具体含义如下：\n\n- 双引号（\" \"）：对字符串中出现的 $, '', `和\\ 进行替换，除此以外所有的字符都解释成字符本身。\n- 单引号（' '）：不替换特殊字符（$,'',`和\\），将字符串中所有字符作为普通字符输出。\n- 反引号（\\` \\`）：字符串作为shell命令执行，并返回执行结果。\n\n------------------------------------------------------------------------------------------------------------------\n\n# Shell的for循环语句\n\n第一类：数字性循环\n``` shell\n# 1\nfor((i=1;i<=10;i++));  \ndo   \necho $(expr $i \\* 3 + 1);  \ndone  \n\n# 2 \nfor i in $(seq 1 10)  \ndo   \necho $(expr $i \\* 3 + 1);  \ndone   \n\n# 3\nfor i in {1..10}  \ndo  \necho $(expr $i \\* 3 + 1);  \ndone  \n\n# 4\nawk 'BEGIN{for(i=1; i<=10; i++) print i}'  \n```\n\n第二类：字符性循环\n\n``` bash\n# 1\nfor i in `ls`;  \ndo   \necho $i is file name\\! ;  \ndone \n\n# 2\nfor i in $* ;  \ndo  \necho $i is input chart\\! ;  \ndone  \n\n# 3\nfor i in f1 f2 f3 ;  \ndo  \necho $i is appoint ;  \ndone  \n\n# 4\nlist=\"rootfs usr data data2\"  \nfor i in $list;  \ndo  \necho $i is appoint ;  \ndone  \n```\n\n第三类：路径查找\n``` shell\nfor file in /proc/*;  \ndo  \necho $file is file path \\! ;  \ndone  \n\nfor file in $(ls *.sh)  \ndo  \necho $file is file path \\! ;  \ndone  \n```\n现在一般都使用for in结构，for in结构后面可以使用函数来构造范围，比如$()、这些，里面写一些查找的语法，比如ls test*，那么遍历之后就是输出文件名了。","source":"_posts/201807-shell-script-guide.md","raw":"---\ntitle: shell 脚本note\ndate: 2018-07-30 10:30:49\ncategories: 工具箱\ntags:\n    - shell\n    - 脚本\n---\n\n# shell中的带名参数\n\ngetopts\n\n语法格式：getopts [option[:]] [DESCPRITION] VARIABLE\noption：表示为某个脚本可以使用的选项\n\":\"：如果某个选项（option）后面出现了冒号（\":\"），则表示这个选项后面可以接参数（即一段描述信息DESCPRITION）\nVARIABLE：表示将某个选项保存在变量VARIABLE中\n\n``` bash\n\nwhile getopts \":a:b:c:\" opt\ndo\n    case $opt in\n        a)\n        echo \"参数a的值$OPTARG\"\n        ;;\n        b)\n        echo \"参数b的值$OPTARG\"\n        ;;\n        c)\n        echo \"参数c的值$OPTARG\"\n        ;;\n        ?)\n        echo \"未知参数\"\n        exit 1;;\n    esac\ndone\n```\n\n# Shell中逻辑运算\n\n常见错误\n``` bash\n-bash: [: missing `]' # [ 1 -gt 1 ] 括号两边都要有空格，不然就报这个错\n```\n\n## 一、逻辑运算符\n\n### 1.关于档案与目录的侦测逻辑卷标！\n| 逻辑卷标 | 表示意思                                          |\n| -------- | ------------------------------------------------- |\n| -f       | 常用！侦测『档案』是否存在 eg: if [ -f filename ] |\n| -d       | 常用！侦测『目录』是否存在                        |\n| -b       | 侦测是否为一个『 block 档案』                     |\n| -c       | 侦测是否为一个『 character 档案』                 |\n| -S       | 侦测是否为一个『 socket 标签档案』                |\n| -L       | 侦测是否为一个『 symbolic link 的档案』           |\n| -e       | 侦测『某个东西』是否存在！                        |\n\n### 2.关于程序的逻辑卷标！\n\n| 逻辑卷标 | 表示意思                                                                |\n| -------- | ----------------------------------------------------------------------- |\n| -G       | 侦测是否由 GID 所执行的程序所拥有                                       |\n| -O       | 侦测是否由 UID 所执行的程序所拥有                                       |\n| -p       | 侦测是否为程序间传送信息的 name pipe 或是 FIFO （老实说，这个不太懂！） |\n\n### 3.关于档案的属性侦测！\n\n| 逻辑卷标 | 表示意思                           |\n| -------- | ---------------------------------- |\n| -r       | 侦测是否为可读的属性               |\n| -w       | 侦测是否为可以写入的属性           |\n| -x       | 侦测是否为可执行的属性             |\n| -s       | 侦测是否为『非空白档案』           |\n| -u       | 侦测是否具有『 SUID 』的属性       |\n| -g       | 侦测是否具有『 SGID 』的属性       |\n| -k       | 侦测是否具有『 sticky bit 』的属性 |\n\n### 4.两个档案之间的判断与比较 ；例如[ test file1 -nt file2 ]\n\n| 逻辑卷标 | 表示意思                                               |\n| -------- | ------------------------------------------------------ |\n| -nt      | 第一个档案比第二个档案新                               |\n| -ot      | 第一个档案比第二个档案旧                               |\n| -ef      | 第一个档案与第二个档案为同一个档案（ link 之类的档案） |\n\n### 5.逻辑的『和(and)』『或(or)』\n\n| 逻辑卷标 | 表示意思          |\n| -------- | ----------------- |\n| &&       | 逻辑的 AND 的意思 |\n| \\|\\|     | 逻辑的 OR 的意思  |\n\n### 逻辑运算符\n\n| 运算符号 | 代表意义                                                    |\n| -------- | ----------------------------------------------------------- |\n| =        | 等于 应用于：整型或字符串比较 (如果在[] 中，只能是字符串)   |\n| !=       | 不等于 应用于：整型或字符串比较 (如果在[] 中，只能是字符串) |\n| <        | 小于 应用于：整型比较 (在[] 中，不能使用 表示字符串 )       |\n| >        | 大于 应用于：整型比较 (在[] 中，不能使用 表示字符串)        |\n| -eq      | 等于 应用于：整型比较                                       |\n| -ne      | 不等于 应用于：整型比较                                     |\n| -lt      | 小于 应用于：整型比较                                       |\n| -gt      | 大于 应用于：整型比较                                       |\n| -le      | 小于或等于 应用于：整型比较                                 |\n| -ge      | 大于或等于 应用于：整型比较                                 |\n| -a       | 双方都成立（and） 逻辑表达式 –a 逻辑表达式                  |\n| -o       | 单方成立（or） 逻辑表达式 –o 逻辑表达式                     |\n| -z       | 空字符串                                                    |\n| -n       | 非空字符串                                                  |\n\n## 二、逻辑表达式\n\n### test 命令\n使用方法：test EXPRESSION\n\n如：\n``` bash\ntest 1 = 1 && echo 'ok'\nok\ntest -d /etc/ && echo 'ok' \nok\ntest 1 -eq 1 && echo 'ok'\nok\nif test 1 = 1 ; then echo 'ok'; fi\nok\n```\n注意：所有字符 与逻辑运算符直接用“空格”分开，不能连到一起。\n\n### 精简表达式\n[] 表达式\n``` bash\n[ 1 -eq 1 ] && echo 'ok'  # ok\n[ 2 < 1 ] && echo 'ok'  # -bash: 1: No such file or directory\n[ 2 \\> 1 ] && echo 'ok'  # ok\n[ 2 -gt 1 -a 3 -lt 4 ] && echo 'ok'  # ok\n[ 2 -gt 1 && 3 -lt 4 ] && echo 'ok'  # 这么写不对 -bash: [: missing `]'\n[ 2 -gt 1 ] && [ 3 -lt 4 ] && echo 'ok'  # ok\n```\n注意：在[] 表达式中，常见的`>` 和 `<`需要加转义字符，表示字符串大小比较，以acill码 位置作为比较。 不直接支持<>运算符，还有逻辑运算符|| && 它需要用-a[and] –o[or]表示\n\n### [[]] 表达式\n\n``` bash\n[ 1 -eq 1 ] && echo 'ok' # ok\n[[ 2 < 3 ]] && echo 'ok' # ok\n[[ 2 < 3 && 4 < 5 ]] && echo 'ok'  # ok\n```\n\n注意：[[]] 运算符只是[]运算符的扩充。能够支持 `<` 和 `>` 符号运算不需要转义符，它还是以字符串比较大小。里面支持逻辑运算符：|| &&\n\n## 三、性能比较\n\nbash的条件表达式中有三个几乎等效的符号和命令：test，[]和[[]]。通常，大家习惯用if [];then这样的形式。而[[]]的出现，根据ABS所说，是为了兼容><之类的运算符。以下是比较它们性能，发现[[]]是最快的。\n\n``` bash\ntime (for m in {1..100000}; do test -d .;done;)\n#real    0m0.658s\n#user    0m0.558s\n#sys     0m0.100s\n\ntime (for m in {1..100000}; do [ -d . ];done;)\n#real    0m0.609s\n#user    0m0.524s\n#sys     0m0.085s\n\ntime (for m in {1..100000}; do [[ -d . ]];done;)\n#real    0m0.311s\n#user    0m0.275s\n#sys     0m0.036s\n```\n不考虑对低版本bash和对sh的兼容的情况下，用[[]]是兼容性强，而且性能比较快，在做条件运算时候，可以使用该运算符。\n\n# shell脚本参数\n\n$0 当前脚本的文件名\n\n``` bash\nif [ $# -gt 0 ]; then\n    data=$1 \nelse\n    data=`date +\"%Y-%m-%d\"`\nfi\n```\n\n# 2>&1\n\n配置spark每日例行任务时候，直接运行脚本可以输入spark任务的运行信息，可是一旦用crontab就不行了，原来spark的任务日志是linux“错误输出”，要加2>&1 才能从正常输出里面捕捉到，坑死了。\n\nref:[Linux 2>&1](https://www.cnblogs.com/zhenghongxin/p/7029173.html)\n\n# 获取当前脚本的路径\n\n``` bash\n$(cd `dirname $0`;pwd)\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\n# $() 和 `` 作用相同，字符串作为shell命令执行\n\n# BASH_SOURCE[0] 等价于 BASH_SOURCE， 取得当前执行的shell文件所在的路径及文件名。\n# 如/home/abc/test.sh 内容如下：\n\n#!/bin/sh\necho \"${BASH_SOURCE[0]}\"\necho \"${BASH_SOURCE]}\"\necho \"$( dirname \"${BASH_SOURCE[0]}\" )\"\nDIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\necho $DIR\n\n# 若当前目录在/home/,执行source ./abc/test.sh, 则输出：\n# ./abc/test.sh\n# ./abc/test.sh\n# ./abc/\n# /home/abc\n```\n总之：\n`DIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\" `得到shell脚本文件所在完整路径（绝对路径）及文件名（无论source,sh,.三种调用方式），且不改变shell的当前目录。\n\n------------------------------------------------------------------------------------------------------------------\n\n# Linux 中的各种括号\n\n参考：https://www.jb51.net/article/123081.htm\n\n## 一、小括号，圆括号（）\n\n1、单小括号 ()\n\n①命令组。括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用。括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括号之间不必有空格。\n\n②命令替换。等同于`cmd`，shell扫描一遍命令行，发现了$(cmd)结构，便将$(cmd)中的cmd执行一次，得到其标准输出，再将此输出放到原来命令。有些shell不支持，如tcsh。\n\n③用于初始化数组。如：array=(a b c d)\n\n2、双小括号 (( ))\n\n①整数扩展。这种扩展计算是整数型的计算，不支持浮点型。((exp))结构扩展并计算一个算术表达式的值，如果表达式的结果为0，那么返回的退出状态码为1，或者 是\"假\"，而一个非零值的表达式所返回的退出状态码将为0，或者是\"true\"。若是逻辑判断，表达式exp为真则为1,假则为0。\n\n②只要括号中的运算符、表达式符合C语言运算规则，都可用在$((exp))中，甚至是三目运算符。作不同进位(如二进制、八进制、十六进制)运算时，输出结果全都自动转化成了十进制。如：echo $((16#5f)) 结果为95 (16进位转十进制)\n\n③单纯用 (( )) 也可重定义变量值，比如 a=5; ((a++)) 可将 $a 重定义为6\n\n④常用于算术运算比较，双括号中的变量可以不使用 `$` 符号前缀。括号内支持多个表达式用逗号分开。 只要括号中的表达式符合C语言运算规则,比如可以直接使用`for((i=0;i<5;i++))`, 如果不使用双括号, 则为``` for i in `seq 0 4` ```或者```for i in {0..4}```。再如可以直接使用if (($i<5)), 如果不使用双括号, 则为if [ $i -lt 5 ]。\n\n\n## 二、中括号，方括号[]\n\n1、单中括号 []\n\n①bash 的内部命令，[和test是等同的。如果我们不用绝对路径指明，通常我们用的都是bash自带的命令。if/test结构中的左中括号是调用test的命令标识，右中括号是关闭条件判断的。这个命令把它的参数作为比较表达式或者作为文件测试，并且根据比较的结果来返回一个退出状态码。if/test结构中并不是必须右中括号，但是新版的Bash中要求必须这样。\n\n②Test和[]中可用的比较运算符只有==和!=，两者都是用于字符串比较的，不可用于整数比较，整数比较只能使用-eq，-gt这种形式。无论是字符串比较还是整数比较都不支持大于号小于号。如果实在想用，对于字符串比较可以使用转义形式，如果比较\"ab\"和\"bc\"：[ ab \\< bc ]，结果为真，也就是返回状态为0。[ ]中的逻辑与和逻辑或使用-a 和-o 表示。\n\n③字符范围。用作正则表达式的一部分，描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。\n\n④在一个array 结构的上下文中，中括号用来引用数组中每个元素的编号。\n\n2、双中括号[[ ]]\n\n①[[是 bash 程序语言的关键字。并不是一个命令，[[ ]] 结构比[ ]结构更加通用。在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割，但是会发生参数扩展和命令替换。\n\n②支持字符串的模式匹配，使用=~操作符时甚至支持shell的正则表达式。字符串比较时可以把右边的作为一个模式，而不仅仅是一个字符串，比如[[ hello == hell? ]]，结果为真。[[ ]] 中匹配字符串或通配符，不需要引号。\n\n③使用[[ ... ]]条件判断结构，而不是[ ... ]，能够防止脚本中的许多逻辑错误。比如，&&、||、<和> 操作符能够正常存在于[[ ]]条件判断结构中，但是如果出现在[ ]结构中的话，会报错。比如可以直接使用if [[ $a != 1 && $a != 2 ]], 如果不适用双括号, 则为if [ $a -ne 1] && [ $a != 2 ]或者if [ $a -ne 1 -a $a != 2 ]。\n\n④bash把双中括号中的表达式看作一个单独的元素，并返回一个退出状态码。\n\n例子：\n``` bash\nif ($i<5) \nif [ $i -lt 5 ] \nif [ $a -ne 1 -a $a != 2 ] \nif [ $a -ne 1] && [ $a != 2 ] \nif [[ $a != 1 && $a != 2 ]] \nfor i in $(seq 0 4);do echo $i;done\nfor i in `seq 0 4`;do echo $i;done\nfor ((i=0;i<5;i++));do echo $i;done\nfor i in {0..4};do echo $i;done\n```\n\n## 三、大括号、花括号 {}\n\n1、常规用法\n\n①大括号拓展。(通配(globbing))将对大括号中的文件名做扩展。在大括号中，不允许有空白，除非这个空白被引用或转义。第一种：对大括号中的以逗号分割的文件列表进行拓展。如 touch {a,b}.txt 结果为a.txt b.txt。第二种：对大括号中以点点（..）分割的顺序文件列表起拓展作用，如：touch {a..d}.txt 结果为a.txt b.txt c.txt d.txt\n\n``` bash\nls {ex1,ex2}.sh \n# ex1.sh ex2.sh \nls {ex{1..3},ex4}.sh \n# ex1.sh ex2.sh ex3.sh ex4.sh \nls {ex[1-3],ex4}.sh \n# ex1.sh ex2.sh ex3.sh ex4.sh\n```\n\n②代码块，又被称为内部组，这个结构事实上创建了一个匿名函数 。与小括号中的命令不同，大括号内的命令不会新开一个子shell运行，即脚本余下部分仍可使用括号内变量。括号内的命令间用分号隔开，最后一个也必须有分号。{}的第一个命令和左括号之间必须要有一个空格。\n\n2、几种特殊的替换结构\n\n``` bash\n${var:-string},${var:+string},${var:=string},${var:?string}\n```\n①${var:-string}和${var:=string}:若变量var为空，则用在命令行中用string来替换${var:-string}，否则变量var不为空时，则用变量var的值来替换${var:-string}；对于${var:=string}的替换规则和${var:-string}是一样的，所不同之处是${var:=string}若var为空时，用string替换${var:=string}的同时，把string赋给变量var： ${var:=string}很常用的一种用法是，判断某个变量是否赋值，没有的话则给它赋上一个默认值。\n\n② ${var:+string}的替换规则和上面的相反，即只有当var不是空的时候才替换成string，若var为空时则不替换或者说是替换成变量 var的值，即空值。(因为变量var此时为空，所以这两种说法是等价的)\n\n③${var:?string}替换规则为：若变量var不为空，则用变量var的值来替换${var:?string}；若变量var为空，则把string输出到标准错误中，并从脚本中退出。我们可利用此特性来检查是否设置了变量的值。\n\n补充扩展：在上面这五种替换结构中string不一定是常值的，可用另外一个变量的值或是一种命令的输出。\n\n3、四种模式匹配替换结构\n\n模式匹配记忆方法：\n\n- # 是去掉左边(在键盘上#在$之左边)\n- % 是去掉右边(在键盘上%在$之右边)\n\n#和%中的单一符号是最小匹配，两个相同符号是最大匹配。\n\n``` bash\n${var%pattern},${var%%pattern},${var#pattern},${var##pattern}\n```\n\n第一种模式：${variable%pattern}，这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最短的匹配模式\n第二种模式： ${variable%%pattern}，这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式\n第三种模式：${variable#pattern} 这种模式时，shell在variable中查找，看它是否一给的模式pattern开始，如果是，就从命令行把variable中的内容去掉左边最短的匹配模式\n第四种模式： ${variable##pattern} 这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式\n\n这四种模式中都不会改变variable的值，其中，只有在pattern中使用了*匹配符号时，%和%%，#和##才有区别。结构中的pattern支持通配符，*表示零个或多个任意字符，?表示仅与一个任意字符匹配，[...]表示匹配中括号里面的字符，[!...]表示不匹配中括号里面的字符。\n``` bash\n# var=testcase \n# echo $var \ntestcase \n# echo ${var%s*e} \ntestca \n# echo $var \ntestcase \n# echo ${var%%s*e} \nte \n# echo ${var#?e} \nstcase \n# echo ${var##?e} \nstcase \n# echo ${var##*e}\n# echo ${var##*s} \ne \n# echo ${var##test} \ncase\n```\n\n4、字符串提取和替换\n``` bash\n${var:num},${var:num1:num2},${var/pattern/pattern},${var//pattern/pattern}\n```\n第一种模式：${var:num}，这种模式时，shell在var中提取第num个字符到末尾的所有字符。若num为正数，从左边0处开始；若num为负数，从右边开始提取字串，但必须使用在冒号后面加空格或一个数字或整个num加上括号，如${var: -2}、${var:1-3}或${var:(-2)}。\n\n第二种模式：${var:num1:num2}，num1是位置，num2是长度。表示从$var字符串的第$num1个位置开始提取长度为$num2的子串。不能为负数。\n\n第三种模式：${var/pattern/pattern}表示将var字符串的第一个匹配的pattern替换为另一个pattern。\n\n第四种模式：${var//pattern/pattern}表示将var字符串中的所有能匹配的pattern替换为另一个pattern。\n\n``` bash\nvar=/home/centos \necho $var \n#/home/centos\necho ${var:5} \n#/centos\necho ${var: -6} \n#centos \necho ${var:(-6)} \n#centos \necho ${var:1:4} \n#home \necho ${var/o/h} \n#/hhme/centos\necho ${var//o/h} \n#/hhme/cenths\n```\n\n## 四、符号$后的括号\n\n（1）${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。\n\n（2）$(cmd) 命令替换，和`cmd`效果相同，结果为shell命令cmd的输，过某些Shell版本不支持$()形式的命令替换, 如tcsh。\n\n（3）$((expression)) 和`exprexpression`效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。\n\n## 五、使用\n\n1、多条命令执行\n\n（1）单小括号，(cmd1;cmd2;cmd3) 新开一个子shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后可以没有分号。\n\n（2）单大括号，{ cmd1;cmd2;cmd3;} 在当前shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后必须有分号, 第一条命令和左括号之间必须用空格隔开。\n\n对{}和()而言, 括号中的重定向符只影响该条命令， 而括号外的重定向符影响到括号中的所有命令。\n\n------------------------------------------------------------------------------------------------------------------\n\n# Linux Shell中三种引号的用法及区别\n\nLinux Shell中有三种引号，分别为双引号（\" \"）、单引号(' ')以及反引号(\\` \\`)。\n\n单引号不进行替换，将字符串中所有字符作为普通字符输出，而反引号中字符串作为shell命令执行，并返回执行结果。具体含义如下：\n\n- 双引号（\" \"）：对字符串中出现的 $, '', `和\\ 进行替换，除此以外所有的字符都解释成字符本身。\n- 单引号（' '）：不替换特殊字符（$,'',`和\\），将字符串中所有字符作为普通字符输出。\n- 反引号（\\` \\`）：字符串作为shell命令执行，并返回执行结果。\n\n------------------------------------------------------------------------------------------------------------------\n\n# Shell的for循环语句\n\n第一类：数字性循环\n``` shell\n# 1\nfor((i=1;i<=10;i++));  \ndo   \necho $(expr $i \\* 3 + 1);  \ndone  \n\n# 2 \nfor i in $(seq 1 10)  \ndo   \necho $(expr $i \\* 3 + 1);  \ndone   \n\n# 3\nfor i in {1..10}  \ndo  \necho $(expr $i \\* 3 + 1);  \ndone  \n\n# 4\nawk 'BEGIN{for(i=1; i<=10; i++) print i}'  \n```\n\n第二类：字符性循环\n\n``` bash\n# 1\nfor i in `ls`;  \ndo   \necho $i is file name\\! ;  \ndone \n\n# 2\nfor i in $* ;  \ndo  \necho $i is input chart\\! ;  \ndone  \n\n# 3\nfor i in f1 f2 f3 ;  \ndo  \necho $i is appoint ;  \ndone  \n\n# 4\nlist=\"rootfs usr data data2\"  \nfor i in $list;  \ndo  \necho $i is appoint ;  \ndone  \n```\n\n第三类：路径查找\n``` shell\nfor file in /proc/*;  \ndo  \necho $file is file path \\! ;  \ndone  \n\nfor file in $(ls *.sh)  \ndo  \necho $file is file path \\! ;  \ndone  \n```\n现在一般都使用for in结构，for in结构后面可以使用函数来构造范围，比如$()、这些，里面写一些查找的语法，比如ls test*，那么遍历之后就是输出文件名了。","slug":"shell-script-guide","published":1,"updated":"2018-08-21T04:52:22.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7y6001en61djsxhcvp1","content":"<h1 id=\"shell中的带名参数\"><a href=\"#shell中的带名参数\" class=\"headerlink\" title=\"shell中的带名参数\"></a>shell中的带名参数</h1><p>getopts</p>\n<p>语法格式：getopts [option[:]] [DESCPRITION] VARIABLE<br>option：表示为某个脚本可以使用的选项<br>“:”：如果某个选项（option）后面出现了冒号（”:”），则表示这个选项后面可以接参数（即一段描述信息DESCPRITION）<br>VARIABLE：表示将某个选项保存在变量VARIABLE中</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"built_in\">getopts</span> <span class=\"string\">\":a:b:c:\"</span> opt</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">    <span class=\"keyword\">case</span> <span class=\"variable\">$opt</span> <span class=\"keyword\">in</span></span><br><span class=\"line\">        a)</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"参数a的值<span class=\"variable\">$OPTARG</span>\"</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        b)</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"参数b的值<span class=\"variable\">$OPTARG</span>\"</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        c)</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"参数c的值<span class=\"variable\">$OPTARG</span>\"</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        ?)</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"未知参数\"</span></span><br><span class=\"line\">        <span class=\"built_in\">exit</span> 1;;</span><br><span class=\"line\">    <span class=\"keyword\">esac</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"Shell中逻辑运算\"><a href=\"#Shell中逻辑运算\" class=\"headerlink\" title=\"Shell中逻辑运算\"></a>Shell中逻辑运算</h1><p>常见错误<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-bash: [: missing `]<span class=\"string\">' # [ 1 -gt 1 ] 括号两边都要有空格，不然就报这个错</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"一、逻辑运算符\"><a href=\"#一、逻辑运算符\" class=\"headerlink\" title=\"一、逻辑运算符\"></a>一、逻辑运算符</h2><h3 id=\"1-关于档案与目录的侦测逻辑卷标！\"><a href=\"#1-关于档案与目录的侦测逻辑卷标！\" class=\"headerlink\" title=\"1.关于档案与目录的侦测逻辑卷标！\"></a>1.关于档案与目录的侦测逻辑卷标！</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>逻辑卷标</th>\n<th>表示意思</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-f</td>\n<td>常用！侦测『档案』是否存在 eg: if [ -f filename ]</td>\n</tr>\n<tr>\n<td>-d</td>\n<td>常用！侦测『目录』是否存在</td>\n</tr>\n<tr>\n<td>-b</td>\n<td>侦测是否为一个『 block 档案』</td>\n</tr>\n<tr>\n<td>-c</td>\n<td>侦测是否为一个『 character 档案』</td>\n</tr>\n<tr>\n<td>-S</td>\n<td>侦测是否为一个『 socket 标签档案』</td>\n</tr>\n<tr>\n<td>-L</td>\n<td>侦测是否为一个『 symbolic link 的档案』</td>\n</tr>\n<tr>\n<td>-e</td>\n<td>侦测『某个东西』是否存在！</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"2-关于程序的逻辑卷标！\"><a href=\"#2-关于程序的逻辑卷标！\" class=\"headerlink\" title=\"2.关于程序的逻辑卷标！\"></a>2.关于程序的逻辑卷标！</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>逻辑卷标</th>\n<th>表示意思</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-G</td>\n<td>侦测是否由 GID 所执行的程序所拥有</td>\n</tr>\n<tr>\n<td>-O</td>\n<td>侦测是否由 UID 所执行的程序所拥有</td>\n</tr>\n<tr>\n<td>-p</td>\n<td>侦测是否为程序间传送信息的 name pipe 或是 FIFO （老实说，这个不太懂！）</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"3-关于档案的属性侦测！\"><a href=\"#3-关于档案的属性侦测！\" class=\"headerlink\" title=\"3.关于档案的属性侦测！\"></a>3.关于档案的属性侦测！</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>逻辑卷标</th>\n<th>表示意思</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-r</td>\n<td>侦测是否为可读的属性</td>\n</tr>\n<tr>\n<td>-w</td>\n<td>侦测是否为可以写入的属性</td>\n</tr>\n<tr>\n<td>-x</td>\n<td>侦测是否为可执行的属性</td>\n</tr>\n<tr>\n<td>-s</td>\n<td>侦测是否为『非空白档案』</td>\n</tr>\n<tr>\n<td>-u</td>\n<td>侦测是否具有『 SUID 』的属性</td>\n</tr>\n<tr>\n<td>-g</td>\n<td>侦测是否具有『 SGID 』的属性</td>\n</tr>\n<tr>\n<td>-k</td>\n<td>侦测是否具有『 sticky bit 』的属性</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"4-两个档案之间的判断与比较-；例如-test-file1-nt-file2\"><a href=\"#4-两个档案之间的判断与比较-；例如-test-file1-nt-file2\" class=\"headerlink\" title=\"4.两个档案之间的判断与比较 ；例如[ test file1 -nt file2 ]\"></a>4.两个档案之间的判断与比较 ；例如[ test file1 -nt file2 ]</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>逻辑卷标</th>\n<th>表示意思</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-nt</td>\n<td>第一个档案比第二个档案新</td>\n</tr>\n<tr>\n<td>-ot</td>\n<td>第一个档案比第二个档案旧</td>\n</tr>\n<tr>\n<td>-ef</td>\n<td>第一个档案与第二个档案为同一个档案（ link 之类的档案）</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"5-逻辑的『和-and-』『或-or-』\"><a href=\"#5-逻辑的『和-and-』『或-or-』\" class=\"headerlink\" title=\"5.逻辑的『和(and)』『或(or)』\"></a>5.逻辑的『和(and)』『或(or)』</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>逻辑卷标</th>\n<th>表示意思</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&amp;&amp;</td>\n<td>逻辑的 AND 的意思</td>\n</tr>\n<tr>\n<td>\\</td>\n<td>\\</td>\n<td></td>\n<td>逻辑的 OR 的意思</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"逻辑运算符\"><a href=\"#逻辑运算符\" class=\"headerlink\" title=\"逻辑运算符\"></a>逻辑运算符</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>运算符号</th>\n<th>代表意义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>=</td>\n<td>等于 应用于：整型或字符串比较 (如果在[] 中，只能是字符串)</td>\n</tr>\n<tr>\n<td>!=</td>\n<td>不等于 应用于：整型或字符串比较 (如果在[] 中，只能是字符串)</td>\n</tr>\n<tr>\n<td>&lt;</td>\n<td>小于 应用于：整型比较 (在[] 中，不能使用 表示字符串 )</td>\n</tr>\n<tr>\n<td>&gt;</td>\n<td>大于 应用于：整型比较 (在[] 中，不能使用 表示字符串)</td>\n</tr>\n<tr>\n<td>-eq</td>\n<td>等于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-ne</td>\n<td>不等于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-lt</td>\n<td>小于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-gt</td>\n<td>大于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-le</td>\n<td>小于或等于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-ge</td>\n<td>大于或等于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-a</td>\n<td>双方都成立（and） 逻辑表达式 –a 逻辑表达式</td>\n</tr>\n<tr>\n<td>-o</td>\n<td>单方成立（or） 逻辑表达式 –o 逻辑表达式</td>\n</tr>\n<tr>\n<td>-z</td>\n<td>空字符串</td>\n</tr>\n<tr>\n<td>-n</td>\n<td>非空字符串</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"二、逻辑表达式\"><a href=\"#二、逻辑表达式\" class=\"headerlink\" title=\"二、逻辑表达式\"></a>二、逻辑表达式</h2><h3 id=\"test-命令\"><a href=\"#test-命令\" class=\"headerlink\" title=\"test 命令\"></a>test 命令</h3><p>使用方法：test EXPRESSION</p>\n<p>如：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">test</span> 1 = 1 &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span></span><br><span class=\"line\">ok</span><br><span class=\"line\"><span class=\"built_in\">test</span> -d /etc/ &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span> </span><br><span class=\"line\">ok</span><br><span class=\"line\"><span class=\"built_in\">test</span> 1 -eq 1 &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span></span><br><span class=\"line\">ok</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"built_in\">test</span> 1 = 1 ; <span class=\"keyword\">then</span> <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>; <span class=\"keyword\">fi</span></span><br><span class=\"line\">ok</span><br></pre></td></tr></table></figure></p>\n<p>注意：所有字符 与逻辑运算符直接用“空格”分开，不能连到一起。</p>\n<h3 id=\"精简表达式\"><a href=\"#精简表达式\" class=\"headerlink\" title=\"精简表达式\"></a>精简表达式</h3><p>[] 表达式<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[ 1 -eq 1 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># ok</span></span><br><span class=\"line\">[ 2 &lt; 1 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># -bash: 1: No such file or directory</span></span><br><span class=\"line\">[ 2 \\&gt; 1 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># ok</span></span><br><span class=\"line\">[ 2 -gt 1 -a 3 -lt 4 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># ok</span></span><br><span class=\"line\">[ 2 -gt 1 &amp;&amp; 3 -lt 4 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># 这么写不对 -bash: [: missing `]'</span></span><br><span class=\"line\">[ 2 -gt 1 ] &amp;&amp; [ 3 -lt 4 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># ok</span></span><br></pre></td></tr></table></figure></p>\n<p>注意：在[] 表达式中，常见的<code>&gt;</code> 和 <code>&lt;</code>需要加转义字符，表示字符串大小比较，以acill码 位置作为比较。 不直接支持&lt;&gt;运算符，还有逻辑运算符|| &amp;&amp; 它需要用-a[and] –o[or]表示</p>\n<h3 id=\"表达式\"><a href=\"#表达式\" class=\"headerlink\" title=\"[[]] 表达式\"></a>[[]] 表达式</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[ 1 -eq 1 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span> <span class=\"comment\"># ok</span></span><br><span class=\"line\">[[ 2 &lt; 3 ]] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span> <span class=\"comment\"># ok</span></span><br><span class=\"line\">[[ 2 &lt; 3 &amp;&amp; 4 &lt; 5 ]] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># ok</span></span><br></pre></td></tr></table></figure>\n<p>注意：[[]] 运算符只是[]运算符的扩充。能够支持 <code>&lt;</code> 和 <code>&gt;</code> 符号运算不需要转义符，它还是以字符串比较大小。里面支持逻辑运算符：|| &amp;&amp;</p>\n<h2 id=\"三、性能比较\"><a href=\"#三、性能比较\" class=\"headerlink\" title=\"三、性能比较\"></a>三、性能比较</h2><p>bash的条件表达式中有三个几乎等效的符号和命令：test，[]和[[]]。通常，大家习惯用if [];then这样的形式。而[[]]的出现，根据ABS所说，是为了兼容&gt;&lt;之类的运算符。以下是比较它们性能，发现[[]]是最快的。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">time (<span class=\"keyword\">for</span> m <span class=\"keyword\">in</span> &#123;1..100000&#125;; <span class=\"keyword\">do</span> <span class=\"built_in\">test</span> -d .;<span class=\"keyword\">done</span>;)</span><br><span class=\"line\"><span class=\"comment\">#real    0m0.658s</span></span><br><span class=\"line\"><span class=\"comment\">#user    0m0.558s</span></span><br><span class=\"line\"><span class=\"comment\">#sys     0m0.100s</span></span><br><span class=\"line\"></span><br><span class=\"line\">time (<span class=\"keyword\">for</span> m <span class=\"keyword\">in</span> &#123;1..100000&#125;; <span class=\"keyword\">do</span> [ -d . ];<span class=\"keyword\">done</span>;)</span><br><span class=\"line\"><span class=\"comment\">#real    0m0.609s</span></span><br><span class=\"line\"><span class=\"comment\">#user    0m0.524s</span></span><br><span class=\"line\"><span class=\"comment\">#sys     0m0.085s</span></span><br><span class=\"line\"></span><br><span class=\"line\">time (<span class=\"keyword\">for</span> m <span class=\"keyword\">in</span> &#123;1..100000&#125;; <span class=\"keyword\">do</span> [[ -d . ]];<span class=\"keyword\">done</span>;)</span><br><span class=\"line\"><span class=\"comment\">#real    0m0.311s</span></span><br><span class=\"line\"><span class=\"comment\">#user    0m0.275s</span></span><br><span class=\"line\"><span class=\"comment\">#sys     0m0.036s</span></span><br></pre></td></tr></table></figure>\n<p>不考虑对低版本bash和对sh的兼容的情况下，用[[]]是兼容性强，而且性能比较快，在做条件运算时候，可以使用该运算符。</p>\n<h1 id=\"shell脚本参数\"><a href=\"#shell脚本参数\" class=\"headerlink\" title=\"shell脚本参数\"></a>shell脚本参数</h1><p>$0 当前脚本的文件名</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$#</span> -gt 0 ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    data=<span class=\"variable\">$1</span> </span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    data=`date +<span class=\"string\">\"%Y-%m-%d\"</span>`</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"2-gt-amp-1\"><a href=\"#2-gt-amp-1\" class=\"headerlink\" title=\"2&gt;&amp;1\"></a>2&gt;&amp;1</h1><p>配置spark每日例行任务时候，直接运行脚本可以输入spark任务的运行信息，可是一旦用crontab就不行了，原来spark的任务日志是linux“错误输出”，要加2&gt;&amp;1 才能从正常输出里面捕捉到，坑死了。</p>\n<p>ref:<a href=\"https://www.cnblogs.com/zhenghongxin/p/7029173.html\" target=\"_blank\" rel=\"noopener\">Linux 2&gt;&amp;1</a></p>\n<h1 id=\"获取当前脚本的路径\"><a href=\"#获取当前脚本的路径\" class=\"headerlink\" title=\"获取当前脚本的路径\"></a>获取当前脚本的路径</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(<span class=\"built_in\">cd</span> `dirname <span class=\"variable\">$0</span>`;<span class=\"built_in\">pwd</span>)</span><br><span class=\"line\">SCRIPT_DIR=<span class=\"string\">\"<span class=\"variable\">$(cd \"$(dirname \"$&#123;BASH_SOURCE[0]&#125;\")</span>\"</span> &amp;&amp; <span class=\"built_in\">pwd</span>)<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\"># <span class=\"variable\">$()</span> 和 `` 作用相同，字符串作为shell命令执行</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"># BASH_SOURCE[0] 等价于 BASH_SOURCE， 取得当前执行的shell文件所在的路径及文件名。</span></span><br><span class=\"line\"><span class=\"string\"># 如/home/abc/test.sh 内容如下：</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">#!/bin/sh</span></span><br><span class=\"line\"><span class=\"string\">echo \"</span><span class=\"variable\">$&#123;BASH_SOURCE[0]&#125;</span><span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">echo \"</span><span class=\"variable\">$&#123;BASH_SOURCE]&#125;</span><span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">echo \"</span>$( dirname <span class=\"string\">\"<span class=\"variable\">$&#123;BASH_SOURCE[0]&#125;</span>\"</span> )<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">DIR=\"</span>$( <span class=\"built_in\">cd</span> <span class=\"string\">\"<span class=\"variable\">$( dirname \"$&#123;BASH_SOURCE[0]&#125;\" )</span>\"</span> &amp;&amp; <span class=\"built_in\">pwd</span> )<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">echo <span class=\"variable\">$DIR</span></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"># 若当前目录在/home/,执行source ./abc/test.sh, 则输出：</span></span><br><span class=\"line\"><span class=\"string\"># ./abc/test.sh</span></span><br><span class=\"line\"><span class=\"string\"># ./abc/test.sh</span></span><br><span class=\"line\"><span class=\"string\"># ./abc/</span></span><br><span class=\"line\"><span class=\"string\"># /home/abc</span></span><br></pre></td></tr></table></figure>\n<p>总之：<br><code>DIR=&quot;$( cd &quot;$( dirname &quot;${BASH_SOURCE[0]}&quot; )&quot; &amp;&amp; pwd )&quot;</code>得到shell脚本文件所在完整路径（绝对路径）及文件名（无论source,sh,.三种调用方式），且不改变shell的当前目录。</p>\n<hr>\n<h1 id=\"Linux-中的各种括号\"><a href=\"#Linux-中的各种括号\" class=\"headerlink\" title=\"Linux 中的各种括号\"></a>Linux 中的各种括号</h1><p>参考：<a href=\"https://www.jb51.net/article/123081.htm\" target=\"_blank\" rel=\"noopener\">https://www.jb51.net/article/123081.htm</a></p>\n<h2 id=\"一、小括号，圆括号（）\"><a href=\"#一、小括号，圆括号（）\" class=\"headerlink\" title=\"一、小括号，圆括号（）\"></a>一、小括号，圆括号（）</h2><p>1、单小括号 ()</p>\n<p>①命令组。括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用。括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括号之间不必有空格。</p>\n<p>②命令替换。等同于<code>cmd</code>，shell扫描一遍命令行，发现了$(cmd)结构，便将$(cmd)中的cmd执行一次，得到其标准输出，再将此输出放到原来命令。有些shell不支持，如tcsh。</p>\n<p>③用于初始化数组。如：array=(a b c d)</p>\n<p>2、双小括号 (( ))</p>\n<p>①整数扩展。这种扩展计算是整数型的计算，不支持浮点型。((exp))结构扩展并计算一个算术表达式的值，如果表达式的结果为0，那么返回的退出状态码为1，或者 是”假”，而一个非零值的表达式所返回的退出状态码将为0，或者是”true”。若是逻辑判断，表达式exp为真则为1,假则为0。</p>\n<p>②只要括号中的运算符、表达式符合C语言运算规则，都可用在$((exp))中，甚至是三目运算符。作不同进位(如二进制、八进制、十六进制)运算时，输出结果全都自动转化成了十进制。如：echo $((16#5f)) 结果为95 (16进位转十进制)</p>\n<p>③单纯用 (( )) 也可重定义变量值，比如 a=5; ((a++)) 可将 $a 重定义为6</p>\n<p>④常用于算术运算比较，双括号中的变量可以不使用 <code>$</code> 符号前缀。括号内支持多个表达式用逗号分开。 只要括号中的表达式符合C语言运算规则,比如可以直接使用<code>for((i=0;i&lt;5;i++))</code>, 如果不使用双括号, 则为<figure class=\"highlight plain\"><figcaption><span>i in `seq 0 4` ```或者```for i in &#123;0..4&#125;```。再如可以直接使用if (($i<5)), 5=\"\" 如果不使用双括号,=\"\" 则为if=\"\" [=\"\" $i=\"\" -lt=\"\" ]。<=\"\" span=\"\"></5)),></span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">## 二、中括号，方括号[]</span><br><span class=\"line\"></span><br><span class=\"line\">1、单中括号 []</span><br><span class=\"line\"></span><br><span class=\"line\">①bash 的内部命令，[和test是等同的。如果我们不用绝对路径指明，通常我们用的都是bash自带的命令。if/test结构中的左中括号是调用test的命令标识，右中括号是关闭条件判断的。这个命令把它的参数作为比较表达式或者作为文件测试，并且根据比较的结果来返回一个退出状态码。if/test结构中并不是必须右中括号，但是新版的Bash中要求必须这样。</span><br><span class=\"line\"></span><br><span class=\"line\">②Test和[]中可用的比较运算符只有==和!=，两者都是用于字符串比较的，不可用于整数比较，整数比较只能使用-eq，-gt这种形式。无论是字符串比较还是整数比较都不支持大于号小于号。如果实在想用，对于字符串比较可以使用转义形式，如果比较&quot;ab&quot;和&quot;bc&quot;：[ ab \\&lt; bc ]，结果为真，也就是返回状态为0。[ ]中的逻辑与和逻辑或使用-a 和-o 表示。</span><br><span class=\"line\"></span><br><span class=\"line\">③字符范围。用作正则表达式的一部分，描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。</span><br><span class=\"line\"></span><br><span class=\"line\">④在一个array 结构的上下文中，中括号用来引用数组中每个元素的编号。</span><br><span class=\"line\"></span><br><span class=\"line\">2、双中括号[[ ]]</span><br><span class=\"line\"></span><br><span class=\"line\">①[[是 bash 程序语言的关键字。并不是一个命令，[[ ]] 结构比[ ]结构更加通用。在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割，但是会发生参数扩展和命令替换。</span><br><span class=\"line\"></span><br><span class=\"line\">②支持字符串的模式匹配，使用=~操作符时甚至支持shell的正则表达式。字符串比较时可以把右边的作为一个模式，而不仅仅是一个字符串，比如[[ hello == hell? ]]，结果为真。[[ ]] 中匹配字符串或通配符，不需要引号。</span><br><span class=\"line\"></span><br><span class=\"line\">③使用[[ ... ]]条件判断结构，而不是[ ... ]，能够防止脚本中的许多逻辑错误。比如，&amp;&amp;、||、&lt;和&gt; 操作符能够正常存在于[[ ]]条件判断结构中，但是如果出现在[ ]结构中的话，会报错。比如可以直接使用if [[ $a != 1 &amp;&amp; $a != 2 ]], 如果不适用双括号, 则为if [ $a -ne 1] &amp;&amp; [ $a != 2 ]或者if [ $a -ne 1 -a $a != 2 ]。</span><br><span class=\"line\"></span><br><span class=\"line\">④bash把双中括号中的表达式看作一个单独的元素，并返回一个退出状态码。</span><br><span class=\"line\"></span><br><span class=\"line\">例子：</span><br><span class=\"line\">``` bash</span><br><span class=\"line\">if ($i&lt;5) </span><br><span class=\"line\">if [ $i -lt 5 ] </span><br><span class=\"line\">if [ $a -ne 1 -a $a != 2 ] </span><br><span class=\"line\">if [ $a -ne 1] &amp;&amp; [ $a != 2 ] </span><br><span class=\"line\">if [[ $a != 1 &amp;&amp; $a != 2 ]] </span><br><span class=\"line\">for i in $(seq 0 4);do echo $i;done</span><br><span class=\"line\">for i in `seq 0 4`;do echo $i;done</span><br><span class=\"line\">for ((i=0;i&lt;5;i++));do echo $i;done</span><br><span class=\"line\">for i in &#123;0..4&#125;;do echo $i;done</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"三、大括号、花括号\"><a href=\"#三、大括号、花括号\" class=\"headerlink\" title=\"三、大括号、花括号 {}\"></a>三、大括号、花括号 {}</h2><p>1、常规用法</p>\n<p>①大括号拓展。(通配(globbing))将对大括号中的文件名做扩展。在大括号中，不允许有空白，除非这个空白被引用或转义。第一种：对大括号中的以逗号分割的文件列表进行拓展。如 touch {a,b}.txt 结果为a.txt b.txt。第二种：对大括号中以点点（..）分割的顺序文件列表起拓展作用，如：touch {a..d}.txt 结果为a.txt b.txt c.txt d.txt</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ls &#123;ex1,ex2&#125;.sh </span><br><span class=\"line\"><span class=\"comment\"># ex1.sh ex2.sh </span></span><br><span class=\"line\">ls &#123;ex&#123;1..3&#125;,ex4&#125;.sh </span><br><span class=\"line\"><span class=\"comment\"># ex1.sh ex2.sh ex3.sh ex4.sh </span></span><br><span class=\"line\">ls &#123;ex[1-3],ex4&#125;.sh </span><br><span class=\"line\"><span class=\"comment\"># ex1.sh ex2.sh ex3.sh ex4.sh</span></span><br></pre></td></tr></table></figure>\n<p>②代码块，又被称为内部组，这个结构事实上创建了一个匿名函数 。与小括号中的命令不同，大括号内的命令不会新开一个子shell运行，即脚本余下部分仍可使用括号内变量。括号内的命令间用分号隔开，最后一个也必须有分号。{}的第一个命令和左括号之间必须要有一个空格。</p>\n<p>2、几种特殊的替换结构</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$&#123;var:-string&#125;</span>,<span class=\"variable\">$&#123;var:+string&#125;</span>,<span class=\"variable\">$&#123;var:=string&#125;</span>,<span class=\"variable\">$&#123;var:?string&#125;</span></span><br></pre></td></tr></table></figure>\n<p>①${var:-string}和${var:=string}:若变量var为空，则用在命令行中用string来替换${var:-string}，否则变量var不为空时，则用变量var的值来替换${var:-string}；对于${var:=string}的替换规则和${var:-string}是一样的，所不同之处是${var:=string}若var为空时，用string替换${var:=string}的同时，把string赋给变量var： ${var:=string}很常用的一种用法是，判断某个变量是否赋值，没有的话则给它赋上一个默认值。</p>\n<p>② ${var:+string}的替换规则和上面的相反，即只有当var不是空的时候才替换成string，若var为空时则不替换或者说是替换成变量 var的值，即空值。(因为变量var此时为空，所以这两种说法是等价的)</p>\n<p>③${var:?string}替换规则为：若变量var不为空，则用变量var的值来替换${var:?string}；若变量var为空，则把string输出到标准错误中，并从脚本中退出。我们可利用此特性来检查是否设置了变量的值。</p>\n<p>补充扩展：在上面这五种替换结构中string不一定是常值的，可用另外一个变量的值或是一种命令的输出。</p>\n<p>3、四种模式匹配替换结构</p>\n<p>模式匹配记忆方法：</p>\n<ul>\n<li><h1 id=\"是去掉左边-在键盘上-在-之左边\"><a href=\"#是去掉左边-在键盘上-在-之左边\" class=\"headerlink\" title=\"是去掉左边(在键盘上#在$之左边)\"></a>是去掉左边(在键盘上#在$之左边)</h1></li>\n<li>% 是去掉右边(在键盘上%在$之右边)</li>\n</ul>\n<h1 id=\"和-中的单一符号是最小匹配，两个相同符号是最大匹配。\"><a href=\"#和-中的单一符号是最小匹配，两个相同符号是最大匹配。\" class=\"headerlink\" title=\"和%中的单一符号是最小匹配，两个相同符号是最大匹配。\"></a>和%中的单一符号是最小匹配，两个相同符号是最大匹配。</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$&#123;var%pattern&#125;</span>,<span class=\"variable\">$&#123;var%%pattern&#125;</span>,<span class=\"variable\">$&#123;var#pattern&#125;</span>,<span class=\"variable\">$&#123;var##pattern&#125;</span></span><br></pre></td></tr></table></figure>\n<p>第一种模式：${variable%pattern}，这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最短的匹配模式<br>第二种模式： ${variable%%pattern}，这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式<br>第三种模式：${variable#pattern} 这种模式时，shell在variable中查找，看它是否一给的模式pattern开始，如果是，就从命令行把variable中的内容去掉左边最短的匹配模式<br>第四种模式： ${variable##pattern} 这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式</p>\n<p>这四种模式中都不会改变variable的值，其中，只有在pattern中使用了<em>匹配符号时，%和%%，#和##才有区别。结构中的pattern支持通配符，</em>表示零个或多个任意字符，?表示仅与一个任意字符匹配，[…]表示匹配中括号里面的字符，[!…]表示不匹配中括号里面的字符。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># var=testcase </span></span><br><span class=\"line\"><span class=\"comment\"># echo $var </span></span><br><span class=\"line\">testcase </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var%s*e&#125; </span></span><br><span class=\"line\">testca </span><br><span class=\"line\"><span class=\"comment\"># echo $var </span></span><br><span class=\"line\">testcase </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var%%s*e&#125; </span></span><br><span class=\"line\">te </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var#?e&#125; </span></span><br><span class=\"line\">stcase </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var##?e&#125; </span></span><br><span class=\"line\">stcase </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var##*e&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var##*s&#125; </span></span><br><span class=\"line\">e </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var##test&#125; </span></span><br><span class=\"line\"><span class=\"keyword\">case</span></span><br></pre></td></tr></table></figure></p>\n<p>4、字符串提取和替换<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$&#123;var:num&#125;</span>,<span class=\"variable\">$&#123;var:num1:num2&#125;</span>,<span class=\"variable\">$&#123;var/pattern/pattern&#125;</span>,<span class=\"variable\">$&#123;var//pattern/pattern&#125;</span></span><br></pre></td></tr></table></figure></p>\n<p>第一种模式：${var:num}，这种模式时，shell在var中提取第num个字符到末尾的所有字符。若num为正数，从左边0处开始；若num为负数，从右边开始提取字串，但必须使用在冒号后面加空格或一个数字或整个num加上括号，如${var: -2}、${var:1-3}或${var:(-2)}。</p>\n<p>第二种模式：${var:num1:num2}，num1是位置，num2是长度。表示从$var字符串的第$num1个位置开始提取长度为$num2的子串。不能为负数。</p>\n<p>第三种模式：${var/pattern/pattern}表示将var字符串的第一个匹配的pattern替换为另一个pattern。</p>\n<p>第四种模式：${var//pattern/pattern}表示将var字符串中的所有能匹配的pattern替换为另一个pattern。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var=/home/centos </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$var</span> </span><br><span class=\"line\"><span class=\"comment\">#/home/centos</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var:5&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#/centos</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var: -6&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#centos </span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var:(-6)&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#centos </span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var:1:4&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#home </span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var/o/h&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#/hhme/centos</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var//o/h&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#/hhme/cenths</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"四、符号-后的括号\"><a href=\"#四、符号-后的括号\" class=\"headerlink\" title=\"四、符号$后的括号\"></a>四、符号$后的括号</h2><p>（1）${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。</p>\n<p>（2）$(cmd) 命令替换，和<code>cmd</code>效果相同，结果为shell命令cmd的输，过某些Shell版本不支持$()形式的命令替换, 如tcsh。</p>\n<p>（3）$((expression)) 和<code>exprexpression</code>效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。</p>\n<h2 id=\"五、使用\"><a href=\"#五、使用\" class=\"headerlink\" title=\"五、使用\"></a>五、使用</h2><p>1、多条命令执行</p>\n<p>（1）单小括号，(cmd1;cmd2;cmd3) 新开一个子shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后可以没有分号。</p>\n<p>（2）单大括号，{ cmd1;cmd2;cmd3;} 在当前shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后必须有分号, 第一条命令和左括号之间必须用空格隔开。</p>\n<p>对{}和()而言, 括号中的重定向符只影响该条命令， 而括号外的重定向符影响到括号中的所有命令。</p>\n<hr>\n<h1 id=\"Linux-Shell中三种引号的用法及区别\"><a href=\"#Linux-Shell中三种引号的用法及区别\" class=\"headerlink\" title=\"Linux Shell中三种引号的用法及区别\"></a>Linux Shell中三种引号的用法及区别</h1><p>Linux Shell中有三种引号，分别为双引号（” “）、单引号(‘ ‘)以及反引号(` `)。</p>\n<p>单引号不进行替换，将字符串中所有字符作为普通字符输出，而反引号中字符串作为shell命令执行，并返回执行结果。具体含义如下：</p>\n<ul>\n<li>双引号（” “）：对字符串中出现的 $, ‘’, `和 进行替换，除此以外所有的字符都解释成字符本身。</li>\n<li>单引号（’ ‘）：不替换特殊字符（$,’’,`和\\），将字符串中所有字符作为普通字符输出。</li>\n<li>反引号（` `）：字符串作为shell命令执行，并返回执行结果。</li>\n</ul>\n<hr>\n<h1 id=\"Shell的for循环语句\"><a href=\"#Shell的for循环语句\" class=\"headerlink\" title=\"Shell的for循环语句\"></a>Shell的for循环语句</h1><p>第一类：数字性循环<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 1</span></span><br><span class=\"line\">for((i=1;i&lt;=10;i++));  </span><br><span class=\"line\">do   </span><br><span class=\"line\">echo $(expr $i \\* 3 + 1);  </span><br><span class=\"line\">done  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 2 </span></span><br><span class=\"line\">for i in $(seq 1 10)  </span><br><span class=\"line\">do   </span><br><span class=\"line\">echo $(expr $i \\* 3 + 1);  </span><br><span class=\"line\">done   </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 3</span></span><br><span class=\"line\">for i in &#123;1..10&#125;  </span><br><span class=\"line\">do  </span><br><span class=\"line\">echo $(expr $i \\* 3 + 1);  </span><br><span class=\"line\">done  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 4</span></span><br><span class=\"line\">awk 'BEGIN&#123;for(i=1; i&lt;=10; i++) print i&#125;'</span><br></pre></td></tr></table></figure></p>\n<p>第二类：字符性循环</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> `ls`;  </span><br><span class=\"line\"><span class=\"keyword\">do</span>   </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$i</span> is file name\\! ;  </span><br><span class=\"line\"><span class=\"keyword\">done</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> $* ;  </span><br><span class=\"line\"><span class=\"keyword\">do</span>  </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$i</span> is input chart\\! ;  </span><br><span class=\"line\"><span class=\"keyword\">done</span>  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> f1 f2 f3 ;  </span><br><span class=\"line\"><span class=\"keyword\">do</span>  </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$i</span> is appoint ;  </span><br><span class=\"line\"><span class=\"keyword\">done</span>  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4</span></span><br><span class=\"line\">list=<span class=\"string\">\"rootfs usr data data2\"</span>  </span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"variable\">$list</span>;  </span><br><span class=\"line\"><span class=\"keyword\">do</span>  </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$i</span> is appoint ;  </span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure>\n<p>第三类：路径查找<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for file in /proc/*;  </span><br><span class=\"line\">do  </span><br><span class=\"line\">echo $file is file path \\! ;  </span><br><span class=\"line\">done  </span><br><span class=\"line\"></span><br><span class=\"line\">for file in $(ls *.sh)  </span><br><span class=\"line\">do  </span><br><span class=\"line\">echo $file is file path \\! ;  </span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<p>现在一般都使用for in结构，for in结构后面可以使用函数来构造范围，比如$()、这些，里面写一些查找的语法，比如ls test*，那么遍历之后就是输出文件名了。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"shell中的带名参数\"><a href=\"#shell中的带名参数\" class=\"headerlink\" title=\"shell中的带名参数\"></a>shell中的带名参数</h1><p>getopts</p>\n<p>语法格式：getopts [option[:]] [DESCPRITION] VARIABLE<br>option：表示为某个脚本可以使用的选项<br>“:”：如果某个选项（option）后面出现了冒号（”:”），则表示这个选项后面可以接参数（即一段描述信息DESCPRITION）<br>VARIABLE：表示将某个选项保存在变量VARIABLE中</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"built_in\">getopts</span> <span class=\"string\">\":a:b:c:\"</span> opt</span><br><span class=\"line\"><span class=\"keyword\">do</span></span><br><span class=\"line\">    <span class=\"keyword\">case</span> <span class=\"variable\">$opt</span> <span class=\"keyword\">in</span></span><br><span class=\"line\">        a)</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"参数a的值<span class=\"variable\">$OPTARG</span>\"</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        b)</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"参数b的值<span class=\"variable\">$OPTARG</span>\"</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        c)</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"参数c的值<span class=\"variable\">$OPTARG</span>\"</span></span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        ?)</span><br><span class=\"line\">        <span class=\"built_in\">echo</span> <span class=\"string\">\"未知参数\"</span></span><br><span class=\"line\">        <span class=\"built_in\">exit</span> 1;;</span><br><span class=\"line\">    <span class=\"keyword\">esac</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"Shell中逻辑运算\"><a href=\"#Shell中逻辑运算\" class=\"headerlink\" title=\"Shell中逻辑运算\"></a>Shell中逻辑运算</h1><p>常见错误<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-bash: [: missing `]<span class=\"string\">' # [ 1 -gt 1 ] 括号两边都要有空格，不然就报这个错</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"一、逻辑运算符\"><a href=\"#一、逻辑运算符\" class=\"headerlink\" title=\"一、逻辑运算符\"></a>一、逻辑运算符</h2><h3 id=\"1-关于档案与目录的侦测逻辑卷标！\"><a href=\"#1-关于档案与目录的侦测逻辑卷标！\" class=\"headerlink\" title=\"1.关于档案与目录的侦测逻辑卷标！\"></a>1.关于档案与目录的侦测逻辑卷标！</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>逻辑卷标</th>\n<th>表示意思</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-f</td>\n<td>常用！侦测『档案』是否存在 eg: if [ -f filename ]</td>\n</tr>\n<tr>\n<td>-d</td>\n<td>常用！侦测『目录』是否存在</td>\n</tr>\n<tr>\n<td>-b</td>\n<td>侦测是否为一个『 block 档案』</td>\n</tr>\n<tr>\n<td>-c</td>\n<td>侦测是否为一个『 character 档案』</td>\n</tr>\n<tr>\n<td>-S</td>\n<td>侦测是否为一个『 socket 标签档案』</td>\n</tr>\n<tr>\n<td>-L</td>\n<td>侦测是否为一个『 symbolic link 的档案』</td>\n</tr>\n<tr>\n<td>-e</td>\n<td>侦测『某个东西』是否存在！</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"2-关于程序的逻辑卷标！\"><a href=\"#2-关于程序的逻辑卷标！\" class=\"headerlink\" title=\"2.关于程序的逻辑卷标！\"></a>2.关于程序的逻辑卷标！</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>逻辑卷标</th>\n<th>表示意思</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-G</td>\n<td>侦测是否由 GID 所执行的程序所拥有</td>\n</tr>\n<tr>\n<td>-O</td>\n<td>侦测是否由 UID 所执行的程序所拥有</td>\n</tr>\n<tr>\n<td>-p</td>\n<td>侦测是否为程序间传送信息的 name pipe 或是 FIFO （老实说，这个不太懂！）</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"3-关于档案的属性侦测！\"><a href=\"#3-关于档案的属性侦测！\" class=\"headerlink\" title=\"3.关于档案的属性侦测！\"></a>3.关于档案的属性侦测！</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>逻辑卷标</th>\n<th>表示意思</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-r</td>\n<td>侦测是否为可读的属性</td>\n</tr>\n<tr>\n<td>-w</td>\n<td>侦测是否为可以写入的属性</td>\n</tr>\n<tr>\n<td>-x</td>\n<td>侦测是否为可执行的属性</td>\n</tr>\n<tr>\n<td>-s</td>\n<td>侦测是否为『非空白档案』</td>\n</tr>\n<tr>\n<td>-u</td>\n<td>侦测是否具有『 SUID 』的属性</td>\n</tr>\n<tr>\n<td>-g</td>\n<td>侦测是否具有『 SGID 』的属性</td>\n</tr>\n<tr>\n<td>-k</td>\n<td>侦测是否具有『 sticky bit 』的属性</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"4-两个档案之间的判断与比较-；例如-test-file1-nt-file2\"><a href=\"#4-两个档案之间的判断与比较-；例如-test-file1-nt-file2\" class=\"headerlink\" title=\"4.两个档案之间的判断与比较 ；例如[ test file1 -nt file2 ]\"></a>4.两个档案之间的判断与比较 ；例如[ test file1 -nt file2 ]</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>逻辑卷标</th>\n<th>表示意思</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-nt</td>\n<td>第一个档案比第二个档案新</td>\n</tr>\n<tr>\n<td>-ot</td>\n<td>第一个档案比第二个档案旧</td>\n</tr>\n<tr>\n<td>-ef</td>\n<td>第一个档案与第二个档案为同一个档案（ link 之类的档案）</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"5-逻辑的『和-and-』『或-or-』\"><a href=\"#5-逻辑的『和-and-』『或-or-』\" class=\"headerlink\" title=\"5.逻辑的『和(and)』『或(or)』\"></a>5.逻辑的『和(and)』『或(or)』</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>逻辑卷标</th>\n<th>表示意思</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&amp;&amp;</td>\n<td>逻辑的 AND 的意思</td>\n</tr>\n<tr>\n<td>\\</td>\n<td>\\</td>\n<td></td>\n<td>逻辑的 OR 的意思</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"逻辑运算符\"><a href=\"#逻辑运算符\" class=\"headerlink\" title=\"逻辑运算符\"></a>逻辑运算符</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>运算符号</th>\n<th>代表意义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>=</td>\n<td>等于 应用于：整型或字符串比较 (如果在[] 中，只能是字符串)</td>\n</tr>\n<tr>\n<td>!=</td>\n<td>不等于 应用于：整型或字符串比较 (如果在[] 中，只能是字符串)</td>\n</tr>\n<tr>\n<td>&lt;</td>\n<td>小于 应用于：整型比较 (在[] 中，不能使用 表示字符串 )</td>\n</tr>\n<tr>\n<td>&gt;</td>\n<td>大于 应用于：整型比较 (在[] 中，不能使用 表示字符串)</td>\n</tr>\n<tr>\n<td>-eq</td>\n<td>等于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-ne</td>\n<td>不等于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-lt</td>\n<td>小于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-gt</td>\n<td>大于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-le</td>\n<td>小于或等于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-ge</td>\n<td>大于或等于 应用于：整型比较</td>\n</tr>\n<tr>\n<td>-a</td>\n<td>双方都成立（and） 逻辑表达式 –a 逻辑表达式</td>\n</tr>\n<tr>\n<td>-o</td>\n<td>单方成立（or） 逻辑表达式 –o 逻辑表达式</td>\n</tr>\n<tr>\n<td>-z</td>\n<td>空字符串</td>\n</tr>\n<tr>\n<td>-n</td>\n<td>非空字符串</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"二、逻辑表达式\"><a href=\"#二、逻辑表达式\" class=\"headerlink\" title=\"二、逻辑表达式\"></a>二、逻辑表达式</h2><h3 id=\"test-命令\"><a href=\"#test-命令\" class=\"headerlink\" title=\"test 命令\"></a>test 命令</h3><p>使用方法：test EXPRESSION</p>\n<p>如：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">test</span> 1 = 1 &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span></span><br><span class=\"line\">ok</span><br><span class=\"line\"><span class=\"built_in\">test</span> -d /etc/ &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span> </span><br><span class=\"line\">ok</span><br><span class=\"line\"><span class=\"built_in\">test</span> 1 -eq 1 &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span></span><br><span class=\"line\">ok</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"built_in\">test</span> 1 = 1 ; <span class=\"keyword\">then</span> <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>; <span class=\"keyword\">fi</span></span><br><span class=\"line\">ok</span><br></pre></td></tr></table></figure></p>\n<p>注意：所有字符 与逻辑运算符直接用“空格”分开，不能连到一起。</p>\n<h3 id=\"精简表达式\"><a href=\"#精简表达式\" class=\"headerlink\" title=\"精简表达式\"></a>精简表达式</h3><p>[] 表达式<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[ 1 -eq 1 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># ok</span></span><br><span class=\"line\">[ 2 &lt; 1 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># -bash: 1: No such file or directory</span></span><br><span class=\"line\">[ 2 \\&gt; 1 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># ok</span></span><br><span class=\"line\">[ 2 -gt 1 -a 3 -lt 4 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># ok</span></span><br><span class=\"line\">[ 2 -gt 1 &amp;&amp; 3 -lt 4 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># 这么写不对 -bash: [: missing `]'</span></span><br><span class=\"line\">[ 2 -gt 1 ] &amp;&amp; [ 3 -lt 4 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># ok</span></span><br></pre></td></tr></table></figure></p>\n<p>注意：在[] 表达式中，常见的<code>&gt;</code> 和 <code>&lt;</code>需要加转义字符，表示字符串大小比较，以acill码 位置作为比较。 不直接支持&lt;&gt;运算符，还有逻辑运算符|| &amp;&amp; 它需要用-a[and] –o[or]表示</p>\n<h3 id=\"表达式\"><a href=\"#表达式\" class=\"headerlink\" title=\"[[]] 表达式\"></a>[[]] 表达式</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[ 1 -eq 1 ] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span> <span class=\"comment\"># ok</span></span><br><span class=\"line\">[[ 2 &lt; 3 ]] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span> <span class=\"comment\"># ok</span></span><br><span class=\"line\">[[ 2 &lt; 3 &amp;&amp; 4 &lt; 5 ]] &amp;&amp; <span class=\"built_in\">echo</span> <span class=\"string\">'ok'</span>  <span class=\"comment\"># ok</span></span><br></pre></td></tr></table></figure>\n<p>注意：[[]] 运算符只是[]运算符的扩充。能够支持 <code>&lt;</code> 和 <code>&gt;</code> 符号运算不需要转义符，它还是以字符串比较大小。里面支持逻辑运算符：|| &amp;&amp;</p>\n<h2 id=\"三、性能比较\"><a href=\"#三、性能比较\" class=\"headerlink\" title=\"三、性能比较\"></a>三、性能比较</h2><p>bash的条件表达式中有三个几乎等效的符号和命令：test，[]和[[]]。通常，大家习惯用if [];then这样的形式。而[[]]的出现，根据ABS所说，是为了兼容&gt;&lt;之类的运算符。以下是比较它们性能，发现[[]]是最快的。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">time (<span class=\"keyword\">for</span> m <span class=\"keyword\">in</span> &#123;1..100000&#125;; <span class=\"keyword\">do</span> <span class=\"built_in\">test</span> -d .;<span class=\"keyword\">done</span>;)</span><br><span class=\"line\"><span class=\"comment\">#real    0m0.658s</span></span><br><span class=\"line\"><span class=\"comment\">#user    0m0.558s</span></span><br><span class=\"line\"><span class=\"comment\">#sys     0m0.100s</span></span><br><span class=\"line\"></span><br><span class=\"line\">time (<span class=\"keyword\">for</span> m <span class=\"keyword\">in</span> &#123;1..100000&#125;; <span class=\"keyword\">do</span> [ -d . ];<span class=\"keyword\">done</span>;)</span><br><span class=\"line\"><span class=\"comment\">#real    0m0.609s</span></span><br><span class=\"line\"><span class=\"comment\">#user    0m0.524s</span></span><br><span class=\"line\"><span class=\"comment\">#sys     0m0.085s</span></span><br><span class=\"line\"></span><br><span class=\"line\">time (<span class=\"keyword\">for</span> m <span class=\"keyword\">in</span> &#123;1..100000&#125;; <span class=\"keyword\">do</span> [[ -d . ]];<span class=\"keyword\">done</span>;)</span><br><span class=\"line\"><span class=\"comment\">#real    0m0.311s</span></span><br><span class=\"line\"><span class=\"comment\">#user    0m0.275s</span></span><br><span class=\"line\"><span class=\"comment\">#sys     0m0.036s</span></span><br></pre></td></tr></table></figure>\n<p>不考虑对低版本bash和对sh的兼容的情况下，用[[]]是兼容性强，而且性能比较快，在做条件运算时候，可以使用该运算符。</p>\n<h1 id=\"shell脚本参数\"><a href=\"#shell脚本参数\" class=\"headerlink\" title=\"shell脚本参数\"></a>shell脚本参数</h1><p>$0 当前脚本的文件名</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$#</span> -gt 0 ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    data=<span class=\"variable\">$1</span> </span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    data=`date +<span class=\"string\">\"%Y-%m-%d\"</span>`</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"2-gt-amp-1\"><a href=\"#2-gt-amp-1\" class=\"headerlink\" title=\"2&gt;&amp;1\"></a>2&gt;&amp;1</h1><p>配置spark每日例行任务时候，直接运行脚本可以输入spark任务的运行信息，可是一旦用crontab就不行了，原来spark的任务日志是linux“错误输出”，要加2&gt;&amp;1 才能从正常输出里面捕捉到，坑死了。</p>\n<p>ref:<a href=\"https://www.cnblogs.com/zhenghongxin/p/7029173.html\" target=\"_blank\" rel=\"noopener\">Linux 2&gt;&amp;1</a></p>\n<h1 id=\"获取当前脚本的路径\"><a href=\"#获取当前脚本的路径\" class=\"headerlink\" title=\"获取当前脚本的路径\"></a>获取当前脚本的路径</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$(<span class=\"built_in\">cd</span> `dirname <span class=\"variable\">$0</span>`;<span class=\"built_in\">pwd</span>)</span><br><span class=\"line\">SCRIPT_DIR=<span class=\"string\">\"<span class=\"variable\">$(cd \"$(dirname \"$&#123;BASH_SOURCE[0]&#125;\")</span>\"</span> &amp;&amp; <span class=\"built_in\">pwd</span>)<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\"># <span class=\"variable\">$()</span> 和 `` 作用相同，字符串作为shell命令执行</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"># BASH_SOURCE[0] 等价于 BASH_SOURCE， 取得当前执行的shell文件所在的路径及文件名。</span></span><br><span class=\"line\"><span class=\"string\"># 如/home/abc/test.sh 内容如下：</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">#!/bin/sh</span></span><br><span class=\"line\"><span class=\"string\">echo \"</span><span class=\"variable\">$&#123;BASH_SOURCE[0]&#125;</span><span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">echo \"</span><span class=\"variable\">$&#123;BASH_SOURCE]&#125;</span><span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">echo \"</span>$( dirname <span class=\"string\">\"<span class=\"variable\">$&#123;BASH_SOURCE[0]&#125;</span>\"</span> )<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">DIR=\"</span>$( <span class=\"built_in\">cd</span> <span class=\"string\">\"<span class=\"variable\">$( dirname \"$&#123;BASH_SOURCE[0]&#125;\" )</span>\"</span> &amp;&amp; <span class=\"built_in\">pwd</span> )<span class=\"string\">\"</span></span><br><span class=\"line\"><span class=\"string\">echo <span class=\"variable\">$DIR</span></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"># 若当前目录在/home/,执行source ./abc/test.sh, 则输出：</span></span><br><span class=\"line\"><span class=\"string\"># ./abc/test.sh</span></span><br><span class=\"line\"><span class=\"string\"># ./abc/test.sh</span></span><br><span class=\"line\"><span class=\"string\"># ./abc/</span></span><br><span class=\"line\"><span class=\"string\"># /home/abc</span></span><br></pre></td></tr></table></figure>\n<p>总之：<br><code>DIR=&quot;$( cd &quot;$( dirname &quot;${BASH_SOURCE[0]}&quot; )&quot; &amp;&amp; pwd )&quot;</code>得到shell脚本文件所在完整路径（绝对路径）及文件名（无论source,sh,.三种调用方式），且不改变shell的当前目录。</p>\n<hr>\n<h1 id=\"Linux-中的各种括号\"><a href=\"#Linux-中的各种括号\" class=\"headerlink\" title=\"Linux 中的各种括号\"></a>Linux 中的各种括号</h1><p>参考：<a href=\"https://www.jb51.net/article/123081.htm\" target=\"_blank\" rel=\"noopener\">https://www.jb51.net/article/123081.htm</a></p>\n<h2 id=\"一、小括号，圆括号（）\"><a href=\"#一、小括号，圆括号（）\" class=\"headerlink\" title=\"一、小括号，圆括号（）\"></a>一、小括号，圆括号（）</h2><p>1、单小括号 ()</p>\n<p>①命令组。括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用。括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括号之间不必有空格。</p>\n<p>②命令替换。等同于<code>cmd</code>，shell扫描一遍命令行，发现了$(cmd)结构，便将$(cmd)中的cmd执行一次，得到其标准输出，再将此输出放到原来命令。有些shell不支持，如tcsh。</p>\n<p>③用于初始化数组。如：array=(a b c d)</p>\n<p>2、双小括号 (( ))</p>\n<p>①整数扩展。这种扩展计算是整数型的计算，不支持浮点型。((exp))结构扩展并计算一个算术表达式的值，如果表达式的结果为0，那么返回的退出状态码为1，或者 是”假”，而一个非零值的表达式所返回的退出状态码将为0，或者是”true”。若是逻辑判断，表达式exp为真则为1,假则为0。</p>\n<p>②只要括号中的运算符、表达式符合C语言运算规则，都可用在$((exp))中，甚至是三目运算符。作不同进位(如二进制、八进制、十六进制)运算时，输出结果全都自动转化成了十进制。如：echo $((16#5f)) 结果为95 (16进位转十进制)</p>\n<p>③单纯用 (( )) 也可重定义变量值，比如 a=5; ((a++)) 可将 $a 重定义为6</p>\n<p>④常用于算术运算比较，双括号中的变量可以不使用 <code>$</code> 符号前缀。括号内支持多个表达式用逗号分开。 只要括号中的表达式符合C语言运算规则,比如可以直接使用<code>for((i=0;i&lt;5;i++))</code>, 如果不使用双括号, 则为<figure class=\"highlight plain\"><figcaption><span>i in `seq 0 4` ```或者```for i in &#123;0..4&#125;```。再如可以直接使用if (($i<5)), 5=\"\" 如果不使用双括号,=\"\" 则为if=\"\" [=\"\" $i=\"\" -lt=\"\" ]。<=\"\" span=\"\"></5)),></span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">## 二、中括号，方括号[]</span><br><span class=\"line\"></span><br><span class=\"line\">1、单中括号 []</span><br><span class=\"line\"></span><br><span class=\"line\">①bash 的内部命令，[和test是等同的。如果我们不用绝对路径指明，通常我们用的都是bash自带的命令。if/test结构中的左中括号是调用test的命令标识，右中括号是关闭条件判断的。这个命令把它的参数作为比较表达式或者作为文件测试，并且根据比较的结果来返回一个退出状态码。if/test结构中并不是必须右中括号，但是新版的Bash中要求必须这样。</span><br><span class=\"line\"></span><br><span class=\"line\">②Test和[]中可用的比较运算符只有==和!=，两者都是用于字符串比较的，不可用于整数比较，整数比较只能使用-eq，-gt这种形式。无论是字符串比较还是整数比较都不支持大于号小于号。如果实在想用，对于字符串比较可以使用转义形式，如果比较&quot;ab&quot;和&quot;bc&quot;：[ ab \\&lt; bc ]，结果为真，也就是返回状态为0。[ ]中的逻辑与和逻辑或使用-a 和-o 表示。</span><br><span class=\"line\"></span><br><span class=\"line\">③字符范围。用作正则表达式的一部分，描述一个匹配的字符范围。作为test用途的中括号内不能使用正则。</span><br><span class=\"line\"></span><br><span class=\"line\">④在一个array 结构的上下文中，中括号用来引用数组中每个元素的编号。</span><br><span class=\"line\"></span><br><span class=\"line\">2、双中括号[[ ]]</span><br><span class=\"line\"></span><br><span class=\"line\">①[[是 bash 程序语言的关键字。并不是一个命令，[[ ]] 结构比[ ]结构更加通用。在[[和]]之间所有的字符都不会发生文件名扩展或者单词分割，但是会发生参数扩展和命令替换。</span><br><span class=\"line\"></span><br><span class=\"line\">②支持字符串的模式匹配，使用=~操作符时甚至支持shell的正则表达式。字符串比较时可以把右边的作为一个模式，而不仅仅是一个字符串，比如[[ hello == hell? ]]，结果为真。[[ ]] 中匹配字符串或通配符，不需要引号。</span><br><span class=\"line\"></span><br><span class=\"line\">③使用[[ ... ]]条件判断结构，而不是[ ... ]，能够防止脚本中的许多逻辑错误。比如，&amp;&amp;、||、&lt;和&gt; 操作符能够正常存在于[[ ]]条件判断结构中，但是如果出现在[ ]结构中的话，会报错。比如可以直接使用if [[ $a != 1 &amp;&amp; $a != 2 ]], 如果不适用双括号, 则为if [ $a -ne 1] &amp;&amp; [ $a != 2 ]或者if [ $a -ne 1 -a $a != 2 ]。</span><br><span class=\"line\"></span><br><span class=\"line\">④bash把双中括号中的表达式看作一个单独的元素，并返回一个退出状态码。</span><br><span class=\"line\"></span><br><span class=\"line\">例子：</span><br><span class=\"line\">``` bash</span><br><span class=\"line\">if ($i&lt;5) </span><br><span class=\"line\">if [ $i -lt 5 ] </span><br><span class=\"line\">if [ $a -ne 1 -a $a != 2 ] </span><br><span class=\"line\">if [ $a -ne 1] &amp;&amp; [ $a != 2 ] </span><br><span class=\"line\">if [[ $a != 1 &amp;&amp; $a != 2 ]] </span><br><span class=\"line\">for i in $(seq 0 4);do echo $i;done</span><br><span class=\"line\">for i in `seq 0 4`;do echo $i;done</span><br><span class=\"line\">for ((i=0;i&lt;5;i++));do echo $i;done</span><br><span class=\"line\">for i in &#123;0..4&#125;;do echo $i;done</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"三、大括号、花括号\"><a href=\"#三、大括号、花括号\" class=\"headerlink\" title=\"三、大括号、花括号 {}\"></a>三、大括号、花括号 {}</h2><p>1、常规用法</p>\n<p>①大括号拓展。(通配(globbing))将对大括号中的文件名做扩展。在大括号中，不允许有空白，除非这个空白被引用或转义。第一种：对大括号中的以逗号分割的文件列表进行拓展。如 touch {a,b}.txt 结果为a.txt b.txt。第二种：对大括号中以点点（..）分割的顺序文件列表起拓展作用，如：touch {a..d}.txt 结果为a.txt b.txt c.txt d.txt</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ls &#123;ex1,ex2&#125;.sh </span><br><span class=\"line\"><span class=\"comment\"># ex1.sh ex2.sh </span></span><br><span class=\"line\">ls &#123;ex&#123;1..3&#125;,ex4&#125;.sh </span><br><span class=\"line\"><span class=\"comment\"># ex1.sh ex2.sh ex3.sh ex4.sh </span></span><br><span class=\"line\">ls &#123;ex[1-3],ex4&#125;.sh </span><br><span class=\"line\"><span class=\"comment\"># ex1.sh ex2.sh ex3.sh ex4.sh</span></span><br></pre></td></tr></table></figure>\n<p>②代码块，又被称为内部组，这个结构事实上创建了一个匿名函数 。与小括号中的命令不同，大括号内的命令不会新开一个子shell运行，即脚本余下部分仍可使用括号内变量。括号内的命令间用分号隔开，最后一个也必须有分号。{}的第一个命令和左括号之间必须要有一个空格。</p>\n<p>2、几种特殊的替换结构</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$&#123;var:-string&#125;</span>,<span class=\"variable\">$&#123;var:+string&#125;</span>,<span class=\"variable\">$&#123;var:=string&#125;</span>,<span class=\"variable\">$&#123;var:?string&#125;</span></span><br></pre></td></tr></table></figure>\n<p>①${var:-string}和${var:=string}:若变量var为空，则用在命令行中用string来替换${var:-string}，否则变量var不为空时，则用变量var的值来替换${var:-string}；对于${var:=string}的替换规则和${var:-string}是一样的，所不同之处是${var:=string}若var为空时，用string替换${var:=string}的同时，把string赋给变量var： ${var:=string}很常用的一种用法是，判断某个变量是否赋值，没有的话则给它赋上一个默认值。</p>\n<p>② ${var:+string}的替换规则和上面的相反，即只有当var不是空的时候才替换成string，若var为空时则不替换或者说是替换成变量 var的值，即空值。(因为变量var此时为空，所以这两种说法是等价的)</p>\n<p>③${var:?string}替换规则为：若变量var不为空，则用变量var的值来替换${var:?string}；若变量var为空，则把string输出到标准错误中，并从脚本中退出。我们可利用此特性来检查是否设置了变量的值。</p>\n<p>补充扩展：在上面这五种替换结构中string不一定是常值的，可用另外一个变量的值或是一种命令的输出。</p>\n<p>3、四种模式匹配替换结构</p>\n<p>模式匹配记忆方法：</p>\n<ul>\n<li><h1 id=\"是去掉左边-在键盘上-在-之左边\"><a href=\"#是去掉左边-在键盘上-在-之左边\" class=\"headerlink\" title=\"是去掉左边(在键盘上#在$之左边)\"></a>是去掉左边(在键盘上#在$之左边)</h1></li>\n<li>% 是去掉右边(在键盘上%在$之右边)</li>\n</ul>\n<h1 id=\"和-中的单一符号是最小匹配，两个相同符号是最大匹配。\"><a href=\"#和-中的单一符号是最小匹配，两个相同符号是最大匹配。\" class=\"headerlink\" title=\"和%中的单一符号是最小匹配，两个相同符号是最大匹配。\"></a>和%中的单一符号是最小匹配，两个相同符号是最大匹配。</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$&#123;var%pattern&#125;</span>,<span class=\"variable\">$&#123;var%%pattern&#125;</span>,<span class=\"variable\">$&#123;var#pattern&#125;</span>,<span class=\"variable\">$&#123;var##pattern&#125;</span></span><br></pre></td></tr></table></figure>\n<p>第一种模式：${variable%pattern}，这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最短的匹配模式<br>第二种模式： ${variable%%pattern}，这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式<br>第三种模式：${variable#pattern} 这种模式时，shell在variable中查找，看它是否一给的模式pattern开始，如果是，就从命令行把variable中的内容去掉左边最短的匹配模式<br>第四种模式： ${variable##pattern} 这种模式时，shell在variable中查找，看它是否一给的模式pattern结尾，如果是，就从命令行把variable中的内容去掉右边最长的匹配模式</p>\n<p>这四种模式中都不会改变variable的值，其中，只有在pattern中使用了<em>匹配符号时，%和%%，#和##才有区别。结构中的pattern支持通配符，</em>表示零个或多个任意字符，?表示仅与一个任意字符匹配，[…]表示匹配中括号里面的字符，[!…]表示不匹配中括号里面的字符。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># var=testcase </span></span><br><span class=\"line\"><span class=\"comment\"># echo $var </span></span><br><span class=\"line\">testcase </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var%s*e&#125; </span></span><br><span class=\"line\">testca </span><br><span class=\"line\"><span class=\"comment\"># echo $var </span></span><br><span class=\"line\">testcase </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var%%s*e&#125; </span></span><br><span class=\"line\">te </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var#?e&#125; </span></span><br><span class=\"line\">stcase </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var##?e&#125; </span></span><br><span class=\"line\">stcase </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var##*e&#125;</span></span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var##*s&#125; </span></span><br><span class=\"line\">e </span><br><span class=\"line\"><span class=\"comment\"># echo $&#123;var##test&#125; </span></span><br><span class=\"line\"><span class=\"keyword\">case</span></span><br></pre></td></tr></table></figure></p>\n<p>4、字符串提取和替换<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable\">$&#123;var:num&#125;</span>,<span class=\"variable\">$&#123;var:num1:num2&#125;</span>,<span class=\"variable\">$&#123;var/pattern/pattern&#125;</span>,<span class=\"variable\">$&#123;var//pattern/pattern&#125;</span></span><br></pre></td></tr></table></figure></p>\n<p>第一种模式：${var:num}，这种模式时，shell在var中提取第num个字符到末尾的所有字符。若num为正数，从左边0处开始；若num为负数，从右边开始提取字串，但必须使用在冒号后面加空格或一个数字或整个num加上括号，如${var: -2}、${var:1-3}或${var:(-2)}。</p>\n<p>第二种模式：${var:num1:num2}，num1是位置，num2是长度。表示从$var字符串的第$num1个位置开始提取长度为$num2的子串。不能为负数。</p>\n<p>第三种模式：${var/pattern/pattern}表示将var字符串的第一个匹配的pattern替换为另一个pattern。</p>\n<p>第四种模式：${var//pattern/pattern}表示将var字符串中的所有能匹配的pattern替换为另一个pattern。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">var=/home/centos </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$var</span> </span><br><span class=\"line\"><span class=\"comment\">#/home/centos</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var:5&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#/centos</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var: -6&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#centos </span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var:(-6)&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#centos </span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var:1:4&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#home </span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var/o/h&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#/hhme/centos</span></span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$&#123;var//o/h&#125;</span> </span><br><span class=\"line\"><span class=\"comment\">#/hhme/cenths</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"四、符号-后的括号\"><a href=\"#四、符号-后的括号\" class=\"headerlink\" title=\"四、符号$后的括号\"></a>四、符号$后的括号</h2><p>（1）${a} 变量a的值, 在不引起歧义的情况下可以省略大括号。</p>\n<p>（2）$(cmd) 命令替换，和<code>cmd</code>效果相同，结果为shell命令cmd的输，过某些Shell版本不支持$()形式的命令替换, 如tcsh。</p>\n<p>（3）$((expression)) 和<code>exprexpression</code>效果相同, 计算数学表达式exp的数值, 其中exp只要符合C语言的运算规则即可, 甚至三目运算符和逻辑表达式都可以计算。</p>\n<h2 id=\"五、使用\"><a href=\"#五、使用\" class=\"headerlink\" title=\"五、使用\"></a>五、使用</h2><p>1、多条命令执行</p>\n<p>（1）单小括号，(cmd1;cmd2;cmd3) 新开一个子shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后可以没有分号。</p>\n<p>（2）单大括号，{ cmd1;cmd2;cmd3;} 在当前shell顺序执行命令cmd1,cmd2,cmd3, 各命令之间用分号隔开, 最后一个命令后必须有分号, 第一条命令和左括号之间必须用空格隔开。</p>\n<p>对{}和()而言, 括号中的重定向符只影响该条命令， 而括号外的重定向符影响到括号中的所有命令。</p>\n<hr>\n<h1 id=\"Linux-Shell中三种引号的用法及区别\"><a href=\"#Linux-Shell中三种引号的用法及区别\" class=\"headerlink\" title=\"Linux Shell中三种引号的用法及区别\"></a>Linux Shell中三种引号的用法及区别</h1><p>Linux Shell中有三种引号，分别为双引号（” “）、单引号(‘ ‘)以及反引号(` `)。</p>\n<p>单引号不进行替换，将字符串中所有字符作为普通字符输出，而反引号中字符串作为shell命令执行，并返回执行结果。具体含义如下：</p>\n<ul>\n<li>双引号（” “）：对字符串中出现的 $, ‘’, `和 进行替换，除此以外所有的字符都解释成字符本身。</li>\n<li>单引号（’ ‘）：不替换特殊字符（$,’’,`和\\），将字符串中所有字符作为普通字符输出。</li>\n<li>反引号（` `）：字符串作为shell命令执行，并返回执行结果。</li>\n</ul>\n<hr>\n<h1 id=\"Shell的for循环语句\"><a href=\"#Shell的for循环语句\" class=\"headerlink\" title=\"Shell的for循环语句\"></a>Shell的for循环语句</h1><p>第一类：数字性循环<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 1</span></span><br><span class=\"line\">for((i=1;i&lt;=10;i++));  </span><br><span class=\"line\">do   </span><br><span class=\"line\">echo $(expr $i \\* 3 + 1);  </span><br><span class=\"line\">done  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 2 </span></span><br><span class=\"line\">for i in $(seq 1 10)  </span><br><span class=\"line\">do   </span><br><span class=\"line\">echo $(expr $i \\* 3 + 1);  </span><br><span class=\"line\">done   </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 3</span></span><br><span class=\"line\">for i in &#123;1..10&#125;  </span><br><span class=\"line\">do  </span><br><span class=\"line\">echo $(expr $i \\* 3 + 1);  </span><br><span class=\"line\">done  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 4</span></span><br><span class=\"line\">awk 'BEGIN&#123;for(i=1; i&lt;=10; i++) print i&#125;'</span><br></pre></td></tr></table></figure></p>\n<p>第二类：字符性循环</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> `ls`;  </span><br><span class=\"line\"><span class=\"keyword\">do</span>   </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$i</span> is file name\\! ;  </span><br><span class=\"line\"><span class=\"keyword\">done</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> $* ;  </span><br><span class=\"line\"><span class=\"keyword\">do</span>  </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$i</span> is input chart\\! ;  </span><br><span class=\"line\"><span class=\"keyword\">done</span>  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> f1 f2 f3 ;  </span><br><span class=\"line\"><span class=\"keyword\">do</span>  </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$i</span> is appoint ;  </span><br><span class=\"line\"><span class=\"keyword\">done</span>  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4</span></span><br><span class=\"line\">list=<span class=\"string\">\"rootfs usr data data2\"</span>  </span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"variable\">$list</span>;  </span><br><span class=\"line\"><span class=\"keyword\">do</span>  </span><br><span class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$i</span> is appoint ;  </span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br></pre></td></tr></table></figure>\n<p>第三类：路径查找<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for file in /proc/*;  </span><br><span class=\"line\">do  </span><br><span class=\"line\">echo $file is file path \\! ;  </span><br><span class=\"line\">done  </span><br><span class=\"line\"></span><br><span class=\"line\">for file in $(ls *.sh)  </span><br><span class=\"line\">do  </span><br><span class=\"line\">echo $file is file path \\! ;  </span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<p>现在一般都使用for in结构，for in结构后面可以使用函数来构造范围，比如$()、这些，里面写一些查找的语法，比如ls test*，那么遍历之后就是输出文件名了。</p>\n"},{"title":"二叉树的前序、中序、后序遍历（java实现）","date":"2018-08-08T14:44:02.000Z","_content":"\n雄关漫道真如铁！而今迈步从头越。 =。=\n\n# 0\n\n![](http://p8vrqzrnj.bkt.clouddn.com/treetraversal.png)\n\n- 前序遍历：4 2 1 3 6 5 7 8 10\n- 中序遍历：1 2 3 4 5 6 7 8 10\n- 后序遍历：1 3 2 5 10 8 7 6 4\n- 层序遍历：4 2 6 1 3 5 7 8 10\n\n# 前序遍历\n\n## Recursive\n\n``` java\n/**\n * Definition for a binary tree node.\n * public class TreeNode {\n *     int val;\n *     TreeNode left;\n *     TreeNode right;\n *     TreeNode(int x) { val = x; }\n * }\n */\nclass Solution {\n    List<Integer> res = new ArrayList<Integer>();\n    public List<Integer> preorderTraversal(TreeNode root) {\n        if (root != null) {\n            res.add(root.val);\n            preorderTraversal(root.left);\n            preorderTraversal(root.right);\n        }\n        return res;\n    }\n}\n```\n\n## Iterative\n\n``` java\nclass Solution {\n    public List<Integer> preorderTraversal(TreeNode root) {\n        List<Integer> res = new ArrayList<Integer>();\n        Stack<TreeNode> stack = new Stack<TreeNode>();\n        \n        while (root != null || !stack.isEmpty()) {\n            while(root != null) {\n                res.add(root.val);\n                stack.push(root);\n                root = root.left;\n            }\n            root = stack.pop();\n            root = root.right;\n        }\n        return res;\n    }\n}\n```\n\n# 中序遍历\n\n## Recursive\n\n``` java\nclass Solution {\n    List<Integer> res = new ArrayList<Integer>();\n    public List<Integer> inorderTraversal(TreeNode root) {\n        if (root != null) {\n            inorderTraversal(root.left);\n            res.add(root.val);\n            inorderTraversal(root.right);\n        }\n        return res;\n    }\n}\n```\n\n## Iterative\n\n``` java\nclass Solution {\n    public List<Integer> inorderTraversal(TreeNode root) {\n        List<Integer> res = new ArrayList<Integer>();\n        Stack<TreeNode> stack = new Stack<TreeNode>();\n        while (root != null || !stack.isEmpty()) {\n            while (root != null) {\n                stack.push(root);\n                root = root.left;\n            }\n            root = stack.pop();\n            res.add(root.val);\n            root = root.right;\n        }\n        return res;\n    }\n}\n```\n\n# 后续遍历\n\n## Recursive\n\n``` java\nclass Solution {\n    List<Integer> res = new ArrayList<Integer>();\n    public List<Integer> postorderTraversal(TreeNode root) {\n        if (root != null) {\n            postorderTraversal(root.left);\n            postorderTraversal(root.right);\n            res.add(root.val);\n        }\n        return res;\n    }\n}\n```\n\n## Iterative\n\n``` java\nclass Solution {\n    public List<Integer> postorderTraversal(TreeNode root) {\n        List<Integer> res = new ArrayList<Integer>();\n        Stack<TreeNode> stack = new Stack<TreeNode>();\n        TreeNode lastAdd = null;\n        while (!stack.isEmpty() || root != null) {\n            if (root != null) {\n                stack.push(root);\n                root = root.left;\n            } else {\n                TreeNode node = stack.peek();\n                if (node.right != null && node.right != lastAdd) {\n                    root = node.right;\n                } else {\n                    res.add(node.val);\n                    lastAdd = stack.pop();\n                }\n            }\n        }\n        return res;\n    }\n}\n```\n\n# TODO\n\n多叉树的遍历","source":"_posts/201808-alg-tree-traversal.md","raw":"---\ntitle: 二叉树的前序、中序、后序遍历（java实现）\ndate: 2018-08-08 22:44:02\ncategories: 算法\ntags:\n    - 树遍历\n    - 树算法\n    - 算法\n---\n\n雄关漫道真如铁！而今迈步从头越。 =。=\n\n# 0\n\n![](http://p8vrqzrnj.bkt.clouddn.com/treetraversal.png)\n\n- 前序遍历：4 2 1 3 6 5 7 8 10\n- 中序遍历：1 2 3 4 5 6 7 8 10\n- 后序遍历：1 3 2 5 10 8 7 6 4\n- 层序遍历：4 2 6 1 3 5 7 8 10\n\n# 前序遍历\n\n## Recursive\n\n``` java\n/**\n * Definition for a binary tree node.\n * public class TreeNode {\n *     int val;\n *     TreeNode left;\n *     TreeNode right;\n *     TreeNode(int x) { val = x; }\n * }\n */\nclass Solution {\n    List<Integer> res = new ArrayList<Integer>();\n    public List<Integer> preorderTraversal(TreeNode root) {\n        if (root != null) {\n            res.add(root.val);\n            preorderTraversal(root.left);\n            preorderTraversal(root.right);\n        }\n        return res;\n    }\n}\n```\n\n## Iterative\n\n``` java\nclass Solution {\n    public List<Integer> preorderTraversal(TreeNode root) {\n        List<Integer> res = new ArrayList<Integer>();\n        Stack<TreeNode> stack = new Stack<TreeNode>();\n        \n        while (root != null || !stack.isEmpty()) {\n            while(root != null) {\n                res.add(root.val);\n                stack.push(root);\n                root = root.left;\n            }\n            root = stack.pop();\n            root = root.right;\n        }\n        return res;\n    }\n}\n```\n\n# 中序遍历\n\n## Recursive\n\n``` java\nclass Solution {\n    List<Integer> res = new ArrayList<Integer>();\n    public List<Integer> inorderTraversal(TreeNode root) {\n        if (root != null) {\n            inorderTraversal(root.left);\n            res.add(root.val);\n            inorderTraversal(root.right);\n        }\n        return res;\n    }\n}\n```\n\n## Iterative\n\n``` java\nclass Solution {\n    public List<Integer> inorderTraversal(TreeNode root) {\n        List<Integer> res = new ArrayList<Integer>();\n        Stack<TreeNode> stack = new Stack<TreeNode>();\n        while (root != null || !stack.isEmpty()) {\n            while (root != null) {\n                stack.push(root);\n                root = root.left;\n            }\n            root = stack.pop();\n            res.add(root.val);\n            root = root.right;\n        }\n        return res;\n    }\n}\n```\n\n# 后续遍历\n\n## Recursive\n\n``` java\nclass Solution {\n    List<Integer> res = new ArrayList<Integer>();\n    public List<Integer> postorderTraversal(TreeNode root) {\n        if (root != null) {\n            postorderTraversal(root.left);\n            postorderTraversal(root.right);\n            res.add(root.val);\n        }\n        return res;\n    }\n}\n```\n\n## Iterative\n\n``` java\nclass Solution {\n    public List<Integer> postorderTraversal(TreeNode root) {\n        List<Integer> res = new ArrayList<Integer>();\n        Stack<TreeNode> stack = new Stack<TreeNode>();\n        TreeNode lastAdd = null;\n        while (!stack.isEmpty() || root != null) {\n            if (root != null) {\n                stack.push(root);\n                root = root.left;\n            } else {\n                TreeNode node = stack.peek();\n                if (node.right != null && node.right != lastAdd) {\n                    root = node.right;\n                } else {\n                    res.add(node.val);\n                    lastAdd = stack.pop();\n                }\n            }\n        }\n        return res;\n    }\n}\n```\n\n# TODO\n\n多叉树的遍历","slug":"alg-tree-traversal","published":1,"updated":"2018-08-08T17:36:31.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7y7001fn61dw79vqta0","content":"<p>雄关漫道真如铁！而今迈步从头越。 =。=</p>\n<h1 id=\"0\"><a href=\"#0\" class=\"headerlink\" title=\"0\"></a>0</h1><p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/treetraversal.png\" alt=\"\"></p>\n<ul>\n<li>前序遍历：4 2 1 3 6 5 7 8 10</li>\n<li>中序遍历：1 2 3 4 5 6 7 8 10</li>\n<li>后序遍历：1 3 2 5 10 8 7 6 4</li>\n<li>层序遍历：4 2 6 1 3 5 7 8 10</li>\n</ul>\n<h1 id=\"前序遍历\"><a href=\"#前序遍历\" class=\"headerlink\" title=\"前序遍历\"></a>前序遍历</h1><h2 id=\"Recursive\"><a href=\"#Recursive\" class=\"headerlink\" title=\"Recursive\"></a>Recursive</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Definition for a binary tree node.</span></span><br><span class=\"line\"><span class=\"comment\"> * public class TreeNode &#123;</span></span><br><span class=\"line\"><span class=\"comment\"> *     int val;</span></span><br><span class=\"line\"><span class=\"comment\"> *     TreeNode left;</span></span><br><span class=\"line\"><span class=\"comment\"> *     TreeNode right;</span></span><br><span class=\"line\"><span class=\"comment\"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class=\"line\"><span class=\"comment\"> * &#125;</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">preorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            res.add(root.val);</span><br><span class=\"line\">            preorderTraversal(root.left);</span><br><span class=\"line\">            preorderTraversal(root.right);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Iterative\"><a href=\"#Iterative\" class=\"headerlink\" title=\"Iterative\"></a>Iterative</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">preorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">        Stack&lt;TreeNode&gt; stack = <span class=\"keyword\">new</span> Stack&lt;TreeNode&gt;();</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">while</span> (root != <span class=\"keyword\">null</span> || !stack.isEmpty()) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">while</span>(root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                res.add(root.val);</span><br><span class=\"line\">                stack.push(root);</span><br><span class=\"line\">                root = root.left;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            root = stack.pop();</span><br><span class=\"line\">            root = root.right;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"中序遍历\"><a href=\"#中序遍历\" class=\"headerlink\" title=\"中序遍历\"></a>中序遍历</h1><h2 id=\"Recursive-1\"><a href=\"#Recursive-1\" class=\"headerlink\" title=\"Recursive\"></a>Recursive</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">inorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            inorderTraversal(root.left);</span><br><span class=\"line\">            res.add(root.val);</span><br><span class=\"line\">            inorderTraversal(root.right);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Iterative-1\"><a href=\"#Iterative-1\" class=\"headerlink\" title=\"Iterative\"></a>Iterative</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">inorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">        Stack&lt;TreeNode&gt; stack = <span class=\"keyword\">new</span> Stack&lt;TreeNode&gt;();</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (root != <span class=\"keyword\">null</span> || !stack.isEmpty()) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                stack.push(root);</span><br><span class=\"line\">                root = root.left;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            root = stack.pop();</span><br><span class=\"line\">            res.add(root.val);</span><br><span class=\"line\">            root = root.right;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"后续遍历\"><a href=\"#后续遍历\" class=\"headerlink\" title=\"后续遍历\"></a>后续遍历</h1><h2 id=\"Recursive-2\"><a href=\"#Recursive-2\" class=\"headerlink\" title=\"Recursive\"></a>Recursive</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">postorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            postorderTraversal(root.left);</span><br><span class=\"line\">            postorderTraversal(root.right);</span><br><span class=\"line\">            res.add(root.val);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Iterative-2\"><a href=\"#Iterative-2\" class=\"headerlink\" title=\"Iterative\"></a>Iterative</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">postorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">        Stack&lt;TreeNode&gt; stack = <span class=\"keyword\">new</span> Stack&lt;TreeNode&gt;();</span><br><span class=\"line\">        TreeNode lastAdd = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (!stack.isEmpty() || root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                stack.push(root);</span><br><span class=\"line\">                root = root.left;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                TreeNode node = stack.peek();</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (node.right != <span class=\"keyword\">null</span> &amp;&amp; node.right != lastAdd) &#123;</span><br><span class=\"line\">                    root = node.right;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                    res.add(node.val);</span><br><span class=\"line\">                    lastAdd = stack.pop();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"TODO\"><a href=\"#TODO\" class=\"headerlink\" title=\"TODO\"></a>TODO</h1><p>多叉树的遍历</p>\n","site":{"data":{}},"excerpt":"","more":"<p>雄关漫道真如铁！而今迈步从头越。 =。=</p>\n<h1 id=\"0\"><a href=\"#0\" class=\"headerlink\" title=\"0\"></a>0</h1><p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/treetraversal.png\" alt=\"\"></p>\n<ul>\n<li>前序遍历：4 2 1 3 6 5 7 8 10</li>\n<li>中序遍历：1 2 3 4 5 6 7 8 10</li>\n<li>后序遍历：1 3 2 5 10 8 7 6 4</li>\n<li>层序遍历：4 2 6 1 3 5 7 8 10</li>\n</ul>\n<h1 id=\"前序遍历\"><a href=\"#前序遍历\" class=\"headerlink\" title=\"前序遍历\"></a>前序遍历</h1><h2 id=\"Recursive\"><a href=\"#Recursive\" class=\"headerlink\" title=\"Recursive\"></a>Recursive</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Definition for a binary tree node.</span></span><br><span class=\"line\"><span class=\"comment\"> * public class TreeNode &#123;</span></span><br><span class=\"line\"><span class=\"comment\"> *     int val;</span></span><br><span class=\"line\"><span class=\"comment\"> *     TreeNode left;</span></span><br><span class=\"line\"><span class=\"comment\"> *     TreeNode right;</span></span><br><span class=\"line\"><span class=\"comment\"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class=\"line\"><span class=\"comment\"> * &#125;</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">preorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            res.add(root.val);</span><br><span class=\"line\">            preorderTraversal(root.left);</span><br><span class=\"line\">            preorderTraversal(root.right);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Iterative\"><a href=\"#Iterative\" class=\"headerlink\" title=\"Iterative\"></a>Iterative</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">preorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">        Stack&lt;TreeNode&gt; stack = <span class=\"keyword\">new</span> Stack&lt;TreeNode&gt;();</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">while</span> (root != <span class=\"keyword\">null</span> || !stack.isEmpty()) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">while</span>(root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                res.add(root.val);</span><br><span class=\"line\">                stack.push(root);</span><br><span class=\"line\">                root = root.left;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            root = stack.pop();</span><br><span class=\"line\">            root = root.right;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"中序遍历\"><a href=\"#中序遍历\" class=\"headerlink\" title=\"中序遍历\"></a>中序遍历</h1><h2 id=\"Recursive-1\"><a href=\"#Recursive-1\" class=\"headerlink\" title=\"Recursive\"></a>Recursive</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">inorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            inorderTraversal(root.left);</span><br><span class=\"line\">            res.add(root.val);</span><br><span class=\"line\">            inorderTraversal(root.right);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Iterative-1\"><a href=\"#Iterative-1\" class=\"headerlink\" title=\"Iterative\"></a>Iterative</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">inorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">        Stack&lt;TreeNode&gt; stack = <span class=\"keyword\">new</span> Stack&lt;TreeNode&gt;();</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (root != <span class=\"keyword\">null</span> || !stack.isEmpty()) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                stack.push(root);</span><br><span class=\"line\">                root = root.left;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            root = stack.pop();</span><br><span class=\"line\">            res.add(root.val);</span><br><span class=\"line\">            root = root.right;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"后续遍历\"><a href=\"#后续遍历\" class=\"headerlink\" title=\"后续遍历\"></a>后续遍历</h1><h2 id=\"Recursive-2\"><a href=\"#Recursive-2\" class=\"headerlink\" title=\"Recursive\"></a>Recursive</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">postorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            postorderTraversal(root.left);</span><br><span class=\"line\">            postorderTraversal(root.right);</span><br><span class=\"line\">            res.add(root.val);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"Iterative-2\"><a href=\"#Iterative-2\" class=\"headerlink\" title=\"Iterative\"></a>Iterative</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Solution</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> List&lt;Integer&gt; <span class=\"title\">postorderTraversal</span><span class=\"params\">(TreeNode root)</span> </span>&#123;</span><br><span class=\"line\">        List&lt;Integer&gt; res = <span class=\"keyword\">new</span> ArrayList&lt;Integer&gt;();</span><br><span class=\"line\">        Stack&lt;TreeNode&gt; stack = <span class=\"keyword\">new</span> Stack&lt;TreeNode&gt;();</span><br><span class=\"line\">        TreeNode lastAdd = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (!stack.isEmpty() || root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (root != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                stack.push(root);</span><br><span class=\"line\">                root = root.left;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                TreeNode node = stack.peek();</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (node.right != <span class=\"keyword\">null</span> &amp;&amp; node.right != lastAdd) &#123;</span><br><span class=\"line\">                    root = node.right;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                    res.add(node.val);</span><br><span class=\"line\">                    lastAdd = stack.pop();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"TODO\"><a href=\"#TODO\" class=\"headerlink\" title=\"TODO\"></a>TODO</h1><p>多叉树的遍历</p>\n"},{"title":"快乐的python","date":"2018-08-09T13:34:57.000Z","_content":" \n# 格式化dict输出\n\n``` python\nprint (json.dumps(content, encoding='utf-8', ensure_ascii=False, indent=1))\n```\n\n# Python time & datetime & string 相互转换\n\nhttps://www.cnblogs.com/alfred0311/p/7885349.html\n\ndatetime 日期计算\n\nhttps://blog.csdn.net/zhengxiangwen/article/details/55157697\n\n## time 模块\n\nhttps://www.cnblogs.com/jackadam/p/7845888.html","source":"_posts/201808-happy-python.md","raw":"---\ntitle: 快乐的python\ndate: 2018-08-09 21:34:57\ncategories: python\ntags:\n    - python\n    - happy\n    - gg\n---\n \n# 格式化dict输出\n\n``` python\nprint (json.dumps(content, encoding='utf-8', ensure_ascii=False, indent=1))\n```\n\n# Python time & datetime & string 相互转换\n\nhttps://www.cnblogs.com/alfred0311/p/7885349.html\n\ndatetime 日期计算\n\nhttps://blog.csdn.net/zhengxiangwen/article/details/55157697\n\n## time 模块\n\nhttps://www.cnblogs.com/jackadam/p/7845888.html","slug":"happy-python","published":1,"updated":"2018-08-09T16:48:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7y8001in61dslfxmufd","content":"<h1 id=\"格式化dict输出\"><a href=\"#格式化dict输出\" class=\"headerlink\" title=\"格式化dict输出\"></a>格式化dict输出</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">print</span> (json.dumps(content, encoding=<span class=\"string\">'utf-8'</span>, ensure_ascii=<span class=\"keyword\">False</span>, indent=<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<h1 id=\"Python-time-amp-datetime-amp-string-相互转换\"><a href=\"#Python-time-amp-datetime-amp-string-相互转换\" class=\"headerlink\" title=\"Python time &amp; datetime &amp; string 相互转换\"></a>Python time &amp; datetime &amp; string 相互转换</h1><p><a href=\"https://www.cnblogs.com/alfred0311/p/7885349.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/alfred0311/p/7885349.html</a></p>\n<p>datetime 日期计算</p>\n<p><a href=\"https://blog.csdn.net/zhengxiangwen/article/details/55157697\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhengxiangwen/article/details/55157697</a></p>\n<h2 id=\"time-模块\"><a href=\"#time-模块\" class=\"headerlink\" title=\"time 模块\"></a>time 模块</h2><p><a href=\"https://www.cnblogs.com/jackadam/p/7845888.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/jackadam/p/7845888.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"格式化dict输出\"><a href=\"#格式化dict输出\" class=\"headerlink\" title=\"格式化dict输出\"></a>格式化dict输出</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">print</span> (json.dumps(content, encoding=<span class=\"string\">'utf-8'</span>, ensure_ascii=<span class=\"keyword\">False</span>, indent=<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<h1 id=\"Python-time-amp-datetime-amp-string-相互转换\"><a href=\"#Python-time-amp-datetime-amp-string-相互转换\" class=\"headerlink\" title=\"Python time &amp; datetime &amp; string 相互转换\"></a>Python time &amp; datetime &amp; string 相互转换</h1><p><a href=\"https://www.cnblogs.com/alfred0311/p/7885349.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/alfred0311/p/7885349.html</a></p>\n<p>datetime 日期计算</p>\n<p><a href=\"https://blog.csdn.net/zhengxiangwen/article/details/55157697\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhengxiangwen/article/details/55157697</a></p>\n<h2 id=\"time-模块\"><a href=\"#time-模块\" class=\"headerlink\" title=\"time 模块\"></a>time 模块</h2><p><a href=\"https://www.cnblogs.com/jackadam/p/7845888.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/jackadam/p/7845888.html</a></p>\n"},{"title":"lightgbm and I dont know everything","date":"2018-08-02T11:22:57.000Z","_content":"\n\n\n\n\n\n\n\n\n\n\n\n# 安装\n\nGPU版\nhttps://blog.csdn.net/u012969412/article/details/71433960","source":"_posts/201808-lightgbm-and-I-dont-know-everything.md","raw":"---\ntitle: lightgbm and I dont know everything\ndate: 2018-08-02 19:22:57\ntags:\n---\n\n\n\n\n\n\n\n\n\n\n\n\n# 安装\n\nGPU版\nhttps://blog.csdn.net/u012969412/article/details/71433960","slug":"lightgbm-and-I-dont-know-everything","published":1,"updated":"2018-08-02T11:23:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7y9001kn61do0c744f4","content":"<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><p>GPU版<br><a href=\"https://blog.csdn.net/u012969412/article/details/71433960\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u012969412/article/details/71433960</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><p>GPU版<br><a href=\"https://blog.csdn.net/u012969412/article/details/71433960\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u012969412/article/details/71433960</a></p>\n"},{"title":"在线广告基本术语及概念","date":"2018-08-01T02:19:17.000Z","mathjax":true,"_content":"\n# CVR、CTR\n\n通俗的来说CVR、CTR就是两个指标计量，分别是：\n\n- CVR: Click Value Rate,是一个转化成本的指标\n\n$$CVR=\\frac{转化量}{点击量}*100\\%$$\n\n- CTR: Click Through Rate. 点击率 。\n\n$$CVR=\\frac{点击量}{曝光量}*100\\%$$\n\n其中CTR在广告联盟中要比CVR常见。在广告联盟中，每个联盟对于CTR的要求都是不一样的，这也是各个联盟防止和检测作弊的办法之一。\n\n# ROI和RPM\n\n说到CPR、CVR还有两个指标不得不提一下，那就是ROI和RPM，这两者具体是指：\n\n$$ROI投资回报率＝CTR*CVR*Auction/PPC $$    \n$$RPM千次展现收益＝CTR*PPC/CPM$$\n\n注：$CTR*CVR = \\frac{点击量}{曝光量}*\\frac{转化量}{点击量} = \\frac{转化量}{曝光量}$\n\n# ROC 和 AUC\n\n参考\nhttps://segmentfault.com/a/1190000010410634","source":"_posts/201808-online-ads-basics.md","raw":"---\ntitle: 在线广告基本术语及概念\ndate: 2018-08-01 10:19:17\ncategories: 计算广告\ntags:\n    - 计算广告\nmathjax: true\n---\n\n# CVR、CTR\n\n通俗的来说CVR、CTR就是两个指标计量，分别是：\n\n- CVR: Click Value Rate,是一个转化成本的指标\n\n$$CVR=\\frac{转化量}{点击量}*100\\%$$\n\n- CTR: Click Through Rate. 点击率 。\n\n$$CVR=\\frac{点击量}{曝光量}*100\\%$$\n\n其中CTR在广告联盟中要比CVR常见。在广告联盟中，每个联盟对于CTR的要求都是不一样的，这也是各个联盟防止和检测作弊的办法之一。\n\n# ROI和RPM\n\n说到CPR、CVR还有两个指标不得不提一下，那就是ROI和RPM，这两者具体是指：\n\n$$ROI投资回报率＝CTR*CVR*Auction/PPC $$    \n$$RPM千次展现收益＝CTR*PPC/CPM$$\n\n注：$CTR*CVR = \\frac{点击量}{曝光量}*\\frac{转化量}{点击量} = \\frac{转化量}{曝光量}$\n\n# ROC 和 AUC\n\n参考\nhttps://segmentfault.com/a/1190000010410634","slug":"online-ads-basics","published":1,"updated":"2018-08-02T04:54:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7ya001mn61d9usjuset","content":"<h1 id=\"CVR、CTR\"><a href=\"#CVR、CTR\" class=\"headerlink\" title=\"CVR、CTR\"></a>CVR、CTR</h1><p>通俗的来说CVR、CTR就是两个指标计量，分别是：</p>\n<ul>\n<li>CVR: Click Value Rate,是一个转化成本的指标</li>\n</ul>\n<script type=\"math/tex; mode=display\">CVR=\\frac{转化量}{点击量}*100\\%</script><ul>\n<li>CTR: Click Through Rate. 点击率 。</li>\n</ul>\n<script type=\"math/tex; mode=display\">CVR=\\frac{点击量}{曝光量}*100\\%</script><p>其中CTR在广告联盟中要比CVR常见。在广告联盟中，每个联盟对于CTR的要求都是不一样的，这也是各个联盟防止和检测作弊的办法之一。</p>\n<h1 id=\"ROI和RPM\"><a href=\"#ROI和RPM\" class=\"headerlink\" title=\"ROI和RPM\"></a>ROI和RPM</h1><p>说到CPR、CVR还有两个指标不得不提一下，那就是ROI和RPM，这两者具体是指：</p>\n<script type=\"math/tex; mode=display\">ROI投资回报率＝CTR*CVR*Auction/PPC</script><script type=\"math/tex; mode=display\">RPM千次展现收益＝CTR*PPC/CPM</script><p>注：$CTR<em>CVR = \\frac{点击量}{曝光量}</em>\\frac{转化量}{点击量} = \\frac{转化量}{曝光量}$</p>\n<h1 id=\"ROC-和-AUC\"><a href=\"#ROC-和-AUC\" class=\"headerlink\" title=\"ROC 和 AUC\"></a>ROC 和 AUC</h1><p>参考<br><a href=\"https://segmentfault.com/a/1190000010410634\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000010410634</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"CVR、CTR\"><a href=\"#CVR、CTR\" class=\"headerlink\" title=\"CVR、CTR\"></a>CVR、CTR</h1><p>通俗的来说CVR、CTR就是两个指标计量，分别是：</p>\n<ul>\n<li>CVR: Click Value Rate,是一个转化成本的指标</li>\n</ul>\n<script type=\"math/tex; mode=display\">CVR=\\frac{转化量}{点击量}*100\\%</script><ul>\n<li>CTR: Click Through Rate. 点击率 。</li>\n</ul>\n<script type=\"math/tex; mode=display\">CVR=\\frac{点击量}{曝光量}*100\\%</script><p>其中CTR在广告联盟中要比CVR常见。在广告联盟中，每个联盟对于CTR的要求都是不一样的，这也是各个联盟防止和检测作弊的办法之一。</p>\n<h1 id=\"ROI和RPM\"><a href=\"#ROI和RPM\" class=\"headerlink\" title=\"ROI和RPM\"></a>ROI和RPM</h1><p>说到CPR、CVR还有两个指标不得不提一下，那就是ROI和RPM，这两者具体是指：</p>\n<script type=\"math/tex; mode=display\">ROI投资回报率＝CTR*CVR*Auction/PPC</script><script type=\"math/tex; mode=display\">RPM千次展现收益＝CTR*PPC/CPM</script><p>注：$CTR<em>CVR = \\frac{点击量}{曝光量}</em>\\frac{转化量}{点击量} = \\frac{转化量}{曝光量}$</p>\n<h1 id=\"ROC-和-AUC\"><a href=\"#ROC-和-AUC\" class=\"headerlink\" title=\"ROC 和 AUC\"></a>ROC 和 AUC</h1><p>参考<br><a href=\"https://segmentfault.com/a/1190000010410634\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000010410634</a></p>\n"},{"title":"【Spark 使用教程】SparkSession","date":"2018-08-02T11:24:25.000Z","_content":"# SparkSession的功能\nSpark2.0中引入了SparkSession的概念，它为用户提供了一个统一的切入点来使用Spark的各项功能，用户不但可以使用DataFrame和Dataset的各种API，学习Spark的难度也会大大降低。\n\nSpark REPL和Databricks Notebook中的SparkSession对象\n在之前的Spark版本中，Spark shell会自动创建一个SparkContext对象sc。2.0中Spark shell则会自动创建一个SparkSession对象（spark），在输入spark时就会发现它已经存在了。\n\n![](http://p8vrqzrnj.bkt.clouddn.com/20160823134504487.png)\n\n在Databricks notebook中创建集群时也会自动生成一个SparkSession，这里用的名字也是spark。\n\n# SparkContext\n\n![](http://p8vrqzrnj.bkt.clouddn.com/20160823134731334.png)\n\nSparkContext起到的是一个中介的作用，通过它来使用Spark其他的功能。每一个JVM都有一个对应的SparkContext，driver program通过SparkContext连接到集群管理器来实现对集群中任务的控制。Spark配置参数的设置以及对SQLContext、HiveContext和StreamingContext的控制也要通过SparkContext进行。\n\n不过在Spark2.0中上述的一切功能都是通过SparkSession来完成的，同时SparkSession也简化了DataFrame/Dataset API的使用和对数据的操作。\n\n# pyspark.sql.SparkSession\n\nhttps://blog.csdn.net/cjhnbls/article/details/79254188\n\n``` python\nctx = SparkSession.builder.appName(\"ApplicationName\").config(\"spark.driver.memory\", \"6G\").master('local[7]').getOrCreate()\n```\n\n# Scala API\n\n## 创建SparkSession\n\n在2.0版本之前，使用Spark必须先创建SparkConf和SparkContext，代码如下：\n\n``` scala\n//set up the spark configuration and create contexts\nval sparkConf = new SparkConf().setAppName(\"SparkSessionZipsExample\").setMaster(\"local\")\n// your handle to SparkContext to access other context like SQLContext\nval sc = new SparkContext(sparkConf).set(\"spark.some.config.option\", \"some-value\")\nval sqlContext = new org.apache.spark.sql.SQLContext(sc)\n```\n\n不过在Spark2.0中只要创建一个SparkSession就够了，SparkConf、SparkContext和SQLContext都已经被封装在SparkSession当中。下面的代码创建了一个SparkSession对象并设置了一些参数。这里使用了生成器模式，只有此“spark”对象不存在时才会创建一个新对象。\n\n``` scala\n// Create a SparkSession. No need to create SparkContext\n// You automatically get it as part of the SparkSession\nval warehouseLocation = \"file:${system:user.dir}/spark-warehouse\"\nval spark = SparkSession\n   .builder()\n   .appName(\"SparkSessionZipsExample\")\n   .config(\"spark.sql.warehouse.dir\", warehouseLocation)\n   .enableHiveSupport()\n   .getOrCreate()\n```\n执行完上面的代码就可以使用spark对象了。\n\n## 设置运行参数\n\n创建SparkSession之后可以设置运行参数，代码如下, 也可以使用Scala的迭代器来读取configMap中的数据。\n\n``` scala\n//set new runtime options\nspark.conf.set(\"spark.sql.shuffle.partitions\", 6)\nspark.conf.set(\"spark.executor.memory\", \"2g\")\n//get all settings\nval configMap:Map[String, String] = spark.conf.getAll()\n```\n\n## 读取元数据\n\n如果需要读取元数据（catalog），可以通过SparkSession来获取。\n``` scala\n//fetch metadata data from the catalog\nspark.catalog.listDatabases.show(false)\nspark.catalog.listTables.show(false)\n```\n这里返回的都是Dataset，所以可以根据需要再使用Dataset API来读取。 ???\n\n## 创建Dataset和Dataframe\n\n通过SparkSession来创建Dataset和Dataframe有多种方法。其中最简单的就是使用spark.range方法来生成Dataset，在摸索Dataset API的时候这个办法尤其有用。\n\n``` scala\n// create a Dataset using spark.range starting from 5 to 100, with increments of 5\nval numDS = spark.range(5, 100, 5)\n// reverse the order and display first 5 items\nnumDS.orderBy(desc(\"id\")).show(5)\n//compute descriptive stats and display them\nnumDs.describe().show()\n// create a DataFrame using spark.createDataFrame from a List or Seq\nval langPercentDF = spark.createDataFrame(List((\"Scala\", 35), (\"Python\", 30), (\"R\", 15), (\"Java\", 20)))\n//rename the columns\nval lpDF = langPercentDF.withColumnRenamed(\"_1\", \"language\").withColumnRenamed(\"_2\", \"percent\")\n// order the DataFrame in descending order of percentage\nlpDF.orderBy(desc(\"percent\")).show(false)\n```\n\n## 读取JSON数据\n\n此外，还可以用SparkSession读取JSON、CSV、TXT和parquet表。下面的代码中读取了一个JSON文件，返回的是一个DataFrame。\n\n``` scala\n// read the json file and create the dataframe\nval jsonFile = args(0)\nval zipsDF = spark.read.json(jsonFile)\n//filter all cities whose population > 40K\nzipsDF.filter(zipsDF.col(\"pop\") > 40000).show(10)\n```\n\n## 使用SparkSQL\n\n借助SparkSession用户可以像SQLContext一样使用Spark SQL的全部功能。下面的代码中先创建了一个表然后对此表进行查询。\n\n``` scala\n// Now create an SQL table and issue SQL queries against it without\n// using the sqlContext but through the SparkSession object.\n// Creates a temporary view of the DataFrame\nzipsDF.createOrReplaceTempView(\"zips_table\")\nzipsDF.cache()\nval resultsDF = spark.sql(\"SELECT city, pop, state, zip FROM zips_table\")\nresultsDF.show(10)\n```\n\n## 存储/读取Hive表\n\n下面的代码演示了通过SparkSession来创建Hive表并进行查询的方法。\n\n``` scala\n//drop the table if exists to get around existing table error\nspark.sql(\"DROP TABLE IF EXISTS zips_hive_table\")\n//save as a hive table\nspark.table(\"zips_table\").write.saveAsTable(\"zips_hive_table\")\n//make a similar query against the hive table \nval resultsHiveDF = spark.sql(\"SELECT city, pop, state, zip FROM zips_hive_table WHERE pop > 40000\")\nresultsHiveDF.show(10)\n```\n\n这里可以看到从DataFrame API、Spark SQL和Hive语句返回的结果是完全相同的。","source":"_posts/201808-pyspark-easy-lookup.md","raw":"---\ntitle: 【Spark 使用教程】SparkSession\ndate: 2018-08-02 19:24:25\ncategories: spark\ntags:\n    - pyspark\n    - 大数据\n---\n# SparkSession的功能\nSpark2.0中引入了SparkSession的概念，它为用户提供了一个统一的切入点来使用Spark的各项功能，用户不但可以使用DataFrame和Dataset的各种API，学习Spark的难度也会大大降低。\n\nSpark REPL和Databricks Notebook中的SparkSession对象\n在之前的Spark版本中，Spark shell会自动创建一个SparkContext对象sc。2.0中Spark shell则会自动创建一个SparkSession对象（spark），在输入spark时就会发现它已经存在了。\n\n![](http://p8vrqzrnj.bkt.clouddn.com/20160823134504487.png)\n\n在Databricks notebook中创建集群时也会自动生成一个SparkSession，这里用的名字也是spark。\n\n# SparkContext\n\n![](http://p8vrqzrnj.bkt.clouddn.com/20160823134731334.png)\n\nSparkContext起到的是一个中介的作用，通过它来使用Spark其他的功能。每一个JVM都有一个对应的SparkContext，driver program通过SparkContext连接到集群管理器来实现对集群中任务的控制。Spark配置参数的设置以及对SQLContext、HiveContext和StreamingContext的控制也要通过SparkContext进行。\n\n不过在Spark2.0中上述的一切功能都是通过SparkSession来完成的，同时SparkSession也简化了DataFrame/Dataset API的使用和对数据的操作。\n\n# pyspark.sql.SparkSession\n\nhttps://blog.csdn.net/cjhnbls/article/details/79254188\n\n``` python\nctx = SparkSession.builder.appName(\"ApplicationName\").config(\"spark.driver.memory\", \"6G\").master('local[7]').getOrCreate()\n```\n\n# Scala API\n\n## 创建SparkSession\n\n在2.0版本之前，使用Spark必须先创建SparkConf和SparkContext，代码如下：\n\n``` scala\n//set up the spark configuration and create contexts\nval sparkConf = new SparkConf().setAppName(\"SparkSessionZipsExample\").setMaster(\"local\")\n// your handle to SparkContext to access other context like SQLContext\nval sc = new SparkContext(sparkConf).set(\"spark.some.config.option\", \"some-value\")\nval sqlContext = new org.apache.spark.sql.SQLContext(sc)\n```\n\n不过在Spark2.0中只要创建一个SparkSession就够了，SparkConf、SparkContext和SQLContext都已经被封装在SparkSession当中。下面的代码创建了一个SparkSession对象并设置了一些参数。这里使用了生成器模式，只有此“spark”对象不存在时才会创建一个新对象。\n\n``` scala\n// Create a SparkSession. No need to create SparkContext\n// You automatically get it as part of the SparkSession\nval warehouseLocation = \"file:${system:user.dir}/spark-warehouse\"\nval spark = SparkSession\n   .builder()\n   .appName(\"SparkSessionZipsExample\")\n   .config(\"spark.sql.warehouse.dir\", warehouseLocation)\n   .enableHiveSupport()\n   .getOrCreate()\n```\n执行完上面的代码就可以使用spark对象了。\n\n## 设置运行参数\n\n创建SparkSession之后可以设置运行参数，代码如下, 也可以使用Scala的迭代器来读取configMap中的数据。\n\n``` scala\n//set new runtime options\nspark.conf.set(\"spark.sql.shuffle.partitions\", 6)\nspark.conf.set(\"spark.executor.memory\", \"2g\")\n//get all settings\nval configMap:Map[String, String] = spark.conf.getAll()\n```\n\n## 读取元数据\n\n如果需要读取元数据（catalog），可以通过SparkSession来获取。\n``` scala\n//fetch metadata data from the catalog\nspark.catalog.listDatabases.show(false)\nspark.catalog.listTables.show(false)\n```\n这里返回的都是Dataset，所以可以根据需要再使用Dataset API来读取。 ???\n\n## 创建Dataset和Dataframe\n\n通过SparkSession来创建Dataset和Dataframe有多种方法。其中最简单的就是使用spark.range方法来生成Dataset，在摸索Dataset API的时候这个办法尤其有用。\n\n``` scala\n// create a Dataset using spark.range starting from 5 to 100, with increments of 5\nval numDS = spark.range(5, 100, 5)\n// reverse the order and display first 5 items\nnumDS.orderBy(desc(\"id\")).show(5)\n//compute descriptive stats and display them\nnumDs.describe().show()\n// create a DataFrame using spark.createDataFrame from a List or Seq\nval langPercentDF = spark.createDataFrame(List((\"Scala\", 35), (\"Python\", 30), (\"R\", 15), (\"Java\", 20)))\n//rename the columns\nval lpDF = langPercentDF.withColumnRenamed(\"_1\", \"language\").withColumnRenamed(\"_2\", \"percent\")\n// order the DataFrame in descending order of percentage\nlpDF.orderBy(desc(\"percent\")).show(false)\n```\n\n## 读取JSON数据\n\n此外，还可以用SparkSession读取JSON、CSV、TXT和parquet表。下面的代码中读取了一个JSON文件，返回的是一个DataFrame。\n\n``` scala\n// read the json file and create the dataframe\nval jsonFile = args(0)\nval zipsDF = spark.read.json(jsonFile)\n//filter all cities whose population > 40K\nzipsDF.filter(zipsDF.col(\"pop\") > 40000).show(10)\n```\n\n## 使用SparkSQL\n\n借助SparkSession用户可以像SQLContext一样使用Spark SQL的全部功能。下面的代码中先创建了一个表然后对此表进行查询。\n\n``` scala\n// Now create an SQL table and issue SQL queries against it without\n// using the sqlContext but through the SparkSession object.\n// Creates a temporary view of the DataFrame\nzipsDF.createOrReplaceTempView(\"zips_table\")\nzipsDF.cache()\nval resultsDF = spark.sql(\"SELECT city, pop, state, zip FROM zips_table\")\nresultsDF.show(10)\n```\n\n## 存储/读取Hive表\n\n下面的代码演示了通过SparkSession来创建Hive表并进行查询的方法。\n\n``` scala\n//drop the table if exists to get around existing table error\nspark.sql(\"DROP TABLE IF EXISTS zips_hive_table\")\n//save as a hive table\nspark.table(\"zips_table\").write.saveAsTable(\"zips_hive_table\")\n//make a similar query against the hive table \nval resultsHiveDF = spark.sql(\"SELECT city, pop, state, zip FROM zips_hive_table WHERE pop > 40000\")\nresultsHiveDF.show(10)\n```\n\n这里可以看到从DataFrame API、Spark SQL和Hive语句返回的结果是完全相同的。","slug":"pyspark-easy-lookup","published":1,"updated":"2018-08-09T17:18:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7yc001on61d7wk59hms","content":"<h1 id=\"SparkSession的功能\"><a href=\"#SparkSession的功能\" class=\"headerlink\" title=\"SparkSession的功能\"></a>SparkSession的功能</h1><p>Spark2.0中引入了SparkSession的概念，它为用户提供了一个统一的切入点来使用Spark的各项功能，用户不但可以使用DataFrame和Dataset的各种API，学习Spark的难度也会大大降低。</p>\n<p>Spark REPL和Databricks Notebook中的SparkSession对象<br>在之前的Spark版本中，Spark shell会自动创建一个SparkContext对象sc。2.0中Spark shell则会自动创建一个SparkSession对象（spark），在输入spark时就会发现它已经存在了。</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/20160823134504487.png\" alt=\"\"></p>\n<p>在Databricks notebook中创建集群时也会自动生成一个SparkSession，这里用的名字也是spark。</p>\n<h1 id=\"SparkContext\"><a href=\"#SparkContext\" class=\"headerlink\" title=\"SparkContext\"></a>SparkContext</h1><p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/20160823134731334.png\" alt=\"\"></p>\n<p>SparkContext起到的是一个中介的作用，通过它来使用Spark其他的功能。每一个JVM都有一个对应的SparkContext，driver program通过SparkContext连接到集群管理器来实现对集群中任务的控制。Spark配置参数的设置以及对SQLContext、HiveContext和StreamingContext的控制也要通过SparkContext进行。</p>\n<p>不过在Spark2.0中上述的一切功能都是通过SparkSession来完成的，同时SparkSession也简化了DataFrame/Dataset API的使用和对数据的操作。</p>\n<h1 id=\"pyspark-sql-SparkSession\"><a href=\"#pyspark-sql-SparkSession\" class=\"headerlink\" title=\"pyspark.sql.SparkSession\"></a>pyspark.sql.SparkSession</h1><p><a href=\"https://blog.csdn.net/cjhnbls/article/details/79254188\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/cjhnbls/article/details/79254188</a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctx = SparkSession.builder.appName(<span class=\"string\">\"ApplicationName\"</span>).config(<span class=\"string\">\"spark.driver.memory\"</span>, <span class=\"string\">\"6G\"</span>).master(<span class=\"string\">'local[7]'</span>).getOrCreate()</span><br></pre></td></tr></table></figure>\n<h1 id=\"Scala-API\"><a href=\"#Scala-API\" class=\"headerlink\" title=\"Scala API\"></a>Scala API</h1><h2 id=\"创建SparkSession\"><a href=\"#创建SparkSession\" class=\"headerlink\" title=\"创建SparkSession\"></a>创建SparkSession</h2><p>在2.0版本之前，使用Spark必须先创建SparkConf和SparkContext，代码如下：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//set up the spark configuration and create contexts</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> sparkConf = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().setAppName(<span class=\"string\">\"SparkSessionZipsExample\"</span>).setMaster(<span class=\"string\">\"local\"</span>)</span><br><span class=\"line\"><span class=\"comment\">// your handle to SparkContext to access other context like SQLContext</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> sc = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(sparkConf).set(<span class=\"string\">\"spark.some.config.option\"</span>, <span class=\"string\">\"some-value\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">val</span> sqlContext = <span class=\"keyword\">new</span> org.apache.spark.sql.<span class=\"type\">SQLContext</span>(sc)</span><br></pre></td></tr></table></figure>\n<p>不过在Spark2.0中只要创建一个SparkSession就够了，SparkConf、SparkContext和SQLContext都已经被封装在SparkSession当中。下面的代码创建了一个SparkSession对象并设置了一些参数。这里使用了生成器模式，只有此“spark”对象不存在时才会创建一个新对象。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Create a SparkSession. No need to create SparkContext</span></span><br><span class=\"line\"><span class=\"comment\">// You automatically get it as part of the SparkSession</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> warehouseLocation = <span class=\"string\">\"file:$&#123;system:user.dir&#125;/spark-warehouse\"</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> spark = <span class=\"type\">SparkSession</span></span><br><span class=\"line\">   .builder()</span><br><span class=\"line\">   .appName(<span class=\"string\">\"SparkSessionZipsExample\"</span>)</span><br><span class=\"line\">   .config(<span class=\"string\">\"spark.sql.warehouse.dir\"</span>, warehouseLocation)</span><br><span class=\"line\">   .enableHiveSupport()</span><br><span class=\"line\">   .getOrCreate()</span><br></pre></td></tr></table></figure>\n<p>执行完上面的代码就可以使用spark对象了。</p>\n<h2 id=\"设置运行参数\"><a href=\"#设置运行参数\" class=\"headerlink\" title=\"设置运行参数\"></a>设置运行参数</h2><p>创建SparkSession之后可以设置运行参数，代码如下, 也可以使用Scala的迭代器来读取configMap中的数据。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//set new runtime options</span></span><br><span class=\"line\">spark.conf.set(<span class=\"string\">\"spark.sql.shuffle.partitions\"</span>, <span class=\"number\">6</span>)</span><br><span class=\"line\">spark.conf.set(<span class=\"string\">\"spark.executor.memory\"</span>, <span class=\"string\">\"2g\"</span>)</span><br><span class=\"line\"><span class=\"comment\">//get all settings</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> configMap:<span class=\"type\">Map</span>[<span class=\"type\">String</span>, <span class=\"type\">String</span>] = spark.conf.getAll()</span><br></pre></td></tr></table></figure>\n<h2 id=\"读取元数据\"><a href=\"#读取元数据\" class=\"headerlink\" title=\"读取元数据\"></a>读取元数据</h2><p>如果需要读取元数据（catalog），可以通过SparkSession来获取。<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//fetch metadata data from the catalog</span></span><br><span class=\"line\">spark.catalog.listDatabases.show(<span class=\"literal\">false</span>)</span><br><span class=\"line\">spark.catalog.listTables.show(<span class=\"literal\">false</span>)</span><br></pre></td></tr></table></figure></p>\n<p>这里返回的都是Dataset，所以可以根据需要再使用Dataset API来读取。 ???</p>\n<h2 id=\"创建Dataset和Dataframe\"><a href=\"#创建Dataset和Dataframe\" class=\"headerlink\" title=\"创建Dataset和Dataframe\"></a>创建Dataset和Dataframe</h2><p>通过SparkSession来创建Dataset和Dataframe有多种方法。其中最简单的就是使用spark.range方法来生成Dataset，在摸索Dataset API的时候这个办法尤其有用。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// create a Dataset using spark.range starting from 5 to 100, with increments of 5</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> numDS = spark.range(<span class=\"number\">5</span>, <span class=\"number\">100</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\"><span class=\"comment\">// reverse the order and display first 5 items</span></span><br><span class=\"line\">numDS.orderBy(desc(<span class=\"string\">\"id\"</span>)).show(<span class=\"number\">5</span>)</span><br><span class=\"line\"><span class=\"comment\">//compute descriptive stats and display them</span></span><br><span class=\"line\">numDs.describe().show()</span><br><span class=\"line\"><span class=\"comment\">// create a DataFrame using spark.createDataFrame from a List or Seq</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> langPercentDF = spark.createDataFrame(<span class=\"type\">List</span>((<span class=\"string\">\"Scala\"</span>, <span class=\"number\">35</span>), (<span class=\"string\">\"Python\"</span>, <span class=\"number\">30</span>), (<span class=\"string\">\"R\"</span>, <span class=\"number\">15</span>), (<span class=\"string\">\"Java\"</span>, <span class=\"number\">20</span>)))</span><br><span class=\"line\"><span class=\"comment\">//rename the columns</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> lpDF = langPercentDF.withColumnRenamed(<span class=\"string\">\"_1\"</span>, <span class=\"string\">\"language\"</span>).withColumnRenamed(<span class=\"string\">\"_2\"</span>, <span class=\"string\">\"percent\"</span>)</span><br><span class=\"line\"><span class=\"comment\">// order the DataFrame in descending order of percentage</span></span><br><span class=\"line\">lpDF.orderBy(desc(<span class=\"string\">\"percent\"</span>)).show(<span class=\"literal\">false</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"读取JSON数据\"><a href=\"#读取JSON数据\" class=\"headerlink\" title=\"读取JSON数据\"></a>读取JSON数据</h2><p>此外，还可以用SparkSession读取JSON、CSV、TXT和parquet表。下面的代码中读取了一个JSON文件，返回的是一个DataFrame。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// read the json file and create the dataframe</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> jsonFile = args(<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">val</span> zipsDF = spark.read.json(jsonFile)</span><br><span class=\"line\"><span class=\"comment\">//filter all cities whose population &gt; 40K</span></span><br><span class=\"line\">zipsDF.filter(zipsDF.col(<span class=\"string\">\"pop\"</span>) &gt; <span class=\"number\">40000</span>).show(<span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用SparkSQL\"><a href=\"#使用SparkSQL\" class=\"headerlink\" title=\"使用SparkSQL\"></a>使用SparkSQL</h2><p>借助SparkSession用户可以像SQLContext一样使用Spark SQL的全部功能。下面的代码中先创建了一个表然后对此表进行查询。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Now create an SQL table and issue SQL queries against it without</span></span><br><span class=\"line\"><span class=\"comment\">// using the sqlContext but through the SparkSession object.</span></span><br><span class=\"line\"><span class=\"comment\">// Creates a temporary view of the DataFrame</span></span><br><span class=\"line\">zipsDF.createOrReplaceTempView(<span class=\"string\">\"zips_table\"</span>)</span><br><span class=\"line\">zipsDF.cache()</span><br><span class=\"line\"><span class=\"keyword\">val</span> resultsDF = spark.sql(<span class=\"string\">\"SELECT city, pop, state, zip FROM zips_table\"</span>)</span><br><span class=\"line\">resultsDF.show(<span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"存储-读取Hive表\"><a href=\"#存储-读取Hive表\" class=\"headerlink\" title=\"存储/读取Hive表\"></a>存储/读取Hive表</h2><p>下面的代码演示了通过SparkSession来创建Hive表并进行查询的方法。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//drop the table if exists to get around existing table error</span></span><br><span class=\"line\">spark.sql(<span class=\"string\">\"DROP TABLE IF EXISTS zips_hive_table\"</span>)</span><br><span class=\"line\"><span class=\"comment\">//save as a hive table</span></span><br><span class=\"line\">spark.table(<span class=\"string\">\"zips_table\"</span>).write.saveAsTable(<span class=\"string\">\"zips_hive_table\"</span>)</span><br><span class=\"line\"><span class=\"comment\">//make a similar query against the hive table </span></span><br><span class=\"line\"><span class=\"keyword\">val</span> resultsHiveDF = spark.sql(<span class=\"string\">\"SELECT city, pop, state, zip FROM zips_hive_table WHERE pop &gt; 40000\"</span>)</span><br><span class=\"line\">resultsHiveDF.show(<span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n<p>这里可以看到从DataFrame API、Spark SQL和Hive语句返回的结果是完全相同的。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"SparkSession的功能\"><a href=\"#SparkSession的功能\" class=\"headerlink\" title=\"SparkSession的功能\"></a>SparkSession的功能</h1><p>Spark2.0中引入了SparkSession的概念，它为用户提供了一个统一的切入点来使用Spark的各项功能，用户不但可以使用DataFrame和Dataset的各种API，学习Spark的难度也会大大降低。</p>\n<p>Spark REPL和Databricks Notebook中的SparkSession对象<br>在之前的Spark版本中，Spark shell会自动创建一个SparkContext对象sc。2.0中Spark shell则会自动创建一个SparkSession对象（spark），在输入spark时就会发现它已经存在了。</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/20160823134504487.png\" alt=\"\"></p>\n<p>在Databricks notebook中创建集群时也会自动生成一个SparkSession，这里用的名字也是spark。</p>\n<h1 id=\"SparkContext\"><a href=\"#SparkContext\" class=\"headerlink\" title=\"SparkContext\"></a>SparkContext</h1><p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/20160823134731334.png\" alt=\"\"></p>\n<p>SparkContext起到的是一个中介的作用，通过它来使用Spark其他的功能。每一个JVM都有一个对应的SparkContext，driver program通过SparkContext连接到集群管理器来实现对集群中任务的控制。Spark配置参数的设置以及对SQLContext、HiveContext和StreamingContext的控制也要通过SparkContext进行。</p>\n<p>不过在Spark2.0中上述的一切功能都是通过SparkSession来完成的，同时SparkSession也简化了DataFrame/Dataset API的使用和对数据的操作。</p>\n<h1 id=\"pyspark-sql-SparkSession\"><a href=\"#pyspark-sql-SparkSession\" class=\"headerlink\" title=\"pyspark.sql.SparkSession\"></a>pyspark.sql.SparkSession</h1><p><a href=\"https://blog.csdn.net/cjhnbls/article/details/79254188\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/cjhnbls/article/details/79254188</a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctx = SparkSession.builder.appName(<span class=\"string\">\"ApplicationName\"</span>).config(<span class=\"string\">\"spark.driver.memory\"</span>, <span class=\"string\">\"6G\"</span>).master(<span class=\"string\">'local[7]'</span>).getOrCreate()</span><br></pre></td></tr></table></figure>\n<h1 id=\"Scala-API\"><a href=\"#Scala-API\" class=\"headerlink\" title=\"Scala API\"></a>Scala API</h1><h2 id=\"创建SparkSession\"><a href=\"#创建SparkSession\" class=\"headerlink\" title=\"创建SparkSession\"></a>创建SparkSession</h2><p>在2.0版本之前，使用Spark必须先创建SparkConf和SparkContext，代码如下：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//set up the spark configuration and create contexts</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> sparkConf = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().setAppName(<span class=\"string\">\"SparkSessionZipsExample\"</span>).setMaster(<span class=\"string\">\"local\"</span>)</span><br><span class=\"line\"><span class=\"comment\">// your handle to SparkContext to access other context like SQLContext</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> sc = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(sparkConf).set(<span class=\"string\">\"spark.some.config.option\"</span>, <span class=\"string\">\"some-value\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">val</span> sqlContext = <span class=\"keyword\">new</span> org.apache.spark.sql.<span class=\"type\">SQLContext</span>(sc)</span><br></pre></td></tr></table></figure>\n<p>不过在Spark2.0中只要创建一个SparkSession就够了，SparkConf、SparkContext和SQLContext都已经被封装在SparkSession当中。下面的代码创建了一个SparkSession对象并设置了一些参数。这里使用了生成器模式，只有此“spark”对象不存在时才会创建一个新对象。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Create a SparkSession. No need to create SparkContext</span></span><br><span class=\"line\"><span class=\"comment\">// You automatically get it as part of the SparkSession</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> warehouseLocation = <span class=\"string\">\"file:$&#123;system:user.dir&#125;/spark-warehouse\"</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> spark = <span class=\"type\">SparkSession</span></span><br><span class=\"line\">   .builder()</span><br><span class=\"line\">   .appName(<span class=\"string\">\"SparkSessionZipsExample\"</span>)</span><br><span class=\"line\">   .config(<span class=\"string\">\"spark.sql.warehouse.dir\"</span>, warehouseLocation)</span><br><span class=\"line\">   .enableHiveSupport()</span><br><span class=\"line\">   .getOrCreate()</span><br></pre></td></tr></table></figure>\n<p>执行完上面的代码就可以使用spark对象了。</p>\n<h2 id=\"设置运行参数\"><a href=\"#设置运行参数\" class=\"headerlink\" title=\"设置运行参数\"></a>设置运行参数</h2><p>创建SparkSession之后可以设置运行参数，代码如下, 也可以使用Scala的迭代器来读取configMap中的数据。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//set new runtime options</span></span><br><span class=\"line\">spark.conf.set(<span class=\"string\">\"spark.sql.shuffle.partitions\"</span>, <span class=\"number\">6</span>)</span><br><span class=\"line\">spark.conf.set(<span class=\"string\">\"spark.executor.memory\"</span>, <span class=\"string\">\"2g\"</span>)</span><br><span class=\"line\"><span class=\"comment\">//get all settings</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> configMap:<span class=\"type\">Map</span>[<span class=\"type\">String</span>, <span class=\"type\">String</span>] = spark.conf.getAll()</span><br></pre></td></tr></table></figure>\n<h2 id=\"读取元数据\"><a href=\"#读取元数据\" class=\"headerlink\" title=\"读取元数据\"></a>读取元数据</h2><p>如果需要读取元数据（catalog），可以通过SparkSession来获取。<br><figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//fetch metadata data from the catalog</span></span><br><span class=\"line\">spark.catalog.listDatabases.show(<span class=\"literal\">false</span>)</span><br><span class=\"line\">spark.catalog.listTables.show(<span class=\"literal\">false</span>)</span><br></pre></td></tr></table></figure></p>\n<p>这里返回的都是Dataset，所以可以根据需要再使用Dataset API来读取。 ???</p>\n<h2 id=\"创建Dataset和Dataframe\"><a href=\"#创建Dataset和Dataframe\" class=\"headerlink\" title=\"创建Dataset和Dataframe\"></a>创建Dataset和Dataframe</h2><p>通过SparkSession来创建Dataset和Dataframe有多种方法。其中最简单的就是使用spark.range方法来生成Dataset，在摸索Dataset API的时候这个办法尤其有用。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// create a Dataset using spark.range starting from 5 to 100, with increments of 5</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> numDS = spark.range(<span class=\"number\">5</span>, <span class=\"number\">100</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\"><span class=\"comment\">// reverse the order and display first 5 items</span></span><br><span class=\"line\">numDS.orderBy(desc(<span class=\"string\">\"id\"</span>)).show(<span class=\"number\">5</span>)</span><br><span class=\"line\"><span class=\"comment\">//compute descriptive stats and display them</span></span><br><span class=\"line\">numDs.describe().show()</span><br><span class=\"line\"><span class=\"comment\">// create a DataFrame using spark.createDataFrame from a List or Seq</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> langPercentDF = spark.createDataFrame(<span class=\"type\">List</span>((<span class=\"string\">\"Scala\"</span>, <span class=\"number\">35</span>), (<span class=\"string\">\"Python\"</span>, <span class=\"number\">30</span>), (<span class=\"string\">\"R\"</span>, <span class=\"number\">15</span>), (<span class=\"string\">\"Java\"</span>, <span class=\"number\">20</span>)))</span><br><span class=\"line\"><span class=\"comment\">//rename the columns</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> lpDF = langPercentDF.withColumnRenamed(<span class=\"string\">\"_1\"</span>, <span class=\"string\">\"language\"</span>).withColumnRenamed(<span class=\"string\">\"_2\"</span>, <span class=\"string\">\"percent\"</span>)</span><br><span class=\"line\"><span class=\"comment\">// order the DataFrame in descending order of percentage</span></span><br><span class=\"line\">lpDF.orderBy(desc(<span class=\"string\">\"percent\"</span>)).show(<span class=\"literal\">false</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"读取JSON数据\"><a href=\"#读取JSON数据\" class=\"headerlink\" title=\"读取JSON数据\"></a>读取JSON数据</h2><p>此外，还可以用SparkSession读取JSON、CSV、TXT和parquet表。下面的代码中读取了一个JSON文件，返回的是一个DataFrame。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// read the json file and create the dataframe</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> jsonFile = args(<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">val</span> zipsDF = spark.read.json(jsonFile)</span><br><span class=\"line\"><span class=\"comment\">//filter all cities whose population &gt; 40K</span></span><br><span class=\"line\">zipsDF.filter(zipsDF.col(<span class=\"string\">\"pop\"</span>) &gt; <span class=\"number\">40000</span>).show(<span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用SparkSQL\"><a href=\"#使用SparkSQL\" class=\"headerlink\" title=\"使用SparkSQL\"></a>使用SparkSQL</h2><p>借助SparkSession用户可以像SQLContext一样使用Spark SQL的全部功能。下面的代码中先创建了一个表然后对此表进行查询。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Now create an SQL table and issue SQL queries against it without</span></span><br><span class=\"line\"><span class=\"comment\">// using the sqlContext but through the SparkSession object.</span></span><br><span class=\"line\"><span class=\"comment\">// Creates a temporary view of the DataFrame</span></span><br><span class=\"line\">zipsDF.createOrReplaceTempView(<span class=\"string\">\"zips_table\"</span>)</span><br><span class=\"line\">zipsDF.cache()</span><br><span class=\"line\"><span class=\"keyword\">val</span> resultsDF = spark.sql(<span class=\"string\">\"SELECT city, pop, state, zip FROM zips_table\"</span>)</span><br><span class=\"line\">resultsDF.show(<span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"存储-读取Hive表\"><a href=\"#存储-读取Hive表\" class=\"headerlink\" title=\"存储/读取Hive表\"></a>存储/读取Hive表</h2><p>下面的代码演示了通过SparkSession来创建Hive表并进行查询的方法。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//drop the table if exists to get around existing table error</span></span><br><span class=\"line\">spark.sql(<span class=\"string\">\"DROP TABLE IF EXISTS zips_hive_table\"</span>)</span><br><span class=\"line\"><span class=\"comment\">//save as a hive table</span></span><br><span class=\"line\">spark.table(<span class=\"string\">\"zips_table\"</span>).write.saveAsTable(<span class=\"string\">\"zips_hive_table\"</span>)</span><br><span class=\"line\"><span class=\"comment\">//make a similar query against the hive table </span></span><br><span class=\"line\"><span class=\"keyword\">val</span> resultsHiveDF = spark.sql(<span class=\"string\">\"SELECT city, pop, state, zip FROM zips_hive_table WHERE pop &gt; 40000\"</span>)</span><br><span class=\"line\">resultsHiveDF.show(<span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n<p>这里可以看到从DataFrame API、Spark SQL和Hive语句返回的结果是完全相同的。</p>\n"},{"title":"python pandas 使用指南","date":"2018-08-24T02:14:58.000Z","_content":"\n# Series 操作\n\n``` python \n# 获取所有的值\nIn [27]: ser2.values\nOut[27]: array([0, 1, 2, 3])\n# 获取所有的索引\nIn [28]: ser2.index\nOut[28]: Index([u'a', u'b', u'c', u'd'], dtype='object')\n```\n\n# 按行遍历DataFrame\n\n## 不修改内容\n\n要以 Pandas 的方式迭代遍历DataFrame的行，可以使用：\n\n\n``` python\n# 1、DataFrame.iterrows()\nfor index, row in df.iterrows():  # 返回（索引， Series）元组\n    print row[\"c1\"], row[\"c2\"]\n\n# 2 DataFrame.itertuples()\nfor row in df.itertuples(index=True, name='Pandas'):\n    print getattr(row, \"c1\"), getattr(row, \"c2\")\n```\n\nitertuples()应该比iterrows()快\n\n但请注意，根据文档(目前 Pandas 0.19.1)：\n\ndf.iterrows：数据的dtype可能不是按行匹配的，因为iterrows返回一个系列的每一行，它不会保留行的dtypes(dtypes跨DataFrames列保留)*\n\niterrows：不要修改行，你不应该修改你正在迭代的东西。这不能保证在所有情况下都能正常工作。根据数据类型的不同，迭代器返回一个副本而不是一个视图，写入它将不起作用。\n\n## 第二种方案: apply()\n\nDataFrame.apply(),对每行的内容进行修改\n\n``` python\ndef valuation_formula(x, y):\n    return x * y * 0.5\n \ndf['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)\n```\n\n## 方案3：df.iloc函数\n\n``` python \nfor i in range(0, len(df)):\n    print df.iloc[i]['c1'], df.iloc[i]['c2']\n```\n\n## 第四种方案：略麻烦，但是更高效，将DataFrame转为List\n可以编写自己的实现namedtuple的迭代器,这相当于pd.DataFrame.itertuples，但是效率更高。\n\n``` python\nfrom collections import namedtuple\n \ndef myiter(d, cols=None):\n    if cols is None:\n        v = d.values.tolist()\n        cols = d.columns.values.tolist()\n    else:\n        j = [d.columns.get_loc(c) for c in cols]\n        v = d.values[:, j].tolist()\n \n    n = namedtuple('MyTuple', cols)\n \n    for line in iter(v):\n        yield n(*line)\n```\n\n``` python \n# 将自定义函数用于给定的DataFrame：\nlist(myiter(df))\n### [MyTuple(c1=10, c2=100), MyTuple(c1=11, c2=110), MyTuple(c1=12, c2=120)]\n\n# 或与pd.DataFrame.itertuples：\nlist(df.itertuples(index=False))\n### [Pandas(c1=10, c2=100), Pandas(c1=11, c2=110), Pandas(c1=12, c2=120)]\n```","source":"_posts/201808-python-pandas-guide.md","raw":"---\ntitle: python pandas 使用指南\ndate: 2018-08-24 10:14:58\ntags: \n    - 工具箱\n---\n\n# Series 操作\n\n``` python \n# 获取所有的值\nIn [27]: ser2.values\nOut[27]: array([0, 1, 2, 3])\n# 获取所有的索引\nIn [28]: ser2.index\nOut[28]: Index([u'a', u'b', u'c', u'd'], dtype='object')\n```\n\n# 按行遍历DataFrame\n\n## 不修改内容\n\n要以 Pandas 的方式迭代遍历DataFrame的行，可以使用：\n\n\n``` python\n# 1、DataFrame.iterrows()\nfor index, row in df.iterrows():  # 返回（索引， Series）元组\n    print row[\"c1\"], row[\"c2\"]\n\n# 2 DataFrame.itertuples()\nfor row in df.itertuples(index=True, name='Pandas'):\n    print getattr(row, \"c1\"), getattr(row, \"c2\")\n```\n\nitertuples()应该比iterrows()快\n\n但请注意，根据文档(目前 Pandas 0.19.1)：\n\ndf.iterrows：数据的dtype可能不是按行匹配的，因为iterrows返回一个系列的每一行，它不会保留行的dtypes(dtypes跨DataFrames列保留)*\n\niterrows：不要修改行，你不应该修改你正在迭代的东西。这不能保证在所有情况下都能正常工作。根据数据类型的不同，迭代器返回一个副本而不是一个视图，写入它将不起作用。\n\n## 第二种方案: apply()\n\nDataFrame.apply(),对每行的内容进行修改\n\n``` python\ndef valuation_formula(x, y):\n    return x * y * 0.5\n \ndf['price'] = df.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)\n```\n\n## 方案3：df.iloc函数\n\n``` python \nfor i in range(0, len(df)):\n    print df.iloc[i]['c1'], df.iloc[i]['c2']\n```\n\n## 第四种方案：略麻烦，但是更高效，将DataFrame转为List\n可以编写自己的实现namedtuple的迭代器,这相当于pd.DataFrame.itertuples，但是效率更高。\n\n``` python\nfrom collections import namedtuple\n \ndef myiter(d, cols=None):\n    if cols is None:\n        v = d.values.tolist()\n        cols = d.columns.values.tolist()\n    else:\n        j = [d.columns.get_loc(c) for c in cols]\n        v = d.values[:, j].tolist()\n \n    n = namedtuple('MyTuple', cols)\n \n    for line in iter(v):\n        yield n(*line)\n```\n\n``` python \n# 将自定义函数用于给定的DataFrame：\nlist(myiter(df))\n### [MyTuple(c1=10, c2=100), MyTuple(c1=11, c2=110), MyTuple(c1=12, c2=120)]\n\n# 或与pd.DataFrame.itertuples：\nlist(df.itertuples(index=False))\n### [Pandas(c1=10, c2=100), Pandas(c1=11, c2=110), Pandas(c1=12, c2=120)]\n```","slug":"python-pandas-guide","published":1,"updated":"2018-08-24T02:25:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7yd001rn61d3tetlxt3","content":"<h1 id=\"Series-操作\"><a href=\"#Series-操作\" class=\"headerlink\" title=\"Series 操作\"></a>Series 操作</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 获取所有的值</span></span><br><span class=\"line\">In [<span class=\"number\">27</span>]: ser2.values</span><br><span class=\"line\">Out[<span class=\"number\">27</span>]: array([<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\"><span class=\"comment\"># 获取所有的索引</span></span><br><span class=\"line\">In [<span class=\"number\">28</span>]: ser2.index</span><br><span class=\"line\">Out[<span class=\"number\">28</span>]: Index([<span class=\"string\">u'a'</span>, <span class=\"string\">u'b'</span>, <span class=\"string\">u'c'</span>, <span class=\"string\">u'd'</span>], dtype=<span class=\"string\">'object'</span>)</span><br></pre></td></tr></table></figure>\n<h1 id=\"按行遍历DataFrame\"><a href=\"#按行遍历DataFrame\" class=\"headerlink\" title=\"按行遍历DataFrame\"></a>按行遍历DataFrame</h1><h2 id=\"不修改内容\"><a href=\"#不修改内容\" class=\"headerlink\" title=\"不修改内容\"></a>不修改内容</h2><p>要以 Pandas 的方式迭代遍历DataFrame的行，可以使用：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1、DataFrame.iterrows()</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> index, row <span class=\"keyword\">in</span> df.iterrows():  <span class=\"comment\"># 返回（索引， Series）元组</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> row[<span class=\"string\">\"c1\"</span>], row[<span class=\"string\">\"c2\"</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2 DataFrame.itertuples()</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> df.itertuples(index=<span class=\"keyword\">True</span>, name=<span class=\"string\">'Pandas'</span>):</span><br><span class=\"line\">    <span class=\"keyword\">print</span> getattr(row, <span class=\"string\">\"c1\"</span>), getattr(row, <span class=\"string\">\"c2\"</span>)</span><br></pre></td></tr></table></figure>\n<p>itertuples()应该比iterrows()快</p>\n<p>但请注意，根据文档(目前 Pandas 0.19.1)：</p>\n<p>df.iterrows：数据的dtype可能不是按行匹配的，因为iterrows返回一个系列的每一行，它不会保留行的dtypes(dtypes跨DataFrames列保留)*</p>\n<p>iterrows：不要修改行，你不应该修改你正在迭代的东西。这不能保证在所有情况下都能正常工作。根据数据类型的不同，迭代器返回一个副本而不是一个视图，写入它将不起作用。</p>\n<h2 id=\"第二种方案-apply\"><a href=\"#第二种方案-apply\" class=\"headerlink\" title=\"第二种方案: apply()\"></a>第二种方案: apply()</h2><p>DataFrame.apply(),对每行的内容进行修改</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">valuation_formula</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x * y * <span class=\"number\">0.5</span></span><br><span class=\"line\"> </span><br><span class=\"line\">df[<span class=\"string\">'price'</span>] = df.apply(<span class=\"keyword\">lambda</span> row: valuation_formula(row[<span class=\"string\">'x'</span>], row[<span class=\"string\">'y'</span>]), axis=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"方案3：df-iloc函数\"><a href=\"#方案3：df-iloc函数\" class=\"headerlink\" title=\"方案3：df.iloc函数\"></a>方案3：df.iloc函数</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, len(df)):</span><br><span class=\"line\">    <span class=\"keyword\">print</span> df.iloc[i][<span class=\"string\">'c1'</span>], df.iloc[i][<span class=\"string\">'c2'</span>]</span><br></pre></td></tr></table></figure>\n<h2 id=\"第四种方案：略麻烦，但是更高效，将DataFrame转为List\"><a href=\"#第四种方案：略麻烦，但是更高效，将DataFrame转为List\" class=\"headerlink\" title=\"第四种方案：略麻烦，但是更高效，将DataFrame转为List\"></a>第四种方案：略麻烦，但是更高效，将DataFrame转为List</h2><p>可以编写自己的实现namedtuple的迭代器,这相当于pd.DataFrame.itertuples，但是效率更高。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> namedtuple</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">myiter</span><span class=\"params\">(d, cols=None)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> cols <span class=\"keyword\">is</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        v = d.values.tolist()</span><br><span class=\"line\">        cols = d.columns.values.tolist()</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        j = [d.columns.get_loc(c) <span class=\"keyword\">for</span> c <span class=\"keyword\">in</span> cols]</span><br><span class=\"line\">        v = d.values[:, j].tolist()</span><br><span class=\"line\"> </span><br><span class=\"line\">    n = namedtuple(<span class=\"string\">'MyTuple'</span>, cols)</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> iter(v):</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> n(*line)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将自定义函数用于给定的DataFrame：</span></span><br><span class=\"line\">list(myiter(df))</span><br><span class=\"line\"><span class=\"comment\">### [MyTuple(c1=10, c2=100), MyTuple(c1=11, c2=110), MyTuple(c1=12, c2=120)]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 或与pd.DataFrame.itertuples：</span></span><br><span class=\"line\">list(df.itertuples(index=<span class=\"keyword\">False</span>))</span><br><span class=\"line\"><span class=\"comment\">### [Pandas(c1=10, c2=100), Pandas(c1=11, c2=110), Pandas(c1=12, c2=120)]</span></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Series-操作\"><a href=\"#Series-操作\" class=\"headerlink\" title=\"Series 操作\"></a>Series 操作</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 获取所有的值</span></span><br><span class=\"line\">In [<span class=\"number\">27</span>]: ser2.values</span><br><span class=\"line\">Out[<span class=\"number\">27</span>]: array([<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\"><span class=\"comment\"># 获取所有的索引</span></span><br><span class=\"line\">In [<span class=\"number\">28</span>]: ser2.index</span><br><span class=\"line\">Out[<span class=\"number\">28</span>]: Index([<span class=\"string\">u'a'</span>, <span class=\"string\">u'b'</span>, <span class=\"string\">u'c'</span>, <span class=\"string\">u'd'</span>], dtype=<span class=\"string\">'object'</span>)</span><br></pre></td></tr></table></figure>\n<h1 id=\"按行遍历DataFrame\"><a href=\"#按行遍历DataFrame\" class=\"headerlink\" title=\"按行遍历DataFrame\"></a>按行遍历DataFrame</h1><h2 id=\"不修改内容\"><a href=\"#不修改内容\" class=\"headerlink\" title=\"不修改内容\"></a>不修改内容</h2><p>要以 Pandas 的方式迭代遍历DataFrame的行，可以使用：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1、DataFrame.iterrows()</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> index, row <span class=\"keyword\">in</span> df.iterrows():  <span class=\"comment\"># 返回（索引， Series）元组</span></span><br><span class=\"line\">    <span class=\"keyword\">print</span> row[<span class=\"string\">\"c1\"</span>], row[<span class=\"string\">\"c2\"</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2 DataFrame.itertuples()</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> df.itertuples(index=<span class=\"keyword\">True</span>, name=<span class=\"string\">'Pandas'</span>):</span><br><span class=\"line\">    <span class=\"keyword\">print</span> getattr(row, <span class=\"string\">\"c1\"</span>), getattr(row, <span class=\"string\">\"c2\"</span>)</span><br></pre></td></tr></table></figure>\n<p>itertuples()应该比iterrows()快</p>\n<p>但请注意，根据文档(目前 Pandas 0.19.1)：</p>\n<p>df.iterrows：数据的dtype可能不是按行匹配的，因为iterrows返回一个系列的每一行，它不会保留行的dtypes(dtypes跨DataFrames列保留)*</p>\n<p>iterrows：不要修改行，你不应该修改你正在迭代的东西。这不能保证在所有情况下都能正常工作。根据数据类型的不同，迭代器返回一个副本而不是一个视图，写入它将不起作用。</p>\n<h2 id=\"第二种方案-apply\"><a href=\"#第二种方案-apply\" class=\"headerlink\" title=\"第二种方案: apply()\"></a>第二种方案: apply()</h2><p>DataFrame.apply(),对每行的内容进行修改</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">valuation_formula</span><span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x * y * <span class=\"number\">0.5</span></span><br><span class=\"line\"> </span><br><span class=\"line\">df[<span class=\"string\">'price'</span>] = df.apply(<span class=\"keyword\">lambda</span> row: valuation_formula(row[<span class=\"string\">'x'</span>], row[<span class=\"string\">'y'</span>]), axis=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"方案3：df-iloc函数\"><a href=\"#方案3：df-iloc函数\" class=\"headerlink\" title=\"方案3：df.iloc函数\"></a>方案3：df.iloc函数</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>, len(df)):</span><br><span class=\"line\">    <span class=\"keyword\">print</span> df.iloc[i][<span class=\"string\">'c1'</span>], df.iloc[i][<span class=\"string\">'c2'</span>]</span><br></pre></td></tr></table></figure>\n<h2 id=\"第四种方案：略麻烦，但是更高效，将DataFrame转为List\"><a href=\"#第四种方案：略麻烦，但是更高效，将DataFrame转为List\" class=\"headerlink\" title=\"第四种方案：略麻烦，但是更高效，将DataFrame转为List\"></a>第四种方案：略麻烦，但是更高效，将DataFrame转为List</h2><p>可以编写自己的实现namedtuple的迭代器,这相当于pd.DataFrame.itertuples，但是效率更高。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> namedtuple</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">myiter</span><span class=\"params\">(d, cols=None)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> cols <span class=\"keyword\">is</span> <span class=\"keyword\">None</span>:</span><br><span class=\"line\">        v = d.values.tolist()</span><br><span class=\"line\">        cols = d.columns.values.tolist()</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        j = [d.columns.get_loc(c) <span class=\"keyword\">for</span> c <span class=\"keyword\">in</span> cols]</span><br><span class=\"line\">        v = d.values[:, j].tolist()</span><br><span class=\"line\"> </span><br><span class=\"line\">    n = namedtuple(<span class=\"string\">'MyTuple'</span>, cols)</span><br><span class=\"line\"> </span><br><span class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> iter(v):</span><br><span class=\"line\">        <span class=\"keyword\">yield</span> n(*line)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 将自定义函数用于给定的DataFrame：</span></span><br><span class=\"line\">list(myiter(df))</span><br><span class=\"line\"><span class=\"comment\">### [MyTuple(c1=10, c2=100), MyTuple(c1=11, c2=110), MyTuple(c1=12, c2=120)]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 或与pd.DataFrame.itertuples：</span></span><br><span class=\"line\">list(df.itertuples(index=<span class=\"keyword\">False</span>))</span><br><span class=\"line\"><span class=\"comment\">### [Pandas(c1=10, c2=100), Pandas(c1=11, c2=110), Pandas(c1=12, c2=120)]</span></span><br></pre></td></tr></table></figure>"},{"title":"python 字符串处理","date":"2018-07-31T16:02:02.000Z","_content":"# Refs\n\nhttp://www.runoob.com/python/python-strings.html\n\n# 字符串转义\n\n| 转义字符      | 描述   |\n| ------------- | ------ |\n| `\\`(在行尾时) | 续行符 |\n\n# Python字符串运算符\n下表实例变量 a 值为字符串 \"Hello\"，b 变量值为 \"Python\"：\n\n``` python\n# + 字符串连接\t\na + b\n'HelloPython'\n# * 重复输出字符串\t\na * 2\n'HelloHello'\n# in 成员运算符:如果字符串中包含给定的字符返回 True\t\n\"H\" in a\nTrue\n# r/R 原始字符串 - 原始字符串：所有的字符串都是直接按照字面的意思来使用，没有转义特殊或不能打印的字符。 原始字符串除在字符串的第一个引号前加上字母\"r\"（可以大小写）以外，与普通字符串有着几乎完全相同的语法。\t\nprint r'\\n'\n\\n\nprint R'\\n'\n\\n\n```\n\n# 内建函数\n\n## find()方法\n\n``` python\nstr.find(str, beg=0, end=len(string))\n\n```\n\n参数\n- str -- 指定检索的字符串\n- beg -- 开始索引，默认为0。\n- end -- 结束索引，默认为字符串的长度。\n\n返回值\n如果包含子字符串返回开始的索引值，否则返回-1。\n\n## index()方法\n\n描述\n\nPython index() 方法检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。\n\n语法\n\n``` python\nstr.index(str, beg=0, end=len(string))\n```\n\n参数\n- str -- 指定检索的字符串\n- beg -- 开始索引，默认为0。\n- end -- 结束索引，默认为字符串的长度。\n  \n返回值\n\n如果包含子字符串返回开始的索引值，否则抛出异常。\n\n## 其他方法\n\n| 方法                                      | 描述                                                         |\n| ----------------------------------------- | ------------------------------------------------------------ |\n| string.rfind(str, beg=0,end=len(string) ) | 类似于 find()函数，不过是从右边开始查找.                     |\n| string.zfill(width)                       | 返回长度为 width 的字符串，原字符串 string 右对齐，前面填充0 |","source":"_posts/201808-python-string-handle.md","raw":"---\ntitle: python 字符串处理\ndate: 2018-08-01 00:02:02\ntags:\n---\n# Refs\n\nhttp://www.runoob.com/python/python-strings.html\n\n# 字符串转义\n\n| 转义字符      | 描述   |\n| ------------- | ------ |\n| `\\`(在行尾时) | 续行符 |\n\n# Python字符串运算符\n下表实例变量 a 值为字符串 \"Hello\"，b 变量值为 \"Python\"：\n\n``` python\n# + 字符串连接\t\na + b\n'HelloPython'\n# * 重复输出字符串\t\na * 2\n'HelloHello'\n# in 成员运算符:如果字符串中包含给定的字符返回 True\t\n\"H\" in a\nTrue\n# r/R 原始字符串 - 原始字符串：所有的字符串都是直接按照字面的意思来使用，没有转义特殊或不能打印的字符。 原始字符串除在字符串的第一个引号前加上字母\"r\"（可以大小写）以外，与普通字符串有着几乎完全相同的语法。\t\nprint r'\\n'\n\\n\nprint R'\\n'\n\\n\n```\n\n# 内建函数\n\n## find()方法\n\n``` python\nstr.find(str, beg=0, end=len(string))\n\n```\n\n参数\n- str -- 指定检索的字符串\n- beg -- 开始索引，默认为0。\n- end -- 结束索引，默认为字符串的长度。\n\n返回值\n如果包含子字符串返回开始的索引值，否则返回-1。\n\n## index()方法\n\n描述\n\nPython index() 方法检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。\n\n语法\n\n``` python\nstr.index(str, beg=0, end=len(string))\n```\n\n参数\n- str -- 指定检索的字符串\n- beg -- 开始索引，默认为0。\n- end -- 结束索引，默认为字符串的长度。\n  \n返回值\n\n如果包含子字符串返回开始的索引值，否则抛出异常。\n\n## 其他方法\n\n| 方法                                      | 描述                                                         |\n| ----------------------------------------- | ------------------------------------------------------------ |\n| string.rfind(str, beg=0,end=len(string) ) | 类似于 find()函数，不过是从右边开始查找.                     |\n| string.zfill(width)                       | 返回长度为 width 的字符串，原字符串 string 右对齐，前面填充0 |","slug":"python-string-handle","published":1,"updated":"2018-08-05T08:02:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7yf001tn61dvb5qrkms","content":"<h1 id=\"Refs\"><a href=\"#Refs\" class=\"headerlink\" title=\"Refs\"></a>Refs</h1><p><a href=\"http://www.runoob.com/python/python-strings.html\" target=\"_blank\" rel=\"noopener\">http://www.runoob.com/python/python-strings.html</a></p>\n<h1 id=\"字符串转义\"><a href=\"#字符串转义\" class=\"headerlink\" title=\"字符串转义\"></a>字符串转义</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>转义字符</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>\\</code>(在行尾时)</td>\n<td>续行符</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"Python字符串运算符\"><a href=\"#Python字符串运算符\" class=\"headerlink\" title=\"Python字符串运算符\"></a>Python字符串运算符</h1><p>下表实例变量 a 值为字符串 “Hello”，b 变量值为 “Python”：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># + 字符串连接\t</span></span><br><span class=\"line\">a + b</span><br><span class=\"line\"><span class=\"string\">'HelloPython'</span></span><br><span class=\"line\"><span class=\"comment\"># * 重复输出字符串\t</span></span><br><span class=\"line\">a * <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"string\">'HelloHello'</span></span><br><span class=\"line\"><span class=\"comment\"># in 成员运算符:如果字符串中包含给定的字符返回 True\t</span></span><br><span class=\"line\"><span class=\"string\">\"H\"</span> <span class=\"keyword\">in</span> a</span><br><span class=\"line\"><span class=\"keyword\">True</span></span><br><span class=\"line\"><span class=\"comment\"># r/R 原始字符串 - 原始字符串：所有的字符串都是直接按照字面的意思来使用，没有转义特殊或不能打印的字符。 原始字符串除在字符串的第一个引号前加上字母\"r\"（可以大小写）以外，与普通字符串有着几乎完全相同的语法。\t</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> <span class=\"string\">r'\\n'</span></span><br><span class=\"line\">\\n</span><br><span class=\"line\"><span class=\"keyword\">print</span> R<span class=\"string\">'\\n'</span></span><br><span class=\"line\">\\n</span><br></pre></td></tr></table></figure>\n<h1 id=\"内建函数\"><a href=\"#内建函数\" class=\"headerlink\" title=\"内建函数\"></a>内建函数</h1><h2 id=\"find-方法\"><a href=\"#find-方法\" class=\"headerlink\" title=\"find()方法\"></a>find()方法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">str.find(str, beg=<span class=\"number\">0</span>, end=len(string))</span><br></pre></td></tr></table></figure>\n<p>参数</p>\n<ul>\n<li>str — 指定检索的字符串</li>\n<li>beg — 开始索引，默认为0。</li>\n<li>end — 结束索引，默认为字符串的长度。</li>\n</ul>\n<p>返回值<br>如果包含子字符串返回开始的索引值，否则返回-1。</p>\n<h2 id=\"index-方法\"><a href=\"#index-方法\" class=\"headerlink\" title=\"index()方法\"></a>index()方法</h2><p>描述</p>\n<p>Python index() 方法检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。</p>\n<p>语法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">str.index(str, beg=<span class=\"number\">0</span>, end=len(string))</span><br></pre></td></tr></table></figure>\n<p>参数</p>\n<ul>\n<li>str — 指定检索的字符串</li>\n<li>beg — 开始索引，默认为0。</li>\n<li>end — 结束索引，默认为字符串的长度。</li>\n</ul>\n<p>返回值</p>\n<p>如果包含子字符串返回开始的索引值，否则抛出异常。</p>\n<h2 id=\"其他方法\"><a href=\"#其他方法\" class=\"headerlink\" title=\"其他方法\"></a>其他方法</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>方法</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>string.rfind(str, beg=0,end=len(string) )</td>\n<td>类似于 find()函数，不过是从右边开始查找.</td>\n</tr>\n<tr>\n<td>string.zfill(width)</td>\n<td>返回长度为 width 的字符串，原字符串 string 右对齐，前面填充0</td>\n</tr>\n</tbody>\n</table>\n</div>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Refs\"><a href=\"#Refs\" class=\"headerlink\" title=\"Refs\"></a>Refs</h1><p><a href=\"http://www.runoob.com/python/python-strings.html\" target=\"_blank\" rel=\"noopener\">http://www.runoob.com/python/python-strings.html</a></p>\n<h1 id=\"字符串转义\"><a href=\"#字符串转义\" class=\"headerlink\" title=\"字符串转义\"></a>字符串转义</h1><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>转义字符</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>\\</code>(在行尾时)</td>\n<td>续行符</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"Python字符串运算符\"><a href=\"#Python字符串运算符\" class=\"headerlink\" title=\"Python字符串运算符\"></a>Python字符串运算符</h1><p>下表实例变量 a 值为字符串 “Hello”，b 变量值为 “Python”：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># + 字符串连接\t</span></span><br><span class=\"line\">a + b</span><br><span class=\"line\"><span class=\"string\">'HelloPython'</span></span><br><span class=\"line\"><span class=\"comment\"># * 重复输出字符串\t</span></span><br><span class=\"line\">a * <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"string\">'HelloHello'</span></span><br><span class=\"line\"><span class=\"comment\"># in 成员运算符:如果字符串中包含给定的字符返回 True\t</span></span><br><span class=\"line\"><span class=\"string\">\"H\"</span> <span class=\"keyword\">in</span> a</span><br><span class=\"line\"><span class=\"keyword\">True</span></span><br><span class=\"line\"><span class=\"comment\"># r/R 原始字符串 - 原始字符串：所有的字符串都是直接按照字面的意思来使用，没有转义特殊或不能打印的字符。 原始字符串除在字符串的第一个引号前加上字母\"r\"（可以大小写）以外，与普通字符串有着几乎完全相同的语法。\t</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> <span class=\"string\">r'\\n'</span></span><br><span class=\"line\">\\n</span><br><span class=\"line\"><span class=\"keyword\">print</span> R<span class=\"string\">'\\n'</span></span><br><span class=\"line\">\\n</span><br></pre></td></tr></table></figure>\n<h1 id=\"内建函数\"><a href=\"#内建函数\" class=\"headerlink\" title=\"内建函数\"></a>内建函数</h1><h2 id=\"find-方法\"><a href=\"#find-方法\" class=\"headerlink\" title=\"find()方法\"></a>find()方法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">str.find(str, beg=<span class=\"number\">0</span>, end=len(string))</span><br></pre></td></tr></table></figure>\n<p>参数</p>\n<ul>\n<li>str — 指定检索的字符串</li>\n<li>beg — 开始索引，默认为0。</li>\n<li>end — 结束索引，默认为字符串的长度。</li>\n</ul>\n<p>返回值<br>如果包含子字符串返回开始的索引值，否则返回-1。</p>\n<h2 id=\"index-方法\"><a href=\"#index-方法\" class=\"headerlink\" title=\"index()方法\"></a>index()方法</h2><p>描述</p>\n<p>Python index() 方法检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。</p>\n<p>语法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">str.index(str, beg=<span class=\"number\">0</span>, end=len(string))</span><br></pre></td></tr></table></figure>\n<p>参数</p>\n<ul>\n<li>str — 指定检索的字符串</li>\n<li>beg — 开始索引，默认为0。</li>\n<li>end — 结束索引，默认为字符串的长度。</li>\n</ul>\n<p>返回值</p>\n<p>如果包含子字符串返回开始的索引值，否则抛出异常。</p>\n<h2 id=\"其他方法\"><a href=\"#其他方法\" class=\"headerlink\" title=\"其他方法\"></a>其他方法</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>方法</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>string.rfind(str, beg=0,end=len(string) )</td>\n<td>类似于 find()函数，不过是从右边开始查找.</td>\n</tr>\n<tr>\n<td>string.zfill(width)</td>\n<td>返回长度为 width 的字符串，原字符串 string 右对齐，前面填充0</td>\n</tr>\n</tbody>\n</table>\n</div>\n"},{"title":"【推荐系统算法系列一】FM及其衍生算法","date":"2018-08-23T03:35:30.000Z","_content":"\n# 1、 FM背景\n\n在进行CTR预估时，除了单特征外，往往要对特征进行组合。对于特征组合来说，业界现在通用的做法主要有两大类：FM系列与Tree系列。今天，我们就来讲讲FM算法。\n\n# FM 解决one-hot特征稀疏的问题\nFM(Factorization Machine)主要是为了解决数据稀疏的情况下，特征怎样组合的问题。已一个广告分类的问题为例，根据用户与广告位的一些特征，来预测用户是否会点击广告。数据如下：(本例来自美团技术团队分享的paper)\n\n| Clicked? | Country | Day      | Ad_type |\n| -------- | ------- | -------- | ------- |\n| 1        | USA     | 26/11/15 | Movie   |\n| 0        | China   | 1/7/14   | Game    |\n| 1        | China   | 19/2/15  | Game    |\n\n\"Clicked?\"是label，Country、Day、Ad_type是特征。由于三种特征都是categorical类型的，需要经过独热编码（One-Hot Encoding）转换成数值型特征。\n\n因为是categorical特征，所以经过one-hot编码以后，不可避免的样本的数据就变得很稀疏。举个非常简单的例子，假设淘宝或者京东上的item为100万，如果对item这个维度进行one-hot编码，光这一个维度数据的稀疏度就是百万分之一。由此可见，数据的稀疏性，是我们在实际应用场景中面临的一个非常常见的挑战与问题。\n\none-hot编码带来的另一个问题是特征空间变大。同样以上面淘宝上的item为例，将item进行one-hot编码以后，样本空间有一个categorical变为了百万维的数值特征，特征空间一下子暴增一百万。所以大厂动不动上亿维度，就是这么来的。\n\n# FM\n\nFM模型用n个隐变量来刻画特征之间的交互关系。这里要强调的一点是，n是特征的总数，是one-hot展开之后的，比如有三组特征，两个连续特征，一个离散特征有5个取值，那么n=7而不是n=3.\n\n# FM 公式\n\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-990377c58bf6a215.png)\n\n上式中，n表示样本的特征数量,xi表示第i个特征。\n与线性模型相比，FM的模型就多了后面特征组合的部分。\n\n从上面的式子可以很容易看出，组合部分的特征相关参数共有n(n−1)/2个。但是如第二部分所分析，在数据很稀疏的情况下，满足xi,xj都不为0的情况非常少，这样将导致ωij无法通过训练得出。\n\n为了求出ωij，我们对每一个特征分量xi引入辅助向量Vi=(vi1,vi2,⋯,vik)。然后，利用$v_iv_j^T$对$ω_{ij}$进行求解。\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-1f638fe25a63244c.png)\n\n那么ωij组成的矩阵可以表示为:\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-a262e2244174e776.png)\n\n那么，如何求解vi和vj呢？主要采用了公式：\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-6a02a396266a34d7.png)\n\n具体过程如下：\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-b79f3cdc1229ffbb.png)\n\n经过这样的分解之后，我们就可以通过随机梯度下降SGD进行求解：\n\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-6d08a2cdcc6668fb.png)\n\n\n# KDD2018 论文对FM构建特征交叉的评价\n\nKDD 2018 微软论文：\n\n从特征构建的层面而言，现阶段深度学习技术在推荐系统中的应用可以大致分为两类：\n\n（1）从原始数据中自动学习出蕴含语义的隐特征，例如从本文、图像或者知识网络中提取出有效的隐特征；\n\n（2）自动学习多个相关特征之间的交互关系。\n\n特征交互指的是学习两个或多个原始特征之间的交叉组合。例如，经典的基于模型的协同过滤其实是在学习二阶的交叉特征，即学习二元组[user_id, item_id]的联系。而当输入数据的内容变得丰富时，就需要高阶的交叉特征，例如，在新闻推荐场景中，一个三阶交叉特征为AND(user_organization=msra,item_category=deeplearning,time=monday_morning) , 它表示当前用户的工作单位为微软亚洲研究院，当前文章的类别是与深度学习相关的，并且推送时间是周一上午。\n\n传统的推荐系统中，高阶交叉特征通常是由工程师手工提取的，这种做法主要有三种缺点：\n\n（1）重要的特征都是与应用场景息息相关的，针对每一种应用场景，工程师们都需要首先花费大量时间和精力深入了解数据的规律之后才能设计、提取出高效的高阶交叉特征，因此人力成本高昂；\n\n（2）原始数据中往往包含大量稀疏的特征，例如用户和物品的ID，交叉特征的维度空间是原始特征维度的乘积，因此很容易带来维度灾难的问题；\n\n（3）人工提取的交叉特征无法泛化到未曾在训练样本中出现过的模式中。\n\n因此自动学习特征间的交互关系是十分有意义的。目前大部分相关的研究工作是基于因子分解机的框架，利用多层全连接神经网络去自动学习特征间的高阶交互关系，例如FNN、PNN和DeepFM等。其缺点是模型学习出的是隐式的交互特征，其形式是未知的、不可控的；同时它们的特征交互是发生在元素级（bit-wise）而不是特征向量之间（vector-wise），这一点违背了因子分解机的初衷。来自Google的团队在KDD 2017 AdKDD & TargetAD研讨会上提出了DCN模型，旨在显式地学习高阶特征交互，其优点是模型非常轻巧高效，但缺点是最终模型的表现形式是一种很特殊的向量扩张，同时特征交互依旧是发生在元素级上。\n\n# 参考资料\n\n美团点评《深入FFM原理与实践》\nhttps://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html\n\n《推荐系统遇上深度学习(一)--FM模型理论和实践》https://www.jianshu.com/p/152ae633fb00\n\n《第09章：深入浅出ML之Factorization家族》\nhttp://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/","source":"_posts/201808-recommender-algorithm-fm-alg.md","raw":"---\ntitle: 【推荐系统算法系列一】FM及其衍生算法\ndate: 2018-08-23 11:35:30\ncategories: 推荐系统\ntags:\n    - 推荐系统\n---\n\n# 1、 FM背景\n\n在进行CTR预估时，除了单特征外，往往要对特征进行组合。对于特征组合来说，业界现在通用的做法主要有两大类：FM系列与Tree系列。今天，我们就来讲讲FM算法。\n\n# FM 解决one-hot特征稀疏的问题\nFM(Factorization Machine)主要是为了解决数据稀疏的情况下，特征怎样组合的问题。已一个广告分类的问题为例，根据用户与广告位的一些特征，来预测用户是否会点击广告。数据如下：(本例来自美团技术团队分享的paper)\n\n| Clicked? | Country | Day      | Ad_type |\n| -------- | ------- | -------- | ------- |\n| 1        | USA     | 26/11/15 | Movie   |\n| 0        | China   | 1/7/14   | Game    |\n| 1        | China   | 19/2/15  | Game    |\n\n\"Clicked?\"是label，Country、Day、Ad_type是特征。由于三种特征都是categorical类型的，需要经过独热编码（One-Hot Encoding）转换成数值型特征。\n\n因为是categorical特征，所以经过one-hot编码以后，不可避免的样本的数据就变得很稀疏。举个非常简单的例子，假设淘宝或者京东上的item为100万，如果对item这个维度进行one-hot编码，光这一个维度数据的稀疏度就是百万分之一。由此可见，数据的稀疏性，是我们在实际应用场景中面临的一个非常常见的挑战与问题。\n\none-hot编码带来的另一个问题是特征空间变大。同样以上面淘宝上的item为例，将item进行one-hot编码以后，样本空间有一个categorical变为了百万维的数值特征，特征空间一下子暴增一百万。所以大厂动不动上亿维度，就是这么来的。\n\n# FM\n\nFM模型用n个隐变量来刻画特征之间的交互关系。这里要强调的一点是，n是特征的总数，是one-hot展开之后的，比如有三组特征，两个连续特征，一个离散特征有5个取值，那么n=7而不是n=3.\n\n# FM 公式\n\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-990377c58bf6a215.png)\n\n上式中，n表示样本的特征数量,xi表示第i个特征。\n与线性模型相比，FM的模型就多了后面特征组合的部分。\n\n从上面的式子可以很容易看出，组合部分的特征相关参数共有n(n−1)/2个。但是如第二部分所分析，在数据很稀疏的情况下，满足xi,xj都不为0的情况非常少，这样将导致ωij无法通过训练得出。\n\n为了求出ωij，我们对每一个特征分量xi引入辅助向量Vi=(vi1,vi2,⋯,vik)。然后，利用$v_iv_j^T$对$ω_{ij}$进行求解。\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-1f638fe25a63244c.png)\n\n那么ωij组成的矩阵可以表示为:\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-a262e2244174e776.png)\n\n那么，如何求解vi和vj呢？主要采用了公式：\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-6a02a396266a34d7.png)\n\n具体过程如下：\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-b79f3cdc1229ffbb.png)\n\n经过这样的分解之后，我们就可以通过随机梯度下降SGD进行求解：\n\n![](http://p8vrqzrnj.bkt.clouddn.com/4155986-6d08a2cdcc6668fb.png)\n\n\n# KDD2018 论文对FM构建特征交叉的评价\n\nKDD 2018 微软论文：\n\n从特征构建的层面而言，现阶段深度学习技术在推荐系统中的应用可以大致分为两类：\n\n（1）从原始数据中自动学习出蕴含语义的隐特征，例如从本文、图像或者知识网络中提取出有效的隐特征；\n\n（2）自动学习多个相关特征之间的交互关系。\n\n特征交互指的是学习两个或多个原始特征之间的交叉组合。例如，经典的基于模型的协同过滤其实是在学习二阶的交叉特征，即学习二元组[user_id, item_id]的联系。而当输入数据的内容变得丰富时，就需要高阶的交叉特征，例如，在新闻推荐场景中，一个三阶交叉特征为AND(user_organization=msra,item_category=deeplearning,time=monday_morning) , 它表示当前用户的工作单位为微软亚洲研究院，当前文章的类别是与深度学习相关的，并且推送时间是周一上午。\n\n传统的推荐系统中，高阶交叉特征通常是由工程师手工提取的，这种做法主要有三种缺点：\n\n（1）重要的特征都是与应用场景息息相关的，针对每一种应用场景，工程师们都需要首先花费大量时间和精力深入了解数据的规律之后才能设计、提取出高效的高阶交叉特征，因此人力成本高昂；\n\n（2）原始数据中往往包含大量稀疏的特征，例如用户和物品的ID，交叉特征的维度空间是原始特征维度的乘积，因此很容易带来维度灾难的问题；\n\n（3）人工提取的交叉特征无法泛化到未曾在训练样本中出现过的模式中。\n\n因此自动学习特征间的交互关系是十分有意义的。目前大部分相关的研究工作是基于因子分解机的框架，利用多层全连接神经网络去自动学习特征间的高阶交互关系，例如FNN、PNN和DeepFM等。其缺点是模型学习出的是隐式的交互特征，其形式是未知的、不可控的；同时它们的特征交互是发生在元素级（bit-wise）而不是特征向量之间（vector-wise），这一点违背了因子分解机的初衷。来自Google的团队在KDD 2017 AdKDD & TargetAD研讨会上提出了DCN模型，旨在显式地学习高阶特征交互，其优点是模型非常轻巧高效，但缺点是最终模型的表现形式是一种很特殊的向量扩张，同时特征交互依旧是发生在元素级上。\n\n# 参考资料\n\n美团点评《深入FFM原理与实践》\nhttps://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html\n\n《推荐系统遇上深度学习(一)--FM模型理论和实践》https://www.jianshu.com/p/152ae633fb00\n\n《第09章：深入浅出ML之Factorization家族》\nhttp://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/","slug":"recommender-algorithm-fm-alg","published":1,"updated":"2018-08-23T07:25:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7yg001xn61db533lm5t","content":"<h1 id=\"1、-FM背景\"><a href=\"#1、-FM背景\" class=\"headerlink\" title=\"1、 FM背景\"></a>1、 FM背景</h1><p>在进行CTR预估时，除了单特征外，往往要对特征进行组合。对于特征组合来说，业界现在通用的做法主要有两大类：FM系列与Tree系列。今天，我们就来讲讲FM算法。</p>\n<h1 id=\"FM-解决one-hot特征稀疏的问题\"><a href=\"#FM-解决one-hot特征稀疏的问题\" class=\"headerlink\" title=\"FM 解决one-hot特征稀疏的问题\"></a>FM 解决one-hot特征稀疏的问题</h1><p>FM(Factorization Machine)主要是为了解决数据稀疏的情况下，特征怎样组合的问题。已一个广告分类的问题为例，根据用户与广告位的一些特征，来预测用户是否会点击广告。数据如下：(本例来自美团技术团队分享的paper)</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Clicked?</th>\n<th>Country</th>\n<th>Day</th>\n<th>Ad_type</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>USA</td>\n<td>26/11/15</td>\n<td>Movie</td>\n</tr>\n<tr>\n<td>0</td>\n<td>China</td>\n<td>1/7/14</td>\n<td>Game</td>\n</tr>\n<tr>\n<td>1</td>\n<td>China</td>\n<td>19/2/15</td>\n<td>Game</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>“Clicked?”是label，Country、Day、Ad_type是特征。由于三种特征都是categorical类型的，需要经过独热编码（One-Hot Encoding）转换成数值型特征。</p>\n<p>因为是categorical特征，所以经过one-hot编码以后，不可避免的样本的数据就变得很稀疏。举个非常简单的例子，假设淘宝或者京东上的item为100万，如果对item这个维度进行one-hot编码，光这一个维度数据的稀疏度就是百万分之一。由此可见，数据的稀疏性，是我们在实际应用场景中面临的一个非常常见的挑战与问题。</p>\n<p>one-hot编码带来的另一个问题是特征空间变大。同样以上面淘宝上的item为例，将item进行one-hot编码以后，样本空间有一个categorical变为了百万维的数值特征，特征空间一下子暴增一百万。所以大厂动不动上亿维度，就是这么来的。</p>\n<h1 id=\"FM\"><a href=\"#FM\" class=\"headerlink\" title=\"FM\"></a>FM</h1><p>FM模型用n个隐变量来刻画特征之间的交互关系。这里要强调的一点是，n是特征的总数，是one-hot展开之后的，比如有三组特征，两个连续特征，一个离散特征有5个取值，那么n=7而不是n=3.</p>\n<h1 id=\"FM-公式\"><a href=\"#FM-公式\" class=\"headerlink\" title=\"FM 公式\"></a>FM 公式</h1><p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-990377c58bf6a215.png\" alt=\"\"></p>\n<p>上式中，n表示样本的特征数量,xi表示第i个特征。<br>与线性模型相比，FM的模型就多了后面特征组合的部分。</p>\n<p>从上面的式子可以很容易看出，组合部分的特征相关参数共有n(n−1)/2个。但是如第二部分所分析，在数据很稀疏的情况下，满足xi,xj都不为0的情况非常少，这样将导致ωij无法通过训练得出。</p>\n<p>为了求出ωij，我们对每一个特征分量xi引入辅助向量Vi=(vi1,vi2,⋯,vik)。然后，利用$v_iv_j^T$对$ω_{ij}$进行求解。<br><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-1f638fe25a63244c.png\" alt=\"\"></p>\n<p>那么ωij组成的矩阵可以表示为:<br><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-a262e2244174e776.png\" alt=\"\"></p>\n<p>那么，如何求解vi和vj呢？主要采用了公式：<br><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-6a02a396266a34d7.png\" alt=\"\"></p>\n<p>具体过程如下：<br><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-b79f3cdc1229ffbb.png\" alt=\"\"></p>\n<p>经过这样的分解之后，我们就可以通过随机梯度下降SGD进行求解：</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-6d08a2cdcc6668fb.png\" alt=\"\"></p>\n<h1 id=\"KDD2018-论文对FM构建特征交叉的评价\"><a href=\"#KDD2018-论文对FM构建特征交叉的评价\" class=\"headerlink\" title=\"KDD2018 论文对FM构建特征交叉的评价\"></a>KDD2018 论文对FM构建特征交叉的评价</h1><p>KDD 2018 微软论文：</p>\n<p>从特征构建的层面而言，现阶段深度学习技术在推荐系统中的应用可以大致分为两类：</p>\n<p>（1）从原始数据中自动学习出蕴含语义的隐特征，例如从本文、图像或者知识网络中提取出有效的隐特征；</p>\n<p>（2）自动学习多个相关特征之间的交互关系。</p>\n<p>特征交互指的是学习两个或多个原始特征之间的交叉组合。例如，经典的基于模型的协同过滤其实是在学习二阶的交叉特征，即学习二元组[user_id, item_id]的联系。而当输入数据的内容变得丰富时，就需要高阶的交叉特征，例如，在新闻推荐场景中，一个三阶交叉特征为AND(user_organization=msra,item_category=deeplearning,time=monday_morning) , 它表示当前用户的工作单位为微软亚洲研究院，当前文章的类别是与深度学习相关的，并且推送时间是周一上午。</p>\n<p>传统的推荐系统中，高阶交叉特征通常是由工程师手工提取的，这种做法主要有三种缺点：</p>\n<p>（1）重要的特征都是与应用场景息息相关的，针对每一种应用场景，工程师们都需要首先花费大量时间和精力深入了解数据的规律之后才能设计、提取出高效的高阶交叉特征，因此人力成本高昂；</p>\n<p>（2）原始数据中往往包含大量稀疏的特征，例如用户和物品的ID，交叉特征的维度空间是原始特征维度的乘积，因此很容易带来维度灾难的问题；</p>\n<p>（3）人工提取的交叉特征无法泛化到未曾在训练样本中出现过的模式中。</p>\n<p>因此自动学习特征间的交互关系是十分有意义的。目前大部分相关的研究工作是基于因子分解机的框架，利用多层全连接神经网络去自动学习特征间的高阶交互关系，例如FNN、PNN和DeepFM等。其缺点是模型学习出的是隐式的交互特征，其形式是未知的、不可控的；同时它们的特征交互是发生在元素级（bit-wise）而不是特征向量之间（vector-wise），这一点违背了因子分解机的初衷。来自Google的团队在KDD 2017 AdKDD &amp; TargetAD研讨会上提出了DCN模型，旨在显式地学习高阶特征交互，其优点是模型非常轻巧高效，但缺点是最终模型的表现形式是一种很特殊的向量扩张，同时特征交互依旧是发生在元素级上。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><p>美团点评《深入FFM原理与实践》<br><a href=\"https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html</a></p>\n<p>《推荐系统遇上深度学习(一)—FM模型理论和实践》<a href=\"https://www.jianshu.com/p/152ae633fb00\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/152ae633fb00</a></p>\n<p>《第09章：深入浅出ML之Factorization家族》<br><a href=\"http://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/\" target=\"_blank\" rel=\"noopener\">http://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1、-FM背景\"><a href=\"#1、-FM背景\" class=\"headerlink\" title=\"1、 FM背景\"></a>1、 FM背景</h1><p>在进行CTR预估时，除了单特征外，往往要对特征进行组合。对于特征组合来说，业界现在通用的做法主要有两大类：FM系列与Tree系列。今天，我们就来讲讲FM算法。</p>\n<h1 id=\"FM-解决one-hot特征稀疏的问题\"><a href=\"#FM-解决one-hot特征稀疏的问题\" class=\"headerlink\" title=\"FM 解决one-hot特征稀疏的问题\"></a>FM 解决one-hot特征稀疏的问题</h1><p>FM(Factorization Machine)主要是为了解决数据稀疏的情况下，特征怎样组合的问题。已一个广告分类的问题为例，根据用户与广告位的一些特征，来预测用户是否会点击广告。数据如下：(本例来自美团技术团队分享的paper)</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Clicked?</th>\n<th>Country</th>\n<th>Day</th>\n<th>Ad_type</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>USA</td>\n<td>26/11/15</td>\n<td>Movie</td>\n</tr>\n<tr>\n<td>0</td>\n<td>China</td>\n<td>1/7/14</td>\n<td>Game</td>\n</tr>\n<tr>\n<td>1</td>\n<td>China</td>\n<td>19/2/15</td>\n<td>Game</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>“Clicked?”是label，Country、Day、Ad_type是特征。由于三种特征都是categorical类型的，需要经过独热编码（One-Hot Encoding）转换成数值型特征。</p>\n<p>因为是categorical特征，所以经过one-hot编码以后，不可避免的样本的数据就变得很稀疏。举个非常简单的例子，假设淘宝或者京东上的item为100万，如果对item这个维度进行one-hot编码，光这一个维度数据的稀疏度就是百万分之一。由此可见，数据的稀疏性，是我们在实际应用场景中面临的一个非常常见的挑战与问题。</p>\n<p>one-hot编码带来的另一个问题是特征空间变大。同样以上面淘宝上的item为例，将item进行one-hot编码以后，样本空间有一个categorical变为了百万维的数值特征，特征空间一下子暴增一百万。所以大厂动不动上亿维度，就是这么来的。</p>\n<h1 id=\"FM\"><a href=\"#FM\" class=\"headerlink\" title=\"FM\"></a>FM</h1><p>FM模型用n个隐变量来刻画特征之间的交互关系。这里要强调的一点是，n是特征的总数，是one-hot展开之后的，比如有三组特征，两个连续特征，一个离散特征有5个取值，那么n=7而不是n=3.</p>\n<h1 id=\"FM-公式\"><a href=\"#FM-公式\" class=\"headerlink\" title=\"FM 公式\"></a>FM 公式</h1><p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-990377c58bf6a215.png\" alt=\"\"></p>\n<p>上式中，n表示样本的特征数量,xi表示第i个特征。<br>与线性模型相比，FM的模型就多了后面特征组合的部分。</p>\n<p>从上面的式子可以很容易看出，组合部分的特征相关参数共有n(n−1)/2个。但是如第二部分所分析，在数据很稀疏的情况下，满足xi,xj都不为0的情况非常少，这样将导致ωij无法通过训练得出。</p>\n<p>为了求出ωij，我们对每一个特征分量xi引入辅助向量Vi=(vi1,vi2,⋯,vik)。然后，利用$v_iv_j^T$对$ω_{ij}$进行求解。<br><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-1f638fe25a63244c.png\" alt=\"\"></p>\n<p>那么ωij组成的矩阵可以表示为:<br><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-a262e2244174e776.png\" alt=\"\"></p>\n<p>那么，如何求解vi和vj呢？主要采用了公式：<br><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-6a02a396266a34d7.png\" alt=\"\"></p>\n<p>具体过程如下：<br><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-b79f3cdc1229ffbb.png\" alt=\"\"></p>\n<p>经过这样的分解之后，我们就可以通过随机梯度下降SGD进行求解：</p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/4155986-6d08a2cdcc6668fb.png\" alt=\"\"></p>\n<h1 id=\"KDD2018-论文对FM构建特征交叉的评价\"><a href=\"#KDD2018-论文对FM构建特征交叉的评价\" class=\"headerlink\" title=\"KDD2018 论文对FM构建特征交叉的评价\"></a>KDD2018 论文对FM构建特征交叉的评价</h1><p>KDD 2018 微软论文：</p>\n<p>从特征构建的层面而言，现阶段深度学习技术在推荐系统中的应用可以大致分为两类：</p>\n<p>（1）从原始数据中自动学习出蕴含语义的隐特征，例如从本文、图像或者知识网络中提取出有效的隐特征；</p>\n<p>（2）自动学习多个相关特征之间的交互关系。</p>\n<p>特征交互指的是学习两个或多个原始特征之间的交叉组合。例如，经典的基于模型的协同过滤其实是在学习二阶的交叉特征，即学习二元组[user_id, item_id]的联系。而当输入数据的内容变得丰富时，就需要高阶的交叉特征，例如，在新闻推荐场景中，一个三阶交叉特征为AND(user_organization=msra,item_category=deeplearning,time=monday_morning) , 它表示当前用户的工作单位为微软亚洲研究院，当前文章的类别是与深度学习相关的，并且推送时间是周一上午。</p>\n<p>传统的推荐系统中，高阶交叉特征通常是由工程师手工提取的，这种做法主要有三种缺点：</p>\n<p>（1）重要的特征都是与应用场景息息相关的，针对每一种应用场景，工程师们都需要首先花费大量时间和精力深入了解数据的规律之后才能设计、提取出高效的高阶交叉特征，因此人力成本高昂；</p>\n<p>（2）原始数据中往往包含大量稀疏的特征，例如用户和物品的ID，交叉特征的维度空间是原始特征维度的乘积，因此很容易带来维度灾难的问题；</p>\n<p>（3）人工提取的交叉特征无法泛化到未曾在训练样本中出现过的模式中。</p>\n<p>因此自动学习特征间的交互关系是十分有意义的。目前大部分相关的研究工作是基于因子分解机的框架，利用多层全连接神经网络去自动学习特征间的高阶交互关系，例如FNN、PNN和DeepFM等。其缺点是模型学习出的是隐式的交互特征，其形式是未知的、不可控的；同时它们的特征交互是发生在元素级（bit-wise）而不是特征向量之间（vector-wise），这一点违背了因子分解机的初衷。来自Google的团队在KDD 2017 AdKDD &amp; TargetAD研讨会上提出了DCN模型，旨在显式地学习高阶特征交互，其优点是模型非常轻巧高效，但缺点是最终模型的表现形式是一种很特殊的向量扩张，同时特征交互依旧是发生在元素级上。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><p>美团点评《深入FFM原理与实践》<br><a href=\"https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/deep_understanding_of_ffm_principles_and_practices.html</a></p>\n<p>《推荐系统遇上深度学习(一)—FM模型理论和实践》<a href=\"https://www.jianshu.com/p/152ae633fb00\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/152ae633fb00</a></p>\n<p>《第09章：深入浅出ML之Factorization家族》<br><a href=\"http://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/\" target=\"_blank\" rel=\"noopener\">http://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/</a></p>\n"},{"title":"spark 原理资料","date":"2018-08-21T04:17:29.000Z","_content":"\n《Spark学习: 简述总结》\nhttps://blog.csdn.net/databatman/article/details/53023818\n\n2 Spark 系统架构\n首先明确相关术语:\n\n- 应用程序(Application): 基于Spark的用户程序，包含了一个Driver Program 和集群中多个的Executor；\n驱动(Driver): 运行Application的main()函数并且创建SparkContext;\n- 执行单元(Executor): 是为某Application运行在Worker Node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上，每个Application都有各自独立的Executors;\n- 集群管理程序(Cluster Manager): 在集群上获取资源的外部服务(例如：Local、Standalone、Mesos或Yarn等集群管理系统)；\n- 操作(Operation): 作用于RDD的各种操作分为Transformation和Action.\n\n整个 Spark 集群中,分为 Master 节点与 worker 节点,,其中 Master 节点上常驻 Master 守护进程和 Driver 进程, Master 负责将串行任务变成可并行执行的任务集Tasks, 同时还负责出错问题处理等,而 Worker 节点上常驻 Worker 守护进程, Master 节点与 Worker 节点分工不同, Master 负载管理全部的 Worker 节点,而 Worker 节点负责执行任务. \n\nDriver 的功能是创建 SparkContext, 负责执行用户写的 Application 的 main 函数进程,Application 就是用户写的程序. \nSpark 支持不同的运行模式,包括Local, Standalone,Mesoses,Yarn 模式.不同的模式可能会将 Driver 调度到不同的节点上执行.集群管理模式里, local 一般用于本地调试. \n\n每个 Worker 上存在一个或多个 Executor 进程,该对象拥有一个线程池,每个线程负责一个 Task 任务的执行.根据 Executor 上 CPU-core 的数量,其每个时间可以并行多个 跟 core 一样数量的 Task4.Task 任务即为具体执行的 Spark 程序的任务. \n\n![](http://p8vrqzrnj.bkt.clouddn.com/20161103175047811)\n\n在实际编程中,我们不需关心以上调度细节.只需使用 Spark 提供的指定语言的编程接口调用相应的 API 即可. \n\n在 Spark API 中, 一个 应用(Application) 对应一个 SparkContext 的实例。一个 应用 可以用于单个 Job，或者分开的多个 Job 的 session，或者响应请求的长时间生存的服务器。与 MapReduce 不同的是，一个 应用 的进程（我们称之为 Executor)，会一直在集群上运行，即使当时没有 Job 在上面运行。 \n\n而调用一个Spark内部的 Action 会产生一个 Spark job 来完成它。 为了确定这些job实际的内容，Spark 检查 RDD 的DAG再计算出执行 plan 。这个 plan 以最远端的 RDD 为起点（最远端指的是对外没有依赖的 RDD 或者 数据已经缓存下来的 RDD），产生结果 RDD 的 Action 为结束 。并根据是否发生 shuffle 划分 DAG 的 stage.\n\n``` scala\n// parameter\nval appName = \"RetailLocAdjust\"\nval master = \"local\"   // 选择模式\nval conf = new SparkConf().setMaster(master).setAppName(appName)\n// 启动一个 SparkContext Application\nval sc = new SparkContext(conf)\nval rdd = sc.textFile(\"path/...\")\n```\n\n# 参考文献\n\n文献:大数据分析平台建设与应用综述\nSpark学习手册（三）：Spark模块摘读\nSpark入门实战系列–3.Spark编程模型（上）–编程模型及SparkShell实战 \n文献: 基于 spark 平台推荐系统研究.\nApache Spark源码走读之7 – Standalone部署方式分析\nSpark性能优化指南——基础篇\nApache Spark Jobs 性能调优（一）\nSpark性能优化指南——基础篇\nApache Spark Jobs 性能调优（一）\nApache Spark Jobs 性能调优（一）\nApache Spark Jobs 性能调优（一）\nSpark性能优化指南——基础篇","source":"_posts/201808-spark-guide.md","raw":"---\ntitle: spark 原理资料\ndate: 2018-08-21 12:17:29\ntags:\n---\n\n《Spark学习: 简述总结》\nhttps://blog.csdn.net/databatman/article/details/53023818\n\n2 Spark 系统架构\n首先明确相关术语:\n\n- 应用程序(Application): 基于Spark的用户程序，包含了一个Driver Program 和集群中多个的Executor；\n驱动(Driver): 运行Application的main()函数并且创建SparkContext;\n- 执行单元(Executor): 是为某Application运行在Worker Node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上，每个Application都有各自独立的Executors;\n- 集群管理程序(Cluster Manager): 在集群上获取资源的外部服务(例如：Local、Standalone、Mesos或Yarn等集群管理系统)；\n- 操作(Operation): 作用于RDD的各种操作分为Transformation和Action.\n\n整个 Spark 集群中,分为 Master 节点与 worker 节点,,其中 Master 节点上常驻 Master 守护进程和 Driver 进程, Master 负责将串行任务变成可并行执行的任务集Tasks, 同时还负责出错问题处理等,而 Worker 节点上常驻 Worker 守护进程, Master 节点与 Worker 节点分工不同, Master 负载管理全部的 Worker 节点,而 Worker 节点负责执行任务. \n\nDriver 的功能是创建 SparkContext, 负责执行用户写的 Application 的 main 函数进程,Application 就是用户写的程序. \nSpark 支持不同的运行模式,包括Local, Standalone,Mesoses,Yarn 模式.不同的模式可能会将 Driver 调度到不同的节点上执行.集群管理模式里, local 一般用于本地调试. \n\n每个 Worker 上存在一个或多个 Executor 进程,该对象拥有一个线程池,每个线程负责一个 Task 任务的执行.根据 Executor 上 CPU-core 的数量,其每个时间可以并行多个 跟 core 一样数量的 Task4.Task 任务即为具体执行的 Spark 程序的任务. \n\n![](http://p8vrqzrnj.bkt.clouddn.com/20161103175047811)\n\n在实际编程中,我们不需关心以上调度细节.只需使用 Spark 提供的指定语言的编程接口调用相应的 API 即可. \n\n在 Spark API 中, 一个 应用(Application) 对应一个 SparkContext 的实例。一个 应用 可以用于单个 Job，或者分开的多个 Job 的 session，或者响应请求的长时间生存的服务器。与 MapReduce 不同的是，一个 应用 的进程（我们称之为 Executor)，会一直在集群上运行，即使当时没有 Job 在上面运行。 \n\n而调用一个Spark内部的 Action 会产生一个 Spark job 来完成它。 为了确定这些job实际的内容，Spark 检查 RDD 的DAG再计算出执行 plan 。这个 plan 以最远端的 RDD 为起点（最远端指的是对外没有依赖的 RDD 或者 数据已经缓存下来的 RDD），产生结果 RDD 的 Action 为结束 。并根据是否发生 shuffle 划分 DAG 的 stage.\n\n``` scala\n// parameter\nval appName = \"RetailLocAdjust\"\nval master = \"local\"   // 选择模式\nval conf = new SparkConf().setMaster(master).setAppName(appName)\n// 启动一个 SparkContext Application\nval sc = new SparkContext(conf)\nval rdd = sc.textFile(\"path/...\")\n```\n\n# 参考文献\n\n文献:大数据分析平台建设与应用综述\nSpark学习手册（三）：Spark模块摘读\nSpark入门实战系列–3.Spark编程模型（上）–编程模型及SparkShell实战 \n文献: 基于 spark 平台推荐系统研究.\nApache Spark源码走读之7 – Standalone部署方式分析\nSpark性能优化指南——基础篇\nApache Spark Jobs 性能调优（一）\nSpark性能优化指南——基础篇\nApache Spark Jobs 性能调优（一）\nApache Spark Jobs 性能调优（一）\nApache Spark Jobs 性能调优（一）\nSpark性能优化指南——基础篇","slug":"spark-guide","published":1,"updated":"2018-08-21T04:52:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7yh0020n61d16ztdqcy","content":"<p>《Spark学习: 简述总结》<br><a href=\"https://blog.csdn.net/databatman/article/details/53023818\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/databatman/article/details/53023818</a></p>\n<p>2 Spark 系统架构<br>首先明确相关术语:</p>\n<ul>\n<li>应用程序(Application): 基于Spark的用户程序，包含了一个Driver Program 和集群中多个的Executor；<br>驱动(Driver): 运行Application的main()函数并且创建SparkContext;</li>\n<li>执行单元(Executor): 是为某Application运行在Worker Node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上，每个Application都有各自独立的Executors;</li>\n<li>集群管理程序(Cluster Manager): 在集群上获取资源的外部服务(例如：Local、Standalone、Mesos或Yarn等集群管理系统)；</li>\n<li>操作(Operation): 作用于RDD的各种操作分为Transformation和Action.</li>\n</ul>\n<p>整个 Spark 集群中,分为 Master 节点与 worker 节点,,其中 Master 节点上常驻 Master 守护进程和 Driver 进程, Master 负责将串行任务变成可并行执行的任务集Tasks, 同时还负责出错问题处理等,而 Worker 节点上常驻 Worker 守护进程, Master 节点与 Worker 节点分工不同, Master 负载管理全部的 Worker 节点,而 Worker 节点负责执行任务. </p>\n<p>Driver 的功能是创建 SparkContext, 负责执行用户写的 Application 的 main 函数进程,Application 就是用户写的程序.<br>Spark 支持不同的运行模式,包括Local, Standalone,Mesoses,Yarn 模式.不同的模式可能会将 Driver 调度到不同的节点上执行.集群管理模式里, local 一般用于本地调试. </p>\n<p>每个 Worker 上存在一个或多个 Executor 进程,该对象拥有一个线程池,每个线程负责一个 Task 任务的执行.根据 Executor 上 CPU-core 的数量,其每个时间可以并行多个 跟 core 一样数量的 Task4.Task 任务即为具体执行的 Spark 程序的任务. </p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/20161103175047811\" alt=\"\"></p>\n<p>在实际编程中,我们不需关心以上调度细节.只需使用 Spark 提供的指定语言的编程接口调用相应的 API 即可. </p>\n<p>在 Spark API 中, 一个 应用(Application) 对应一个 SparkContext 的实例。一个 应用 可以用于单个 Job，或者分开的多个 Job 的 session，或者响应请求的长时间生存的服务器。与 MapReduce 不同的是，一个 应用 的进程（我们称之为 Executor)，会一直在集群上运行，即使当时没有 Job 在上面运行。 </p>\n<p>而调用一个Spark内部的 Action 会产生一个 Spark job 来完成它。 为了确定这些job实际的内容，Spark 检查 RDD 的DAG再计算出执行 plan 。这个 plan 以最远端的 RDD 为起点（最远端指的是对外没有依赖的 RDD 或者 数据已经缓存下来的 RDD），产生结果 RDD 的 Action 为结束 。并根据是否发生 shuffle 划分 DAG 的 stage.</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// parameter</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> appName = <span class=\"string\">\"RetailLocAdjust\"</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> master = <span class=\"string\">\"local\"</span>   <span class=\"comment\">// 选择模式</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> conf = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().setMaster(master).setAppName(appName)</span><br><span class=\"line\"><span class=\"comment\">// 启动一个 SparkContext Application</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> sc = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(conf)</span><br><span class=\"line\"><span class=\"keyword\">val</span> rdd = sc.textFile(<span class=\"string\">\"path/...\"</span>)</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>文献:大数据分析平台建设与应用综述<br>Spark学习手册（三）：Spark模块摘读<br>Spark入门实战系列–3.Spark编程模型（上）–编程模型及SparkShell实战<br>文献: 基于 spark 平台推荐系统研究.<br>Apache Spark源码走读之7 – Standalone部署方式分析<br>Spark性能优化指南——基础篇<br>Apache Spark Jobs 性能调优（一）<br>Spark性能优化指南——基础篇<br>Apache Spark Jobs 性能调优（一）<br>Apache Spark Jobs 性能调优（一）<br>Apache Spark Jobs 性能调优（一）<br>Spark性能优化指南——基础篇</p>\n","site":{"data":{}},"excerpt":"","more":"<p>《Spark学习: 简述总结》<br><a href=\"https://blog.csdn.net/databatman/article/details/53023818\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/databatman/article/details/53023818</a></p>\n<p>2 Spark 系统架构<br>首先明确相关术语:</p>\n<ul>\n<li>应用程序(Application): 基于Spark的用户程序，包含了一个Driver Program 和集群中多个的Executor；<br>驱动(Driver): 运行Application的main()函数并且创建SparkContext;</li>\n<li>执行单元(Executor): 是为某Application运行在Worker Node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上，每个Application都有各自独立的Executors;</li>\n<li>集群管理程序(Cluster Manager): 在集群上获取资源的外部服务(例如：Local、Standalone、Mesos或Yarn等集群管理系统)；</li>\n<li>操作(Operation): 作用于RDD的各种操作分为Transformation和Action.</li>\n</ul>\n<p>整个 Spark 集群中,分为 Master 节点与 worker 节点,,其中 Master 节点上常驻 Master 守护进程和 Driver 进程, Master 负责将串行任务变成可并行执行的任务集Tasks, 同时还负责出错问题处理等,而 Worker 节点上常驻 Worker 守护进程, Master 节点与 Worker 节点分工不同, Master 负载管理全部的 Worker 节点,而 Worker 节点负责执行任务. </p>\n<p>Driver 的功能是创建 SparkContext, 负责执行用户写的 Application 的 main 函数进程,Application 就是用户写的程序.<br>Spark 支持不同的运行模式,包括Local, Standalone,Mesoses,Yarn 模式.不同的模式可能会将 Driver 调度到不同的节点上执行.集群管理模式里, local 一般用于本地调试. </p>\n<p>每个 Worker 上存在一个或多个 Executor 进程,该对象拥有一个线程池,每个线程负责一个 Task 任务的执行.根据 Executor 上 CPU-core 的数量,其每个时间可以并行多个 跟 core 一样数量的 Task4.Task 任务即为具体执行的 Spark 程序的任务. </p>\n<p><img src=\"http://p8vrqzrnj.bkt.clouddn.com/20161103175047811\" alt=\"\"></p>\n<p>在实际编程中,我们不需关心以上调度细节.只需使用 Spark 提供的指定语言的编程接口调用相应的 API 即可. </p>\n<p>在 Spark API 中, 一个 应用(Application) 对应一个 SparkContext 的实例。一个 应用 可以用于单个 Job，或者分开的多个 Job 的 session，或者响应请求的长时间生存的服务器。与 MapReduce 不同的是，一个 应用 的进程（我们称之为 Executor)，会一直在集群上运行，即使当时没有 Job 在上面运行。 </p>\n<p>而调用一个Spark内部的 Action 会产生一个 Spark job 来完成它。 为了确定这些job实际的内容，Spark 检查 RDD 的DAG再计算出执行 plan 。这个 plan 以最远端的 RDD 为起点（最远端指的是对外没有依赖的 RDD 或者 数据已经缓存下来的 RDD），产生结果 RDD 的 Action 为结束 。并根据是否发生 shuffle 划分 DAG 的 stage.</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// parameter</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> appName = <span class=\"string\">\"RetailLocAdjust\"</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> master = <span class=\"string\">\"local\"</span>   <span class=\"comment\">// 选择模式</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> conf = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().setMaster(master).setAppName(appName)</span><br><span class=\"line\"><span class=\"comment\">// 启动一个 SparkContext Application</span></span><br><span class=\"line\"><span class=\"keyword\">val</span> sc = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(conf)</span><br><span class=\"line\"><span class=\"keyword\">val</span> rdd = sc.textFile(<span class=\"string\">\"path/...\"</span>)</span><br></pre></td></tr></table></figure>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><p>文献:大数据分析平台建设与应用综述<br>Spark学习手册（三）：Spark模块摘读<br>Spark入门实战系列–3.Spark编程模型（上）–编程模型及SparkShell实战<br>文献: 基于 spark 平台推荐系统研究.<br>Apache Spark源码走读之7 – Standalone部署方式分析<br>Spark性能优化指南——基础篇<br>Apache Spark Jobs 性能调优（一）<br>Spark性能优化指南——基础篇<br>Apache Spark Jobs 性能调优（一）<br>Apache Spark Jobs 性能调优（一）<br>Apache Spark Jobs 性能调优（一）<br>Spark性能优化指南——基础篇</p>\n"},{"title":"spark SQL 笔记","date":"2018-08-09T16:49:02.000Z","_content":"","source":"_posts/201808-spark-sql.md","raw":"---\ntitle: spark SQL 笔记\ndate: 2018-08-10 00:49:02\ntags:\n---\n","slug":"spark-sql","published":1,"updated":"2018-08-21T04:52:27.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7yj0024n61d1fh3rx5v","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"spark作业参数设置及调优","date":"2018-08-09T16:43:55.000Z","_content":"\n# Spark作业基本运行原理\n\n在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导致各种异常。总之，无论是哪种情况，都会导致Spark作业的运行效率低下，甚至根本无法运行。因此我们必须对Spark作业的资源使用原理有一个清晰的认识，并知道在Spark作业运行过程中，有哪些资源参数是可以设置的，以及如何设置合适的参数值。\n![](http://p8vrqzrnj.bkt.clouddn.com/20160515225532299)\n\n详细原理见上图。我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。而Driver进程要做的第一件事情，就是向集群管理器（可以是Spark Standalone集群，也可以是其他的资源管理集群，美团•大众点评使用的是YARN作为资源管理集群）申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPU core。\n\n在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批task，然后将这些task分配到各个Executor进程中执行。task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个task处理的数据不同而已。一个stage的所有task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。\n\n## stage划分\n\nSpark是根据shuffle类算子来进行stage的划分。如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。\n\n> 在Spark中，什么情况下，会发生shuffle？reduceByKey、groupByKey、sortByKey、countByKey、join、cogroup等操作。\n\n## Executor内存与cache/persist持久化\n\n当我们在代码中执行了cache/persist等持久化操作时，根据我们选择的持久化级别的不同，每个task计算出来的数据也会保存到Executor进程的内存或者所在节点的磁盘文件中。\n\n因此Executor的内存主要分为三块：第一块是让task执行我们自己编写的代码时使用，默认是占Executor总内存的20%；第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用，默认也是占Executor总内存的20%；第三块是让RDD持久化时使用，默认占Executor总内存的60%。\n\n## core数量与task执行速度\n\ntask的执行速度是跟每个Executor进程的CPU core数量有直接关系的。一个CPU core同一时间只能执行一个线程。而每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。\n\n以上就是Spark作业的基本运行原理的说明，大家可以结合上图来理解。理解作业基本原理，是我们进行资源参数调优的基本前提。\n\n# 资源参数调优\n\n了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，我们同时也给出了一个调优的参考值。\n\n\n## 内容\n\n### 1.num-executors\n\n- 参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。\n- 参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。\n\n### 2.executor-memory\n\n参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。\n\n参数调优建议：每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。\n\n### 3.executor-cores\n\n参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。\n\n参数调优建议：Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。\n\n### 4.driver-memory\n\n参数说明：该参数用于设置Driver进程的内存。\n\n参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。\n\n### 5.spark.default.parallelism\n\n参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。\n\n参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。\n\n### 6.spark.storage.memoryFraction\n\n参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。\n\n参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。\n\n### 7.spark.shuffle.memoryFraction\n\n参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。\n\n参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。\n\n### 8.total-executor-cores\n\n参数说明：Total cores for all executors.\n\n\n# spark配置示例\n\n``` bash\nworker_num=500\n\n/xxxx/spark-2.2/bin/spark-submit \\\n  --name push_online_single@$user_name \\\n  --queue root.dmlc.hadoop-mining.mining \\\n  --master yarn-cluster \\\n  --num-executors $worker_num \\\n  --class com.xxx.Group \\\n  --executor-cores 1 \\\n  --executor-memory 2g \\\n  --driver-memory 6g \\\n  --conf spark.rdd.compress=true \\\n  --conf spark.driver.maxResultSize=2g \\\n  --conf spark.akka.frameSize=500 \\\n  --conf spark.default.parallelism=2000 \\\n  --conf spark.storage.memoryFraction=0.6 \\\n  --conf spark.shuffle.consolidateFiles=true \\\n  --conf spark.shuffle.manager=sort \\\n  --conf spark.yarn.executor.memoryOverhead=2048 \\\n  --conf spark.yarn.driver.memoryOverhead=4096 \\\n  --conf spark.hadoop.validateOutputSpecs=false \\\n  --conf spark.speculation=false \\\n  --conf spark.speculation.multiplier=3 \\\n  --conf spark.sql.shuffle.partitions=2000 \\\n  --conf spark.memory.fraction=0.8 \\\n  --conf spark.memory.storageFraction=0.2 \\\n  --conf spark.network.timeout=360s \\\n  $MLX_MODEL_PUSH_DIR/target/model-push-1.0.jar \\\n  param_path:$param_path_root/$dump_mid_path/$to_model_name/WEIGHTS/PROTO/*.param.* \\\n  meta_path:$param_path_root/$to_model_name/WEIGHTS/PROTO/001.meta \\\n  model_name:${model_name_tmp} \\\n  group_num:4 \\\n  batch_size:512 \\\n  is_repartition:true \\\n  partition_num:500 \\\n  engine_room:test \\\n  group_id:-1 \\\n  copy_id:-1 \\\n  copy_num:-1 \\\n  is_move_model:$is_move_model \\\n  is_create_model:$is_create_model \\\n  to_model_name:$to_model_name \\\n  push_interval:10 \\\n  is_push_to_test:$is_push_to_test\n```\n\n``` scala\nval conf = new SparkConf().set(\"spark.hadoop.validateOutputSpecs\", \"false\").setAppName(\"mlx_push_\" + modelName)\nval sc = new SparkContext(conf)\n```\n\n# 补充\n\nrdd的全称为Resilient Distributed Datasets（弹性分布式数据集）\n\nrdd的操作有两种transfrom和action。\n\ntransfrom并不引发真正的rdd计算，action才会引发真正的rdd计算。\n\n## spark中的持久化\n\nSpark最重要的一个功能，就是在不同操作间，持久化（或缓存）一个数据集在内存中。当你持久化一个RDD，每一个结点都将把它的计算分块结果保存在内存中，并在对此数据集（或者衍生出的数据集）进行的其它动作中重用。这将使得后续的动作(Actions)变得更加迅速（通常快10倍）。缓存是用Spark构建迭代算法的关键。\n\n你可以用persist()或cache()方法来标记一个要被持久化的RDD，然后一旦首次被一个动作（Action）触发计算，它将会被保留在计算结点的内存中并重用。Cache有容错机制，如果RDD的任一分区丢失了，通过使用原先创建它的转换操作，它将会被自动重算（不需要全部重算，只计算丢失的部分）。当需要删除被持久化的RDD，可以用unpersistRDD()来完成该工作。\n\n此外，每一个RDD都可以用不同的保存级别进行保存，从而允许你持久化数据集在硬盘，或者在内存作为序列化的Java对象（节省空间），甚至于跨结点复制。这些等级选择，是通过将一个org.apache.spark.storage.StorageLevel对象传递给persist()方法进行确定。cache()方法是使用默认存储级别的快捷方法，也就是StorageLevel.MEMORY_ONLY(将反序列化的对象存入内存）。\n\nrdd的持久化是便于rdd计算的重复使用。\n\n官方的api说明如下：\n\n``` scala\npersist(storageLevel=StorageLevel(False, True, False, False, 1))\n\nSet this RDD’s storage level to persist its values across operations after the first time it is computed. This can only be used to assign a new storage level if the RDD does not have a storage level set yet. If no storage level is specified defaults to (MEMORY_ONLY_SER)\n```\n\n(1) 在rdd参与第一次计算后，设置rdd的存储级别可以保持rdd计算后的值在内存中。例如：rdd1要经过transform1得到rdd2,然后在一个循环L内rdd2进行transform2和action1。由于trasform操作是不会真正执行的，所以rdd1执行transform1需要在循环L第一次循环的时候触发。如果设置了rdd1的存储级别，那么循环L的第二次循环起，只需要从rdd2开始计算就好了，而不用向第一次循环时从rdd1开始计算。\n\n(2) 另外，只有未曾设置存储级别的rdd才能设置存储级别，设置了存储级别的rdd不能修改其存储级别。\n\n### 持久化方式\nrdd的持久化操作有cache()和presist()函数这两种方式。\n\n# 转载&参考\n[spark submit参数调优](https://blog.csdn.net/chenjieit619/article/details/53421080)\n\n[官方参数配置](http://spark.apache.org/docs/latest/configuration.html)\n","source":"_posts/201808-spark-parameters-balance.md","raw":"---\ntitle: spark作业参数设置及调优\ndate: 2018-08-10 00:43:55\ncategories: spark\ntags:\n    - spark\n---\n\n# Spark作业基本运行原理\n\n在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导致各种异常。总之，无论是哪种情况，都会导致Spark作业的运行效率低下，甚至根本无法运行。因此我们必须对Spark作业的资源使用原理有一个清晰的认识，并知道在Spark作业运行过程中，有哪些资源参数是可以设置的，以及如何设置合适的参数值。\n![](http://p8vrqzrnj.bkt.clouddn.com/20160515225532299)\n\n详细原理见上图。我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。而Driver进程要做的第一件事情，就是向集群管理器（可以是Spark Standalone集群，也可以是其他的资源管理集群，美团•大众点评使用的是YARN作为资源管理集群）申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPU core。\n\n在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批task，然后将这些task分配到各个Executor进程中执行。task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个task处理的数据不同而已。一个stage的所有task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。\n\n## stage划分\n\nSpark是根据shuffle类算子来进行stage的划分。如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。\n\n> 在Spark中，什么情况下，会发生shuffle？reduceByKey、groupByKey、sortByKey、countByKey、join、cogroup等操作。\n\n## Executor内存与cache/persist持久化\n\n当我们在代码中执行了cache/persist等持久化操作时，根据我们选择的持久化级别的不同，每个task计算出来的数据也会保存到Executor进程的内存或者所在节点的磁盘文件中。\n\n因此Executor的内存主要分为三块：第一块是让task执行我们自己编写的代码时使用，默认是占Executor总内存的20%；第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用，默认也是占Executor总内存的20%；第三块是让RDD持久化时使用，默认占Executor总内存的60%。\n\n## core数量与task执行速度\n\ntask的执行速度是跟每个Executor进程的CPU core数量有直接关系的。一个CPU core同一时间只能执行一个线程。而每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。\n\n以上就是Spark作业的基本运行原理的说明，大家可以结合上图来理解。理解作业基本原理，是我们进行资源参数调优的基本前提。\n\n# 资源参数调优\n\n了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，我们同时也给出了一个调优的参考值。\n\n\n## 内容\n\n### 1.num-executors\n\n- 参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。\n- 参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。\n\n### 2.executor-memory\n\n参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。\n\n参数调优建议：每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。\n\n### 3.executor-cores\n\n参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。\n\n参数调优建议：Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。\n\n### 4.driver-memory\n\n参数说明：该参数用于设置Driver进程的内存。\n\n参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。\n\n### 5.spark.default.parallelism\n\n参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。\n\n参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。\n\n### 6.spark.storage.memoryFraction\n\n参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。\n\n参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。\n\n### 7.spark.shuffle.memoryFraction\n\n参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。\n\n参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。\n\n### 8.total-executor-cores\n\n参数说明：Total cores for all executors.\n\n\n# spark配置示例\n\n``` bash\nworker_num=500\n\n/xxxx/spark-2.2/bin/spark-submit \\\n  --name push_online_single@$user_name \\\n  --queue root.dmlc.hadoop-mining.mining \\\n  --master yarn-cluster \\\n  --num-executors $worker_num \\\n  --class com.xxx.Group \\\n  --executor-cores 1 \\\n  --executor-memory 2g \\\n  --driver-memory 6g \\\n  --conf spark.rdd.compress=true \\\n  --conf spark.driver.maxResultSize=2g \\\n  --conf spark.akka.frameSize=500 \\\n  --conf spark.default.parallelism=2000 \\\n  --conf spark.storage.memoryFraction=0.6 \\\n  --conf spark.shuffle.consolidateFiles=true \\\n  --conf spark.shuffle.manager=sort \\\n  --conf spark.yarn.executor.memoryOverhead=2048 \\\n  --conf spark.yarn.driver.memoryOverhead=4096 \\\n  --conf spark.hadoop.validateOutputSpecs=false \\\n  --conf spark.speculation=false \\\n  --conf spark.speculation.multiplier=3 \\\n  --conf spark.sql.shuffle.partitions=2000 \\\n  --conf spark.memory.fraction=0.8 \\\n  --conf spark.memory.storageFraction=0.2 \\\n  --conf spark.network.timeout=360s \\\n  $MLX_MODEL_PUSH_DIR/target/model-push-1.0.jar \\\n  param_path:$param_path_root/$dump_mid_path/$to_model_name/WEIGHTS/PROTO/*.param.* \\\n  meta_path:$param_path_root/$to_model_name/WEIGHTS/PROTO/001.meta \\\n  model_name:${model_name_tmp} \\\n  group_num:4 \\\n  batch_size:512 \\\n  is_repartition:true \\\n  partition_num:500 \\\n  engine_room:test \\\n  group_id:-1 \\\n  copy_id:-1 \\\n  copy_num:-1 \\\n  is_move_model:$is_move_model \\\n  is_create_model:$is_create_model \\\n  to_model_name:$to_model_name \\\n  push_interval:10 \\\n  is_push_to_test:$is_push_to_test\n```\n\n``` scala\nval conf = new SparkConf().set(\"spark.hadoop.validateOutputSpecs\", \"false\").setAppName(\"mlx_push_\" + modelName)\nval sc = new SparkContext(conf)\n```\n\n# 补充\n\nrdd的全称为Resilient Distributed Datasets（弹性分布式数据集）\n\nrdd的操作有两种transfrom和action。\n\ntransfrom并不引发真正的rdd计算，action才会引发真正的rdd计算。\n\n## spark中的持久化\n\nSpark最重要的一个功能，就是在不同操作间，持久化（或缓存）一个数据集在内存中。当你持久化一个RDD，每一个结点都将把它的计算分块结果保存在内存中，并在对此数据集（或者衍生出的数据集）进行的其它动作中重用。这将使得后续的动作(Actions)变得更加迅速（通常快10倍）。缓存是用Spark构建迭代算法的关键。\n\n你可以用persist()或cache()方法来标记一个要被持久化的RDD，然后一旦首次被一个动作（Action）触发计算，它将会被保留在计算结点的内存中并重用。Cache有容错机制，如果RDD的任一分区丢失了，通过使用原先创建它的转换操作，它将会被自动重算（不需要全部重算，只计算丢失的部分）。当需要删除被持久化的RDD，可以用unpersistRDD()来完成该工作。\n\n此外，每一个RDD都可以用不同的保存级别进行保存，从而允许你持久化数据集在硬盘，或者在内存作为序列化的Java对象（节省空间），甚至于跨结点复制。这些等级选择，是通过将一个org.apache.spark.storage.StorageLevel对象传递给persist()方法进行确定。cache()方法是使用默认存储级别的快捷方法，也就是StorageLevel.MEMORY_ONLY(将反序列化的对象存入内存）。\n\nrdd的持久化是便于rdd计算的重复使用。\n\n官方的api说明如下：\n\n``` scala\npersist(storageLevel=StorageLevel(False, True, False, False, 1))\n\nSet this RDD’s storage level to persist its values across operations after the first time it is computed. This can only be used to assign a new storage level if the RDD does not have a storage level set yet. If no storage level is specified defaults to (MEMORY_ONLY_SER)\n```\n\n(1) 在rdd参与第一次计算后，设置rdd的存储级别可以保持rdd计算后的值在内存中。例如：rdd1要经过transform1得到rdd2,然后在一个循环L内rdd2进行transform2和action1。由于trasform操作是不会真正执行的，所以rdd1执行transform1需要在循环L第一次循环的时候触发。如果设置了rdd1的存储级别，那么循环L的第二次循环起，只需要从rdd2开始计算就好了，而不用向第一次循环时从rdd1开始计算。\n\n(2) 另外，只有未曾设置存储级别的rdd才能设置存储级别，设置了存储级别的rdd不能修改其存储级别。\n\n### 持久化方式\nrdd的持久化操作有cache()和presist()函数这两种方式。\n\n# 转载&参考\n[spark submit参数调优](https://blog.csdn.net/chenjieit619/article/details/53421080)\n\n[官方参数配置](http://spark.apache.org/docs/latest/configuration.html)\n","slug":"spark-parameters-balance","published":1,"updated":"2018-08-21T04:52:23.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7yk0026n61d2m2zex9m","content":"<h1 id=\"Spark作业基本运行原理\"><a href=\"#Spark作业基本运行原理\" class=\"headerlink\" title=\"Spark作业基本运行原理\"></a>Spark作业基本运行原理</h1><p>在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导致各种异常。总之，无论是哪种情况，都会导致Spark作业的运行效率低下，甚至根本无法运行。因此我们必须对Spark作业的资源使用原理有一个清晰的认识，并知道在Spark作业运行过程中，有哪些资源参数是可以设置的，以及如何设置合适的参数值。<br><img src=\"http://p8vrqzrnj.bkt.clouddn.com/20160515225532299\" alt=\"\"></p>\n<p>详细原理见上图。我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。而Driver进程要做的第一件事情，就是向集群管理器（可以是Spark Standalone集群，也可以是其他的资源管理集群，美团•大众点评使用的是YARN作为资源管理集群）申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPU core。</p>\n<p>在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批task，然后将这些task分配到各个Executor进程中执行。task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个task处理的数据不同而已。一个stage的所有task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。</p>\n<h2 id=\"stage划分\"><a href=\"#stage划分\" class=\"headerlink\" title=\"stage划分\"></a>stage划分</h2><p>Spark是根据shuffle类算子来进行stage的划分。如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。</p>\n<blockquote>\n<p>在Spark中，什么情况下，会发生shuffle？reduceByKey、groupByKey、sortByKey、countByKey、join、cogroup等操作。</p>\n</blockquote>\n<h2 id=\"Executor内存与cache-persist持久化\"><a href=\"#Executor内存与cache-persist持久化\" class=\"headerlink\" title=\"Executor内存与cache/persist持久化\"></a>Executor内存与cache/persist持久化</h2><p>当我们在代码中执行了cache/persist等持久化操作时，根据我们选择的持久化级别的不同，每个task计算出来的数据也会保存到Executor进程的内存或者所在节点的磁盘文件中。</p>\n<p>因此Executor的内存主要分为三块：第一块是让task执行我们自己编写的代码时使用，默认是占Executor总内存的20%；第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用，默认也是占Executor总内存的20%；第三块是让RDD持久化时使用，默认占Executor总内存的60%。</p>\n<h2 id=\"core数量与task执行速度\"><a href=\"#core数量与task执行速度\" class=\"headerlink\" title=\"core数量与task执行速度\"></a>core数量与task执行速度</h2><p>task的执行速度是跟每个Executor进程的CPU core数量有直接关系的。一个CPU core同一时间只能执行一个线程。而每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。</p>\n<p>以上就是Spark作业的基本运行原理的说明，大家可以结合上图来理解。理解作业基本原理，是我们进行资源参数调优的基本前提。</p>\n<h1 id=\"资源参数调优\"><a href=\"#资源参数调优\" class=\"headerlink\" title=\"资源参数调优\"></a>资源参数调优</h1><p>了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，我们同时也给出了一个调优的参考值。</p>\n<h2 id=\"内容\"><a href=\"#内容\" class=\"headerlink\" title=\"内容\"></a>内容</h2><h3 id=\"1-num-executors\"><a href=\"#1-num-executors\" class=\"headerlink\" title=\"1.num-executors\"></a>1.num-executors</h3><ul>\n<li>参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。</li>\n<li>参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。</li>\n</ul>\n<h3 id=\"2-executor-memory\"><a href=\"#2-executor-memory\" class=\"headerlink\" title=\"2.executor-memory\"></a>2.executor-memory</h3><p>参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。</p>\n<p>参数调优建议：每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。</p>\n<h3 id=\"3-executor-cores\"><a href=\"#3-executor-cores\" class=\"headerlink\" title=\"3.executor-cores\"></a>3.executor-cores</h3><p>参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。</p>\n<p>参数调优建议：Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。</p>\n<h3 id=\"4-driver-memory\"><a href=\"#4-driver-memory\" class=\"headerlink\" title=\"4.driver-memory\"></a>4.driver-memory</h3><p>参数说明：该参数用于设置Driver进程的内存。</p>\n<p>参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。</p>\n<h3 id=\"5-spark-default-parallelism\"><a href=\"#5-spark-default-parallelism\" class=\"headerlink\" title=\"5.spark.default.parallelism\"></a>5.spark.default.parallelism</h3><p>参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。</p>\n<p>参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。</p>\n<h3 id=\"6-spark-storage-memoryFraction\"><a href=\"#6-spark-storage-memoryFraction\" class=\"headerlink\" title=\"6.spark.storage.memoryFraction\"></a>6.spark.storage.memoryFraction</h3><p>参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。</p>\n<p>参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>\n<h3 id=\"7-spark-shuffle-memoryFraction\"><a href=\"#7-spark-shuffle-memoryFraction\" class=\"headerlink\" title=\"7.spark.shuffle.memoryFraction\"></a>7.spark.shuffle.memoryFraction</h3><p>参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</p>\n<p>参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>\n<h3 id=\"8-total-executor-cores\"><a href=\"#8-total-executor-cores\" class=\"headerlink\" title=\"8.total-executor-cores\"></a>8.total-executor-cores</h3><p>参数说明：Total cores for all executors.</p>\n<h1 id=\"spark配置示例\"><a href=\"#spark配置示例\" class=\"headerlink\" title=\"spark配置示例\"></a>spark配置示例</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">worker_num=500</span><br><span class=\"line\"></span><br><span class=\"line\">/xxxx/spark-2.2/bin/spark-submit \\</span><br><span class=\"line\">  --name push_online_single@<span class=\"variable\">$user_name</span> \\</span><br><span class=\"line\">  --queue root.dmlc.hadoop-mining.mining \\</span><br><span class=\"line\">  --master yarn-cluster \\</span><br><span class=\"line\">  --num-executors <span class=\"variable\">$worker_num</span> \\</span><br><span class=\"line\">  --class com.xxx.Group \\</span><br><span class=\"line\">  --executor-cores 1 \\</span><br><span class=\"line\">  --executor-memory 2g \\</span><br><span class=\"line\">  --driver-memory 6g \\</span><br><span class=\"line\">  --conf spark.rdd.compress=<span class=\"literal\">true</span> \\</span><br><span class=\"line\">  --conf spark.driver.maxResultSize=2g \\</span><br><span class=\"line\">  --conf spark.akka.frameSize=500 \\</span><br><span class=\"line\">  --conf spark.default.parallelism=2000 \\</span><br><span class=\"line\">  --conf spark.storage.memoryFraction=0.6 \\</span><br><span class=\"line\">  --conf spark.shuffle.consolidateFiles=<span class=\"literal\">true</span> \\</span><br><span class=\"line\">  --conf spark.shuffle.manager=sort \\</span><br><span class=\"line\">  --conf spark.yarn.executor.memoryOverhead=2048 \\</span><br><span class=\"line\">  --conf spark.yarn.driver.memoryOverhead=4096 \\</span><br><span class=\"line\">  --conf spark.hadoop.validateOutputSpecs=<span class=\"literal\">false</span> \\</span><br><span class=\"line\">  --conf spark.speculation=<span class=\"literal\">false</span> \\</span><br><span class=\"line\">  --conf spark.speculation.multiplier=3 \\</span><br><span class=\"line\">  --conf spark.sql.shuffle.partitions=2000 \\</span><br><span class=\"line\">  --conf spark.memory.fraction=0.8 \\</span><br><span class=\"line\">  --conf spark.memory.storageFraction=0.2 \\</span><br><span class=\"line\">  --conf spark.network.timeout=360s \\</span><br><span class=\"line\">  <span class=\"variable\">$MLX_MODEL_PUSH_DIR</span>/target/model-push-1.0.jar \\</span><br><span class=\"line\">  param_path:<span class=\"variable\">$param_path_root</span>/<span class=\"variable\">$dump_mid_path</span>/<span class=\"variable\">$to_model_name</span>/WEIGHTS/PROTO/*.param.* \\</span><br><span class=\"line\">  meta_path:<span class=\"variable\">$param_path_root</span>/<span class=\"variable\">$to_model_name</span>/WEIGHTS/PROTO/001.meta \\</span><br><span class=\"line\">  model_name:<span class=\"variable\">$&#123;model_name_tmp&#125;</span> \\</span><br><span class=\"line\">  group_num:4 \\</span><br><span class=\"line\">  batch_size:512 \\</span><br><span class=\"line\">  is_repartition:<span class=\"literal\">true</span> \\</span><br><span class=\"line\">  partition_num:500 \\</span><br><span class=\"line\">  engine_room:<span class=\"built_in\">test</span> \\</span><br><span class=\"line\">  group_id:-1 \\</span><br><span class=\"line\">  copy_id:-1 \\</span><br><span class=\"line\">  copy_num:-1 \\</span><br><span class=\"line\">  is_move_model:<span class=\"variable\">$is_move_model</span> \\</span><br><span class=\"line\">  is_create_model:<span class=\"variable\">$is_create_model</span> \\</span><br><span class=\"line\">  to_model_name:<span class=\"variable\">$to_model_name</span> \\</span><br><span class=\"line\">  push_interval:10 \\</span><br><span class=\"line\">  is_push_to_test:<span class=\"variable\">$is_push_to_test</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">val</span> conf = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().set(<span class=\"string\">\"spark.hadoop.validateOutputSpecs\"</span>, <span class=\"string\">\"false\"</span>).setAppName(<span class=\"string\">\"mlx_push_\"</span> + modelName)</span><br><span class=\"line\"><span class=\"keyword\">val</span> sc = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure>\n<h1 id=\"补充\"><a href=\"#补充\" class=\"headerlink\" title=\"补充\"></a>补充</h1><p>rdd的全称为Resilient Distributed Datasets（弹性分布式数据集）</p>\n<p>rdd的操作有两种transfrom和action。</p>\n<p>transfrom并不引发真正的rdd计算，action才会引发真正的rdd计算。</p>\n<h2 id=\"spark中的持久化\"><a href=\"#spark中的持久化\" class=\"headerlink\" title=\"spark中的持久化\"></a>spark中的持久化</h2><p>Spark最重要的一个功能，就是在不同操作间，持久化（或缓存）一个数据集在内存中。当你持久化一个RDD，每一个结点都将把它的计算分块结果保存在内存中，并在对此数据集（或者衍生出的数据集）进行的其它动作中重用。这将使得后续的动作(Actions)变得更加迅速（通常快10倍）。缓存是用Spark构建迭代算法的关键。</p>\n<p>你可以用persist()或cache()方法来标记一个要被持久化的RDD，然后一旦首次被一个动作（Action）触发计算，它将会被保留在计算结点的内存中并重用。Cache有容错机制，如果RDD的任一分区丢失了，通过使用原先创建它的转换操作，它将会被自动重算（不需要全部重算，只计算丢失的部分）。当需要删除被持久化的RDD，可以用unpersistRDD()来完成该工作。</p>\n<p>此外，每一个RDD都可以用不同的保存级别进行保存，从而允许你持久化数据集在硬盘，或者在内存作为序列化的Java对象（节省空间），甚至于跨结点复制。这些等级选择，是通过将一个org.apache.spark.storage.StorageLevel对象传递给persist()方法进行确定。cache()方法是使用默认存储级别的快捷方法，也就是StorageLevel.MEMORY_ONLY(将反序列化的对象存入内存）。</p>\n<p>rdd的持久化是便于rdd计算的重复使用。</p>\n<p>官方的api说明如下：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">persist(storageLevel=<span class=\"type\">StorageLevel</span>(<span class=\"type\">False</span>, <span class=\"type\">True</span>, <span class=\"type\">False</span>, <span class=\"type\">False</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">Set</span> <span class=\"keyword\">this</span> <span class=\"type\">RDD</span>’s storage level to persist its values across operations after the first time it is computed. <span class=\"type\">This</span> can only be used to assign a <span class=\"keyword\">new</span> storage level <span class=\"keyword\">if</span> the <span class=\"type\">RDD</span> does not have a storage level set yet. <span class=\"type\">If</span> no storage level is specified defaults to (<span class=\"type\">MEMORY_ONLY_SER</span>)</span><br></pre></td></tr></table></figure>\n<p>(1) 在rdd参与第一次计算后，设置rdd的存储级别可以保持rdd计算后的值在内存中。例如：rdd1要经过transform1得到rdd2,然后在一个循环L内rdd2进行transform2和action1。由于trasform操作是不会真正执行的，所以rdd1执行transform1需要在循环L第一次循环的时候触发。如果设置了rdd1的存储级别，那么循环L的第二次循环起，只需要从rdd2开始计算就好了，而不用向第一次循环时从rdd1开始计算。</p>\n<p>(2) 另外，只有未曾设置存储级别的rdd才能设置存储级别，设置了存储级别的rdd不能修改其存储级别。</p>\n<h3 id=\"持久化方式\"><a href=\"#持久化方式\" class=\"headerlink\" title=\"持久化方式\"></a>持久化方式</h3><p>rdd的持久化操作有cache()和presist()函数这两种方式。</p>\n<h1 id=\"转载-amp-参考\"><a href=\"#转载-amp-参考\" class=\"headerlink\" title=\"转载&amp;参考\"></a>转载&amp;参考</h1><p><a href=\"https://blog.csdn.net/chenjieit619/article/details/53421080\" target=\"_blank\" rel=\"noopener\">spark submit参数调优</a></p>\n<p><a href=\"http://spark.apache.org/docs/latest/configuration.html\" target=\"_blank\" rel=\"noopener\">官方参数配置</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Spark作业基本运行原理\"><a href=\"#Spark作业基本运行原理\" class=\"headerlink\" title=\"Spark作业基本运行原理\"></a>Spark作业基本运行原理</h1><p>在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导致各种异常。总之，无论是哪种情况，都会导致Spark作业的运行效率低下，甚至根本无法运行。因此我们必须对Spark作业的资源使用原理有一个清晰的认识，并知道在Spark作业运行过程中，有哪些资源参数是可以设置的，以及如何设置合适的参数值。<br><img src=\"http://p8vrqzrnj.bkt.clouddn.com/20160515225532299\" alt=\"\"></p>\n<p>详细原理见上图。我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。而Driver进程要做的第一件事情，就是向集群管理器（可以是Spark Standalone集群，也可以是其他的资源管理集群，美团•大众点评使用的是YARN作为资源管理集群）申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPU core。</p>\n<p>在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批task，然后将这些task分配到各个Executor进程中执行。task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个task处理的数据不同而已。一个stage的所有task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。</p>\n<h2 id=\"stage划分\"><a href=\"#stage划分\" class=\"headerlink\" title=\"stage划分\"></a>stage划分</h2><p>Spark是根据shuffle类算子来进行stage的划分。如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。</p>\n<blockquote>\n<p>在Spark中，什么情况下，会发生shuffle？reduceByKey、groupByKey、sortByKey、countByKey、join、cogroup等操作。</p>\n</blockquote>\n<h2 id=\"Executor内存与cache-persist持久化\"><a href=\"#Executor内存与cache-persist持久化\" class=\"headerlink\" title=\"Executor内存与cache/persist持久化\"></a>Executor内存与cache/persist持久化</h2><p>当我们在代码中执行了cache/persist等持久化操作时，根据我们选择的持久化级别的不同，每个task计算出来的数据也会保存到Executor进程的内存或者所在节点的磁盘文件中。</p>\n<p>因此Executor的内存主要分为三块：第一块是让task执行我们自己编写的代码时使用，默认是占Executor总内存的20%；第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用，默认也是占Executor总内存的20%；第三块是让RDD持久化时使用，默认占Executor总内存的60%。</p>\n<h2 id=\"core数量与task执行速度\"><a href=\"#core数量与task执行速度\" class=\"headerlink\" title=\"core数量与task执行速度\"></a>core数量与task执行速度</h2><p>task的执行速度是跟每个Executor进程的CPU core数量有直接关系的。一个CPU core同一时间只能执行一个线程。而每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。</p>\n<p>以上就是Spark作业的基本运行原理的说明，大家可以结合上图来理解。理解作业基本原理，是我们进行资源参数调优的基本前提。</p>\n<h1 id=\"资源参数调优\"><a href=\"#资源参数调优\" class=\"headerlink\" title=\"资源参数调优\"></a>资源参数调优</h1><p>了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，我们同时也给出了一个调优的参考值。</p>\n<h2 id=\"内容\"><a href=\"#内容\" class=\"headerlink\" title=\"内容\"></a>内容</h2><h3 id=\"1-num-executors\"><a href=\"#1-num-executors\" class=\"headerlink\" title=\"1.num-executors\"></a>1.num-executors</h3><ul>\n<li>参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。</li>\n<li>参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。</li>\n</ul>\n<h3 id=\"2-executor-memory\"><a href=\"#2-executor-memory\" class=\"headerlink\" title=\"2.executor-memory\"></a>2.executor-memory</h3><p>参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。</p>\n<p>参数调优建议：每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。</p>\n<h3 id=\"3-executor-cores\"><a href=\"#3-executor-cores\" class=\"headerlink\" title=\"3.executor-cores\"></a>3.executor-cores</h3><p>参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。</p>\n<p>参数调优建议：Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。</p>\n<h3 id=\"4-driver-memory\"><a href=\"#4-driver-memory\" class=\"headerlink\" title=\"4.driver-memory\"></a>4.driver-memory</h3><p>参数说明：该参数用于设置Driver进程的内存。</p>\n<p>参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。</p>\n<h3 id=\"5-spark-default-parallelism\"><a href=\"#5-spark-default-parallelism\" class=\"headerlink\" title=\"5.spark.default.parallelism\"></a>5.spark.default.parallelism</h3><p>参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。</p>\n<p>参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。</p>\n<h3 id=\"6-spark-storage-memoryFraction\"><a href=\"#6-spark-storage-memoryFraction\" class=\"headerlink\" title=\"6.spark.storage.memoryFraction\"></a>6.spark.storage.memoryFraction</h3><p>参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。</p>\n<p>参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>\n<h3 id=\"7-spark-shuffle-memoryFraction\"><a href=\"#7-spark-shuffle-memoryFraction\" class=\"headerlink\" title=\"7.spark.shuffle.memoryFraction\"></a>7.spark.shuffle.memoryFraction</h3><p>参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</p>\n<p>参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>\n<h3 id=\"8-total-executor-cores\"><a href=\"#8-total-executor-cores\" class=\"headerlink\" title=\"8.total-executor-cores\"></a>8.total-executor-cores</h3><p>参数说明：Total cores for all executors.</p>\n<h1 id=\"spark配置示例\"><a href=\"#spark配置示例\" class=\"headerlink\" title=\"spark配置示例\"></a>spark配置示例</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">worker_num=500</span><br><span class=\"line\"></span><br><span class=\"line\">/xxxx/spark-2.2/bin/spark-submit \\</span><br><span class=\"line\">  --name push_online_single@<span class=\"variable\">$user_name</span> \\</span><br><span class=\"line\">  --queue root.dmlc.hadoop-mining.mining \\</span><br><span class=\"line\">  --master yarn-cluster \\</span><br><span class=\"line\">  --num-executors <span class=\"variable\">$worker_num</span> \\</span><br><span class=\"line\">  --class com.xxx.Group \\</span><br><span class=\"line\">  --executor-cores 1 \\</span><br><span class=\"line\">  --executor-memory 2g \\</span><br><span class=\"line\">  --driver-memory 6g \\</span><br><span class=\"line\">  --conf spark.rdd.compress=<span class=\"literal\">true</span> \\</span><br><span class=\"line\">  --conf spark.driver.maxResultSize=2g \\</span><br><span class=\"line\">  --conf spark.akka.frameSize=500 \\</span><br><span class=\"line\">  --conf spark.default.parallelism=2000 \\</span><br><span class=\"line\">  --conf spark.storage.memoryFraction=0.6 \\</span><br><span class=\"line\">  --conf spark.shuffle.consolidateFiles=<span class=\"literal\">true</span> \\</span><br><span class=\"line\">  --conf spark.shuffle.manager=sort \\</span><br><span class=\"line\">  --conf spark.yarn.executor.memoryOverhead=2048 \\</span><br><span class=\"line\">  --conf spark.yarn.driver.memoryOverhead=4096 \\</span><br><span class=\"line\">  --conf spark.hadoop.validateOutputSpecs=<span class=\"literal\">false</span> \\</span><br><span class=\"line\">  --conf spark.speculation=<span class=\"literal\">false</span> \\</span><br><span class=\"line\">  --conf spark.speculation.multiplier=3 \\</span><br><span class=\"line\">  --conf spark.sql.shuffle.partitions=2000 \\</span><br><span class=\"line\">  --conf spark.memory.fraction=0.8 \\</span><br><span class=\"line\">  --conf spark.memory.storageFraction=0.2 \\</span><br><span class=\"line\">  --conf spark.network.timeout=360s \\</span><br><span class=\"line\">  <span class=\"variable\">$MLX_MODEL_PUSH_DIR</span>/target/model-push-1.0.jar \\</span><br><span class=\"line\">  param_path:<span class=\"variable\">$param_path_root</span>/<span class=\"variable\">$dump_mid_path</span>/<span class=\"variable\">$to_model_name</span>/WEIGHTS/PROTO/*.param.* \\</span><br><span class=\"line\">  meta_path:<span class=\"variable\">$param_path_root</span>/<span class=\"variable\">$to_model_name</span>/WEIGHTS/PROTO/001.meta \\</span><br><span class=\"line\">  model_name:<span class=\"variable\">$&#123;model_name_tmp&#125;</span> \\</span><br><span class=\"line\">  group_num:4 \\</span><br><span class=\"line\">  batch_size:512 \\</span><br><span class=\"line\">  is_repartition:<span class=\"literal\">true</span> \\</span><br><span class=\"line\">  partition_num:500 \\</span><br><span class=\"line\">  engine_room:<span class=\"built_in\">test</span> \\</span><br><span class=\"line\">  group_id:-1 \\</span><br><span class=\"line\">  copy_id:-1 \\</span><br><span class=\"line\">  copy_num:-1 \\</span><br><span class=\"line\">  is_move_model:<span class=\"variable\">$is_move_model</span> \\</span><br><span class=\"line\">  is_create_model:<span class=\"variable\">$is_create_model</span> \\</span><br><span class=\"line\">  to_model_name:<span class=\"variable\">$to_model_name</span> \\</span><br><span class=\"line\">  push_interval:10 \\</span><br><span class=\"line\">  is_push_to_test:<span class=\"variable\">$is_push_to_test</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">val</span> conf = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().set(<span class=\"string\">\"spark.hadoop.validateOutputSpecs\"</span>, <span class=\"string\">\"false\"</span>).setAppName(<span class=\"string\">\"mlx_push_\"</span> + modelName)</span><br><span class=\"line\"><span class=\"keyword\">val</span> sc = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure>\n<h1 id=\"补充\"><a href=\"#补充\" class=\"headerlink\" title=\"补充\"></a>补充</h1><p>rdd的全称为Resilient Distributed Datasets（弹性分布式数据集）</p>\n<p>rdd的操作有两种transfrom和action。</p>\n<p>transfrom并不引发真正的rdd计算，action才会引发真正的rdd计算。</p>\n<h2 id=\"spark中的持久化\"><a href=\"#spark中的持久化\" class=\"headerlink\" title=\"spark中的持久化\"></a>spark中的持久化</h2><p>Spark最重要的一个功能，就是在不同操作间，持久化（或缓存）一个数据集在内存中。当你持久化一个RDD，每一个结点都将把它的计算分块结果保存在内存中，并在对此数据集（或者衍生出的数据集）进行的其它动作中重用。这将使得后续的动作(Actions)变得更加迅速（通常快10倍）。缓存是用Spark构建迭代算法的关键。</p>\n<p>你可以用persist()或cache()方法来标记一个要被持久化的RDD，然后一旦首次被一个动作（Action）触发计算，它将会被保留在计算结点的内存中并重用。Cache有容错机制，如果RDD的任一分区丢失了，通过使用原先创建它的转换操作，它将会被自动重算（不需要全部重算，只计算丢失的部分）。当需要删除被持久化的RDD，可以用unpersistRDD()来完成该工作。</p>\n<p>此外，每一个RDD都可以用不同的保存级别进行保存，从而允许你持久化数据集在硬盘，或者在内存作为序列化的Java对象（节省空间），甚至于跨结点复制。这些等级选择，是通过将一个org.apache.spark.storage.StorageLevel对象传递给persist()方法进行确定。cache()方法是使用默认存储级别的快捷方法，也就是StorageLevel.MEMORY_ONLY(将反序列化的对象存入内存）。</p>\n<p>rdd的持久化是便于rdd计算的重复使用。</p>\n<p>官方的api说明如下：</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">persist(storageLevel=<span class=\"type\">StorageLevel</span>(<span class=\"type\">False</span>, <span class=\"type\">True</span>, <span class=\"type\">False</span>, <span class=\"type\">False</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">Set</span> <span class=\"keyword\">this</span> <span class=\"type\">RDD</span>’s storage level to persist its values across operations after the first time it is computed. <span class=\"type\">This</span> can only be used to assign a <span class=\"keyword\">new</span> storage level <span class=\"keyword\">if</span> the <span class=\"type\">RDD</span> does not have a storage level set yet. <span class=\"type\">If</span> no storage level is specified defaults to (<span class=\"type\">MEMORY_ONLY_SER</span>)</span><br></pre></td></tr></table></figure>\n<p>(1) 在rdd参与第一次计算后，设置rdd的存储级别可以保持rdd计算后的值在内存中。例如：rdd1要经过transform1得到rdd2,然后在一个循环L内rdd2进行transform2和action1。由于trasform操作是不会真正执行的，所以rdd1执行transform1需要在循环L第一次循环的时候触发。如果设置了rdd1的存储级别，那么循环L的第二次循环起，只需要从rdd2开始计算就好了，而不用向第一次循环时从rdd1开始计算。</p>\n<p>(2) 另外，只有未曾设置存储级别的rdd才能设置存储级别，设置了存储级别的rdd不能修改其存储级别。</p>\n<h3 id=\"持久化方式\"><a href=\"#持久化方式\" class=\"headerlink\" title=\"持久化方式\"></a>持久化方式</h3><p>rdd的持久化操作有cache()和presist()函数这两种方式。</p>\n<h1 id=\"转载-amp-参考\"><a href=\"#转载-amp-参考\" class=\"headerlink\" title=\"转载&amp;参考\"></a>转载&amp;参考</h1><p><a href=\"https://blog.csdn.net/chenjieit619/article/details/53421080\" target=\"_blank\" rel=\"noopener\">spark submit参数调优</a></p>\n<p><a href=\"http://spark.apache.org/docs/latest/configuration.html\" target=\"_blank\" rel=\"noopener\">官方参数配置</a></p>\n"},{"title":"时间处理总结 shell python","date":"2018-08-10T09:30:26.000Z","_content":"\n# shell 篇\n\ndate命令\n\nlinux 和 mac 不一样！\n环境centos 6\n\n``` bash \ndate -d \"1 days ago\" +%F  # 指定显示日期的格式 %F | full date; same as %Y-%m-%d \ndate +\"%Y%m%d\" -d \"-2 day\"  # -d 指定哪一天\n2017-03-04\n\n```\n\n## 指定显示日期的格式\n\n| 格式 | 含义                                  |\n| ---- | ------------------------------------- |\n| %s   | seconds since 1970-01-01 00:00:00 UTC |\n| %F   | full date; same as %Y-%m-%d           |\n| %Y   | year                                  |\n| %m   | month                                 |\n| %d   | day                                   |\n\n时间戳 seconds since 1970-01-01 00:00:00 UTC","source":"_posts/201808-time-parse-in-every-script.md","raw":"---\ntitle: 时间处理总结 shell python\ndate: 2018-08-10 17:30:26\ncategories: 珍惜时间\ntags:\n    - time\n    - datetime\n---\n\n# shell 篇\n\ndate命令\n\nlinux 和 mac 不一样！\n环境centos 6\n\n``` bash \ndate -d \"1 days ago\" +%F  # 指定显示日期的格式 %F | full date; same as %Y-%m-%d \ndate +\"%Y%m%d\" -d \"-2 day\"  # -d 指定哪一天\n2017-03-04\n\n```\n\n## 指定显示日期的格式\n\n| 格式 | 含义                                  |\n| ---- | ------------------------------------- |\n| %s   | seconds since 1970-01-01 00:00:00 UTC |\n| %F   | full date; same as %Y-%m-%d           |\n| %Y   | year                                  |\n| %m   | month                                 |\n| %d   | day                                   |\n\n时间戳 seconds since 1970-01-01 00:00:00 UTC","slug":"time-parse-in-every-script","published":1,"updated":"2018-08-21T04:52:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjldai7yl0029n61daw9yb218","content":"<h1 id=\"shell-篇\"><a href=\"#shell-篇\" class=\"headerlink\" title=\"shell 篇\"></a>shell 篇</h1><p>date命令</p>\n<p>linux 和 mac 不一样！<br>环境centos 6</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date -d <span class=\"string\">\"1 days ago\"</span> +%F  <span class=\"comment\"># 指定显示日期的格式 %F | full date; same as %Y-%m-%d </span></span><br><span class=\"line\">date +<span class=\"string\">\"%Y%m%d\"</span> -d <span class=\"string\">\"-2 day\"</span>  <span class=\"comment\"># -d 指定哪一天</span></span><br><span class=\"line\">2017-03-04</span><br></pre></td></tr></table></figure>\n<h2 id=\"指定显示日期的格式\"><a href=\"#指定显示日期的格式\" class=\"headerlink\" title=\"指定显示日期的格式\"></a>指定显示日期的格式</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>格式</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>%s</td>\n<td>seconds since 1970-01-01 00:00:00 UTC</td>\n</tr>\n<tr>\n<td>%F</td>\n<td>full date; same as %Y-%m-%d</td>\n</tr>\n<tr>\n<td>%Y</td>\n<td>year</td>\n</tr>\n<tr>\n<td>%m</td>\n<td>month</td>\n</tr>\n<tr>\n<td>%d</td>\n<td>day</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>时间戳 seconds since 1970-01-01 00:00:00 UTC</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"shell-篇\"><a href=\"#shell-篇\" class=\"headerlink\" title=\"shell 篇\"></a>shell 篇</h1><p>date命令</p>\n<p>linux 和 mac 不一样！<br>环境centos 6</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date -d <span class=\"string\">\"1 days ago\"</span> +%F  <span class=\"comment\"># 指定显示日期的格式 %F | full date; same as %Y-%m-%d </span></span><br><span class=\"line\">date +<span class=\"string\">\"%Y%m%d\"</span> -d <span class=\"string\">\"-2 day\"</span>  <span class=\"comment\"># -d 指定哪一天</span></span><br><span class=\"line\">2017-03-04</span><br></pre></td></tr></table></figure>\n<h2 id=\"指定显示日期的格式\"><a href=\"#指定显示日期的格式\" class=\"headerlink\" title=\"指定显示日期的格式\"></a>指定显示日期的格式</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>格式</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>%s</td>\n<td>seconds since 1970-01-01 00:00:00 UTC</td>\n</tr>\n<tr>\n<td>%F</td>\n<td>full date; same as %Y-%m-%d</td>\n</tr>\n<tr>\n<td>%Y</td>\n<td>year</td>\n</tr>\n<tr>\n<td>%m</td>\n<td>month</td>\n</tr>\n<tr>\n<td>%d</td>\n<td>day</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>时间戳 seconds since 1970-01-01 00:00:00 UTC</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjldai7x20001n61dfdawpuns","category_id":"cjldai7x90005n61dsma0zbhw","_id":"cjldai7xk000fn61dwyzujyes"},{"post_id":"cjldai7xo000ln61d1kevt15n","category_id":"cjldai7xq000on61ddroa2apy","_id":"cjldai7xw000wn61d72zcp55c"},{"post_id":"cjldai7y6001en61djsxhcvp1","category_id":"cjldai7x90005n61dsma0zbhw","_id":"cjldai7ya001ln61ds7qt5bza"},{"post_id":"cjldai7y7001fn61dw79vqta0","category_id":"cjldai7y9001jn61ddwe1scyf","_id":"cjldai7yf001un61d2x5umu9z"},{"post_id":"cjldai7y8001in61dslfxmufd","category_id":"cjldai7yd001pn61d2p1qz3oq","_id":"cjldai7yi0021n61dhlw2igv7"},{"post_id":"cjldai7ya001mn61d9usjuset","category_id":"cjldai7yf001wn61dks5def30","_id":"cjldai7yl0027n61d2zn5zptr"},{"post_id":"cjldai7yc001on61d7wk59hms","category_id":"cjldai7yi0022n61dt4vsbmoa","_id":"cjldai7yn002bn61dyh7pwpsm"},{"post_id":"cjldai7yk0026n61d2m2zex9m","category_id":"cjldai7yi0022n61dt4vsbmoa","_id":"cjldai7yn002en61dwiaudsve"},{"post_id":"cjldai7yg001xn61db533lm5t","category_id":"cjldai7yl0028n61d8rlnr6rs","_id":"cjldai7yo002in61dwtyy4woi"},{"post_id":"cjldai7yl0029n61daw9yb218","category_id":"cjldai7yn002dn61dd31evkny","_id":"cjldai7yo002kn61dy1y7hq85"}],"PostTag":[{"post_id":"cjldai7x20001n61dfdawpuns","tag_id":"cjldai7xb0006n61dc58qr44q","_id":"cjldai7xh000cn61d0f9ynve0"},{"post_id":"cjldai7xd0009n61d9i0zgl89","tag_id":"cjldai7xh000bn61dgktppmxk","_id":"cjldai7xm000in61dgeav2fmt"},{"post_id":"cjldai7xj000en61dej98qgq8","tag_id":"cjldai7xm000hn61dpywyh5jj","_id":"cjldai7xp000mn61di2ybaf6y"},{"post_id":"cjldai7xo000ln61d1kevt15n","tag_id":"cjldai7xq000pn61ds1cn5nzn","_id":"cjldai7xx000zn61dvsvpzt07"},{"post_id":"cjldai7xo000ln61d1kevt15n","tag_id":"cjldai7xt000tn61dt2guc284","_id":"cjldai7xy0011n61dhvvajpb6"},{"post_id":"cjldai7xp000nn61dqvitxwlu","tag_id":"cjldai7xw000xn61dlgpekr2a","_id":"cjldai7y00014n61dp4sh8r7n"},{"post_id":"cjldai7xs000sn61dap4mjdgn","tag_id":"cjldai7xy0012n61dxumimw4d","_id":"cjldai7y20018n61dva8zfdvh"},{"post_id":"cjldai7xt000un61dz8nkl94x","tag_id":"cjldai7y10016n61d6umcplvs","_id":"cjldai7y5001cn61d04b1n8co"},{"post_id":"cjldai7xu000vn61dm8qc9bz3","tag_id":"cjldai7y4001bn61dz1mphfpg","_id":"cjldai7y7001gn61d2whjb04s"},{"post_id":"cjldai7ya001mn61d9usjuset","tag_id":"cjldai7xt000tn61dt2guc284","_id":"cjldai7yd001qn61dnvjbum5s"},{"post_id":"cjldai7y6001en61djsxhcvp1","tag_id":"cjldai7y8001hn61dz2snxlev","_id":"cjldai7yf001vn61d57s3zrj5"},{"post_id":"cjldai7y6001en61djsxhcvp1","tag_id":"cjldai7yb001nn61dgb7u7z28","_id":"cjldai7yh001yn61d68x6tzat"},{"post_id":"cjldai7yg001xn61db533lm5t","tag_id":"cjldai7xq000pn61ds1cn5nzn","_id":"cjldai7yi0023n61di94vxfy2"},{"post_id":"cjldai7y7001fn61dw79vqta0","tag_id":"cjldai7ye001sn61dx92sfoc4","_id":"cjldai7yn002cn61dkgthwpa2"},{"post_id":"cjldai7y7001fn61dw79vqta0","tag_id":"cjldai7yh001zn61dsp0qmjsj","_id":"cjldai7yn002fn61de444x3gx"},{"post_id":"cjldai7y7001fn61dw79vqta0","tag_id":"cjldai7yj0025n61d2rx87fbk","_id":"cjldai7yo002hn61dge7juol8"},{"post_id":"cjldai7y8001in61dslfxmufd","tag_id":"cjldai7yn002an61dybj0x80w","_id":"cjldai7yp002mn61dw91b9a54"},{"post_id":"cjldai7y8001in61dslfxmufd","tag_id":"cjldai7yo002gn61d11kyco5c","_id":"cjldai7yp002nn61dmis69y7x"},{"post_id":"cjldai7y8001in61dslfxmufd","tag_id":"cjldai7yo002jn61dblju2ven","_id":"cjldai7yp002pn61dgqppxmgo"},{"post_id":"cjldai7yc001on61d7wk59hms","tag_id":"cjldai7yp002ln61dtpveebnk","_id":"cjldai7yq002rn61dgrsi0gcv"},{"post_id":"cjldai7yc001on61d7wk59hms","tag_id":"cjldai7yp002on61dpppjh5qc","_id":"cjldai7yq002sn61df3tqx6n9"},{"post_id":"cjldai7yd001rn61d3tetlxt3","tag_id":"cjldai7yq002qn61dyxplhzpz","_id":"cjldai7yr002un61dbl6ksn43"},{"post_id":"cjldai7yk0026n61d2m2zex9m","tag_id":"cjldai7yq002tn61dnc19gksw","_id":"cjldai7yr002wn61dc126by1f"},{"post_id":"cjldai7yl0029n61daw9yb218","tag_id":"cjldai7yr002vn61d8tylc5ad","_id":"cjldai7yr002yn61dcosvgepo"},{"post_id":"cjldai7yl0029n61daw9yb218","tag_id":"cjldai7yr002xn61d5u6vgbj9","_id":"cjldai7yr002zn61dpg2esjsg"}],"Tag":[{"name":"git","_id":"cjldai7xb0006n61dc58qr44q"},{"name":"linux command line, iterms, shortcut","_id":"cjldai7xh000bn61dgktppmxk"},{"name":"Linux, vim","_id":"cjldai7xm000hn61dpywyh5jj"},{"name":"推荐系统","_id":"cjldai7xq000pn61ds1cn5nzn"},{"name":"计算广告","_id":"cjldai7xt000tn61dt2guc284"},{"name":"tensorflow onlinelearning 在线学习","_id":"cjldai7xw000xn61dlgpekr2a"},{"name":"embedding_lookup, tf.gather, embedding_lookup_sparse","_id":"cjldai7xy0012n61dxumimw4d"},{"name":"vscode shortcut mac os","_id":"cjldai7y10016n61d6umcplvs"},{"name":"设计模式 工程模式 代码 宏定义","_id":"cjldai7y4001bn61dz1mphfpg"},{"name":"shell","_id":"cjldai7y8001hn61dz2snxlev"},{"name":"脚本","_id":"cjldai7yb001nn61dgb7u7z28"},{"name":"树遍历","_id":"cjldai7ye001sn61dx92sfoc4"},{"name":"树算法","_id":"cjldai7yh001zn61dsp0qmjsj"},{"name":"算法","_id":"cjldai7yj0025n61d2rx87fbk"},{"name":"python","_id":"cjldai7yn002an61dybj0x80w"},{"name":"happy","_id":"cjldai7yo002gn61d11kyco5c"},{"name":"gg","_id":"cjldai7yo002jn61dblju2ven"},{"name":"pyspark","_id":"cjldai7yp002ln61dtpveebnk"},{"name":"大数据","_id":"cjldai7yp002on61dpppjh5qc"},{"name":"工具箱","_id":"cjldai7yq002qn61dyxplhzpz"},{"name":"spark","_id":"cjldai7yq002tn61dnc19gksw"},{"name":"time","_id":"cjldai7yr002vn61d8tylc5ad"},{"name":"datetime","_id":"cjldai7yr002xn61d5u6vgbj9"}]}}