---
title: meituan ads deep learning
date: 2018-07-09 21:33:00
tags:
---
深度学习在美团搜索广告排序的应用实践

链接：https://gitbook.cn/gitchat/activity/5b39e067353da7153271877e

CTR/CVR 预估由机器学习向深度学习迁移的模型探索；
CTR/CVR 预估基于深度学习模型的线下训练/线上预估的工程优化。

# 交流环节
tensorflow实时化会遇到过哪些问题？怎么处理？
第一个是时效性问题。目前解决办法是小批量来模拟流式计算。
第二个问题是如何处理新数据问题，因为embedding矩阵的size要在定义tensorflow图的时候确定，但是如果有新的数据进来，要扩充embedding矩阵的话应该如何操作。
这个问题我们也咨询的Google的同学，他们也说目前安装tf的设计并没有直接解决的办法。但是可以通过在embedding之前根据经验加一个hashtable。相当于预留一些位置为新数据。

3.拉模型到线上机器的组建详细讲解
拉取模型我们目前是从hdfs上拉取的，直接使用的 httpfs 这个工具。
主要是考虑模型的多版本存储、灰度发布、快速回滚以及模型更新时对内存、网络、磁盘的影响。 异常情况比如下载较慢时的处理。后面我们正在进行的优化是，通过类似bittorrent的方案提高模型的分发效率。主要是实现稳定可靠的将模型分发的线上服务机器上的目标。
模型通过离线训练平台训练好以后，我们是保存在 hdfs 上。 之后通过前面提到的模型分发工具分发到线上机器。 线上部署的话，模型小的话，我们保存在本地。再大一点的模型，我们保存在我们这的模型服务，基于model sharding 的架构； 我们也有基于 ps架构的在线服务系统。


tensorflow建模过程的预处理应注意哪些问题
tensorflow建模过程的预处理，我理解的是对数据及特征的预处理。数据预处理包括清理脏数据，样本标注，样本权重等等。特征预处理包括对离散特征和连续特征等的预处理，包括特征频次过滤、缺失值处理、离散化，连续特征归一化等等。

分布式深度学习系统的研究热点
目前有两个热点，第一个是通用计算框架的底层扩展。比如如何拓展tensorflow的分布式扩展性，因为tf的通讯协议是grpc，而目前开源的grpc在以太网上性能一般，在大规模分布式情况下，性能较差。再比如扩展一些目前主流框架没有算子。或者基于ps-lite这种基础组件自己封装一个框架。
第二个是基于已有的开源框架订制属于自己的上层wrapper。比如keras就是其中之一。还有早起比较活跃的tf.learn


7.研究分布式深度学习系统是如何进行模型压缩与通信优化的？
模型压缩主要是模型量化，以及降精度。量化的思路是用计算来换取空间
通讯的优化目前主要思路是用rdma来替换tcp
目前tensorflow1.5以上版本已经很好的支持rdma了。


# REF

![机器学习之特征选择常用方法](https://vimsky.com/article/362.html)

频次

频次这个比较简单，就是看某个特征在所有训练集中的出现次数。例如，我们有3000个训练集样本，统计发现某特征A只出现在5个样本中（无论是正例还是负例），那么特征A就是个超低频特征，对模型的预测性作用不大，可以直接踢掉。总之，我们可以统计训练集中每个特征的出现频次，将低频特征过滤掉。