<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">


  <meta name="baidu-site-verification" content="B61higctgm" />









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="true" />








  <meta name="baidu-site-verification" content="true" />







  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="spark," />










<meta name="description" content="Spark作业基本运行原理在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="spark作业参数设置及调优">
<meta property="og:url" content="https://gshtime.github.com/2018/08/10/spark-parameters-balance/index.html">
<meta property="og:site_name" content="Swim in ML&#x2F;Ad Tech Ocean - MaricLe Gao Blog">
<meta property="og:description" content="Spark作业基本运行原理在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://p8vrqzrnj.bkt.clouddn.com/20160515225532299">
<meta property="og:updated_time" content="2018-08-21T04:52:23.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="spark作业参数设置及调优">
<meta name="twitter:description" content="Spark作业基本运行原理在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导">
<meta name="twitter:image" content="http://p8vrqzrnj.bkt.clouddn.com/20160515225532299">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://gshtime.github.com/2018/08/10/spark-parameters-balance/"/>





  <title>spark作业参数设置及调优 | Swim in ML/Ad Tech Ocean - MaricLe Gao Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Swim in ML/Ad Tech Ocean - MaricLe Gao Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Record study process, and keep improving and producing.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            日程表
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://gshtime.github.com/2018/08/10/spark-parameters-balance/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gao Shang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Swim in ML/Ad Tech Ocean - MaricLe Gao Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">spark作业参数设置及调优</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-10T00:43:55+08:00">
                2018-08-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Spark作业基本运行原理"><a href="#Spark作业基本运行原理" class="headerlink" title="Spark作业基本运行原理"></a>Spark作业基本运行原理</h1><p>在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导致各种异常。总之，无论是哪种情况，都会导致Spark作业的运行效率低下，甚至根本无法运行。因此我们必须对Spark作业的资源使用原理有一个清晰的认识，并知道在Spark作业运行过程中，有哪些资源参数是可以设置的，以及如何设置合适的参数值。<br><img src="http://p8vrqzrnj.bkt.clouddn.com/20160515225532299" alt=""></p>
<p>详细原理见上图。我们使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。Driver进程本身会根据我们设置的参数，占有一定数量的内存和CPU core。而Driver进程要做的第一件事情，就是向集群管理器（可以是Spark Standalone集群，也可以是其他的资源管理集群，美团•大众点评使用的是YARN作为资源管理集群）申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPU core。</p>
<p>在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批task，然后将这些task分配到各个Executor进程中执行。task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个task处理的数据不同而已。一个stage的所有task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。</p>
<h2 id="stage划分"><a href="#stage划分" class="headerlink" title="stage划分"></a>stage划分</h2><p>Spark是根据shuffle类算子来进行stage的划分。如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。</p>
<blockquote>
<p>在Spark中，什么情况下，会发生shuffle？reduceByKey、groupByKey、sortByKey、countByKey、join、cogroup等操作。</p>
</blockquote>
<h2 id="Executor内存与cache-persist持久化"><a href="#Executor内存与cache-persist持久化" class="headerlink" title="Executor内存与cache/persist持久化"></a>Executor内存与cache/persist持久化</h2><p>当我们在代码中执行了cache/persist等持久化操作时，根据我们选择的持久化级别的不同，每个task计算出来的数据也会保存到Executor进程的内存或者所在节点的磁盘文件中。</p>
<p>因此Executor的内存主要分为三块：第一块是让task执行我们自己编写的代码时使用，默认是占Executor总内存的20%；第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用，默认也是占Executor总内存的20%；第三块是让RDD持久化时使用，默认占Executor总内存的60%。</p>
<h2 id="core数量与task执行速度"><a href="#core数量与task执行速度" class="headerlink" title="core数量与task执行速度"></a>core数量与task执行速度</h2><p>task的执行速度是跟每个Executor进程的CPU core数量有直接关系的。一个CPU core同一时间只能执行一个线程。而每个Executor进程上分配到的多个task，都是以每个task一条线程的方式，多线程并发运行的。如果CPU core数量比较充足，而且分配到的task数量比较合理，那么通常来说，可以比较快速和高效地执行完这些task线程。</p>
<p>以上就是Spark作业的基本运行原理的说明，大家可以结合上图来理解。理解作业基本原理，是我们进行资源参数调优的基本前提。</p>
<h1 id="资源参数调优"><a href="#资源参数调优" class="headerlink" title="资源参数调优"></a>资源参数调优</h1><p>了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，我们同时也给出了一个调优的参考值。</p>
<h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><h3 id="1-num-executors"><a href="#1-num-executors" class="headerlink" title="1.num-executors"></a>1.num-executors</h3><ul>
<li>参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。</li>
<li>参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。</li>
</ul>
<h3 id="2-executor-memory"><a href="#2-executor-memory" class="headerlink" title="2.executor-memory"></a>2.executor-memory</h3><p>参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。</p>
<p>参数调优建议：每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。</p>
<h3 id="3-executor-cores"><a href="#3-executor-cores" class="headerlink" title="3.executor-cores"></a>3.executor-cores</h3><p>参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。</p>
<p>参数调优建议：Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。</p>
<h3 id="4-driver-memory"><a href="#4-driver-memory" class="headerlink" title="4.driver-memory"></a>4.driver-memory</h3><p>参数说明：该参数用于设置Driver进程的内存。</p>
<p>参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。</p>
<h3 id="5-spark-default-parallelism"><a href="#5-spark-default-parallelism" class="headerlink" title="5.spark.default.parallelism"></a>5.spark.default.parallelism</h3><p>参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。</p>
<p>参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。</p>
<h3 id="6-spark-storage-memoryFraction"><a href="#6-spark-storage-memoryFraction" class="headerlink" title="6.spark.storage.memoryFraction"></a>6.spark.storage.memoryFraction</h3><p>参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。</p>
<p>参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>
<h3 id="7-spark-shuffle-memoryFraction"><a href="#7-spark-shuffle-memoryFraction" class="headerlink" title="7.spark.shuffle.memoryFraction"></a>7.spark.shuffle.memoryFraction</h3><p>参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</p>
<p>参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>
<h3 id="8-total-executor-cores"><a href="#8-total-executor-cores" class="headerlink" title="8.total-executor-cores"></a>8.total-executor-cores</h3><p>参数说明：Total cores for all executors.</p>
<h1 id="spark配置示例"><a href="#spark配置示例" class="headerlink" title="spark配置示例"></a>spark配置示例</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">worker_num=500</span><br><span class="line"></span><br><span class="line">/xxxx/spark-2.2/bin/spark-submit \</span><br><span class="line">  --name push_online_single@<span class="variable">$user_name</span> \</span><br><span class="line">  --queue root.dmlc.hadoop-mining.mining \</span><br><span class="line">  --master yarn-cluster \</span><br><span class="line">  --num-executors <span class="variable">$worker_num</span> \</span><br><span class="line">  --class com.xxx.Group \</span><br><span class="line">  --executor-cores 1 \</span><br><span class="line">  --executor-memory 2g \</span><br><span class="line">  --driver-memory 6g \</span><br><span class="line">  --conf spark.rdd.compress=<span class="literal">true</span> \</span><br><span class="line">  --conf spark.driver.maxResultSize=2g \</span><br><span class="line">  --conf spark.akka.frameSize=500 \</span><br><span class="line">  --conf spark.default.parallelism=2000 \</span><br><span class="line">  --conf spark.storage.memoryFraction=0.6 \</span><br><span class="line">  --conf spark.shuffle.consolidateFiles=<span class="literal">true</span> \</span><br><span class="line">  --conf spark.shuffle.manager=sort \</span><br><span class="line">  --conf spark.yarn.executor.memoryOverhead=2048 \</span><br><span class="line">  --conf spark.yarn.driver.memoryOverhead=4096 \</span><br><span class="line">  --conf spark.hadoop.validateOutputSpecs=<span class="literal">false</span> \</span><br><span class="line">  --conf spark.speculation=<span class="literal">false</span> \</span><br><span class="line">  --conf spark.speculation.multiplier=3 \</span><br><span class="line">  --conf spark.sql.shuffle.partitions=2000 \</span><br><span class="line">  --conf spark.memory.fraction=0.8 \</span><br><span class="line">  --conf spark.memory.storageFraction=0.2 \</span><br><span class="line">  --conf spark.network.timeout=360s \</span><br><span class="line">  <span class="variable">$MLX_MODEL_PUSH_DIR</span>/target/model-push-1.0.jar \</span><br><span class="line">  param_path:<span class="variable">$param_path_root</span>/<span class="variable">$dump_mid_path</span>/<span class="variable">$to_model_name</span>/WEIGHTS/PROTO/*.param.* \</span><br><span class="line">  meta_path:<span class="variable">$param_path_root</span>/<span class="variable">$to_model_name</span>/WEIGHTS/PROTO/001.meta \</span><br><span class="line">  model_name:<span class="variable">$&#123;model_name_tmp&#125;</span> \</span><br><span class="line">  group_num:4 \</span><br><span class="line">  batch_size:512 \</span><br><span class="line">  is_repartition:<span class="literal">true</span> \</span><br><span class="line">  partition_num:500 \</span><br><span class="line">  engine_room:<span class="built_in">test</span> \</span><br><span class="line">  group_id:-1 \</span><br><span class="line">  copy_id:-1 \</span><br><span class="line">  copy_num:-1 \</span><br><span class="line">  is_move_model:<span class="variable">$is_move_model</span> \</span><br><span class="line">  is_create_model:<span class="variable">$is_create_model</span> \</span><br><span class="line">  to_model_name:<span class="variable">$to_model_name</span> \</span><br><span class="line">  push_interval:10 \</span><br><span class="line">  is_push_to_test:<span class="variable">$is_push_to_test</span></span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().set(<span class="string">"spark.hadoop.validateOutputSpecs"</span>, <span class="string">"false"</span>).setAppName(<span class="string">"mlx_push_"</span> + modelName)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure>
<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p>rdd的全称为Resilient Distributed Datasets（弹性分布式数据集）</p>
<p>rdd的操作有两种transfrom和action。</p>
<p>transfrom并不引发真正的rdd计算，action才会引发真正的rdd计算。</p>
<h2 id="spark中的持久化"><a href="#spark中的持久化" class="headerlink" title="spark中的持久化"></a>spark中的持久化</h2><p>Spark最重要的一个功能，就是在不同操作间，持久化（或缓存）一个数据集在内存中。当你持久化一个RDD，每一个结点都将把它的计算分块结果保存在内存中，并在对此数据集（或者衍生出的数据集）进行的其它动作中重用。这将使得后续的动作(Actions)变得更加迅速（通常快10倍）。缓存是用Spark构建迭代算法的关键。</p>
<p>你可以用persist()或cache()方法来标记一个要被持久化的RDD，然后一旦首次被一个动作（Action）触发计算，它将会被保留在计算结点的内存中并重用。Cache有容错机制，如果RDD的任一分区丢失了，通过使用原先创建它的转换操作，它将会被自动重算（不需要全部重算，只计算丢失的部分）。当需要删除被持久化的RDD，可以用unpersistRDD()来完成该工作。</p>
<p>此外，每一个RDD都可以用不同的保存级别进行保存，从而允许你持久化数据集在硬盘，或者在内存作为序列化的Java对象（节省空间），甚至于跨结点复制。这些等级选择，是通过将一个org.apache.spark.storage.StorageLevel对象传递给persist()方法进行确定。cache()方法是使用默认存储级别的快捷方法，也就是StorageLevel.MEMORY_ONLY(将反序列化的对象存入内存）。</p>
<p>rdd的持久化是便于rdd计算的重复使用。</p>
<p>官方的api说明如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">persist(storageLevel=<span class="type">StorageLevel</span>(<span class="type">False</span>, <span class="type">True</span>, <span class="type">False</span>, <span class="type">False</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="type">Set</span> <span class="keyword">this</span> <span class="type">RDD</span>’s storage level to persist its values across operations after the first time it is computed. <span class="type">This</span> can only be used to assign a <span class="keyword">new</span> storage level <span class="keyword">if</span> the <span class="type">RDD</span> does not have a storage level set yet. <span class="type">If</span> no storage level is specified defaults to (<span class="type">MEMORY_ONLY_SER</span>)</span><br></pre></td></tr></table></figure>
<p>(1) 在rdd参与第一次计算后，设置rdd的存储级别可以保持rdd计算后的值在内存中。例如：rdd1要经过transform1得到rdd2,然后在一个循环L内rdd2进行transform2和action1。由于trasform操作是不会真正执行的，所以rdd1执行transform1需要在循环L第一次循环的时候触发。如果设置了rdd1的存储级别，那么循环L的第二次循环起，只需要从rdd2开始计算就好了，而不用向第一次循环时从rdd1开始计算。</p>
<p>(2) 另外，只有未曾设置存储级别的rdd才能设置存储级别，设置了存储级别的rdd不能修改其存储级别。</p>
<h3 id="持久化方式"><a href="#持久化方式" class="headerlink" title="持久化方式"></a>持久化方式</h3><p>rdd的持久化操作有cache()和presist()函数这两种方式。</p>
<h1 id="转载-amp-参考"><a href="#转载-amp-参考" class="headerlink" title="转载&amp;参考"></a>转载&amp;参考</h1><p><a href="https://blog.csdn.net/chenjieit619/article/details/53421080" target="_blank" rel="noopener">spark submit参数调优</a></p>
<p><a href="http://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="noopener">官方参数配置</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/spark/" rel="tag"># spark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/08/09/happy-python/" rel="next" title="快乐的python">
                <i class="fa fa-chevron-left"></i> 快乐的python
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/08/10/spark-sql/" rel="prev" title="spark SQL 笔记">
                spark SQL 笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zOTE2Ni8xNTY5Mw=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Gao Shang</p>
              <p class="site-description motion-element" itemprop="description">Hi, I'm fan of Machine Learing and Online Advertisement technologies, I will record lots of simple and important information for us here.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">37</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark作业基本运行原理"><span class="nav-number">1.</span> <span class="nav-text">Spark作业基本运行原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#stage划分"><span class="nav-number">1.1.</span> <span class="nav-text">stage划分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Executor内存与cache-persist持久化"><span class="nav-number">1.2.</span> <span class="nav-text">Executor内存与cache/persist持久化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#core数量与task执行速度"><span class="nav-number">1.3.</span> <span class="nav-text">core数量与task执行速度</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#资源参数调优"><span class="nav-number">2.</span> <span class="nav-text">资源参数调优</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#内容"><span class="nav-number">2.1.</span> <span class="nav-text">内容</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-num-executors"><span class="nav-number">2.1.1.</span> <span class="nav-text">1.num-executors</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-executor-memory"><span class="nav-number">2.1.2.</span> <span class="nav-text">2.executor-memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-executor-cores"><span class="nav-number">2.1.3.</span> <span class="nav-text">3.executor-cores</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-driver-memory"><span class="nav-number">2.1.4.</span> <span class="nav-text">4.driver-memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-spark-default-parallelism"><span class="nav-number">2.1.5.</span> <span class="nav-text">5.spark.default.parallelism</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-spark-storage-memoryFraction"><span class="nav-number">2.1.6.</span> <span class="nav-text">6.spark.storage.memoryFraction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-spark-shuffle-memoryFraction"><span class="nav-number">2.1.7.</span> <span class="nav-text">7.spark.shuffle.memoryFraction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-total-executor-cores"><span class="nav-number">2.1.8.</span> <span class="nav-text">8.total-executor-cores</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#spark配置示例"><span class="nav-number">3.</span> <span class="nav-text">spark配置示例</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#补充"><span class="nav-number">4.</span> <span class="nav-text">补充</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#spark中的持久化"><span class="nav-number">4.1.</span> <span class="nav-text">spark中的持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#持久化方式"><span class="nav-number">4.1.1.</span> <span class="nav-text">持久化方式</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#转载-amp-参考"><span class="nav-number">5.</span> <span class="nav-text">转载&amp;参考</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Gao Shang</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  












  





  

  

  

  
  

  
  


  

  

</body>
</html>
